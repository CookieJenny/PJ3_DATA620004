2023-07-01 18:08:53 - network: resnet18cifar
2023-07-01 18:08:53 - num_classes: 100
2023-07-01 18:08:53 - input_image_size: 32
2023-07-01 18:08:53 - trained_model_path: 
2023-07-01 18:08:53 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 18:08:53 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 18:08:53 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f0aea057e50>
2023-07-01 18:08:53 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f0aea0570d0>
2023-07-01 18:08:53 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f0aea0572e0>
2023-07-01 18:08:53 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f0aea057220>
2023-07-01 18:08:53 - seed: 0
2023-07-01 18:08:53 - batch_size: 128
2023-07-01 18:08:53 - num_workers: 16
2023-07-01 18:08:53 - accumulation_steps: 1
2023-07-01 18:08:53 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-01 18:08:53 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-07-01 18:08:53 - epochs: 200
2023-07-01 18:08:53 - print_interval: 50
2023-07-01 18:08:53 - sync_bn: False
2023-07-01 18:08:53 - apex: True
2023-07-01 18:08:53 - use_ema_model: False
2023-07-01 18:08:53 - ema_model_decay: 0.9999
2023-07-01 18:08:53 - AUG: none
2023-07-01 18:08:53 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-01 18:08:53 - gpus_num: 1
2023-07-01 18:08:53 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f0aea04cbb0>
2023-07-01 18:08:53 - --------------------parameters--------------------
2023-07-01 18:08:53 - name: conv1.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: conv1.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: conv1.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer1.0.conv1.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer1.0.conv1.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer1.0.conv1.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer1.0.conv2.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer1.0.conv2.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer1.0.conv2.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer1.1.conv1.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer1.1.conv1.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer1.1.conv1.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer1.1.conv2.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer1.1.conv2.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer1.1.conv2.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer2.0.conv1.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer2.0.conv1.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer2.0.conv1.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer2.0.conv2.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer2.0.conv2.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer2.0.conv2.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer2.1.conv1.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer2.1.conv1.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer2.1.conv1.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer2.1.conv2.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer2.1.conv2.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer2.1.conv2.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer3.0.conv1.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer3.0.conv1.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer3.0.conv1.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer3.0.conv2.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer3.0.conv2.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer3.0.conv2.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer3.1.conv1.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer3.1.conv1.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer3.1.conv1.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer3.1.conv2.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer3.1.conv2.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer3.1.conv2.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer4.0.conv1.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer4.0.conv1.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer4.0.conv1.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer4.0.conv2.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer4.0.conv2.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer4.0.conv2.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer4.1.conv1.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer4.1.conv1.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer4.1.conv1.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: layer4.1.conv2.layer.0.weight, grad: True
2023-07-01 18:08:53 - name: layer4.1.conv2.layer.1.weight, grad: True
2023-07-01 18:08:53 - name: layer4.1.conv2.layer.1.bias, grad: True
2023-07-01 18:08:53 - name: fc.weight, grad: True
2023-07-01 18:08:53 - name: fc.bias, grad: True
2023-07-01 18:08:53 - --------------------buffers--------------------
2023-07-01 18:08:53 - name: conv1.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: conv1.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer1.0.conv1.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer1.0.conv2.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer1.1.conv1.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer1.1.conv2.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer2.0.conv1.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer2.0.conv2.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer2.1.conv1.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer2.1.conv2.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer3.0.conv1.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer3.0.conv2.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer3.1.conv1.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer3.1.conv2.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer4.0.conv1.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer4.0.conv2.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer4.1.conv1.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2023-07-01 18:08:53 - name: layer4.1.conv2.layer.1.running_var, grad: False
2023-07-01 18:08:53 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:08:53 - -----------no weight decay layers--------------
2023-07-01 18:08:53 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:08:53 - -------------weight decay layers---------------
2023-07-01 18:08:53 - name: conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:53 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:08:55 - resuming model from ./checkpoints/none/latest.pth. resume_epoch: 200, used_time: 0.680 hours, best_acc1: 76.870%, test_loss: 1.0287, lr: 0.000800
2023-07-01 18:08:55 - train done. model: resnet18cifar, train time: 0.680 hours, best_acc1: 76.870%
2023-07-01 18:14:32 - network: resnet18cifar
2023-07-01 18:14:32 - num_classes: 100
2023-07-01 18:14:32 - input_image_size: 32
2023-07-01 18:14:32 - trained_model_path: 
2023-07-01 18:14:32 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 18:14:32 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 18:14:32 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fa41637de50>
2023-07-01 18:14:32 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fa41637d250>
2023-07-01 18:14:32 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fa41637d100>
2023-07-01 18:14:32 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fa41637d220>
2023-07-01 18:14:32 - seed: 0
2023-07-01 18:14:32 - batch_size: 128
2023-07-01 18:14:32 - num_workers: 16
2023-07-01 18:14:32 - accumulation_steps: 1
2023-07-01 18:14:32 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-01 18:14:32 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-07-01 18:14:32 - epochs: 200
2023-07-01 18:14:32 - print_interval: 50
2023-07-01 18:14:32 - sync_bn: False
2023-07-01 18:14:32 - apex: True
2023-07-01 18:14:32 - use_ema_model: False
2023-07-01 18:14:32 - ema_model_decay: 0.9999
2023-07-01 18:14:32 - AUG: none
2023-07-01 18:14:32 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-01 18:14:32 - gpus_num: 1
2023-07-01 18:14:32 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7fa4163719b0>
2023-07-01 18:14:32 - --------------------parameters--------------------
2023-07-01 18:14:32 - name: conv1.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: conv1.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: conv1.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer1.0.conv1.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer1.0.conv1.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer1.0.conv1.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer1.0.conv2.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer1.0.conv2.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer1.0.conv2.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer1.1.conv1.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer1.1.conv1.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer1.1.conv1.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer1.1.conv2.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer1.1.conv2.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer1.1.conv2.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer2.0.conv1.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer2.0.conv1.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer2.0.conv1.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer2.0.conv2.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer2.0.conv2.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer2.0.conv2.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer2.1.conv1.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer2.1.conv1.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer2.1.conv1.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer2.1.conv2.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer2.1.conv2.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer2.1.conv2.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer3.0.conv1.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer3.0.conv1.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer3.0.conv1.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer3.0.conv2.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer3.0.conv2.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer3.0.conv2.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer3.1.conv1.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer3.1.conv1.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer3.1.conv1.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer3.1.conv2.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer3.1.conv2.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer3.1.conv2.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer4.0.conv1.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer4.0.conv1.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer4.0.conv1.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer4.0.conv2.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer4.0.conv2.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer4.0.conv2.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer4.1.conv1.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer4.1.conv1.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer4.1.conv1.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: layer4.1.conv2.layer.0.weight, grad: True
2023-07-01 18:14:32 - name: layer4.1.conv2.layer.1.weight, grad: True
2023-07-01 18:14:32 - name: layer4.1.conv2.layer.1.bias, grad: True
2023-07-01 18:14:32 - name: fc.weight, grad: True
2023-07-01 18:14:32 - name: fc.bias, grad: True
2023-07-01 18:14:32 - --------------------buffers--------------------
2023-07-01 18:14:32 - name: conv1.layer.1.running_mean, grad: False
2023-07-01 18:14:32 - name: conv1.layer.1.running_var, grad: False
2023-07-01 18:14:32 - name: conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:32 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2023-07-01 18:14:32 - name: layer1.0.conv1.layer.1.running_var, grad: False
2023-07-01 18:14:32 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:32 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2023-07-01 18:14:32 - name: layer1.0.conv2.layer.1.running_var, grad: False
2023-07-01 18:14:32 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:32 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2023-07-01 18:14:32 - name: layer1.1.conv1.layer.1.running_var, grad: False
2023-07-01 18:14:32 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:32 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2023-07-01 18:14:32 - name: layer1.1.conv2.layer.1.running_var, grad: False
2023-07-01 18:14:32 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:32 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2023-07-01 18:14:32 - name: layer2.0.conv1.layer.1.running_var, grad: False
2023-07-01 18:14:32 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:32 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2023-07-01 18:14:32 - name: layer2.0.conv2.layer.1.running_var, grad: False
2023-07-01 18:14:32 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:32 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2023-07-01 18:14:32 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2023-07-01 18:14:32 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:32 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2023-07-01 18:14:32 - name: layer2.1.conv1.layer.1.running_var, grad: False
2023-07-01 18:14:32 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:32 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2023-07-01 18:14:32 - name: layer2.1.conv2.layer.1.running_var, grad: False
2023-07-01 18:14:32 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:32 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2023-07-01 18:14:32 - name: layer3.0.conv1.layer.1.running_var, grad: False
2023-07-01 18:14:32 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:32 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2023-07-01 18:14:32 - name: layer3.0.conv2.layer.1.running_var, grad: False
2023-07-01 18:14:32 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:32 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2023-07-01 18:14:32 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2023-07-01 18:14:33 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:33 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2023-07-01 18:14:33 - name: layer3.1.conv1.layer.1.running_var, grad: False
2023-07-01 18:14:33 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:33 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2023-07-01 18:14:33 - name: layer3.1.conv2.layer.1.running_var, grad: False
2023-07-01 18:14:33 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:33 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2023-07-01 18:14:33 - name: layer4.0.conv1.layer.1.running_var, grad: False
2023-07-01 18:14:33 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:33 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2023-07-01 18:14:33 - name: layer4.0.conv2.layer.1.running_var, grad: False
2023-07-01 18:14:33 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:33 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2023-07-01 18:14:33 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2023-07-01 18:14:33 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:33 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2023-07-01 18:14:33 - name: layer4.1.conv1.layer.1.running_var, grad: False
2023-07-01 18:14:33 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:33 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2023-07-01 18:14:33 - name: layer4.1.conv2.layer.1.running_var, grad: False
2023-07-01 18:14:33 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2023-07-01 18:14:33 - -----------no weight decay layers--------------
2023-07-01 18:14:33 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:14:33 - -------------weight decay layers---------------
2023-07-01 18:14:33 - name: conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:14:33 - epoch 001 lr: 0.100000
2023-07-01 18:14:39 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.1464
2023-07-01 18:14:40 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.1730
2023-07-01 18:14:41 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 3.9723
2023-07-01 18:14:42 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 3.7901
2023-07-01 18:14:44 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 3.8650
2023-07-01 18:14:45 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 3.6104
2023-07-01 18:14:46 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 3.6936
2023-07-01 18:14:47 - train: epoch 001, train_loss: 3.9181
2023-07-01 18:14:48 - eval: epoch: 001, acc1: 15.700%, acc5: 39.990%, test_loss: 3.5818, per_image_load_time: 0.058ms, per_image_inference_time: 0.040ms
2023-07-01 18:14:49 - until epoch: 001, best_acc1: 15.700%
2023-07-01 18:14:49 - epoch 002 lr: 0.100000
2023-07-01 18:14:51 - train: epoch 0002, iter [00050, 00390], lr: 0.100000, loss: 3.4128
2023-07-01 18:14:52 - train: epoch 0002, iter [00100, 00390], lr: 0.100000, loss: 3.2355
2023-07-01 18:14:53 - train: epoch 0002, iter [00150, 00390], lr: 0.100000, loss: 3.2693
2023-07-01 18:14:54 - train: epoch 0002, iter [00200, 00390], lr: 0.100000, loss: 3.5163
2023-07-01 18:14:56 - train: epoch 0002, iter [00250, 00390], lr: 0.100000, loss: 3.0151
2023-07-01 18:14:57 - train: epoch 0002, iter [00300, 00390], lr: 0.100000, loss: 3.3632
2023-07-01 18:14:58 - train: epoch 0002, iter [00350, 00390], lr: 0.100000, loss: 2.8513
2023-07-01 18:14:59 - train: epoch 002, train_loss: 3.2398
2023-07-01 18:15:00 - eval: epoch: 002, acc1: 25.190%, acc5: 55.150%, test_loss: 3.0112, per_image_load_time: 0.059ms, per_image_inference_time: 0.043ms
2023-07-01 18:15:02 - until epoch: 002, best_acc1: 25.190%
2023-07-01 18:15:02 - epoch 003 lr: 0.100000
2023-07-01 18:15:04 - train: epoch 0003, iter [00050, 00390], lr: 0.100000, loss: 2.9890
2023-07-01 18:15:05 - train: epoch 0003, iter [00100, 00390], lr: 0.100000, loss: 2.6186
2023-07-01 18:15:06 - train: epoch 0003, iter [00150, 00390], lr: 0.100000, loss: 2.6711
2023-07-01 18:15:07 - train: epoch 0003, iter [00200, 00390], lr: 0.100000, loss: 2.5853
2023-07-01 18:15:08 - train: epoch 0003, iter [00250, 00390], lr: 0.100000, loss: 2.6778
2023-07-01 18:15:10 - train: epoch 0003, iter [00300, 00390], lr: 0.100000, loss: 2.7918
2023-07-01 18:15:11 - train: epoch 0003, iter [00350, 00390], lr: 0.100000, loss: 2.5508
2023-07-01 18:15:12 - train: epoch 003, train_loss: 2.6898
2023-07-01 18:15:13 - eval: epoch: 003, acc1: 33.940%, acc5: 67.030%, test_loss: 2.5458, per_image_load_time: 0.058ms, per_image_inference_time: 0.041ms
2023-07-01 18:15:16 - until epoch: 003, best_acc1: 33.940%
2023-07-01 18:15:16 - epoch 004 lr: 0.100000
2023-07-01 18:15:18 - train: epoch 0004, iter [00050, 00390], lr: 0.100000, loss: 2.4493
2023-07-01 18:15:19 - train: epoch 0004, iter [00100, 00390], lr: 0.100000, loss: 2.6313
2023-07-01 18:15:20 - train: epoch 0004, iter [00150, 00390], lr: 0.100000, loss: 2.4082
2023-07-01 18:15:21 - train: epoch 0004, iter [00200, 00390], lr: 0.100000, loss: 2.6360
2023-07-01 18:15:22 - train: epoch 0004, iter [00250, 00390], lr: 0.100000, loss: 2.1931
2023-07-01 18:15:24 - train: epoch 0004, iter [00300, 00390], lr: 0.100000, loss: 2.2698
2023-07-01 18:15:25 - train: epoch 0004, iter [00350, 00390], lr: 0.100000, loss: 2.0009
2023-07-01 18:15:26 - train: epoch 004, train_loss: 2.2899
2023-07-01 18:15:27 - eval: epoch: 004, acc1: 41.450%, acc5: 74.000%, test_loss: 2.1782, per_image_load_time: 0.061ms, per_image_inference_time: 0.041ms
2023-07-01 18:15:29 - until epoch: 004, best_acc1: 41.450%
2023-07-01 18:15:29 - epoch 005 lr: 0.100000
2023-07-01 18:15:31 - train: epoch 0005, iter [00050, 00390], lr: 0.100000, loss: 2.0164
2023-07-01 18:15:32 - train: epoch 0005, iter [00100, 00390], lr: 0.100000, loss: 2.1159
2023-07-01 18:15:34 - train: epoch 0005, iter [00150, 00390], lr: 0.100000, loss: 1.9143
2023-07-01 18:15:35 - train: epoch 0005, iter [00200, 00390], lr: 0.100000, loss: 2.1859
2023-07-01 18:15:36 - train: epoch 0005, iter [00250, 00390], lr: 0.100000, loss: 1.9277
2023-07-01 18:15:37 - train: epoch 0005, iter [00300, 00390], lr: 0.100000, loss: 1.8348
2023-07-01 18:15:38 - train: epoch 0005, iter [00350, 00390], lr: 0.100000, loss: 1.5800
2023-07-01 18:15:39 - train: epoch 005, train_loss: 2.0222
2023-07-01 18:15:40 - eval: epoch: 005, acc1: 42.430%, acc5: 74.010%, test_loss: 2.2488, per_image_load_time: 0.057ms, per_image_inference_time: 0.041ms
2023-07-01 18:15:43 - until epoch: 005, best_acc1: 42.430%
2023-07-01 18:15:43 - epoch 006 lr: 0.100000
2023-07-01 18:15:45 - train: epoch 0006, iter [00050, 00390], lr: 0.100000, loss: 1.8547
2023-07-01 18:15:46 - train: epoch 0006, iter [00100, 00390], lr: 0.100000, loss: 1.7321
2023-07-01 18:15:47 - train: epoch 0006, iter [00150, 00390], lr: 0.100000, loss: 1.8835
2023-07-01 18:15:49 - train: epoch 0006, iter [00200, 00390], lr: 0.100000, loss: 1.7777
2023-07-01 18:15:50 - train: epoch 0006, iter [00250, 00390], lr: 0.100000, loss: 1.5994
2023-07-01 18:15:51 - train: epoch 0006, iter [00300, 00390], lr: 0.100000, loss: 1.6303
2023-07-01 18:15:52 - train: epoch 0006, iter [00350, 00390], lr: 0.100000, loss: 1.6783
2023-07-01 18:15:53 - train: epoch 006, train_loss: 1.8199
2023-07-01 18:15:54 - eval: epoch: 006, acc1: 47.380%, acc5: 79.420%, test_loss: 1.9287, per_image_load_time: 0.058ms, per_image_inference_time: 0.041ms
2023-07-01 18:15:56 - until epoch: 006, best_acc1: 47.380%
2023-07-01 18:15:56 - epoch 007 lr: 0.100000
2023-07-01 18:15:58 - train: epoch 0007, iter [00050, 00390], lr: 0.100000, loss: 1.8123
2023-07-01 18:15:59 - train: epoch 0007, iter [00100, 00390], lr: 0.100000, loss: 1.6346
2023-07-01 18:16:00 - train: epoch 0007, iter [00150, 00390], lr: 0.100000, loss: 1.7017
2023-07-01 18:16:01 - train: epoch 0007, iter [00200, 00390], lr: 0.100000, loss: 1.5793
2023-07-01 18:16:02 - train: epoch 0007, iter [00250, 00390], lr: 0.100000, loss: 1.5781
2023-07-01 18:16:04 - train: epoch 0007, iter [00300, 00390], lr: 0.100000, loss: 1.2953
2023-07-01 18:16:05 - train: epoch 0007, iter [00350, 00390], lr: 0.100000, loss: 1.6885
2023-07-01 18:16:06 - train: epoch 007, train_loss: 1.6883
2023-07-01 18:16:07 - eval: epoch: 007, acc1: 49.670%, acc5: 80.970%, test_loss: 1.8485, per_image_load_time: 0.059ms, per_image_inference_time: 0.042ms
2023-07-01 18:16:09 - until epoch: 007, best_acc1: 49.670%
2023-07-01 18:16:09 - epoch 008 lr: 0.100000
2023-07-01 18:16:11 - train: epoch 0008, iter [00050, 00390], lr: 0.100000, loss: 1.6286
2023-07-01 18:16:12 - train: epoch 0008, iter [00100, 00390], lr: 0.100000, loss: 1.3610
2023-07-01 18:16:13 - train: epoch 0008, iter [00150, 00390], lr: 0.100000, loss: 1.5674
2023-07-01 18:16:14 - train: epoch 0008, iter [00200, 00390], lr: 0.100000, loss: 1.2851
2023-07-01 18:16:15 - train: epoch 0008, iter [00250, 00390], lr: 0.100000, loss: 1.2165
2023-07-01 18:16:17 - train: epoch 0008, iter [00300, 00390], lr: 0.100000, loss: 1.6445
2023-07-01 18:16:18 - train: epoch 0008, iter [00350, 00390], lr: 0.100000, loss: 1.5568
2023-07-01 18:16:19 - train: epoch 008, train_loss: 1.5675
2023-07-01 18:16:20 - eval: epoch: 008, acc1: 51.780%, acc5: 80.890%, test_loss: 1.7993, per_image_load_time: 0.058ms, per_image_inference_time: 0.041ms
2023-07-01 18:16:22 - until epoch: 008, best_acc1: 51.780%
2023-07-01 18:16:22 - epoch 009 lr: 0.100000
2023-07-01 18:16:24 - train: epoch 0009, iter [00050, 00390], lr: 0.100000, loss: 1.3565
2023-07-01 18:16:25 - train: epoch 0009, iter [00100, 00390], lr: 0.100000, loss: 1.6747
2023-07-01 18:16:26 - train: epoch 0009, iter [00150, 00390], lr: 0.100000, loss: 1.4970
2023-07-01 18:26:45 - network: vit_tiny_patch16
2023-07-01 18:26:45 - num_classes: 100
2023-07-01 18:26:45 - input_image_size: 32
2023-07-01 18:26:45 - trained_model_path: 
2023-07-01 18:26:45 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 18:26:45 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 18:26:45 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f5990545520>
2023-07-01 18:26:45 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f5990545490>
2023-07-01 18:26:45 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f5990545580>
2023-07-01 18:26:45 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f59905455b0>
2023-07-01 18:26:45 - seed: 0
2023-07-01 18:26:45 - batch_size: 128
2023-07-01 18:26:45 - num_workers: 16
2023-07-01 18:26:45 - accumulation_steps: 1
2023-07-01 18:26:45 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-01 18:26:45 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-07-01 18:26:45 - epochs: 200
2023-07-01 18:26:45 - print_interval: 50
2023-07-01 18:26:45 - sync_bn: False
2023-07-01 18:26:45 - apex: True
2023-07-01 18:26:45 - use_ema_model: False
2023-07-01 18:26:45 - ema_model_decay: 0.9999
2023-07-01 18:26:45 - AUG: none
2023-07-01 18:26:45 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-01 18:26:45 - gpus_num: 1
2023-07-01 18:26:45 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f599053f0b0>
2023-07-01 18:26:45 - --------------------parameters--------------------
2023-07-01 18:26:45 - name: cls_token, grad: True
2023-07-01 18:26:45 - name: position_encoding, grad: True
2023-07-01 18:26:45 - name: patch_embedding.conv.weight, grad: True
2023-07-01 18:26:45 - name: patch_embedding.conv.bias, grad: True
2023-07-01 18:26:45 - name: blocks.0.norm1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.0.norm1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.0.attention.qkv_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.0.attention.qkv_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.0.attention.out_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.0.attention.out_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.0.norm2.weight, grad: True
2023-07-01 18:26:45 - name: blocks.0.norm2.bias, grad: True
2023-07-01 18:26:45 - name: blocks.0.feed_forward.fc1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.0.feed_forward.fc1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.0.feed_forward.fc2.weight, grad: True
2023-07-01 18:26:45 - name: blocks.0.feed_forward.fc2.bias, grad: True
2023-07-01 18:26:45 - name: blocks.1.norm1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.1.norm1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.1.attention.qkv_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.1.attention.qkv_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.1.attention.out_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.1.attention.out_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.1.norm2.weight, grad: True
2023-07-01 18:26:45 - name: blocks.1.norm2.bias, grad: True
2023-07-01 18:26:45 - name: blocks.1.feed_forward.fc1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.1.feed_forward.fc1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.1.feed_forward.fc2.weight, grad: True
2023-07-01 18:26:45 - name: blocks.1.feed_forward.fc2.bias, grad: True
2023-07-01 18:26:45 - name: blocks.2.norm1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.2.norm1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.2.attention.qkv_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.2.attention.qkv_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.2.attention.out_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.2.attention.out_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.2.norm2.weight, grad: True
2023-07-01 18:26:45 - name: blocks.2.norm2.bias, grad: True
2023-07-01 18:26:45 - name: blocks.2.feed_forward.fc1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.2.feed_forward.fc1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.2.feed_forward.fc2.weight, grad: True
2023-07-01 18:26:45 - name: blocks.2.feed_forward.fc2.bias, grad: True
2023-07-01 18:26:45 - name: blocks.3.norm1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.3.norm1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.3.attention.qkv_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.3.attention.qkv_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.3.attention.out_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.3.attention.out_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.3.norm2.weight, grad: True
2023-07-01 18:26:45 - name: blocks.3.norm2.bias, grad: True
2023-07-01 18:26:45 - name: blocks.3.feed_forward.fc1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.3.feed_forward.fc1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.3.feed_forward.fc2.weight, grad: True
2023-07-01 18:26:45 - name: blocks.3.feed_forward.fc2.bias, grad: True
2023-07-01 18:26:45 - name: blocks.4.norm1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.4.norm1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.4.attention.qkv_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.4.attention.qkv_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.4.attention.out_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.4.attention.out_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.4.norm2.weight, grad: True
2023-07-01 18:26:45 - name: blocks.4.norm2.bias, grad: True
2023-07-01 18:26:45 - name: blocks.4.feed_forward.fc1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.4.feed_forward.fc1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.4.feed_forward.fc2.weight, grad: True
2023-07-01 18:26:45 - name: blocks.4.feed_forward.fc2.bias, grad: True
2023-07-01 18:26:45 - name: blocks.5.norm1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.5.norm1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.5.attention.qkv_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.5.attention.qkv_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.5.attention.out_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.5.attention.out_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.5.norm2.weight, grad: True
2023-07-01 18:26:45 - name: blocks.5.norm2.bias, grad: True
2023-07-01 18:26:45 - name: blocks.5.feed_forward.fc1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.5.feed_forward.fc1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.5.feed_forward.fc2.weight, grad: True
2023-07-01 18:26:45 - name: blocks.5.feed_forward.fc2.bias, grad: True
2023-07-01 18:26:45 - name: blocks.6.norm1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.6.norm1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.6.attention.qkv_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.6.attention.qkv_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.6.attention.out_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.6.attention.out_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.6.norm2.weight, grad: True
2023-07-01 18:26:45 - name: blocks.6.norm2.bias, grad: True
2023-07-01 18:26:45 - name: blocks.6.feed_forward.fc1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.6.feed_forward.fc1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.6.feed_forward.fc2.weight, grad: True
2023-07-01 18:26:45 - name: blocks.6.feed_forward.fc2.bias, grad: True
2023-07-01 18:26:45 - name: blocks.7.norm1.weight, grad: True
2023-07-01 18:26:45 - name: blocks.7.norm1.bias, grad: True
2023-07-01 18:26:45 - name: blocks.7.attention.qkv_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.7.attention.qkv_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.7.attention.out_linear.weight, grad: True
2023-07-01 18:26:45 - name: blocks.7.attention.out_linear.bias, grad: True
2023-07-01 18:26:45 - name: blocks.7.norm2.weight, grad: True
2023-07-01 18:26:46 - name: blocks.7.norm2.bias, grad: True
2023-07-01 18:26:46 - name: blocks.7.feed_forward.fc1.weight, grad: True
2023-07-01 18:26:46 - name: blocks.7.feed_forward.fc1.bias, grad: True
2023-07-01 18:26:46 - name: blocks.7.feed_forward.fc2.weight, grad: True
2023-07-01 18:26:46 - name: blocks.7.feed_forward.fc2.bias, grad: True
2023-07-01 18:26:46 - name: blocks.8.norm1.weight, grad: True
2023-07-01 18:26:46 - name: blocks.8.norm1.bias, grad: True
2023-07-01 18:26:46 - name: blocks.8.attention.qkv_linear.weight, grad: True
2023-07-01 18:26:46 - name: blocks.8.attention.qkv_linear.bias, grad: True
2023-07-01 18:26:46 - name: blocks.8.attention.out_linear.weight, grad: True
2023-07-01 18:26:46 - name: blocks.8.attention.out_linear.bias, grad: True
2023-07-01 18:26:46 - name: blocks.8.norm2.weight, grad: True
2023-07-01 18:26:46 - name: blocks.8.norm2.bias, grad: True
2023-07-01 18:26:46 - name: blocks.8.feed_forward.fc1.weight, grad: True
2023-07-01 18:26:46 - name: blocks.8.feed_forward.fc1.bias, grad: True
2023-07-01 18:26:46 - name: blocks.8.feed_forward.fc2.weight, grad: True
2023-07-01 18:26:46 - name: blocks.8.feed_forward.fc2.bias, grad: True
2023-07-01 18:26:46 - name: blocks.9.norm1.weight, grad: True
2023-07-01 18:26:46 - name: blocks.9.norm1.bias, grad: True
2023-07-01 18:26:46 - name: blocks.9.attention.qkv_linear.weight, grad: True
2023-07-01 18:26:46 - name: blocks.9.attention.qkv_linear.bias, grad: True
2023-07-01 18:26:46 - name: blocks.9.attention.out_linear.weight, grad: True
2023-07-01 18:26:46 - name: blocks.9.attention.out_linear.bias, grad: True
2023-07-01 18:26:46 - name: blocks.9.norm2.weight, grad: True
2023-07-01 18:26:46 - name: blocks.9.norm2.bias, grad: True
2023-07-01 18:26:46 - name: blocks.9.feed_forward.fc1.weight, grad: True
2023-07-01 18:26:46 - name: blocks.9.feed_forward.fc1.bias, grad: True
2023-07-01 18:26:46 - name: blocks.9.feed_forward.fc2.weight, grad: True
2023-07-01 18:26:46 - name: blocks.9.feed_forward.fc2.bias, grad: True
2023-07-01 18:26:46 - name: blocks.10.norm1.weight, grad: True
2023-07-01 18:26:46 - name: blocks.10.norm1.bias, grad: True
2023-07-01 18:26:46 - name: blocks.10.attention.qkv_linear.weight, grad: True
2023-07-01 18:26:46 - name: blocks.10.attention.qkv_linear.bias, grad: True
2023-07-01 18:26:46 - name: blocks.10.attention.out_linear.weight, grad: True
2023-07-01 18:26:46 - name: blocks.10.attention.out_linear.bias, grad: True
2023-07-01 18:26:46 - name: blocks.10.norm2.weight, grad: True
2023-07-01 18:26:46 - name: blocks.10.norm2.bias, grad: True
2023-07-01 18:26:46 - name: blocks.10.feed_forward.fc1.weight, grad: True
2023-07-01 18:26:46 - name: blocks.10.feed_forward.fc1.bias, grad: True
2023-07-01 18:26:46 - name: blocks.10.feed_forward.fc2.weight, grad: True
2023-07-01 18:26:46 - name: blocks.10.feed_forward.fc2.bias, grad: True
2023-07-01 18:26:46 - name: blocks.11.norm1.weight, grad: True
2023-07-01 18:26:46 - name: blocks.11.norm1.bias, grad: True
2023-07-01 18:26:46 - name: blocks.11.attention.qkv_linear.weight, grad: True
2023-07-01 18:26:46 - name: blocks.11.attention.qkv_linear.bias, grad: True
2023-07-01 18:26:46 - name: blocks.11.attention.out_linear.weight, grad: True
2023-07-01 18:26:46 - name: blocks.11.attention.out_linear.bias, grad: True
2023-07-01 18:26:46 - name: blocks.11.norm2.weight, grad: True
2023-07-01 18:26:46 - name: blocks.11.norm2.bias, grad: True
2023-07-01 18:26:46 - name: blocks.11.feed_forward.fc1.weight, grad: True
2023-07-01 18:26:46 - name: blocks.11.feed_forward.fc1.bias, grad: True
2023-07-01 18:26:46 - name: blocks.11.feed_forward.fc2.weight, grad: True
2023-07-01 18:26:46 - name: blocks.11.feed_forward.fc2.bias, grad: True
2023-07-01 18:26:46 - name: norm.weight, grad: True
2023-07-01 18:26:46 - name: norm.bias, grad: True
2023-07-01 18:26:46 - name: fc.weight, grad: True
2023-07-01 18:26:46 - name: fc.bias, grad: True
2023-07-01 18:26:46 - --------------------buffers--------------------
2023-07-01 18:26:46 - -----------no weight decay layers--------------
2023-07-01 18:26:46 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.7.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.7.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.7.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.7.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.7.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.7.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.7.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.7.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.8.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.8.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.8.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.8.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.8.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.8.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.8.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.8.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.9.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.9.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.9.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.9.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.9.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.9.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.9.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.9.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.10.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.10.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.10.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.10.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.10.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.10.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.10.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.10.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.11.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.11.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.11.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.11.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.11.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.11.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.11.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.11.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: norm.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: norm.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:26:46 - -------------weight decay layers---------------
2023-07-01 18:26:46 - name: cls_token, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: position_encoding, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: patch_embedding.conv.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.7.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.7.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.7.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.7.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.8.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.8.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.8.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.8.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.9.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.9.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.9.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.9.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.10.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.10.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.10.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.10.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.11.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.11.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.11.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: blocks.11.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:26:46 - epoch 001 lr: 0.100000
2023-07-01 18:31:41 - network: vit_tiny_patch16
2023-07-01 18:31:41 - num_classes: 100
2023-07-01 18:31:41 - input_image_size: 32
2023-07-01 18:31:41 - trained_model_path: 
2023-07-01 18:31:41 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 18:31:41 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 18:31:41 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7ff4195d4520>
2023-07-01 18:31:41 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7ff4195d4490>
2023-07-01 18:31:41 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7ff4195d4580>
2023-07-01 18:31:41 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7ff4195d45b0>
2023-07-01 18:31:41 - seed: 0
2023-07-01 18:31:41 - batch_size: 128
2023-07-01 18:31:41 - num_workers: 16
2023-07-01 18:31:41 - accumulation_steps: 1
2023-07-01 18:31:41 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-01 18:31:41 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-07-01 18:31:41 - epochs: 200
2023-07-01 18:31:41 - print_interval: 50
2023-07-01 18:31:41 - sync_bn: False
2023-07-01 18:31:41 - apex: True
2023-07-01 18:31:41 - use_ema_model: False
2023-07-01 18:31:41 - ema_model_decay: 0.9999
2023-07-01 18:31:41 - AUG: none
2023-07-01 18:31:41 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-01 18:31:41 - gpus_num: 1
2023-07-01 18:31:41 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7ff419737630>
2023-07-01 18:31:41 - --------------------parameters--------------------
2023-07-01 18:31:41 - name: cls_token, grad: True
2023-07-01 18:31:41 - name: position_encoding, grad: True
2023-07-01 18:31:41 - name: patch_embedding.conv.weight, grad: True
2023-07-01 18:31:41 - name: patch_embedding.conv.bias, grad: True
2023-07-01 18:31:41 - name: blocks.0.norm1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.0.norm1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.0.attention.qkv_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.0.attention.qkv_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.0.attention.out_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.0.attention.out_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.0.norm2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.0.norm2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.0.feed_forward.fc1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.0.feed_forward.fc1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.0.feed_forward.fc2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.0.feed_forward.fc2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.1.norm1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.1.norm1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.1.attention.qkv_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.1.attention.qkv_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.1.attention.out_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.1.attention.out_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.1.norm2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.1.norm2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.1.feed_forward.fc1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.1.feed_forward.fc1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.1.feed_forward.fc2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.1.feed_forward.fc2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.2.norm1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.2.norm1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.2.attention.qkv_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.2.attention.qkv_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.2.attention.out_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.2.attention.out_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.2.norm2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.2.norm2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.2.feed_forward.fc1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.2.feed_forward.fc1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.2.feed_forward.fc2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.2.feed_forward.fc2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.3.norm1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.3.norm1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.3.attention.qkv_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.3.attention.qkv_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.3.attention.out_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.3.attention.out_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.3.norm2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.3.norm2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.3.feed_forward.fc1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.3.feed_forward.fc1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.3.feed_forward.fc2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.3.feed_forward.fc2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.4.norm1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.4.norm1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.4.attention.qkv_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.4.attention.qkv_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.4.attention.out_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.4.attention.out_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.4.norm2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.4.norm2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.4.feed_forward.fc1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.4.feed_forward.fc1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.4.feed_forward.fc2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.4.feed_forward.fc2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.5.norm1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.5.norm1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.5.attention.qkv_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.5.attention.qkv_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.5.attention.out_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.5.attention.out_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.5.norm2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.5.norm2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.5.feed_forward.fc1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.5.feed_forward.fc1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.5.feed_forward.fc2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.5.feed_forward.fc2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.6.norm1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.6.norm1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.6.attention.qkv_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.6.attention.qkv_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.6.attention.out_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.6.attention.out_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.6.norm2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.6.norm2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.6.feed_forward.fc1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.6.feed_forward.fc1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.6.feed_forward.fc2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.6.feed_forward.fc2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.7.norm1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.7.norm1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.7.attention.qkv_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.7.attention.qkv_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.7.attention.out_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.7.attention.out_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.7.norm2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.7.norm2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.7.feed_forward.fc1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.7.feed_forward.fc1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.7.feed_forward.fc2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.7.feed_forward.fc2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.8.norm1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.8.norm1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.8.attention.qkv_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.8.attention.qkv_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.8.attention.out_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.8.attention.out_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.8.norm2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.8.norm2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.8.feed_forward.fc1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.8.feed_forward.fc1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.8.feed_forward.fc2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.8.feed_forward.fc2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.9.norm1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.9.norm1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.9.attention.qkv_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.9.attention.qkv_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.9.attention.out_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.9.attention.out_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.9.norm2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.9.norm2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.9.feed_forward.fc1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.9.feed_forward.fc1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.9.feed_forward.fc2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.9.feed_forward.fc2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.10.norm1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.10.norm1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.10.attention.qkv_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.10.attention.qkv_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.10.attention.out_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.10.attention.out_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.10.norm2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.10.norm2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.10.feed_forward.fc1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.10.feed_forward.fc1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.10.feed_forward.fc2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.10.feed_forward.fc2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.11.norm1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.11.norm1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.11.attention.qkv_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.11.attention.qkv_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.11.attention.out_linear.weight, grad: True
2023-07-01 18:31:41 - name: blocks.11.attention.out_linear.bias, grad: True
2023-07-01 18:31:41 - name: blocks.11.norm2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.11.norm2.bias, grad: True
2023-07-01 18:31:41 - name: blocks.11.feed_forward.fc1.weight, grad: True
2023-07-01 18:31:41 - name: blocks.11.feed_forward.fc1.bias, grad: True
2023-07-01 18:31:41 - name: blocks.11.feed_forward.fc2.weight, grad: True
2023-07-01 18:31:41 - name: blocks.11.feed_forward.fc2.bias, grad: True
2023-07-01 18:31:41 - name: norm.weight, grad: True
2023-07-01 18:31:41 - name: norm.bias, grad: True
2023-07-01 18:31:41 - name: fc.weight, grad: True
2023-07-01 18:31:41 - name: fc.bias, grad: True
2023-07-01 18:31:41 - --------------------buffers--------------------
2023-07-01 18:31:41 - -----------no weight decay layers--------------
2023-07-01 18:31:41 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.7.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.7.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.7.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.7.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.7.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.7.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.7.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.7.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.8.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.8.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.8.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.8.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.8.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.8.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.8.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.8.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.9.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.9.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.9.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.9.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.9.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.9.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.9.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.9.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.10.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.10.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.10.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.10.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.10.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.10.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.10.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.10.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.11.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.11.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.11.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.11.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.11.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.11.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.11.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.11.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: norm.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: norm.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:31:41 - -------------weight decay layers---------------
2023-07-01 18:31:41 - name: cls_token, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: position_encoding, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: patch_embedding.conv.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.7.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.7.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.7.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.7.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.8.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.8.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.8.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.8.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.9.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.9.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.9.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.9.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.10.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.10.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.10.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.10.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.11.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.11.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.11.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: blocks.11.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:31:41 - epoch 001 lr: 0.100000
2023-07-01 18:31:49 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.4789
2023-07-01 18:31:51 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.1931
2023-07-01 18:31:53 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 4.1459
2023-07-01 18:31:55 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 4.0038
2023-07-01 18:31:58 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 4.1425
2023-07-01 18:32:00 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 4.0059
2023-07-01 18:32:02 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 3.9769
2023-07-01 18:32:04 - train: epoch 001, train_loss: 4.1381
2023-07-01 18:32:05 - eval: epoch: 001, acc1: 9.990%, acc5: 30.030%, test_loss: 3.8946, per_image_load_time: 0.055ms, per_image_inference_time: 0.085ms
2023-07-01 18:32:06 - until epoch: 001, best_acc1: 9.990%
2023-07-01 18:32:06 - epoch 002 lr: 0.100000
2023-07-01 18:32:09 - train: epoch 0002, iter [00050, 00390], lr: 0.100000, loss: 3.9497
2023-07-01 18:32:11 - train: epoch 0002, iter [00100, 00390], lr: 0.100000, loss: 3.9936
2023-07-01 18:32:13 - train: epoch 0002, iter [00150, 00390], lr: 0.100000, loss: 3.8821
2023-07-01 18:32:16 - train: epoch 0002, iter [00200, 00390], lr: 0.100000, loss: 4.0028
2023-07-01 18:32:18 - train: epoch 0002, iter [00250, 00390], lr: 0.100000, loss: 3.7307
2023-07-01 18:32:20 - train: epoch 0002, iter [00300, 00390], lr: 0.100000, loss: 3.9223
2023-07-01 18:32:22 - train: epoch 0002, iter [00350, 00390], lr: 0.100000, loss: 3.7284
2023-07-01 18:32:24 - train: epoch 002, train_loss: 3.8468
2023-07-01 18:32:26 - eval: epoch: 002, acc1: 11.940%, acc5: 33.440%, test_loss: 3.7513, per_image_load_time: 0.054ms, per_image_inference_time: 0.086ms
2023-07-01 18:32:27 - until epoch: 002, best_acc1: 11.940%
2023-07-01 18:32:27 - epoch 003 lr: 0.100000
2023-07-01 18:32:30 - train: epoch 0003, iter [00050, 00390], lr: 0.100000, loss: 3.7169
2023-07-01 18:32:32 - train: epoch 0003, iter [00100, 00390], lr: 0.100000, loss: 3.6391
2023-07-01 18:32:34 - train: epoch 0003, iter [00150, 00390], lr: 0.100000, loss: 3.9294
2023-07-01 18:32:36 - train: epoch 0003, iter [00200, 00390], lr: 0.100000, loss: 3.5700
2023-07-01 18:32:39 - train: epoch 0003, iter [00250, 00390], lr: 0.100000, loss: 3.9930
2023-07-01 18:32:41 - train: epoch 0003, iter [00300, 00390], lr: 0.100000, loss: 3.7106
2023-07-01 18:32:43 - train: epoch 0003, iter [00350, 00390], lr: 0.100000, loss: 3.7419
2023-07-01 18:32:45 - train: epoch 003, train_loss: 3.7141
2023-07-01 18:32:47 - eval: epoch: 003, acc1: 14.450%, acc5: 37.970%, test_loss: 3.6280, per_image_load_time: 0.055ms, per_image_inference_time: 0.084ms
2023-07-01 18:32:47 - until epoch: 003, best_acc1: 14.450%
2023-07-01 18:32:47 - epoch 004 lr: 0.100000
2023-07-01 18:32:50 - train: epoch 0004, iter [00050, 00390], lr: 0.100000, loss: 3.7025
2023-07-01 18:32:52 - train: epoch 0004, iter [00100, 00390], lr: 0.100000, loss: 3.7093
2023-07-01 18:32:55 - train: epoch 0004, iter [00150, 00390], lr: 0.100000, loss: 3.6938
2023-07-01 18:32:57 - train: epoch 0004, iter [00200, 00390], lr: 0.100000, loss: 3.7390
2023-07-01 18:32:59 - train: epoch 0004, iter [00250, 00390], lr: 0.100000, loss: 3.4423
2023-07-01 18:33:01 - train: epoch 0004, iter [00300, 00390], lr: 0.100000, loss: 3.6635
2023-07-01 18:33:04 - train: epoch 0004, iter [00350, 00390], lr: 0.100000, loss: 3.3710
2023-07-01 18:33:06 - train: epoch 004, train_loss: 3.6138
2023-07-01 18:33:07 - eval: epoch: 004, acc1: 16.540%, acc5: 41.080%, test_loss: 3.5234, per_image_load_time: 0.053ms, per_image_inference_time: 0.085ms
2023-07-01 18:33:08 - until epoch: 004, best_acc1: 16.540%
2023-07-01 18:33:08 - epoch 005 lr: 0.100000
2023-07-01 18:33:11 - train: epoch 0005, iter [00050, 00390], lr: 0.100000, loss: 3.5351
2023-07-01 18:33:13 - train: epoch 0005, iter [00100, 00390], lr: 0.100000, loss: 3.2745
2023-07-01 18:33:15 - train: epoch 0005, iter [00150, 00390], lr: 0.100000, loss: 3.3610
2023-07-01 18:33:17 - train: epoch 0005, iter [00200, 00390], lr: 0.100000, loss: 3.6596
2023-07-01 18:33:20 - train: epoch 0005, iter [00250, 00390], lr: 0.100000, loss: 3.4513
2023-07-01 18:33:22 - train: epoch 0005, iter [00300, 00390], lr: 0.100000, loss: 3.4518
2023-07-01 18:33:24 - train: epoch 0005, iter [00350, 00390], lr: 0.100000, loss: 3.4283
2023-07-01 18:33:26 - train: epoch 005, train_loss: 3.5365
2023-07-01 18:33:27 - eval: epoch: 005, acc1: 18.200%, acc5: 44.330%, test_loss: 3.4292, per_image_load_time: 0.053ms, per_image_inference_time: 0.084ms
2023-07-01 18:33:28 - until epoch: 005, best_acc1: 18.200%
2023-07-01 18:33:28 - epoch 006 lr: 0.100000
2023-07-01 18:33:31 - train: epoch 0006, iter [00050, 00390], lr: 0.100000, loss: 3.5218
2023-07-01 18:33:33 - train: epoch 0006, iter [00100, 00390], lr: 0.100000, loss: 3.3599
2023-07-01 18:33:35 - train: epoch 0006, iter [00150, 00390], lr: 0.100000, loss: 3.5056
2023-07-01 18:33:37 - train: epoch 0006, iter [00200, 00390], lr: 0.100000, loss: 3.3417
2023-07-01 18:33:40 - train: epoch 0006, iter [00250, 00390], lr: 0.100000, loss: 3.4081
2023-07-01 18:33:42 - train: epoch 0006, iter [00300, 00390], lr: 0.100000, loss: 3.3205
2023-07-01 18:33:44 - train: epoch 0006, iter [00350, 00390], lr: 0.100000, loss: 3.5277
2023-07-01 18:33:46 - train: epoch 006, train_loss: 3.4720
2023-07-01 18:33:47 - eval: epoch: 006, acc1: 18.700%, acc5: 44.990%, test_loss: 3.3968, per_image_load_time: 0.052ms, per_image_inference_time: 0.084ms
2023-07-01 18:33:48 - until epoch: 006, best_acc1: 18.700%
2023-07-01 18:33:48 - epoch 007 lr: 0.100000
2023-07-01 18:33:51 - train: epoch 0007, iter [00050, 00390], lr: 0.100000, loss: 3.4913
2023-07-01 18:33:53 - train: epoch 0007, iter [00100, 00390], lr: 0.100000, loss: 3.3892
2023-07-01 18:33:55 - train: epoch 0007, iter [00150, 00390], lr: 0.100000, loss: 3.3819
2023-07-01 18:33:58 - train: epoch 0007, iter [00200, 00390], lr: 0.100000, loss: 3.4200
2023-07-01 18:34:00 - train: epoch 0007, iter [00250, 00390], lr: 0.100000, loss: 3.2687
2023-07-01 18:34:02 - train: epoch 0007, iter [00300, 00390], lr: 0.100000, loss: 3.2309
2023-07-01 18:34:04 - train: epoch 0007, iter [00350, 00390], lr: 0.100000, loss: 3.3526
2023-07-01 18:34:06 - train: epoch 007, train_loss: 3.4194
2023-07-01 18:34:08 - eval: epoch: 007, acc1: 20.140%, acc5: 46.590%, test_loss: 3.3319, per_image_load_time: 0.055ms, per_image_inference_time: 0.084ms
2023-07-01 18:34:09 - until epoch: 007, best_acc1: 20.140%
2023-07-01 18:34:09 - epoch 008 lr: 0.100000
2023-07-01 18:34:12 - train: epoch 0008, iter [00050, 00390], lr: 0.100000, loss: 3.4595
2023-07-01 18:34:14 - train: epoch 0008, iter [00100, 00390], lr: 0.100000, loss: 3.4087
2023-07-01 18:34:16 - train: epoch 0008, iter [00150, 00390], lr: 0.100000, loss: 3.3663
2023-07-01 18:34:18 - train: epoch 0008, iter [00200, 00390], lr: 0.100000, loss: 3.3338
2023-07-01 18:34:21 - train: epoch 0008, iter [00250, 00390], lr: 0.100000, loss: 3.2269
2023-07-01 18:34:23 - train: epoch 0008, iter [00300, 00390], lr: 0.100000, loss: 3.3001
2023-07-01 18:34:25 - train: epoch 0008, iter [00350, 00390], lr: 0.100000, loss: 3.3408
2023-07-01 18:34:27 - train: epoch 008, train_loss: 3.3722
2023-07-01 18:34:28 - eval: epoch: 008, acc1: 20.230%, acc5: 46.710%, test_loss: 3.3357, per_image_load_time: 0.053ms, per_image_inference_time: 0.091ms
2023-07-01 18:34:29 - until epoch: 008, best_acc1: 20.230%
2023-07-01 18:34:29 - epoch 009 lr: 0.100000
2023-07-01 18:34:32 - train: epoch 0009, iter [00050, 00390], lr: 0.100000, loss: 3.2035
2023-07-01 18:34:35 - train: epoch 0009, iter [00100, 00390], lr: 0.100000, loss: 3.5167
2023-07-01 18:34:37 - train: epoch 0009, iter [00150, 00390], lr: 0.100000, loss: 3.1856
2023-07-01 18:34:39 - train: epoch 0009, iter [00200, 00390], lr: 0.100000, loss: 3.3263
2023-07-01 18:34:41 - train: epoch 0009, iter [00250, 00390], lr: 0.100000, loss: 3.3719
2023-07-01 18:34:44 - train: epoch 0009, iter [00300, 00390], lr: 0.100000, loss: 3.4632
2023-07-01 18:34:46 - train: epoch 0009, iter [00350, 00390], lr: 0.100000, loss: 3.4822
2023-07-01 18:34:48 - train: epoch 009, train_loss: 3.3395
2023-07-01 18:34:49 - eval: epoch: 009, acc1: 21.500%, acc5: 48.750%, test_loss: 3.2529, per_image_load_time: 0.053ms, per_image_inference_time: 0.084ms
2023-07-01 18:34:50 - until epoch: 009, best_acc1: 21.500%
2023-07-01 18:34:50 - epoch 010 lr: 0.100000
2023-07-01 18:34:53 - train: epoch 0010, iter [00050, 00390], lr: 0.100000, loss: 3.5183
2023-07-01 18:34:55 - train: epoch 0010, iter [00100, 00390], lr: 0.100000, loss: 3.3706
2023-07-01 18:34:57 - train: epoch 0010, iter [00150, 00390], lr: 0.100000, loss: 3.1873
2023-07-01 18:34:59 - train: epoch 0010, iter [00200, 00390], lr: 0.100000, loss: 3.3270
2023-07-01 18:35:02 - train: epoch 0010, iter [00250, 00390], lr: 0.100000, loss: 3.4012
2023-07-01 18:35:04 - train: epoch 0010, iter [00300, 00390], lr: 0.100000, loss: 3.1298
2023-07-01 18:35:06 - train: epoch 0010, iter [00350, 00390], lr: 0.100000, loss: 3.2908
2023-07-01 18:35:08 - train: epoch 010, train_loss: 3.3123
2023-07-01 18:35:09 - eval: epoch: 010, acc1: 20.890%, acc5: 47.610%, test_loss: 3.2760, per_image_load_time: 0.052ms, per_image_inference_time: 0.084ms
2023-07-01 18:35:09 - until epoch: 010, best_acc1: 21.500%
2023-07-01 18:35:09 - epoch 011 lr: 0.100000
2023-07-01 18:35:12 - train: epoch 0011, iter [00050, 00390], lr: 0.100000, loss: 3.3517
2023-07-01 18:35:14 - train: epoch 0011, iter [00100, 00390], lr: 0.100000, loss: 3.1654
2023-07-01 18:35:17 - train: epoch 0011, iter [00150, 00390], lr: 0.100000, loss: 3.2573
2023-07-01 18:35:19 - train: epoch 0011, iter [00200, 00390], lr: 0.100000, loss: 3.4571
2023-07-01 18:35:21 - train: epoch 0011, iter [00250, 00390], lr: 0.100000, loss: 3.2725
2023-07-01 18:35:23 - train: epoch 0011, iter [00300, 00390], lr: 0.100000, loss: 3.0549
2023-07-01 18:35:26 - train: epoch 0011, iter [00350, 00390], lr: 0.100000, loss: 3.1124
2023-07-01 18:35:28 - train: epoch 011, train_loss: 3.2940
2023-07-01 18:35:29 - eval: epoch: 011, acc1: 21.960%, acc5: 49.120%, test_loss: 3.2258, per_image_load_time: 0.054ms, per_image_inference_time: 0.085ms
2023-07-01 18:35:30 - until epoch: 011, best_acc1: 21.960%
2023-07-01 18:35:30 - epoch 012 lr: 0.100000
2023-07-01 18:35:33 - train: epoch 0012, iter [00050, 00390], lr: 0.100000, loss: 3.2651
2023-07-01 18:35:35 - train: epoch 0012, iter [00100, 00390], lr: 0.100000, loss: 3.4413
2023-07-01 18:35:37 - train: epoch 0012, iter [00150, 00390], lr: 0.100000, loss: 3.3377
2023-07-01 18:35:39 - train: epoch 0012, iter [00200, 00390], lr: 0.100000, loss: 3.4035
2023-07-01 18:35:42 - train: epoch 0012, iter [00250, 00390], lr: 0.100000, loss: 3.1406
2023-07-01 18:35:44 - train: epoch 0012, iter [00300, 00390], lr: 0.100000, loss: 3.3112
2023-07-01 18:35:46 - train: epoch 0012, iter [00350, 00390], lr: 0.100000, loss: 3.3574
2023-07-01 18:35:48 - train: epoch 012, train_loss: 3.2762
2023-07-01 18:35:49 - eval: epoch: 012, acc1: 21.670%, acc5: 49.780%, test_loss: 3.2269, per_image_load_time: 0.056ms, per_image_inference_time: 0.083ms
2023-07-01 18:35:50 - until epoch: 012, best_acc1: 21.960%
2023-07-01 18:35:50 - epoch 013 lr: 0.100000
2023-07-01 18:35:52 - train: epoch 0013, iter [00050, 00390], lr: 0.100000, loss: 3.2443
2023-07-01 18:35:55 - train: epoch 0013, iter [00100, 00390], lr: 0.100000, loss: 3.3457
2023-07-01 18:35:57 - train: epoch 0013, iter [00150, 00390], lr: 0.100000, loss: 3.3307
2023-07-01 18:35:59 - train: epoch 0013, iter [00200, 00390], lr: 0.100000, loss: 3.1614
2023-07-01 18:36:01 - train: epoch 0013, iter [00250, 00390], lr: 0.100000, loss: 3.1966
2023-07-01 18:36:04 - train: epoch 0013, iter [00300, 00390], lr: 0.100000, loss: 3.3730
2023-07-01 18:36:06 - train: epoch 0013, iter [00350, 00390], lr: 0.100000, loss: 2.9883
2023-07-01 18:36:08 - train: epoch 013, train_loss: 3.2512
2023-07-01 18:36:09 - eval: epoch: 013, acc1: 22.350%, acc5: 49.940%, test_loss: 3.2019, per_image_load_time: 0.055ms, per_image_inference_time: 0.084ms
2023-07-01 18:36:10 - until epoch: 013, best_acc1: 22.350%
2023-07-01 18:36:10 - epoch 014 lr: 0.100000
2023-07-01 18:36:13 - train: epoch 0014, iter [00050, 00390], lr: 0.100000, loss: 3.2483
2023-07-01 18:36:15 - train: epoch 0014, iter [00100, 00390], lr: 0.100000, loss: 3.0936
2023-07-01 18:36:17 - train: epoch 0014, iter [00150, 00390], lr: 0.100000, loss: 3.2125
2023-07-01 18:36:19 - train: epoch 0014, iter [00200, 00390], lr: 0.100000, loss: 3.1865
2023-07-01 18:36:22 - train: epoch 0014, iter [00250, 00390], lr: 0.100000, loss: 3.2535
2023-07-01 18:36:24 - train: epoch 0014, iter [00300, 00390], lr: 0.100000, loss: 3.3407
2023-07-01 18:36:26 - train: epoch 0014, iter [00350, 00390], lr: 0.100000, loss: 3.0816
2023-07-01 18:36:28 - train: epoch 014, train_loss: 3.2316
2023-07-01 18:36:29 - eval: epoch: 014, acc1: 21.900%, acc5: 50.140%, test_loss: 3.2027, per_image_load_time: 0.056ms, per_image_inference_time: 0.085ms
2023-07-01 18:36:30 - until epoch: 014, best_acc1: 22.350%
2023-07-01 18:36:30 - epoch 015 lr: 0.100000
2023-07-01 18:36:33 - train: epoch 0015, iter [00050, 00390], lr: 0.100000, loss: 2.9553
2023-07-01 18:36:35 - train: epoch 0015, iter [00100, 00390], lr: 0.100000, loss: 3.3111
2023-07-01 18:36:37 - train: epoch 0015, iter [00150, 00390], lr: 0.100000, loss: 3.5263
2023-07-01 18:36:39 - train: epoch 0015, iter [00200, 00390], lr: 0.100000, loss: 3.1641
2023-07-01 18:36:42 - train: epoch 0015, iter [00250, 00390], lr: 0.100000, loss: 3.0680
2023-07-01 18:36:44 - train: epoch 0015, iter [00300, 00390], lr: 0.100000, loss: 3.0202
2023-07-01 18:36:46 - train: epoch 0015, iter [00350, 00390], lr: 0.100000, loss: 3.1040
2023-07-01 18:36:48 - train: epoch 015, train_loss: 3.2165
2023-07-01 18:36:49 - eval: epoch: 015, acc1: 22.920%, acc5: 50.780%, test_loss: 3.1779, per_image_load_time: 0.055ms, per_image_inference_time: 0.085ms
2023-07-01 18:36:50 - until epoch: 015, best_acc1: 22.920%
2023-07-01 18:36:50 - epoch 016 lr: 0.100000
2023-07-01 18:36:53 - train: epoch 0016, iter [00050, 00390], lr: 0.100000, loss: 3.4157
2023-07-01 18:36:55 - train: epoch 0016, iter [00100, 00390], lr: 0.100000, loss: 3.1239
2023-07-01 18:36:58 - train: epoch 0016, iter [00150, 00390], lr: 0.100000, loss: 3.2325
2023-07-01 18:37:00 - train: epoch 0016, iter [00200, 00390], lr: 0.100000, loss: 3.4114
2023-07-01 18:37:02 - train: epoch 0016, iter [00250, 00390], lr: 0.100000, loss: 3.0532
2023-07-01 18:37:04 - train: epoch 0016, iter [00300, 00390], lr: 0.100000, loss: 3.1502
2023-07-01 18:37:07 - train: epoch 0016, iter [00350, 00390], lr: 0.100000, loss: 2.8639
2023-07-01 18:37:08 - train: epoch 016, train_loss: 3.2046
2023-07-01 18:37:10 - eval: epoch: 016, acc1: 23.680%, acc5: 51.570%, test_loss: 3.1577, per_image_load_time: 0.054ms, per_image_inference_time: 0.090ms
2023-07-01 18:37:11 - until epoch: 016, best_acc1: 23.680%
2023-07-01 18:37:11 - epoch 017 lr: 0.100000
2023-07-01 18:37:13 - train: epoch 0017, iter [00050, 00390], lr: 0.100000, loss: 3.4371
2023-07-01 18:37:16 - train: epoch 0017, iter [00100, 00390], lr: 0.100000, loss: 3.2362
2023-07-01 18:37:18 - train: epoch 0017, iter [00150, 00390], lr: 0.100000, loss: 2.8436
2023-07-01 18:37:20 - train: epoch 0017, iter [00200, 00390], lr: 0.100000, loss: 3.2874
2023-07-01 18:37:22 - train: epoch 0017, iter [00250, 00390], lr: 0.100000, loss: 3.2254
2023-07-01 18:37:24 - train: epoch 0017, iter [00300, 00390], lr: 0.100000, loss: 3.2829
2023-07-01 18:37:27 - train: epoch 0017, iter [00350, 00390], lr: 0.100000, loss: 3.0455
2023-07-01 18:37:29 - train: epoch 017, train_loss: 3.1908
2023-07-01 18:37:30 - eval: epoch: 017, acc1: 23.790%, acc5: 51.690%, test_loss: 3.1540, per_image_load_time: 0.056ms, per_image_inference_time: 0.084ms
2023-07-01 18:37:31 - until epoch: 017, best_acc1: 23.790%
2023-07-01 18:37:31 - epoch 018 lr: 0.100000
2023-07-01 18:37:34 - train: epoch 0018, iter [00050, 00390], lr: 0.100000, loss: 3.1418
2023-07-01 18:37:36 - train: epoch 0018, iter [00100, 00390], lr: 0.100000, loss: 3.4616
2023-07-01 18:37:38 - train: epoch 0018, iter [00150, 00390], lr: 0.100000, loss: 3.4182
2023-07-01 18:37:40 - train: epoch 0018, iter [00200, 00390], lr: 0.100000, loss: 3.1764
2023-07-01 18:37:43 - train: epoch 0018, iter [00250, 00390], lr: 0.100000, loss: 3.2556
2023-07-01 18:37:45 - train: epoch 0018, iter [00300, 00390], lr: 0.100000, loss: 3.1431
2023-07-01 18:37:47 - train: epoch 0018, iter [00350, 00390], lr: 0.100000, loss: 3.1555
2023-07-01 18:37:49 - train: epoch 018, train_loss: 3.1766
2023-07-01 18:37:50 - eval: epoch: 018, acc1: 23.570%, acc5: 51.710%, test_loss: 3.1350, per_image_load_time: 0.056ms, per_image_inference_time: 0.085ms
2023-07-01 18:37:51 - until epoch: 018, best_acc1: 23.790%
2023-07-01 18:37:51 - epoch 019 lr: 0.100000
2023-07-01 18:37:54 - train: epoch 0019, iter [00050, 00390], lr: 0.100000, loss: 3.0850
2023-07-01 18:37:57 - train: epoch 0019, iter [00100, 00390], lr: 0.100000, loss: 3.2054
2023-07-01 18:37:59 - train: epoch 0019, iter [00150, 00390], lr: 0.100000, loss: 3.2630
2023-07-01 18:38:01 - train: epoch 0019, iter [00200, 00390], lr: 0.100000, loss: 3.2517
2023-07-01 18:38:03 - train: epoch 0019, iter [00250, 00390], lr: 0.100000, loss: 3.2323
2023-07-01 18:38:06 - train: epoch 0019, iter [00300, 00390], lr: 0.100000, loss: 3.3740
2023-07-01 18:38:08 - train: epoch 0019, iter [00350, 00390], lr: 0.100000, loss: 3.1203
2023-07-01 18:38:10 - train: epoch 019, train_loss: 3.1600
2023-07-01 18:38:12 - eval: epoch: 019, acc1: 23.000%, acc5: 52.250%, test_loss: 3.1298, per_image_load_time: 0.057ms, per_image_inference_time: 0.085ms
2023-07-01 18:38:12 - until epoch: 019, best_acc1: 23.790%
2023-07-01 18:38:12 - epoch 020 lr: 0.100000
2023-07-01 18:38:15 - train: epoch 0020, iter [00050, 00390], lr: 0.100000, loss: 3.2471
2023-07-01 18:38:17 - train: epoch 0020, iter [00100, 00390], lr: 0.100000, loss: 3.3014
2023-07-01 18:38:19 - train: epoch 0020, iter [00150, 00390], lr: 0.100000, loss: 3.1446
2023-07-01 18:38:22 - train: epoch 0020, iter [00200, 00390], lr: 0.100000, loss: 3.1532
2023-07-01 18:38:24 - train: epoch 0020, iter [00250, 00390], lr: 0.100000, loss: 3.2479
2023-07-01 18:38:26 - train: epoch 0020, iter [00300, 00390], lr: 0.100000, loss: 3.2773
2023-07-01 18:38:28 - train: epoch 0020, iter [00350, 00390], lr: 0.100000, loss: 3.1858
2023-07-01 18:38:30 - train: epoch 020, train_loss: 3.1555
2023-07-01 18:38:32 - eval: epoch: 020, acc1: 24.330%, acc5: 52.790%, test_loss: 3.0867, per_image_load_time: 0.058ms, per_image_inference_time: 0.085ms
2023-07-01 18:38:32 - until epoch: 020, best_acc1: 24.330%
2023-07-01 18:38:32 - epoch 021 lr: 0.100000
2023-07-01 18:38:35 - train: epoch 0021, iter [00050, 00390], lr: 0.100000, loss: 3.0387
2023-07-01 18:38:38 - train: epoch 0021, iter [00100, 00390], lr: 0.100000, loss: 3.2518
2023-07-01 18:38:40 - train: epoch 0021, iter [00150, 00390], lr: 0.100000, loss: 3.2762
2023-07-01 18:38:42 - train: epoch 0021, iter [00200, 00390], lr: 0.100000, loss: 3.4450
2023-07-01 18:38:44 - train: epoch 0021, iter [00250, 00390], lr: 0.100000, loss: 3.1962
2023-07-01 18:38:47 - train: epoch 0021, iter [00300, 00390], lr: 0.100000, loss: 3.2673
2023-07-01 18:38:49 - train: epoch 0021, iter [00350, 00390], lr: 0.100000, loss: 2.9731
2023-07-01 18:38:51 - train: epoch 021, train_loss: 3.1348
2023-07-01 18:38:52 - eval: epoch: 021, acc1: 24.610%, acc5: 53.570%, test_loss: 3.0672, per_image_load_time: 0.054ms, per_image_inference_time: 0.085ms
2023-07-01 18:38:53 - until epoch: 021, best_acc1: 24.610%
2023-07-01 18:38:53 - epoch 022 lr: 0.100000
2023-07-01 18:38:56 - train: epoch 0022, iter [00050, 00390], lr: 0.100000, loss: 3.2019
2023-07-01 18:38:58 - train: epoch 0022, iter [00100, 00390], lr: 0.100000, loss: 3.0892
2023-07-01 18:39:01 - train: epoch 0022, iter [00150, 00390], lr: 0.100000, loss: 3.2425
2023-07-01 18:39:03 - train: epoch 0022, iter [00200, 00390], lr: 0.100000, loss: 3.3283
2023-07-01 18:39:05 - train: epoch 0022, iter [00250, 00390], lr: 0.100000, loss: 3.1724
2023-07-01 18:39:07 - train: epoch 0022, iter [00300, 00390], lr: 0.100000, loss: 3.2174
2023-07-01 18:39:10 - train: epoch 0022, iter [00350, 00390], lr: 0.100000, loss: 3.0483
2023-07-01 18:39:11 - train: epoch 022, train_loss: 3.1226
2023-07-01 18:39:13 - eval: epoch: 022, acc1: 24.760%, acc5: 52.740%, test_loss: 3.1047, per_image_load_time: 0.054ms, per_image_inference_time: 0.085ms
2023-07-01 18:39:14 - until epoch: 022, best_acc1: 24.760%
2023-07-01 18:39:14 - epoch 023 lr: 0.100000
2023-07-01 18:39:17 - train: epoch 0023, iter [00050, 00390], lr: 0.100000, loss: 3.1874
2023-07-01 18:39:19 - train: epoch 0023, iter [00100, 00390], lr: 0.100000, loss: 3.1424
2023-07-01 18:39:22 - train: epoch 0023, iter [00150, 00390], lr: 0.100000, loss: 3.2338
2023-07-01 18:39:24 - train: epoch 0023, iter [00200, 00390], lr: 0.100000, loss: 3.1861
2023-07-01 18:39:27 - train: epoch 0023, iter [00250, 00390], lr: 0.100000, loss: 2.9732
2023-07-01 18:39:29 - train: epoch 0023, iter [00300, 00390], lr: 0.100000, loss: 3.1527
2023-07-01 18:39:31 - train: epoch 0023, iter [00350, 00390], lr: 0.100000, loss: 3.0884
2023-07-01 18:39:33 - train: epoch 023, train_loss: 3.1099
2023-07-01 18:39:34 - eval: epoch: 023, acc1: 24.550%, acc5: 53.580%, test_loss: 3.0830, per_image_load_time: 0.054ms, per_image_inference_time: 0.085ms
2023-07-01 18:39:35 - until epoch: 023, best_acc1: 24.760%
2023-07-01 18:39:35 - epoch 024 lr: 0.100000
2023-07-01 18:39:37 - train: epoch 0024, iter [00050, 00390], lr: 0.100000, loss: 2.9793
2023-07-01 18:39:40 - train: epoch 0024, iter [00100, 00390], lr: 0.100000, loss: 3.1180
2023-07-01 18:39:42 - train: epoch 0024, iter [00150, 00390], lr: 0.100000, loss: 2.8950
2023-07-01 18:39:44 - train: epoch 0024, iter [00200, 00390], lr: 0.100000, loss: 3.2296
2023-07-01 18:39:46 - train: epoch 0024, iter [00250, 00390], lr: 0.100000, loss: 3.1947
2023-07-01 18:39:49 - train: epoch 0024, iter [00300, 00390], lr: 0.100000, loss: 2.9948
2023-07-01 18:39:51 - train: epoch 0024, iter [00350, 00390], lr: 0.100000, loss: 3.0788
2023-07-01 18:39:53 - train: epoch 024, train_loss: 3.0971
2023-07-01 18:39:54 - eval: epoch: 024, acc1: 25.020%, acc5: 53.080%, test_loss: 3.0865, per_image_load_time: 0.054ms, per_image_inference_time: 0.085ms
2023-07-01 18:39:55 - until epoch: 024, best_acc1: 25.020%
2023-07-01 18:39:55 - epoch 025 lr: 0.100000
2023-07-01 18:39:58 - train: epoch 0025, iter [00050, 00390], lr: 0.100000, loss: 3.0839
2023-07-01 18:40:00 - train: epoch 0025, iter [00100, 00390], lr: 0.100000, loss: 2.8760
2023-07-01 18:40:02 - train: epoch 0025, iter [00150, 00390], lr: 0.100000, loss: 3.2607
2023-07-01 18:40:05 - train: epoch 0025, iter [00200, 00390], lr: 0.100000, loss: 3.1437
2023-07-01 18:40:07 - train: epoch 0025, iter [00250, 00390], lr: 0.100000, loss: 3.1023
2023-07-01 18:40:09 - train: epoch 0025, iter [00300, 00390], lr: 0.100000, loss: 3.0217
2023-07-01 18:40:11 - train: epoch 0025, iter [00350, 00390], lr: 0.100000, loss: 2.9968
2023-07-01 18:40:13 - train: epoch 025, train_loss: 3.0875
2023-07-01 18:40:15 - eval: epoch: 025, acc1: 25.020%, acc5: 54.080%, test_loss: 3.0496, per_image_load_time: 0.054ms, per_image_inference_time: 0.085ms
2023-07-01 18:40:15 - until epoch: 025, best_acc1: 25.020%
2023-07-01 18:40:15 - epoch 026 lr: 0.100000
2023-07-01 18:40:18 - train: epoch 0026, iter [00050, 00390], lr: 0.100000, loss: 2.8253
2023-07-01 18:40:20 - train: epoch 0026, iter [00100, 00390], lr: 0.100000, loss: 3.2107
2023-07-01 18:40:23 - train: epoch 0026, iter [00150, 00390], lr: 0.100000, loss: 3.0810
2023-07-01 18:40:25 - train: epoch 0026, iter [00200, 00390], lr: 0.100000, loss: 3.2779
2023-07-01 18:40:27 - train: epoch 0026, iter [00250, 00390], lr: 0.100000, loss: 3.0941
2023-07-01 18:40:29 - train: epoch 0026, iter [00300, 00390], lr: 0.100000, loss: 3.1005
2023-07-01 18:40:32 - train: epoch 0026, iter [00350, 00390], lr: 0.100000, loss: 3.0721
2023-07-01 18:40:33 - train: epoch 026, train_loss: 3.0703
2023-07-01 18:40:35 - eval: epoch: 026, acc1: 25.820%, acc5: 55.770%, test_loss: 2.9977, per_image_load_time: 0.054ms, per_image_inference_time: 0.085ms
2023-07-01 18:40:36 - until epoch: 026, best_acc1: 25.820%
2023-07-01 18:40:36 - epoch 027 lr: 0.100000
2023-07-01 18:40:39 - train: epoch 0027, iter [00050, 00390], lr: 0.100000, loss: 3.0215
2023-07-01 18:40:41 - train: epoch 0027, iter [00100, 00390], lr: 0.100000, loss: 3.1224
2023-07-01 18:40:43 - train: epoch 0027, iter [00150, 00390], lr: 0.100000, loss: 3.1219
2023-07-01 18:40:46 - train: epoch 0027, iter [00200, 00390], lr: 0.100000, loss: 3.1583
2023-07-01 18:40:48 - train: epoch 0027, iter [00250, 00390], lr: 0.100000, loss: 3.2791
2023-07-01 18:40:51 - train: epoch 0027, iter [00300, 00390], lr: 0.100000, loss: 3.1889
2023-07-01 18:40:53 - train: epoch 0027, iter [00350, 00390], lr: 0.100000, loss: 3.1396
2023-07-01 18:40:55 - train: epoch 027, train_loss: 3.0613
2023-07-01 18:40:57 - eval: epoch: 027, acc1: 25.190%, acc5: 54.590%, test_loss: 3.0304, per_image_load_time: 0.068ms, per_image_inference_time: 0.086ms
2023-07-01 18:40:57 - until epoch: 027, best_acc1: 25.820%
2023-07-01 18:40:57 - epoch 028 lr: 0.100000
2023-07-01 18:41:00 - train: epoch 0028, iter [00050, 00390], lr: 0.100000, loss: 3.0674
2023-07-01 18:41:02 - train: epoch 0028, iter [00100, 00390], lr: 0.100000, loss: 2.9475
2023-07-01 18:41:05 - train: epoch 0028, iter [00150, 00390], lr: 0.100000, loss: 2.8685
2023-07-01 18:41:07 - train: epoch 0028, iter [00200, 00390], lr: 0.100000, loss: 3.2863
2023-07-01 18:41:09 - train: epoch 0028, iter [00250, 00390], lr: 0.100000, loss: 3.0435
2023-07-01 18:41:11 - train: epoch 0028, iter [00300, 00390], lr: 0.100000, loss: 3.0159
2023-07-01 18:41:14 - train: epoch 0028, iter [00350, 00390], lr: 0.100000, loss: 3.1508
2023-07-01 18:41:15 - train: epoch 028, train_loss: 3.0457
2023-07-01 18:41:17 - eval: epoch: 028, acc1: 25.470%, acc5: 54.250%, test_loss: 3.0466, per_image_load_time: 0.056ms, per_image_inference_time: 0.085ms
2023-07-01 18:41:18 - until epoch: 028, best_acc1: 25.820%
2023-07-01 18:41:18 - epoch 029 lr: 0.100000
2023-07-01 18:41:21 - train: epoch 0029, iter [00050, 00390], lr: 0.100000, loss: 2.9946
2023-07-01 18:41:23 - train: epoch 0029, iter [00100, 00390], lr: 0.100000, loss: 3.1618
2023-07-01 18:41:25 - train: epoch 0029, iter [00150, 00390], lr: 0.100000, loss: 3.0886
2023-07-01 18:41:27 - train: epoch 0029, iter [00200, 00390], lr: 0.100000, loss: 2.9931
2023-07-01 18:41:30 - train: epoch 0029, iter [00250, 00390], lr: 0.100000, loss: 2.9291
2023-07-01 18:41:32 - train: epoch 0029, iter [00300, 00390], lr: 0.100000, loss: 2.9795
2023-07-01 18:41:34 - train: epoch 0029, iter [00350, 00390], lr: 0.100000, loss: 3.1069
2023-07-01 18:41:36 - train: epoch 029, train_loss: 3.0311
2023-07-01 18:41:37 - eval: epoch: 029, acc1: 26.060%, acc5: 54.870%, test_loss: 3.0027, per_image_load_time: 0.055ms, per_image_inference_time: 0.086ms
2023-07-01 18:41:38 - until epoch: 029, best_acc1: 26.060%
2023-07-01 18:41:38 - epoch 030 lr: 0.100000
2023-07-01 18:41:41 - train: epoch 0030, iter [00050, 00390], lr: 0.100000, loss: 2.7601
2023-07-01 18:41:43 - train: epoch 0030, iter [00100, 00390], lr: 0.100000, loss: 3.0028
2023-07-01 18:41:45 - train: epoch 0030, iter [00150, 00390], lr: 0.100000, loss: 3.0527
2023-07-01 18:41:47 - train: epoch 0030, iter [00200, 00390], lr: 0.100000, loss: 3.1276
2023-07-01 18:41:50 - train: epoch 0030, iter [00250, 00390], lr: 0.100000, loss: 2.9350
2023-07-01 18:41:52 - train: epoch 0030, iter [00300, 00390], lr: 0.100000, loss: 2.9154
2023-07-01 18:41:54 - train: epoch 0030, iter [00350, 00390], lr: 0.100000, loss: 2.9522
2023-07-01 18:41:56 - train: epoch 030, train_loss: 3.0263
2023-07-01 18:41:58 - eval: epoch: 030, acc1: 25.660%, acc5: 55.290%, test_loss: 3.0103, per_image_load_time: 0.056ms, per_image_inference_time: 0.084ms
2023-07-01 18:42:02 - until epoch: 030, best_acc1: 26.060%
2023-07-01 18:42:02 - epoch 031 lr: 0.100000
2023-07-01 18:42:04 - train: epoch 0031, iter [00050, 00390], lr: 0.100000, loss: 3.2494
2023-07-01 18:42:07 - train: epoch 0031, iter [00100, 00390], lr: 0.100000, loss: 3.1979
2023-07-01 18:42:09 - train: epoch 0031, iter [00150, 00390], lr: 0.100000, loss: 2.9992
2023-07-01 18:42:11 - train: epoch 0031, iter [00200, 00390], lr: 0.100000, loss: 3.1454
2023-07-01 18:42:13 - train: epoch 0031, iter [00250, 00390], lr: 0.100000, loss: 3.0908
2023-07-01 18:42:16 - train: epoch 0031, iter [00300, 00390], lr: 0.100000, loss: 3.0511
2023-07-01 18:42:18 - train: epoch 0031, iter [00350, 00390], lr: 0.100000, loss: 2.7004
2023-07-01 18:42:20 - train: epoch 031, train_loss: 3.0111
2023-07-01 18:42:21 - eval: epoch: 031, acc1: 26.220%, acc5: 55.340%, test_loss: 2.9871, per_image_load_time: 0.057ms, per_image_inference_time: 0.085ms
2023-07-01 18:42:23 - until epoch: 031, best_acc1: 26.220%
2023-07-01 18:42:23 - epoch 032 lr: 0.100000
2023-07-01 18:42:26 - train: epoch 0032, iter [00050, 00390], lr: 0.100000, loss: 3.0444
2023-07-01 18:42:28 - train: epoch 0032, iter [00100, 00390], lr: 0.100000, loss: 2.8758
2023-07-01 18:42:31 - train: epoch 0032, iter [00150, 00390], lr: 0.100000, loss: 3.0668
2023-07-01 18:42:33 - train: epoch 0032, iter [00200, 00390], lr: 0.100000, loss: 3.1919
2023-07-01 18:42:35 - train: epoch 0032, iter [00250, 00390], lr: 0.100000, loss: 3.1563
2023-07-01 18:42:37 - train: epoch 0032, iter [00300, 00390], lr: 0.100000, loss: 3.1747
2023-07-01 18:42:39 - train: epoch 0032, iter [00350, 00390], lr: 0.100000, loss: 2.8544
2023-07-01 18:42:41 - train: epoch 032, train_loss: 2.9976
2023-07-01 18:42:43 - eval: epoch: 032, acc1: 27.310%, acc5: 56.100%, test_loss: 2.9622, per_image_load_time: 0.056ms, per_image_inference_time: 0.086ms
2023-07-01 18:42:43 - until epoch: 032, best_acc1: 27.310%
2023-07-01 18:42:43 - epoch 033 lr: 0.100000
2023-07-01 18:42:46 - train: epoch 0033, iter [00050, 00390], lr: 0.100000, loss: 2.8480
2023-07-01 18:42:49 - train: epoch 0033, iter [00100, 00390], lr: 0.100000, loss: 2.9709
2023-07-01 18:42:51 - train: epoch 0033, iter [00150, 00390], lr: 0.100000, loss: 3.1528
2023-07-01 18:42:53 - train: epoch 0033, iter [00200, 00390], lr: 0.100000, loss: 3.0093
2023-07-01 18:42:56 - train: epoch 0033, iter [00250, 00390], lr: 0.100000, loss: 3.0544
2023-07-01 18:42:58 - train: epoch 0033, iter [00300, 00390], lr: 0.100000, loss: 3.1498
2023-07-01 18:43:01 - train: epoch 0033, iter [00350, 00390], lr: 0.100000, loss: 2.9968
2023-07-01 18:43:02 - train: epoch 033, train_loss: 2.9886
2023-07-01 18:43:04 - eval: epoch: 033, acc1: 27.630%, acc5: 57.170%, test_loss: 2.9186, per_image_load_time: 0.064ms, per_image_inference_time: 0.086ms
2023-07-01 18:43:05 - until epoch: 033, best_acc1: 27.630%
2023-07-01 18:43:05 - epoch 034 lr: 0.100000
2023-07-01 18:43:07 - train: epoch 0034, iter [00050, 00390], lr: 0.100000, loss: 3.1758
2023-07-01 18:43:10 - train: epoch 0034, iter [00100, 00390], lr: 0.100000, loss: 3.0627
2023-07-01 18:43:12 - train: epoch 0034, iter [00150, 00390], lr: 0.100000, loss: 2.8216
2023-07-01 18:43:14 - train: epoch 0034, iter [00200, 00390], lr: 0.100000, loss: 3.0295
2023-07-01 18:43:17 - train: epoch 0034, iter [00250, 00390], lr: 0.100000, loss: 2.8818
2023-07-01 18:43:19 - train: epoch 0034, iter [00300, 00390], lr: 0.100000, loss: 3.0313
2023-07-01 18:43:21 - train: epoch 0034, iter [00350, 00390], lr: 0.100000, loss: 2.7065
2023-07-01 18:43:23 - train: epoch 034, train_loss: 2.9779
2023-07-01 18:43:25 - eval: epoch: 034, acc1: 27.720%, acc5: 57.010%, test_loss: 2.9141, per_image_load_time: 0.055ms, per_image_inference_time: 0.086ms
2023-07-01 18:43:26 - until epoch: 034, best_acc1: 27.720%
2023-07-01 18:43:26 - epoch 035 lr: 0.100000
2023-07-01 18:43:29 - train: epoch 0035, iter [00050, 00390], lr: 0.100000, loss: 2.9076
2023-07-01 18:43:31 - train: epoch 0035, iter [00100, 00390], lr: 0.100000, loss: 2.9747
2023-07-01 18:43:34 - train: epoch 0035, iter [00150, 00390], lr: 0.100000, loss: 2.8876
2023-07-01 18:43:36 - train: epoch 0035, iter [00200, 00390], lr: 0.100000, loss: 2.8004
2023-07-01 18:43:38 - train: epoch 0035, iter [00250, 00390], lr: 0.100000, loss: 2.8676
2023-07-01 18:43:40 - train: epoch 0035, iter [00300, 00390], lr: 0.100000, loss: 2.8164
2023-07-01 18:43:43 - train: epoch 0035, iter [00350, 00390], lr: 0.100000, loss: 3.2366
2023-07-01 18:43:44 - train: epoch 035, train_loss: 2.9517
2023-07-01 18:43:46 - eval: epoch: 035, acc1: 27.860%, acc5: 57.180%, test_loss: 2.9234, per_image_load_time: 0.058ms, per_image_inference_time: 0.084ms
2023-07-01 18:43:47 - until epoch: 035, best_acc1: 27.860%
2023-07-01 18:43:47 - epoch 036 lr: 0.100000
2023-07-01 18:43:49 - train: epoch 0036, iter [00050, 00390], lr: 0.100000, loss: 3.0484
2023-07-01 18:43:52 - train: epoch 0036, iter [00100, 00390], lr: 0.100000, loss: 2.8404
2023-07-01 18:43:54 - train: epoch 0036, iter [00150, 00390], lr: 0.100000, loss: 2.9543
2023-07-01 18:43:56 - train: epoch 0036, iter [00200, 00390], lr: 0.100000, loss: 3.1387
2023-07-01 18:43:59 - train: epoch 0036, iter [00250, 00390], lr: 0.100000, loss: 2.8113
2023-07-01 18:44:01 - train: epoch 0036, iter [00300, 00390], lr: 0.100000, loss: 2.9244
2023-07-01 18:44:03 - train: epoch 0036, iter [00350, 00390], lr: 0.100000, loss: 2.6788
2023-07-01 18:44:05 - train: epoch 036, train_loss: 2.9546
2023-07-01 18:44:07 - eval: epoch: 036, acc1: 27.250%, acc5: 57.270%, test_loss: 2.9074, per_image_load_time: 0.056ms, per_image_inference_time: 0.085ms
2023-07-01 18:44:07 - until epoch: 036, best_acc1: 27.860%
2023-07-01 18:44:07 - epoch 037 lr: 0.100000
2023-07-01 18:44:10 - train: epoch 0037, iter [00050, 00390], lr: 0.100000, loss: 3.0866
2023-07-01 18:44:12 - train: epoch 0037, iter [00100, 00390], lr: 0.100000, loss: 2.8013
2023-07-01 18:44:14 - train: epoch 0037, iter [00150, 00390], lr: 0.100000, loss: 2.9503
2023-07-01 18:44:17 - train: epoch 0037, iter [00200, 00390], lr: 0.100000, loss: 3.0233
2023-07-01 18:44:19 - train: epoch 0037, iter [00250, 00390], lr: 0.100000, loss: 2.6928
2023-07-01 18:44:21 - train: epoch 0037, iter [00300, 00390], lr: 0.100000, loss: 2.8867
2023-07-01 18:44:24 - train: epoch 0037, iter [00350, 00390], lr: 0.100000, loss: 2.9872
2023-07-01 18:44:25 - train: epoch 037, train_loss: 2.9409
2023-07-01 18:44:27 - eval: epoch: 037, acc1: 27.330%, acc5: 57.110%, test_loss: 2.9349, per_image_load_time: 0.057ms, per_image_inference_time: 0.086ms
2023-07-01 18:44:27 - until epoch: 037, best_acc1: 27.860%
2023-07-01 18:44:27 - epoch 038 lr: 0.100000
2023-07-01 18:44:30 - train: epoch 0038, iter [00050, 00390], lr: 0.100000, loss: 2.8187
2023-07-01 18:44:33 - train: epoch 0038, iter [00100, 00390], lr: 0.100000, loss: 2.9359
2023-07-01 18:44:35 - train: epoch 0038, iter [00150, 00390], lr: 0.100000, loss: 3.1543
2023-07-01 18:44:37 - train: epoch 0038, iter [00200, 00390], lr: 0.100000, loss: 2.8162
2023-07-01 18:44:39 - train: epoch 0038, iter [00250, 00390], lr: 0.100000, loss: 3.0558
2023-07-01 18:44:41 - train: epoch 0038, iter [00300, 00390], lr: 0.100000, loss: 3.0178
2023-07-01 18:44:44 - train: epoch 0038, iter [00350, 00390], lr: 0.100000, loss: 3.2145
2023-07-01 18:44:45 - train: epoch 038, train_loss: 2.9257
2023-07-01 18:44:47 - eval: epoch: 038, acc1: 27.810%, acc5: 57.050%, test_loss: 2.9265, per_image_load_time: 0.056ms, per_image_inference_time: 0.084ms
2023-07-01 18:44:47 - until epoch: 038, best_acc1: 27.860%
2023-07-01 18:44:47 - epoch 039 lr: 0.100000
2023-07-01 18:44:50 - train: epoch 0039, iter [00050, 00390], lr: 0.100000, loss: 2.9511
2023-07-01 18:44:52 - train: epoch 0039, iter [00100, 00390], lr: 0.100000, loss: 2.9108
2023-07-01 18:44:55 - train: epoch 0039, iter [00150, 00390], lr: 0.100000, loss: 2.8049
2023-07-01 18:44:57 - train: epoch 0039, iter [00200, 00390], lr: 0.100000, loss: 2.7458
2023-07-01 18:44:59 - train: epoch 0039, iter [00250, 00390], lr: 0.100000, loss: 2.8946
2023-07-01 18:45:01 - train: epoch 0039, iter [00300, 00390], lr: 0.100000, loss: 2.8005
2023-07-01 18:45:04 - train: epoch 0039, iter [00350, 00390], lr: 0.100000, loss: 3.0149
2023-07-01 18:45:05 - train: epoch 039, train_loss: 2.9200
2023-07-01 18:45:07 - eval: epoch: 039, acc1: 28.030%, acc5: 58.690%, test_loss: 2.8784, per_image_load_time: 0.057ms, per_image_inference_time: 0.084ms
2023-07-01 18:45:08 - until epoch: 039, best_acc1: 28.030%
2023-07-01 18:45:08 - epoch 040 lr: 0.100000
2023-07-01 18:45:11 - train: epoch 0040, iter [00050, 00390], lr: 0.100000, loss: 3.0129
2023-07-01 18:45:14 - train: epoch 0040, iter [00100, 00390], lr: 0.100000, loss: 2.6832
2023-07-01 18:45:16 - train: epoch 0040, iter [00150, 00390], lr: 0.100000, loss: 2.6245
2023-07-01 18:45:18 - train: epoch 0040, iter [00200, 00390], lr: 0.100000, loss: 3.0259
2023-07-01 18:45:20 - train: epoch 0040, iter [00250, 00390], lr: 0.100000, loss: 2.9762
2023-07-01 18:45:23 - train: epoch 0040, iter [00300, 00390], lr: 0.100000, loss: 2.5876
2023-07-01 18:45:25 - train: epoch 0040, iter [00350, 00390], lr: 0.100000, loss: 2.9892
2023-07-01 18:45:27 - train: epoch 040, train_loss: 2.9073
2023-07-01 18:45:28 - eval: epoch: 040, acc1: 28.760%, acc5: 58.860%, test_loss: 2.8716, per_image_load_time: 0.058ms, per_image_inference_time: 0.084ms
2023-07-01 18:45:30 - until epoch: 040, best_acc1: 28.760%
2023-07-01 18:45:30 - epoch 041 lr: 0.100000
2023-07-01 18:45:33 - train: epoch 0041, iter [00050, 00390], lr: 0.100000, loss: 2.7834
2023-07-01 18:45:35 - train: epoch 0041, iter [00100, 00390], lr: 0.100000, loss: 2.8060
2023-07-01 18:45:37 - train: epoch 0041, iter [00150, 00390], lr: 0.100000, loss: 2.9577
2023-07-01 18:45:39 - train: epoch 0041, iter [00200, 00390], lr: 0.100000, loss: 3.1365
2023-07-01 18:45:42 - train: epoch 0041, iter [00250, 00390], lr: 0.100000, loss: 3.0258
2023-07-01 18:45:44 - train: epoch 0041, iter [00300, 00390], lr: 0.100000, loss: 2.9244
2023-07-01 18:45:46 - train: epoch 0041, iter [00350, 00390], lr: 0.100000, loss: 2.9352
2023-07-01 18:45:48 - train: epoch 041, train_loss: 2.9044
2023-07-01 18:45:49 - eval: epoch: 041, acc1: 29.260%, acc5: 59.390%, test_loss: 2.8439, per_image_load_time: 0.058ms, per_image_inference_time: 0.084ms
2023-07-01 18:45:51 - until epoch: 041, best_acc1: 29.260%
2023-07-01 18:45:51 - epoch 042 lr: 0.100000
2023-07-01 18:45:54 - train: epoch 0042, iter [00050, 00390], lr: 0.100000, loss: 2.6287
2023-07-01 18:45:56 - train: epoch 0042, iter [00100, 00390], lr: 0.100000, loss: 2.9553
2023-07-01 18:45:58 - train: epoch 0042, iter [00150, 00390], lr: 0.100000, loss: 2.7924
2023-07-01 18:46:00 - train: epoch 0042, iter [00200, 00390], lr: 0.100000, loss: 2.8442
2023-07-01 18:46:03 - train: epoch 0042, iter [00250, 00390], lr: 0.100000, loss: 2.8050
2023-07-01 18:46:05 - train: epoch 0042, iter [00300, 00390], lr: 0.100000, loss: 2.8273
2023-07-01 18:46:08 - train: epoch 0042, iter [00350, 00390], lr: 0.100000, loss: 2.7794
2023-07-01 18:46:10 - train: epoch 042, train_loss: 2.8995
2023-07-01 18:46:12 - eval: epoch: 042, acc1: 28.410%, acc5: 58.220%, test_loss: 2.8773, per_image_load_time: 0.071ms, per_image_inference_time: 0.085ms
2023-07-01 18:46:13 - until epoch: 042, best_acc1: 29.260%
2023-07-01 18:46:13 - epoch 043 lr: 0.100000
2023-07-01 18:46:16 - train: epoch 0043, iter [00050, 00390], lr: 0.100000, loss: 3.0589
2023-07-01 18:46:18 - train: epoch 0043, iter [00100, 00390], lr: 0.100000, loss: 2.6337
2023-07-01 18:46:20 - train: epoch 0043, iter [00150, 00390], lr: 0.100000, loss: 2.6880
2023-07-01 18:46:22 - train: epoch 0043, iter [00200, 00390], lr: 0.100000, loss: 3.1559
2023-07-01 18:46:25 - train: epoch 0043, iter [00250, 00390], lr: 0.100000, loss: 2.9330
2023-07-01 18:46:27 - train: epoch 0043, iter [00300, 00390], lr: 0.100000, loss: 2.9234
2023-07-01 18:46:29 - train: epoch 0043, iter [00350, 00390], lr: 0.100000, loss: 2.9272
2023-07-01 18:46:31 - train: epoch 043, train_loss: 2.8855
2023-07-01 18:46:32 - eval: epoch: 043, acc1: 29.220%, acc5: 59.500%, test_loss: 2.8392, per_image_load_time: 0.055ms, per_image_inference_time: 0.086ms
2023-07-01 18:46:33 - until epoch: 043, best_acc1: 29.260%
2023-07-01 18:46:33 - epoch 044 lr: 0.100000
2023-07-01 18:46:36 - train: epoch 0044, iter [00050, 00390], lr: 0.100000, loss: 3.1843
2023-07-01 18:46:38 - train: epoch 0044, iter [00100, 00390], lr: 0.100000, loss: 2.8764
2023-07-01 18:46:40 - train: epoch 0044, iter [00150, 00390], lr: 0.100000, loss: 2.8672
2023-07-01 18:46:42 - train: epoch 0044, iter [00200, 00390], lr: 0.100000, loss: 2.7401
2023-07-01 18:46:45 - train: epoch 0044, iter [00250, 00390], lr: 0.100000, loss: 3.1076
2023-07-01 18:46:47 - train: epoch 0044, iter [00300, 00390], lr: 0.100000, loss: 2.7485
2023-07-01 18:46:49 - train: epoch 0044, iter [00350, 00390], lr: 0.100000, loss: 2.7728
2023-07-01 18:46:51 - train: epoch 044, train_loss: 2.8859
2023-07-01 18:46:52 - eval: epoch: 044, acc1: 29.070%, acc5: 59.050%, test_loss: 2.8389, per_image_load_time: 0.056ms, per_image_inference_time: 0.091ms
2023-07-01 18:46:53 - until epoch: 044, best_acc1: 29.260%
2023-07-01 18:46:53 - epoch 045 lr: 0.100000
2023-07-01 18:46:56 - train: epoch 0045, iter [00050, 00390], lr: 0.100000, loss: 2.9255
2023-07-01 18:46:59 - train: epoch 0045, iter [00100, 00390], lr: 0.100000, loss: 3.1348
2023-07-01 18:47:01 - train: epoch 0045, iter [00150, 00390], lr: 0.100000, loss: 2.7528
2023-07-01 18:47:03 - train: epoch 0045, iter [00200, 00390], lr: 0.100000, loss: 2.8432
2023-07-01 18:47:05 - train: epoch 0045, iter [00250, 00390], lr: 0.100000, loss: 2.8506
2023-07-01 18:47:07 - train: epoch 0045, iter [00300, 00390], lr: 0.100000, loss: 2.8923
2023-07-01 18:47:10 - train: epoch 0045, iter [00350, 00390], lr: 0.100000, loss: 3.0406
2023-07-01 18:47:12 - train: epoch 045, train_loss: 2.8731
2023-07-01 18:47:13 - eval: epoch: 045, acc1: 29.130%, acc5: 59.850%, test_loss: 2.8226, per_image_load_time: 0.055ms, per_image_inference_time: 0.084ms
2023-07-01 18:47:13 - until epoch: 045, best_acc1: 29.260%
2023-07-01 18:47:13 - epoch 046 lr: 0.100000
2023-07-01 18:47:16 - train: epoch 0046, iter [00050, 00390], lr: 0.100000, loss: 3.0962
2023-07-01 18:47:18 - train: epoch 0046, iter [00100, 00390], lr: 0.100000, loss: 2.9686
2023-07-01 18:47:21 - train: epoch 0046, iter [00150, 00390], lr: 0.100000, loss: 2.5925
2023-07-01 18:47:23 - train: epoch 0046, iter [00200, 00390], lr: 0.100000, loss: 2.7170
2023-07-01 18:47:25 - train: epoch 0046, iter [00250, 00390], lr: 0.100000, loss: 2.7447
2023-07-01 18:47:27 - train: epoch 0046, iter [00300, 00390], lr: 0.100000, loss: 2.6864
2023-07-01 18:47:30 - train: epoch 0046, iter [00350, 00390], lr: 0.100000, loss: 2.6872
2023-07-01 18:47:31 - train: epoch 046, train_loss: 2.8706
2023-07-01 18:47:33 - eval: epoch: 046, acc1: 29.560%, acc5: 59.350%, test_loss: 2.8329, per_image_load_time: 0.056ms, per_image_inference_time: 0.084ms
2023-07-01 18:47:34 - until epoch: 046, best_acc1: 29.560%
2023-07-01 18:47:34 - epoch 047 lr: 0.100000
2023-07-01 18:47:37 - train: epoch 0047, iter [00050, 00390], lr: 0.100000, loss: 2.8439
2023-07-01 18:47:39 - train: epoch 0047, iter [00100, 00390], lr: 0.100000, loss: 2.9360
2023-07-01 18:47:41 - train: epoch 0047, iter [00150, 00390], lr: 0.100000, loss: 2.6882
2023-07-01 18:47:44 - train: epoch 0047, iter [00200, 00390], lr: 0.100000, loss: 2.9208
2023-07-01 18:47:46 - train: epoch 0047, iter [00250, 00390], lr: 0.100000, loss: 2.8722
2023-07-01 18:47:48 - train: epoch 0047, iter [00300, 00390], lr: 0.100000, loss: 2.5192
2023-07-01 18:47:50 - train: epoch 0047, iter [00350, 00390], lr: 0.100000, loss: 2.7818
2023-07-01 18:47:52 - train: epoch 047, train_loss: 2.8592
2023-07-01 18:47:54 - eval: epoch: 047, acc1: 29.130%, acc5: 60.040%, test_loss: 2.8276, per_image_load_time: 0.055ms, per_image_inference_time: 0.085ms
2023-07-01 18:47:55 - until epoch: 047, best_acc1: 29.560%
2023-07-01 18:47:55 - epoch 048 lr: 0.100000
2023-07-01 18:47:57 - train: epoch 0048, iter [00050, 00390], lr: 0.100000, loss: 2.8040
2023-07-01 18:48:00 - train: epoch 0048, iter [00100, 00390], lr: 0.100000, loss: 2.6799
2023-07-01 18:48:03 - train: epoch 0048, iter [00150, 00390], lr: 0.100000, loss: 2.7064
2023-07-01 18:48:06 - train: epoch 0048, iter [00200, 00390], lr: 0.100000, loss: 3.0065
2023-07-01 18:48:08 - train: epoch 0048, iter [00250, 00390], lr: 0.100000, loss: 2.9302
2023-07-01 18:48:11 - train: epoch 0048, iter [00300, 00390], lr: 0.100000, loss: 2.8271
2023-07-01 18:48:13 - train: epoch 0048, iter [00350, 00390], lr: 0.100000, loss: 3.1553
2023-07-01 18:48:15 - train: epoch 048, train_loss: 2.8545
2023-07-01 18:48:16 - eval: epoch: 048, acc1: 29.720%, acc5: 59.100%, test_loss: 2.8292, per_image_load_time: 0.059ms, per_image_inference_time: 0.084ms
2023-07-01 18:48:18 - until epoch: 048, best_acc1: 29.720%
2023-07-01 18:48:18 - epoch 049 lr: 0.100000
2023-07-01 18:48:21 - train: epoch 0049, iter [00050, 00390], lr: 0.100000, loss: 3.0073
2023-07-01 18:48:23 - train: epoch 0049, iter [00100, 00390], lr: 0.100000, loss: 2.7602
2023-07-01 18:48:25 - train: epoch 0049, iter [00150, 00390], lr: 0.100000, loss: 2.6867
2023-07-01 18:48:27 - train: epoch 0049, iter [00200, 00390], lr: 0.100000, loss: 2.6603
2023-07-01 18:48:29 - train: epoch 0049, iter [00250, 00390], lr: 0.100000, loss: 2.7107
2023-07-01 18:48:32 - train: epoch 0049, iter [00300, 00390], lr: 0.100000, loss: 2.7672
2023-07-01 18:48:34 - train: epoch 0049, iter [00350, 00390], lr: 0.100000, loss: 2.9129
2023-07-01 18:48:36 - train: epoch 049, train_loss: 2.8546
2023-07-01 18:48:37 - eval: epoch: 049, acc1: 29.130%, acc5: 59.620%, test_loss: 2.8349, per_image_load_time: 0.055ms, per_image_inference_time: 0.085ms
2023-07-01 18:48:38 - until epoch: 049, best_acc1: 29.720%
2023-07-01 18:48:38 - epoch 050 lr: 0.100000
2023-07-01 18:48:41 - train: epoch 0050, iter [00050, 00390], lr: 0.100000, loss: 2.9290
2023-07-01 18:48:43 - train: epoch 0050, iter [00100, 00390], lr: 0.100000, loss: 2.7609
2023-07-01 18:48:45 - train: epoch 0050, iter [00150, 00390], lr: 0.100000, loss: 2.7505
2023-07-01 18:48:48 - train: epoch 0050, iter [00200, 00390], lr: 0.100000, loss: 2.6807
2023-07-01 18:48:50 - train: epoch 0050, iter [00250, 00390], lr: 0.100000, loss: 2.7849
2023-07-01 18:48:52 - train: epoch 0050, iter [00300, 00390], lr: 0.100000, loss: 3.0081
2023-07-01 18:48:54 - train: epoch 0050, iter [00350, 00390], lr: 0.100000, loss: 2.8221
2023-07-01 18:48:56 - train: epoch 050, train_loss: 2.8381
2023-07-01 18:48:58 - eval: epoch: 050, acc1: 29.880%, acc5: 60.590%, test_loss: 2.8164, per_image_load_time: 0.064ms, per_image_inference_time: 0.085ms
2023-07-01 18:48:59 - until epoch: 050, best_acc1: 29.880%
2023-07-01 18:48:59 - epoch 051 lr: 0.100000
2023-07-01 18:49:02 - train: epoch 0051, iter [00050, 00390], lr: 0.100000, loss: 3.1469
2023-07-01 18:49:04 - train: epoch 0051, iter [00100, 00390], lr: 0.100000, loss: 2.6969
2023-07-01 18:49:06 - train: epoch 0051, iter [00150, 00390], lr: 0.100000, loss: 2.6584
2023-07-01 18:49:08 - train: epoch 0051, iter [00200, 00390], lr: 0.100000, loss: 2.7332
2023-07-01 18:49:11 - train: epoch 0051, iter [00250, 00390], lr: 0.100000, loss: 2.8898
2023-07-01 18:49:13 - train: epoch 0051, iter [00300, 00390], lr: 0.100000, loss: 2.5860
2023-07-01 18:49:15 - train: epoch 0051, iter [00350, 00390], lr: 0.100000, loss: 2.8175
2023-07-01 18:49:17 - train: epoch 051, train_loss: 2.8272
2023-07-01 18:49:18 - eval: epoch: 051, acc1: 29.680%, acc5: 59.780%, test_loss: 2.8085, per_image_load_time: 0.054ms, per_image_inference_time: 0.084ms
2023-07-01 18:49:19 - until epoch: 051, best_acc1: 29.880%
2023-07-01 18:49:19 - epoch 052 lr: 0.100000
2023-07-01 18:49:22 - train: epoch 0052, iter [00050, 00390], lr: 0.100000, loss: 2.9370
2023-07-01 18:49:24 - train: epoch 0052, iter [00100, 00390], lr: 0.100000, loss: 2.9463
2023-07-01 18:49:26 - train: epoch 0052, iter [00150, 00390], lr: 0.100000, loss: 2.9783
2023-07-01 18:49:28 - train: epoch 0052, iter [00200, 00390], lr: 0.100000, loss: 2.9258
2023-07-01 18:49:31 - train: epoch 0052, iter [00250, 00390], lr: 0.100000, loss: 2.7546
2023-07-01 18:49:33 - train: epoch 0052, iter [00300, 00390], lr: 0.100000, loss: 2.8975
2023-07-01 18:49:35 - train: epoch 0052, iter [00350, 00390], lr: 0.100000, loss: 3.0154
2023-07-01 18:49:37 - train: epoch 052, train_loss: 2.8364
2023-07-01 18:49:38 - eval: epoch: 052, acc1: 28.940%, acc5: 58.830%, test_loss: 2.8407, per_image_load_time: 0.056ms, per_image_inference_time: 0.084ms
2023-07-01 18:49:39 - until epoch: 052, best_acc1: 29.880%
2023-07-01 18:49:39 - epoch 053 lr: 0.100000
2023-07-01 18:49:42 - train: epoch 0053, iter [00050, 00390], lr: 0.100000, loss: 2.6448
2023-07-01 18:49:44 - train: epoch 0053, iter [00100, 00390], lr: 0.100000, loss: 2.6834
2023-07-01 18:49:46 - train: epoch 0053, iter [00150, 00390], lr: 0.100000, loss: 2.6956
2023-07-01 18:49:49 - train: epoch 0053, iter [00200, 00390], lr: 0.100000, loss: 2.7630
2023-07-01 18:49:51 - train: epoch 0053, iter [00250, 00390], lr: 0.100000, loss: 2.7959
2023-07-01 18:49:53 - train: epoch 0053, iter [00300, 00390], lr: 0.100000, loss: 2.5714
2023-07-01 18:49:55 - train: epoch 0053, iter [00350, 00390], lr: 0.100000, loss: 2.6536
2023-07-01 18:49:57 - train: epoch 053, train_loss: 2.8225
2023-07-01 18:49:59 - eval: epoch: 053, acc1: 29.670%, acc5: 59.750%, test_loss: 2.8217, per_image_load_time: 0.055ms, per_image_inference_time: 0.083ms
2023-07-01 18:50:52 - network: vit_tiny_patch16
2023-07-01 18:50:52 - num_classes: 100
2023-07-01 18:50:52 - input_image_size: 32
2023-07-01 18:50:52 - trained_model_path: 
2023-07-01 18:50:52 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 18:50:52 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 18:50:52 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fd236693520>
2023-07-01 18:50:52 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fd236693490>
2023-07-01 18:50:52 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fd236693580>
2023-07-01 18:50:52 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fd2366935b0>
2023-07-01 18:50:52 - seed: 0
2023-07-01 18:50:52 - batch_size: 128
2023-07-01 18:50:52 - num_workers: 16
2023-07-01 18:50:52 - accumulation_steps: 1
2023-07-01 18:50:52 - optimizer: ('AdamW', {'lr': 0.001, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-01 18:50:52 - scheduler: ('CosineLR', {'min_lr': 1e-05})
2023-07-01 18:50:52 - epochs: 200
2023-07-01 18:50:52 - print_interval: 50
2023-07-01 18:50:52 - sync_bn: False
2023-07-01 18:50:52 - apex: True
2023-07-01 18:50:52 - use_ema_model: False
2023-07-01 18:50:52 - ema_model_decay: 0.9999
2023-07-01 18:50:52 - AUG: none
2023-07-01 18:50:52 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-01 18:50:52 - gpus_num: 1
2023-07-01 18:50:52 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7fd2367f7cb0>
2023-07-01 18:50:52 - --------------------parameters--------------------
2023-07-01 18:50:52 - name: cls_token, grad: True
2023-07-01 18:50:52 - name: position_encoding, grad: True
2023-07-01 18:50:52 - name: patch_embedding.conv.weight, grad: True
2023-07-01 18:50:52 - name: patch_embedding.conv.bias, grad: True
2023-07-01 18:50:52 - name: blocks.0.norm1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.0.norm1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.0.attention.qkv_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.0.attention.qkv_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.0.attention.out_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.0.attention.out_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.0.norm2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.0.norm2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.0.feed_forward.fc1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.0.feed_forward.fc1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.0.feed_forward.fc2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.0.feed_forward.fc2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.1.norm1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.1.norm1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.1.attention.qkv_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.1.attention.qkv_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.1.attention.out_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.1.attention.out_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.1.norm2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.1.norm2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.1.feed_forward.fc1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.1.feed_forward.fc1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.1.feed_forward.fc2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.1.feed_forward.fc2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.2.norm1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.2.norm1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.2.attention.qkv_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.2.attention.qkv_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.2.attention.out_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.2.attention.out_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.2.norm2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.2.norm2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.2.feed_forward.fc1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.2.feed_forward.fc1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.2.feed_forward.fc2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.2.feed_forward.fc2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.3.norm1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.3.norm1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.3.attention.qkv_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.3.attention.qkv_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.3.attention.out_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.3.attention.out_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.3.norm2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.3.norm2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.3.feed_forward.fc1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.3.feed_forward.fc1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.3.feed_forward.fc2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.3.feed_forward.fc2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.4.norm1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.4.norm1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.4.attention.qkv_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.4.attention.qkv_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.4.attention.out_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.4.attention.out_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.4.norm2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.4.norm2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.4.feed_forward.fc1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.4.feed_forward.fc1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.4.feed_forward.fc2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.4.feed_forward.fc2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.5.norm1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.5.norm1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.5.attention.qkv_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.5.attention.qkv_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.5.attention.out_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.5.attention.out_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.5.norm2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.5.norm2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.5.feed_forward.fc1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.5.feed_forward.fc1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.5.feed_forward.fc2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.5.feed_forward.fc2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.6.norm1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.6.norm1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.6.attention.qkv_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.6.attention.qkv_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.6.attention.out_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.6.attention.out_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.6.norm2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.6.norm2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.6.feed_forward.fc1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.6.feed_forward.fc1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.6.feed_forward.fc2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.6.feed_forward.fc2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.7.norm1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.7.norm1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.7.attention.qkv_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.7.attention.qkv_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.7.attention.out_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.7.attention.out_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.7.norm2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.7.norm2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.7.feed_forward.fc1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.7.feed_forward.fc1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.7.feed_forward.fc2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.7.feed_forward.fc2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.8.norm1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.8.norm1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.8.attention.qkv_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.8.attention.qkv_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.8.attention.out_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.8.attention.out_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.8.norm2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.8.norm2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.8.feed_forward.fc1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.8.feed_forward.fc1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.8.feed_forward.fc2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.8.feed_forward.fc2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.9.norm1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.9.norm1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.9.attention.qkv_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.9.attention.qkv_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.9.attention.out_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.9.attention.out_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.9.norm2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.9.norm2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.9.feed_forward.fc1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.9.feed_forward.fc1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.9.feed_forward.fc2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.9.feed_forward.fc2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.10.norm1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.10.norm1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.10.attention.qkv_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.10.attention.qkv_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.10.attention.out_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.10.attention.out_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.10.norm2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.10.norm2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.10.feed_forward.fc1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.10.feed_forward.fc1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.10.feed_forward.fc2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.10.feed_forward.fc2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.11.norm1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.11.norm1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.11.attention.qkv_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.11.attention.qkv_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.11.attention.out_linear.weight, grad: True
2023-07-01 18:50:52 - name: blocks.11.attention.out_linear.bias, grad: True
2023-07-01 18:50:52 - name: blocks.11.norm2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.11.norm2.bias, grad: True
2023-07-01 18:50:52 - name: blocks.11.feed_forward.fc1.weight, grad: True
2023-07-01 18:50:52 - name: blocks.11.feed_forward.fc1.bias, grad: True
2023-07-01 18:50:52 - name: blocks.11.feed_forward.fc2.weight, grad: True
2023-07-01 18:50:52 - name: blocks.11.feed_forward.fc2.bias, grad: True
2023-07-01 18:50:52 - name: norm.weight, grad: True
2023-07-01 18:50:52 - name: norm.bias, grad: True
2023-07-01 18:50:52 - name: fc.weight, grad: True
2023-07-01 18:50:52 - name: fc.bias, grad: True
2023-07-01 18:50:52 - --------------------buffers--------------------
2023-07-01 18:50:52 - -----------no weight decay layers--------------
2023-07-01 18:50:52 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.7.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.7.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.7.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.7.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.7.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.7.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.7.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.7.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.8.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.8.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.8.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.8.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.8.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.8.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.8.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.8.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.9.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.9.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.9.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.9.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.9.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.9.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.9.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.9.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.10.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.10.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.10.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.10.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.10.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.10.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.10.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.10.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.11.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.11.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.11.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.11.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.11.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.11.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.11.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.11.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: norm.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: norm.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:50:52 - -------------weight decay layers---------------
2023-07-01 18:50:52 - name: cls_token, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: position_encoding, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: patch_embedding.conv.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.7.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.7.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.7.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.7.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.8.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.8.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.8.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.8.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.9.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.9.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.9.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.9.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.10.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.10.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.10.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.10.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.11.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.11.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.11.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: blocks.11.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:50:52 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:19 - network: vit_tiny_patch16
2023-07-01 18:52:19 - num_classes: 100
2023-07-01 18:52:19 - input_image_size: 32
2023-07-01 18:52:19 - trained_model_path: 
2023-07-01 18:52:19 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 18:52:19 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 18:52:19 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fc4ba18a4c0>
2023-07-01 18:52:19 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fc4ba18a6a0>
2023-07-01 18:52:19 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fc4ba18a6d0>
2023-07-01 18:52:19 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fc4ba18a730>
2023-07-01 18:52:19 - seed: 0
2023-07-01 18:52:19 - batch_size: 128
2023-07-01 18:52:19 - num_workers: 16
2023-07-01 18:52:19 - accumulation_steps: 1
2023-07-01 18:52:19 - optimizer: ('AdamW', {'lr': 0.001, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-01 18:52:19 - scheduler: ('CosineLR', {'min_lr': 1e-05, 'warm_up_epochs': 5})
2023-07-01 18:52:19 - epochs: 200
2023-07-01 18:52:19 - print_interval: 50
2023-07-01 18:52:19 - sync_bn: False
2023-07-01 18:52:19 - apex: True
2023-07-01 18:52:19 - use_ema_model: False
2023-07-01 18:52:19 - ema_model_decay: 0.9999
2023-07-01 18:52:19 - AUG: none
2023-07-01 18:52:19 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-01 18:52:19 - gpus_num: 1
2023-07-01 18:52:19 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7fc4ba2ed770>
2023-07-01 18:52:19 - --------------------parameters--------------------
2023-07-01 18:52:19 - name: cls_token, grad: True
2023-07-01 18:52:19 - name: position_encoding, grad: True
2023-07-01 18:52:19 - name: patch_embedding.conv.weight, grad: True
2023-07-01 18:52:19 - name: patch_embedding.conv.bias, grad: True
2023-07-01 18:52:19 - name: blocks.0.norm1.weight, grad: True
2023-07-01 18:52:19 - name: blocks.0.norm1.bias, grad: True
2023-07-01 18:52:19 - name: blocks.0.attention.qkv_linear.weight, grad: True
2023-07-01 18:52:19 - name: blocks.0.attention.qkv_linear.bias, grad: True
2023-07-01 18:52:19 - name: blocks.0.attention.out_linear.weight, grad: True
2023-07-01 18:52:19 - name: blocks.0.attention.out_linear.bias, grad: True
2023-07-01 18:52:19 - name: blocks.0.norm2.weight, grad: True
2023-07-01 18:52:19 - name: blocks.0.norm2.bias, grad: True
2023-07-01 18:52:19 - name: blocks.0.feed_forward.fc1.weight, grad: True
2023-07-01 18:52:19 - name: blocks.0.feed_forward.fc1.bias, grad: True
2023-07-01 18:52:19 - name: blocks.0.feed_forward.fc2.weight, grad: True
2023-07-01 18:52:19 - name: blocks.0.feed_forward.fc2.bias, grad: True
2023-07-01 18:52:19 - name: blocks.1.norm1.weight, grad: True
2023-07-01 18:52:19 - name: blocks.1.norm1.bias, grad: True
2023-07-01 18:52:19 - name: blocks.1.attention.qkv_linear.weight, grad: True
2023-07-01 18:52:19 - name: blocks.1.attention.qkv_linear.bias, grad: True
2023-07-01 18:52:19 - name: blocks.1.attention.out_linear.weight, grad: True
2023-07-01 18:52:19 - name: blocks.1.attention.out_linear.bias, grad: True
2023-07-01 18:52:19 - name: blocks.1.norm2.weight, grad: True
2023-07-01 18:52:19 - name: blocks.1.norm2.bias, grad: True
2023-07-01 18:52:19 - name: blocks.1.feed_forward.fc1.weight, grad: True
2023-07-01 18:52:19 - name: blocks.1.feed_forward.fc1.bias, grad: True
2023-07-01 18:52:19 - name: blocks.1.feed_forward.fc2.weight, grad: True
2023-07-01 18:52:19 - name: blocks.1.feed_forward.fc2.bias, grad: True
2023-07-01 18:52:19 - name: blocks.2.norm1.weight, grad: True
2023-07-01 18:52:19 - name: blocks.2.norm1.bias, grad: True
2023-07-01 18:52:19 - name: blocks.2.attention.qkv_linear.weight, grad: True
2023-07-01 18:52:19 - name: blocks.2.attention.qkv_linear.bias, grad: True
2023-07-01 18:52:19 - name: blocks.2.attention.out_linear.weight, grad: True
2023-07-01 18:52:19 - name: blocks.2.attention.out_linear.bias, grad: True
2023-07-01 18:52:19 - name: blocks.2.norm2.weight, grad: True
2023-07-01 18:52:19 - name: blocks.2.norm2.bias, grad: True
2023-07-01 18:52:19 - name: blocks.2.feed_forward.fc1.weight, grad: True
2023-07-01 18:52:19 - name: blocks.2.feed_forward.fc1.bias, grad: True
2023-07-01 18:52:19 - name: blocks.2.feed_forward.fc2.weight, grad: True
2023-07-01 18:52:19 - name: blocks.2.feed_forward.fc2.bias, grad: True
2023-07-01 18:52:19 - name: blocks.3.norm1.weight, grad: True
2023-07-01 18:52:19 - name: blocks.3.norm1.bias, grad: True
2023-07-01 18:52:19 - name: blocks.3.attention.qkv_linear.weight, grad: True
2023-07-01 18:52:19 - name: blocks.3.attention.qkv_linear.bias, grad: True
2023-07-01 18:52:19 - name: blocks.3.attention.out_linear.weight, grad: True
2023-07-01 18:52:19 - name: blocks.3.attention.out_linear.bias, grad: True
2023-07-01 18:52:19 - name: blocks.3.norm2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.3.norm2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.3.feed_forward.fc1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.3.feed_forward.fc1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.3.feed_forward.fc2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.3.feed_forward.fc2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.4.norm1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.4.norm1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.4.attention.qkv_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.4.attention.qkv_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.4.attention.out_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.4.attention.out_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.4.norm2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.4.norm2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.4.feed_forward.fc1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.4.feed_forward.fc1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.4.feed_forward.fc2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.4.feed_forward.fc2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.5.norm1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.5.norm1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.5.attention.qkv_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.5.attention.qkv_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.5.attention.out_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.5.attention.out_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.5.norm2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.5.norm2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.5.feed_forward.fc1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.5.feed_forward.fc1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.5.feed_forward.fc2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.5.feed_forward.fc2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.6.norm1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.6.norm1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.6.attention.qkv_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.6.attention.qkv_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.6.attention.out_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.6.attention.out_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.6.norm2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.6.norm2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.6.feed_forward.fc1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.6.feed_forward.fc1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.6.feed_forward.fc2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.6.feed_forward.fc2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.7.norm1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.7.norm1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.7.attention.qkv_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.7.attention.qkv_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.7.attention.out_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.7.attention.out_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.7.norm2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.7.norm2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.7.feed_forward.fc1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.7.feed_forward.fc1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.7.feed_forward.fc2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.7.feed_forward.fc2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.8.norm1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.8.norm1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.8.attention.qkv_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.8.attention.qkv_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.8.attention.out_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.8.attention.out_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.8.norm2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.8.norm2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.8.feed_forward.fc1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.8.feed_forward.fc1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.8.feed_forward.fc2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.8.feed_forward.fc2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.9.norm1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.9.norm1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.9.attention.qkv_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.9.attention.qkv_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.9.attention.out_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.9.attention.out_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.9.norm2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.9.norm2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.9.feed_forward.fc1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.9.feed_forward.fc1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.9.feed_forward.fc2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.9.feed_forward.fc2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.10.norm1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.10.norm1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.10.attention.qkv_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.10.attention.qkv_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.10.attention.out_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.10.attention.out_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.10.norm2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.10.norm2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.10.feed_forward.fc1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.10.feed_forward.fc1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.10.feed_forward.fc2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.10.feed_forward.fc2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.11.norm1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.11.norm1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.11.attention.qkv_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.11.attention.qkv_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.11.attention.out_linear.weight, grad: True
2023-07-01 18:52:20 - name: blocks.11.attention.out_linear.bias, grad: True
2023-07-01 18:52:20 - name: blocks.11.norm2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.11.norm2.bias, grad: True
2023-07-01 18:52:20 - name: blocks.11.feed_forward.fc1.weight, grad: True
2023-07-01 18:52:20 - name: blocks.11.feed_forward.fc1.bias, grad: True
2023-07-01 18:52:20 - name: blocks.11.feed_forward.fc2.weight, grad: True
2023-07-01 18:52:20 - name: blocks.11.feed_forward.fc2.bias, grad: True
2023-07-01 18:52:20 - name: norm.weight, grad: True
2023-07-01 18:52:20 - name: norm.bias, grad: True
2023-07-01 18:52:20 - name: fc.weight, grad: True
2023-07-01 18:52:20 - name: fc.bias, grad: True
2023-07-01 18:52:20 - --------------------buffers--------------------
2023-07-01 18:52:20 - -----------no weight decay layers--------------
2023-07-01 18:52:20 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.7.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.7.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.7.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.7.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.7.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.7.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.7.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.7.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.8.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.8.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.8.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.8.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.8.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.8.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.8.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.8.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.9.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.9.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.9.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.9.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.9.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.9.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.9.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.9.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.10.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.10.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.10.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.10.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.10.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.10.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.10.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.10.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.11.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.11.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.11.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.11.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.11.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.11.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.11.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.11.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: norm.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: norm.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 18:52:20 - -------------weight decay layers---------------
2023-07-01 18:52:20 - name: cls_token, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: position_encoding, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: patch_embedding.conv.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.7.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.7.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.7.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.7.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.8.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.8.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.8.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.8.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.9.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.9.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.9.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.9.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.10.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.10.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.10.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.10.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.11.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.11.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.11.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: blocks.11.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 18:52:20 - epoch 001 lr: 0.001000
2023-07-01 18:52:28 - train: epoch 0001, iter [00050, 00390], lr: 0.000026, loss: 4.5704
2023-07-01 18:52:30 - train: epoch 0001, iter [00100, 00390], lr: 0.000051, loss: 4.5330
2023-07-01 18:52:33 - train: epoch 0001, iter [00150, 00390], lr: 0.000077, loss: 4.4405
2023-07-01 18:52:36 - train: epoch 0001, iter [00200, 00390], lr: 0.000103, loss: 4.3474
2023-07-01 18:52:38 - train: epoch 0001, iter [00250, 00390], lr: 0.000128, loss: 4.2677
2023-07-01 18:52:41 - train: epoch 0001, iter [00300, 00390], lr: 0.000154, loss: 4.2235
2023-07-01 18:52:43 - train: epoch 0001, iter [00350, 00390], lr: 0.000179, loss: 4.1322
2023-07-01 18:52:45 - train: epoch 001, train_loss: 4.3744
2023-07-01 18:52:47 - eval: epoch: 001, acc1: 6.930%, acc5: 24.730%, test_loss: 4.0963, per_image_load_time: 0.068ms, per_image_inference_time: 0.082ms
2023-07-01 18:52:48 - until epoch: 001, best_acc1: 6.930%
2023-07-01 18:52:48 - epoch 002 lr: 0.000200
2023-07-01 18:52:51 - train: epoch 0002, iter [00050, 00390], lr: 0.000226, loss: 4.0912
2023-07-01 18:52:53 - train: epoch 0002, iter [00100, 00390], lr: 0.000251, loss: 4.1180
2023-07-01 18:52:56 - train: epoch 0002, iter [00150, 00390], lr: 0.000277, loss: 4.0864
2023-07-01 18:52:58 - train: epoch 0002, iter [00200, 00390], lr: 0.000303, loss: 4.0991
2023-07-01 18:53:01 - train: epoch 0002, iter [00250, 00390], lr: 0.000328, loss: 3.9170
2023-07-01 18:53:04 - train: epoch 0002, iter [00300, 00390], lr: 0.000354, loss: 4.1006
2023-07-01 18:53:06 - train: epoch 0002, iter [00350, 00390], lr: 0.000379, loss: 3.8759
2023-07-01 18:53:08 - train: epoch 002, train_loss: 3.9967
2023-07-01 18:53:10 - eval: epoch: 002, acc1: 9.820%, acc5: 30.350%, test_loss: 3.8658, per_image_load_time: 0.065ms, per_image_inference_time: 0.080ms
2023-07-01 18:53:10 - until epoch: 002, best_acc1: 9.820%
2023-07-01 18:53:10 - epoch 003 lr: 0.000400
2023-07-01 18:53:13 - train: epoch 0003, iter [00050, 00390], lr: 0.000426, loss: 3.8213
2023-07-01 18:53:16 - train: epoch 0003, iter [00100, 00390], lr: 0.000451, loss: 3.7513
2023-07-01 18:53:18 - train: epoch 0003, iter [00150, 00390], lr: 0.000477, loss: 3.9218
2023-07-01 18:53:21 - train: epoch 0003, iter [00200, 00390], lr: 0.000503, loss: 3.6451
2023-07-01 18:53:24 - train: epoch 0003, iter [00250, 00390], lr: 0.000528, loss: 3.9231
2023-07-01 18:53:26 - train: epoch 0003, iter [00300, 00390], lr: 0.000554, loss: 3.8145
2023-07-01 18:53:29 - train: epoch 0003, iter [00350, 00390], lr: 0.000579, loss: 3.8063
2023-07-01 18:53:31 - train: epoch 003, train_loss: 3.7886
2023-07-01 18:53:32 - eval: epoch: 003, acc1: 13.110%, acc5: 36.870%, test_loss: 3.6639, per_image_load_time: 0.068ms, per_image_inference_time: 0.080ms
2023-07-01 18:53:33 - until epoch: 003, best_acc1: 13.110%
2023-07-01 18:53:33 - epoch 004 lr: 0.000600
2023-07-01 18:53:37 - train: epoch 0004, iter [00050, 00390], lr: 0.000626, loss: 3.6062
2023-07-01 18:53:39 - train: epoch 0004, iter [00100, 00390], lr: 0.000651, loss: 3.8751
2023-07-01 18:53:42 - train: epoch 0004, iter [00150, 00390], lr: 0.000677, loss: 3.7547
2023-07-01 18:53:45 - train: epoch 0004, iter [00200, 00390], lr: 0.000703, loss: 3.7146
2023-07-01 18:53:47 - train: epoch 0004, iter [00250, 00390], lr: 0.000728, loss: 3.4428
2023-07-01 18:53:50 - train: epoch 0004, iter [00300, 00390], lr: 0.000754, loss: 3.7207
2023-07-01 18:53:52 - train: epoch 0004, iter [00350, 00390], lr: 0.000779, loss: 3.4139
2023-07-01 18:53:54 - train: epoch 004, train_loss: 3.6569
2023-07-01 18:53:56 - eval: epoch: 004, acc1: 15.250%, acc5: 39.990%, test_loss: 3.5531, per_image_load_time: 0.073ms, per_image_inference_time: 0.082ms
2023-07-01 18:53:57 - until epoch: 004, best_acc1: 15.250%
2023-07-01 18:53:57 - epoch 005 lr: 0.000800
2023-07-01 18:54:00 - train: epoch 0005, iter [00050, 00390], lr: 0.000826, loss: 3.5696
2023-07-01 18:54:03 - train: epoch 0005, iter [00100, 00390], lr: 0.000851, loss: 3.3759
2023-07-01 18:54:05 - train: epoch 0005, iter [00150, 00390], lr: 0.000877, loss: 3.4113
2023-07-01 18:54:08 - train: epoch 0005, iter [00200, 00390], lr: 0.000903, loss: 3.6346
2023-07-01 18:54:10 - train: epoch 0005, iter [00250, 00390], lr: 0.000928, loss: 3.4512
2023-07-01 18:54:13 - train: epoch 0005, iter [00300, 00390], lr: 0.000954, loss: 3.4153
2023-07-01 18:54:15 - train: epoch 0005, iter [00350, 00390], lr: 0.000979, loss: 3.3907
2023-07-01 18:54:17 - train: epoch 005, train_loss: 3.5602
2023-07-01 18:54:19 - eval: epoch: 005, acc1: 16.690%, acc5: 42.760%, test_loss: 3.4864, per_image_load_time: 0.070ms, per_image_inference_time: 0.083ms
2023-07-01 18:54:20 - until epoch: 005, best_acc1: 16.690%
2023-07-01 18:54:20 - epoch 006 lr: 0.001000
2023-07-01 18:54:24 - train: epoch 0006, iter [00050, 00390], lr: 0.001000, loss: 3.4667
2023-07-01 18:54:26 - train: epoch 0006, iter [00100, 00390], lr: 0.001000, loss: 3.4047
2023-07-01 18:54:29 - train: epoch 0006, iter [00150, 00390], lr: 0.001000, loss: 3.5549
2023-07-01 18:54:31 - train: epoch 0006, iter [00200, 00390], lr: 0.001000, loss: 3.2623
2023-07-01 18:54:34 - train: epoch 0006, iter [00250, 00390], lr: 0.001000, loss: 3.4133
2023-07-01 18:54:36 - train: epoch 0006, iter [00300, 00390], lr: 0.001000, loss: 3.3276
2023-07-01 18:54:39 - train: epoch 0006, iter [00350, 00390], lr: 0.001000, loss: 3.5366
2023-07-01 18:54:41 - train: epoch 006, train_loss: 3.4598
2023-07-01 18:54:43 - eval: epoch: 006, acc1: 19.290%, acc5: 45.950%, test_loss: 3.3510, per_image_load_time: 0.079ms, per_image_inference_time: 0.082ms
2023-07-01 18:54:44 - until epoch: 006, best_acc1: 19.290%
2023-07-01 18:54:44 - epoch 007 lr: 0.001000
2023-07-01 18:54:48 - train: epoch 0007, iter [00050, 00390], lr: 0.001000, loss: 3.3954
2023-07-01 18:54:50 - train: epoch 0007, iter [00100, 00390], lr: 0.001000, loss: 3.4615
2023-07-01 18:54:53 - train: epoch 0007, iter [00150, 00390], lr: 0.001000, loss: 3.3265
2023-07-01 18:54:55 - train: epoch 0007, iter [00200, 00390], lr: 0.001000, loss: 3.2934
2023-07-01 18:54:58 - train: epoch 0007, iter [00250, 00390], lr: 0.001000, loss: 3.2226
2023-07-01 18:55:00 - train: epoch 0007, iter [00300, 00390], lr: 0.001000, loss: 3.0790
2023-07-01 18:55:03 - train: epoch 0007, iter [00350, 00390], lr: 0.001000, loss: 3.2016
2023-07-01 18:55:05 - train: epoch 007, train_loss: 3.3664
2023-07-01 18:55:07 - eval: epoch: 007, acc1: 20.720%, acc5: 48.700%, test_loss: 3.2748, per_image_load_time: 0.066ms, per_image_inference_time: 0.082ms
2023-07-01 18:55:08 - until epoch: 007, best_acc1: 20.720%
2023-07-01 18:55:08 - epoch 008 lr: 0.001000
2023-07-01 18:55:11 - train: epoch 0008, iter [00050, 00390], lr: 0.001000, loss: 3.4672
2023-07-01 18:55:14 - train: epoch 0008, iter [00100, 00390], lr: 0.001000, loss: 3.3244
2023-07-01 18:55:16 - train: epoch 0008, iter [00150, 00390], lr: 0.001000, loss: 3.2842
2023-07-01 18:55:19 - train: epoch 0008, iter [00200, 00390], lr: 0.001000, loss: 3.1254
2023-07-01 18:55:22 - train: epoch 0008, iter [00250, 00390], lr: 0.001000, loss: 3.0970
2023-07-01 18:55:24 - train: epoch 0008, iter [00300, 00390], lr: 0.001000, loss: 3.1980
2023-07-01 18:55:27 - train: epoch 0008, iter [00350, 00390], lr: 0.000999, loss: 3.1749
2023-07-01 18:55:29 - train: epoch 008, train_loss: 3.2681
2023-07-01 18:55:30 - eval: epoch: 008, acc1: 21.740%, acc5: 49.960%, test_loss: 3.2102, per_image_load_time: 0.069ms, per_image_inference_time: 0.084ms
2023-07-01 18:55:31 - until epoch: 008, best_acc1: 21.740%
2023-07-01 18:55:31 - epoch 009 lr: 0.000999
2023-07-01 18:55:34 - train: epoch 0009, iter [00050, 00390], lr: 0.000999, loss: 3.0575
2023-07-01 18:55:37 - train: epoch 0009, iter [00100, 00390], lr: 0.000999, loss: 3.3740
2023-07-01 18:55:40 - train: epoch 0009, iter [00150, 00390], lr: 0.000999, loss: 3.0251
2023-07-01 18:55:42 - train: epoch 0009, iter [00200, 00390], lr: 0.000999, loss: 3.2855
2023-07-01 18:55:45 - train: epoch 0009, iter [00250, 00390], lr: 0.000999, loss: 3.2369
2023-07-01 18:55:47 - train: epoch 0009, iter [00300, 00390], lr: 0.000999, loss: 3.2996
2023-07-01 18:55:50 - train: epoch 0009, iter [00350, 00390], lr: 0.000999, loss: 3.4246
2023-07-01 18:55:52 - train: epoch 009, train_loss: 3.1908
2023-07-01 18:55:53 - eval: epoch: 009, acc1: 23.690%, acc5: 51.750%, test_loss: 3.1310, per_image_load_time: 0.068ms, per_image_inference_time: 0.082ms
2023-07-01 18:55:54 - until epoch: 009, best_acc1: 23.690%
2023-07-01 18:55:54 - epoch 010 lr: 0.000999
2023-07-01 18:55:57 - train: epoch 0010, iter [00050, 00390], lr: 0.000999, loss: 3.3084
2023-07-01 18:56:00 - train: epoch 0010, iter [00100, 00390], lr: 0.000999, loss: 3.1484
2023-07-01 18:56:03 - train: epoch 0010, iter [00150, 00390], lr: 0.000999, loss: 3.0942
2023-07-01 18:56:06 - train: epoch 0010, iter [00200, 00390], lr: 0.000999, loss: 3.1395
2023-07-01 18:56:08 - train: epoch 0010, iter [00250, 00390], lr: 0.000999, loss: 3.1374
2023-07-01 18:56:11 - train: epoch 0010, iter [00300, 00390], lr: 0.000999, loss: 2.7611
2023-07-01 18:56:13 - train: epoch 0010, iter [00350, 00390], lr: 0.000998, loss: 3.0382
2023-07-01 18:56:15 - train: epoch 010, train_loss: 3.1202
2023-07-01 18:56:17 - eval: epoch: 010, acc1: 24.350%, acc5: 53.480%, test_loss: 3.0774, per_image_load_time: 0.071ms, per_image_inference_time: 0.082ms
2023-07-01 18:56:18 - until epoch: 010, best_acc1: 24.350%
2023-07-01 18:56:18 - epoch 011 lr: 0.000998
2023-07-01 18:56:21 - train: epoch 0011, iter [00050, 00390], lr: 0.000998, loss: 3.1591
2023-07-01 18:56:24 - train: epoch 0011, iter [00100, 00390], lr: 0.000998, loss: 2.8613
2023-07-01 18:56:26 - train: epoch 0011, iter [00150, 00390], lr: 0.000998, loss: 3.0652
2023-07-01 18:56:29 - train: epoch 0011, iter [00200, 00390], lr: 0.000998, loss: 3.1207
2023-07-01 18:56:32 - train: epoch 0011, iter [00250, 00390], lr: 0.000998, loss: 2.9116
2023-07-01 18:56:34 - train: epoch 0011, iter [00300, 00390], lr: 0.000998, loss: 2.8589
2023-07-01 18:56:37 - train: epoch 0011, iter [00350, 00390], lr: 0.000998, loss: 3.0686
2023-07-01 18:56:39 - train: epoch 011, train_loss: 3.0533
2023-07-01 18:56:41 - eval: epoch: 011, acc1: 25.380%, acc5: 54.170%, test_loss: 3.0412, per_image_load_time: 0.069ms, per_image_inference_time: 0.120ms
2023-07-01 18:56:42 - until epoch: 011, best_acc1: 25.380%
2023-07-01 18:56:42 - epoch 012 lr: 0.000998
2023-07-01 18:56:46 - train: epoch 0012, iter [00050, 00390], lr: 0.000998, loss: 2.8581
2023-07-01 18:56:48 - train: epoch 0012, iter [00100, 00390], lr: 0.000997, loss: 3.0942
2023-07-01 18:56:51 - train: epoch 0012, iter [00150, 00390], lr: 0.000997, loss: 3.1325
2023-07-01 18:56:54 - train: epoch 0012, iter [00200, 00390], lr: 0.000997, loss: 3.1228
2023-07-01 18:56:56 - train: epoch 0012, iter [00250, 00390], lr: 0.000997, loss: 2.8988
2023-07-01 18:56:59 - train: epoch 0012, iter [00300, 00390], lr: 0.000997, loss: 3.0220
2023-07-01 18:57:01 - train: epoch 0012, iter [00350, 00390], lr: 0.000997, loss: 3.0201
2023-07-01 18:57:04 - train: epoch 012, train_loss: 2.9895
2023-07-01 18:57:05 - eval: epoch: 012, acc1: 26.560%, acc5: 55.670%, test_loss: 2.9809, per_image_load_time: 0.066ms, per_image_inference_time: 0.081ms
2023-07-01 18:57:06 - until epoch: 012, best_acc1: 26.560%
2023-07-01 18:57:06 - epoch 013 lr: 0.000997
2023-07-01 18:57:09 - train: epoch 0013, iter [00050, 00390], lr: 0.000997, loss: 2.8598
2023-07-01 18:57:11 - train: epoch 0013, iter [00100, 00390], lr: 0.000997, loss: 3.0414
2023-07-01 18:57:14 - train: epoch 0013, iter [00150, 00390], lr: 0.000997, loss: 2.9626
2023-07-01 18:57:17 - train: epoch 0013, iter [00200, 00390], lr: 0.000996, loss: 2.8996
2023-07-01 18:57:19 - train: epoch 0013, iter [00250, 00390], lr: 0.000996, loss: 2.8897
2023-07-01 18:57:22 - train: epoch 0013, iter [00300, 00390], lr: 0.000996, loss: 3.0319
2023-07-01 18:57:24 - train: epoch 0013, iter [00350, 00390], lr: 0.000996, loss: 2.6695
2023-07-01 18:57:26 - train: epoch 013, train_loss: 2.9359
2023-07-01 18:57:28 - eval: epoch: 013, acc1: 27.910%, acc5: 56.920%, test_loss: 2.9376, per_image_load_time: 0.068ms, per_image_inference_time: 0.083ms
2023-07-01 18:57:29 - until epoch: 013, best_acc1: 27.910%
2023-07-01 18:57:29 - epoch 014 lr: 0.000996
2023-07-01 18:57:32 - train: epoch 0014, iter [00050, 00390], lr: 0.000996, loss: 2.8965
2023-07-01 18:57:35 - train: epoch 0014, iter [00100, 00390], lr: 0.000996, loss: 2.6995
2023-07-01 18:57:37 - train: epoch 0014, iter [00150, 00390], lr: 0.000995, loss: 2.7233
2023-07-01 18:57:40 - train: epoch 0014, iter [00200, 00390], lr: 0.000995, loss: 2.8259
2023-07-01 18:57:43 - train: epoch 0014, iter [00250, 00390], lr: 0.000995, loss: 2.8631
2023-07-01 18:57:45 - train: epoch 0014, iter [00300, 00390], lr: 0.000995, loss: 2.9011
2023-07-01 18:57:48 - train: epoch 0014, iter [00350, 00390], lr: 0.000995, loss: 2.9177
2023-07-01 18:57:50 - train: epoch 014, train_loss: 2.8662
2023-07-01 18:57:52 - eval: epoch: 014, acc1: 28.380%, acc5: 57.380%, test_loss: 2.9045, per_image_load_time: 0.074ms, per_image_inference_time: 0.080ms
2023-07-01 18:57:53 - until epoch: 014, best_acc1: 28.380%
2023-07-01 18:57:53 - epoch 015 lr: 0.000995
2023-07-01 18:57:56 - train: epoch 0015, iter [00050, 00390], lr: 0.000995, loss: 2.3948
2023-07-01 18:57:59 - train: epoch 0015, iter [00100, 00390], lr: 0.000995, loss: 3.0805
2023-07-01 18:58:02 - train: epoch 0015, iter [00150, 00390], lr: 0.000994, loss: 3.0972
2023-07-01 18:58:04 - train: epoch 0015, iter [00200, 00390], lr: 0.000994, loss: 2.6713
2023-07-01 18:58:07 - train: epoch 0015, iter [00250, 00390], lr: 0.000994, loss: 2.7169
2023-07-01 18:58:09 - train: epoch 0015, iter [00300, 00390], lr: 0.000994, loss: 2.6177
2023-07-01 18:58:12 - train: epoch 0015, iter [00350, 00390], lr: 0.000994, loss: 2.6598
2023-07-01 18:58:14 - train: epoch 015, train_loss: 2.8046
2023-07-01 18:58:15 - eval: epoch: 015, acc1: 28.410%, acc5: 58.140%, test_loss: 2.8849, per_image_load_time: 0.068ms, per_image_inference_time: 0.081ms
2023-07-01 18:58:16 - until epoch: 015, best_acc1: 28.410%
2023-07-01 18:58:16 - epoch 016 lr: 0.000994
2023-07-01 18:58:19 - train: epoch 0016, iter [00050, 00390], lr: 0.000993, loss: 2.8428
2023-07-01 18:58:22 - train: epoch 0016, iter [00100, 00390], lr: 0.000993, loss: 2.6518
2023-07-01 18:58:24 - train: epoch 0016, iter [00150, 00390], lr: 0.000993, loss: 2.8644
2023-07-01 18:58:27 - train: epoch 0016, iter [00200, 00390], lr: 0.000993, loss: 2.9348
2023-07-01 18:58:29 - train: epoch 0016, iter [00250, 00390], lr: 0.000993, loss: 2.5125
2023-07-01 18:58:32 - train: epoch 0016, iter [00300, 00390], lr: 0.000993, loss: 2.8267
2023-07-01 18:58:34 - train: epoch 0016, iter [00350, 00390], lr: 0.000992, loss: 2.6238
2023-07-01 18:58:37 - train: epoch 016, train_loss: 2.7412
2023-07-01 18:58:38 - eval: epoch: 016, acc1: 29.430%, acc5: 59.200%, test_loss: 2.8537, per_image_load_time: 0.069ms, per_image_inference_time: 0.080ms
2023-07-01 18:58:39 - until epoch: 016, best_acc1: 29.430%
2023-07-01 18:58:39 - epoch 017 lr: 0.000992
2023-07-01 18:58:43 - train: epoch 0017, iter [00050, 00390], lr: 0.000992, loss: 2.8384
2023-07-01 18:58:45 - train: epoch 0017, iter [00100, 00390], lr: 0.000992, loss: 2.8807
2023-07-01 18:58:48 - train: epoch 0017, iter [00150, 00390], lr: 0.000992, loss: 2.2454
2023-07-01 18:58:50 - train: epoch 0017, iter [00200, 00390], lr: 0.000992, loss: 2.9190
2023-07-01 18:58:53 - train: epoch 0017, iter [00250, 00390], lr: 0.000991, loss: 2.7489
2023-07-01 18:58:55 - train: epoch 0017, iter [00300, 00390], lr: 0.000991, loss: 2.9471
2023-07-01 18:58:58 - train: epoch 0017, iter [00350, 00390], lr: 0.000991, loss: 2.4673
2023-07-01 18:59:00 - train: epoch 017, train_loss: 2.6822
2023-07-01 18:59:02 - eval: epoch: 017, acc1: 30.850%, acc5: 60.280%, test_loss: 2.8018, per_image_load_time: 0.069ms, per_image_inference_time: 0.081ms
2023-07-01 18:59:02 - until epoch: 017, best_acc1: 30.850%
2023-07-01 18:59:02 - epoch 018 lr: 0.000991
2023-07-01 18:59:06 - train: epoch 0018, iter [00050, 00390], lr: 0.000991, loss: 2.5235
2023-07-01 18:59:08 - train: epoch 0018, iter [00100, 00390], lr: 0.000990, loss: 2.7356
2023-07-01 18:59:11 - train: epoch 0018, iter [00150, 00390], lr: 0.000990, loss: 2.8581
2023-07-01 18:59:13 - train: epoch 0018, iter [00200, 00390], lr: 0.000990, loss: 2.6741
2023-07-01 18:59:16 - train: epoch 0018, iter [00250, 00390], lr: 0.000990, loss: 2.5751
2023-07-01 18:59:18 - train: epoch 0018, iter [00300, 00390], lr: 0.000990, loss: 2.7791
2023-07-01 18:59:21 - train: epoch 0018, iter [00350, 00390], lr: 0.000989, loss: 2.6526
2023-07-01 18:59:23 - train: epoch 018, train_loss: 2.6131
2023-07-01 18:59:25 - eval: epoch: 018, acc1: 31.230%, acc5: 61.310%, test_loss: 2.7756, per_image_load_time: 0.068ms, per_image_inference_time: 0.080ms
2023-07-01 18:59:26 - until epoch: 018, best_acc1: 31.230%
2023-07-01 18:59:26 - epoch 019 lr: 0.000989
2023-07-01 18:59:30 - train: epoch 0019, iter [00050, 00390], lr: 0.000989, loss: 2.3302
2023-07-01 18:59:32 - train: epoch 0019, iter [00100, 00390], lr: 0.000989, loss: 2.4776
2023-07-01 18:59:35 - train: epoch 0019, iter [00150, 00390], lr: 0.000989, loss: 2.7232
2023-07-01 18:59:37 - train: epoch 0019, iter [00200, 00390], lr: 0.000988, loss: 2.5376
2023-07-01 18:59:40 - train: epoch 0019, iter [00250, 00390], lr: 0.000988, loss: 2.7514
2023-07-01 18:59:42 - train: epoch 0019, iter [00300, 00390], lr: 0.000988, loss: 2.8541
2023-07-01 18:59:45 - train: epoch 0019, iter [00350, 00390], lr: 0.000988, loss: 2.4296
2023-07-01 18:59:47 - train: epoch 019, train_loss: 2.5463
2023-07-01 18:59:48 - eval: epoch: 019, acc1: 31.890%, acc5: 61.060%, test_loss: 2.7679, per_image_load_time: 0.065ms, per_image_inference_time: 0.082ms
2023-07-01 18:59:49 - until epoch: 019, best_acc1: 31.890%
2023-07-01 18:59:49 - epoch 020 lr: 0.000987
2023-07-01 18:59:52 - train: epoch 0020, iter [00050, 00390], lr: 0.000987, loss: 2.4624
2023-07-01 18:59:55 - train: epoch 0020, iter [00100, 00390], lr: 0.000987, loss: 2.5213
2023-07-01 18:59:57 - train: epoch 0020, iter [00150, 00390], lr: 0.000987, loss: 2.4248
2023-07-01 19:00:00 - train: epoch 0020, iter [00200, 00390], lr: 0.000987, loss: 2.5741
2023-07-01 19:00:03 - train: epoch 0020, iter [00250, 00390], lr: 0.000986, loss: 2.5327
2023-07-01 19:00:05 - train: epoch 0020, iter [00300, 00390], lr: 0.000986, loss: 2.5426
2023-07-01 19:00:08 - train: epoch 0020, iter [00350, 00390], lr: 0.000986, loss: 2.4866
2023-07-01 19:00:10 - train: epoch 020, train_loss: 2.4774
2023-07-01 19:00:11 - eval: epoch: 020, acc1: 32.470%, acc5: 61.580%, test_loss: 2.7591, per_image_load_time: 0.067ms, per_image_inference_time: 0.083ms
2023-07-01 19:00:13 - until epoch: 020, best_acc1: 32.470%
2023-07-01 19:00:13 - epoch 021 lr: 0.000986
2023-07-01 19:00:16 - train: epoch 0021, iter [00050, 00390], lr: 0.000985, loss: 2.3633
2023-07-01 19:00:19 - train: epoch 0021, iter [00100, 00390], lr: 0.000985, loss: 2.5114
2023-07-01 19:00:21 - train: epoch 0021, iter [00150, 00390], lr: 0.000985, loss: 2.3788
2023-07-01 19:00:24 - train: epoch 0021, iter [00200, 00390], lr: 0.000985, loss: 2.7158
2023-07-01 19:00:27 - train: epoch 0021, iter [00250, 00390], lr: 0.000984, loss: 2.6138
2023-07-01 19:00:29 - train: epoch 0021, iter [00300, 00390], lr: 0.000984, loss: 2.4536
2023-07-01 19:00:32 - train: epoch 0021, iter [00350, 00390], lr: 0.000984, loss: 2.3374
2023-07-01 19:00:34 - train: epoch 021, train_loss: 2.4077
2023-07-01 19:00:35 - eval: epoch: 021, acc1: 32.670%, acc5: 61.800%, test_loss: 2.7420, per_image_load_time: 0.066ms, per_image_inference_time: 0.081ms
2023-07-01 19:00:36 - until epoch: 021, best_acc1: 32.670%
2023-07-01 19:00:36 - epoch 022 lr: 0.000984
2023-07-01 19:00:39 - train: epoch 0022, iter [00050, 00390], lr: 0.000983, loss: 2.2992
2023-07-01 19:00:41 - train: epoch 0022, iter [00100, 00390], lr: 0.000983, loss: 2.2391
2023-07-01 19:00:44 - train: epoch 0022, iter [00150, 00390], lr: 0.000983, loss: 2.5013
2023-07-01 19:00:47 - train: epoch 0022, iter [00200, 00390], lr: 0.000983, loss: 2.4891
2023-07-01 19:00:49 - train: epoch 0022, iter [00250, 00390], lr: 0.000982, loss: 2.4829
2023-07-01 19:00:52 - train: epoch 0022, iter [00300, 00390], lr: 0.000982, loss: 2.2911
2023-07-01 19:00:54 - train: epoch 0022, iter [00350, 00390], lr: 0.000982, loss: 2.2691
2023-07-01 19:00:56 - train: epoch 022, train_loss: 2.3254
2023-07-01 19:00:58 - eval: epoch: 022, acc1: 32.420%, acc5: 61.870%, test_loss: 2.7526, per_image_load_time: 0.072ms, per_image_inference_time: 0.086ms
2023-07-01 19:00:58 - until epoch: 022, best_acc1: 32.670%
2023-07-01 19:00:58 - epoch 023 lr: 0.000982
2023-07-01 19:01:02 - train: epoch 0023, iter [00050, 00390], lr: 0.000981, loss: 2.1236
2023-07-01 19:01:04 - train: epoch 0023, iter [00100, 00390], lr: 0.000981, loss: 2.3110
2023-07-01 19:01:07 - train: epoch 0023, iter [00150, 00390], lr: 0.000981, loss: 2.1814
2023-07-01 19:01:09 - train: epoch 0023, iter [00200, 00390], lr: 0.000980, loss: 2.4219
2023-07-01 19:01:12 - train: epoch 0023, iter [00250, 00390], lr: 0.000980, loss: 2.3109
2023-07-01 19:01:14 - train: epoch 0023, iter [00300, 00390], lr: 0.000980, loss: 2.4999
2023-07-01 19:01:17 - train: epoch 0023, iter [00350, 00390], lr: 0.000980, loss: 2.1059
2023-07-01 19:01:19 - train: epoch 023, train_loss: 2.2515
2023-07-01 19:01:21 - eval: epoch: 023, acc1: 33.560%, acc5: 62.700%, test_loss: 2.7220, per_image_load_time: 0.070ms, per_image_inference_time: 0.081ms
2023-07-01 19:01:22 - until epoch: 023, best_acc1: 33.560%
2023-07-01 19:01:22 - epoch 024 lr: 0.000979
2023-07-01 19:01:25 - train: epoch 0024, iter [00050, 00390], lr: 0.000979, loss: 2.0853
2023-07-01 19:01:28 - train: epoch 0024, iter [00100, 00390], lr: 0.000979, loss: 2.0805
2023-07-01 19:01:30 - train: epoch 0024, iter [00150, 00390], lr: 0.000978, loss: 1.8747
2023-07-01 19:01:33 - train: epoch 0024, iter [00200, 00390], lr: 0.000978, loss: 2.4111
2023-07-01 19:01:35 - train: epoch 0024, iter [00250, 00390], lr: 0.000978, loss: 2.2818
2023-07-01 19:01:38 - train: epoch 0024, iter [00300, 00390], lr: 0.000978, loss: 2.1088
2023-07-01 19:01:40 - train: epoch 0024, iter [00350, 00390], lr: 0.000977, loss: 2.2542
2023-07-01 19:01:42 - train: epoch 024, train_loss: 2.1764
2023-07-01 19:01:44 - eval: epoch: 024, acc1: 33.190%, acc5: 62.550%, test_loss: 2.7494, per_image_load_time: 0.085ms, per_image_inference_time: 0.082ms
2023-07-01 19:01:45 - until epoch: 024, best_acc1: 33.560%
2023-07-01 19:01:45 - epoch 025 lr: 0.000977
2023-07-01 19:01:49 - train: epoch 0025, iter [00050, 00390], lr: 0.000977, loss: 2.0037
2023-07-01 19:01:51 - train: epoch 0025, iter [00100, 00390], lr: 0.000976, loss: 1.8603
2023-07-01 19:01:54 - train: epoch 0025, iter [00150, 00390], lr: 0.000976, loss: 2.1982
2023-07-01 19:01:56 - train: epoch 0025, iter [00200, 00390], lr: 0.000976, loss: 2.0276
2023-07-01 19:01:59 - train: epoch 0025, iter [00250, 00390], lr: 0.000975, loss: 2.0980
2023-07-01 19:02:01 - train: epoch 0025, iter [00300, 00390], lr: 0.000975, loss: 2.1765
2023-07-01 19:02:04 - train: epoch 0025, iter [00350, 00390], lr: 0.000975, loss: 1.9709
2023-07-01 19:02:06 - train: epoch 025, train_loss: 2.0936
2023-07-01 19:02:08 - eval: epoch: 025, acc1: 33.960%, acc5: 63.050%, test_loss: 2.7524, per_image_load_time: 0.069ms, per_image_inference_time: 0.081ms
2023-07-01 19:02:08 - until epoch: 025, best_acc1: 33.960%
2023-07-01 19:02:08 - epoch 026 lr: 0.000975
2023-07-01 19:02:12 - train: epoch 0026, iter [00050, 00390], lr: 0.000974, loss: 1.8178
2023-07-01 19:02:14 - train: epoch 0026, iter [00100, 00390], lr: 0.000974, loss: 1.9824
2023-07-01 19:02:17 - train: epoch 0026, iter [00150, 00390], lr: 0.000974, loss: 1.9850
2023-07-01 19:02:19 - train: epoch 0026, iter [00200, 00390], lr: 0.000973, loss: 2.1180
2023-07-01 19:02:22 - train: epoch 0026, iter [00250, 00390], lr: 0.000973, loss: 1.9332
2023-07-01 19:02:24 - train: epoch 0026, iter [00300, 00390], lr: 0.000973, loss: 2.0100
2023-07-01 19:02:27 - train: epoch 0026, iter [00350, 00390], lr: 0.000972, loss: 2.1150
2023-07-01 19:02:29 - train: epoch 026, train_loss: 2.0052
2023-07-01 19:02:31 - eval: epoch: 026, acc1: 33.550%, acc5: 63.450%, test_loss: 2.7789, per_image_load_time: 0.066ms, per_image_inference_time: 0.081ms
2023-07-01 19:02:31 - until epoch: 026, best_acc1: 33.960%
2023-07-01 19:02:31 - epoch 027 lr: 0.000972
2023-07-01 19:02:34 - train: epoch 0027, iter [00050, 00390], lr: 0.000972, loss: 1.9259
2023-07-01 19:02:37 - train: epoch 0027, iter [00100, 00390], lr: 0.000971, loss: 1.9462
2023-07-01 19:02:39 - train: epoch 0027, iter [00150, 00390], lr: 0.000971, loss: 1.9315
2023-07-01 19:02:42 - train: epoch 0027, iter [00200, 00390], lr: 0.000971, loss: 2.1334
2023-07-01 19:02:44 - train: epoch 0027, iter [00250, 00390], lr: 0.000970, loss: 2.1519
2023-07-01 19:02:47 - train: epoch 0027, iter [00300, 00390], lr: 0.000970, loss: 1.9227
2023-07-01 19:02:49 - train: epoch 0027, iter [00350, 00390], lr: 0.000970, loss: 2.0755
2023-07-01 19:02:52 - train: epoch 027, train_loss: 1.9291
2023-07-01 19:02:53 - eval: epoch: 027, acc1: 34.700%, acc5: 63.290%, test_loss: 2.7967, per_image_load_time: 0.068ms, per_image_inference_time: 0.087ms
2023-07-01 19:02:54 - until epoch: 027, best_acc1: 34.700%
2023-07-01 19:02:54 - epoch 028 lr: 0.000969
2023-07-01 19:02:57 - train: epoch 0028, iter [00050, 00390], lr: 0.000969, loss: 1.7827
2023-07-01 19:02:59 - train: epoch 0028, iter [00100, 00390], lr: 0.000969, loss: 1.7164
2023-07-01 19:03:02 - train: epoch 0028, iter [00150, 00390], lr: 0.000968, loss: 1.8898
2023-07-01 19:03:05 - train: epoch 0028, iter [00200, 00390], lr: 0.000968, loss: 2.0753
2023-07-01 19:03:07 - train: epoch 0028, iter [00250, 00390], lr: 0.000967, loss: 1.8305
2023-07-01 19:03:10 - train: epoch 0028, iter [00300, 00390], lr: 0.000967, loss: 1.9961
2023-07-01 19:03:13 - train: epoch 0028, iter [00350, 00390], lr: 0.000967, loss: 2.0225
2023-07-01 19:03:15 - train: epoch 028, train_loss: 1.8381
2023-07-01 19:03:16 - eval: epoch: 028, acc1: 34.090%, acc5: 63.130%, test_loss: 2.8026, per_image_load_time: 0.068ms, per_image_inference_time: 0.081ms
2023-07-01 19:03:17 - until epoch: 028, best_acc1: 34.700%
2023-07-01 19:03:17 - epoch 029 lr: 0.000966
2023-07-01 19:03:20 - train: epoch 0029, iter [00050, 00390], lr: 0.000966, loss: 1.7198
2023-07-01 19:03:23 - train: epoch 0029, iter [00100, 00390], lr: 0.000966, loss: 1.6072
2023-07-01 19:03:25 - train: epoch 0029, iter [00150, 00390], lr: 0.000965, loss: 1.9230
2023-07-01 19:03:28 - train: epoch 0029, iter [00200, 00390], lr: 0.000965, loss: 1.7080
2023-07-01 19:03:30 - train: epoch 0029, iter [00250, 00390], lr: 0.000965, loss: 1.6959
2023-07-01 19:03:33 - train: epoch 0029, iter [00300, 00390], lr: 0.000964, loss: 1.9361
2023-07-01 19:03:35 - train: epoch 0029, iter [00350, 00390], lr: 0.000964, loss: 1.8110
2023-07-01 19:03:38 - train: epoch 029, train_loss: 1.7513
2023-07-01 19:03:39 - eval: epoch: 029, acc1: 34.370%, acc5: 63.150%, test_loss: 2.8513, per_image_load_time: 0.067ms, per_image_inference_time: 0.081ms
2023-07-01 19:03:40 - until epoch: 029, best_acc1: 34.700%
2023-07-01 19:03:40 - epoch 030 lr: 0.000963
2023-07-01 19:03:43 - train: epoch 0030, iter [00050, 00390], lr: 0.000963, loss: 1.4860
2023-07-01 19:03:46 - train: epoch 0030, iter [00100, 00390], lr: 0.000963, loss: 1.3911
2023-07-01 19:03:49 - train: epoch 0030, iter [00150, 00390], lr: 0.000962, loss: 1.5460
2023-07-01 19:03:51 - train: epoch 0030, iter [00200, 00390], lr: 0.000962, loss: 1.5054
2023-07-01 19:03:54 - train: epoch 0030, iter [00250, 00390], lr: 0.000962, loss: 1.6334
2023-07-01 19:03:56 - train: epoch 0030, iter [00300, 00390], lr: 0.000961, loss: 1.7731
2023-07-01 19:03:59 - train: epoch 0030, iter [00350, 00390], lr: 0.000961, loss: 1.6419
2023-07-01 19:04:01 - train: epoch 030, train_loss: 1.6671
2023-07-01 19:04:03 - eval: epoch: 030, acc1: 34.290%, acc5: 63.240%, test_loss: 2.8764, per_image_load_time: 0.075ms, per_image_inference_time: 0.081ms
2023-07-01 19:04:03 - until epoch: 030, best_acc1: 34.700%
2023-07-01 19:04:03 - epoch 031 lr: 0.000960
2023-07-01 19:04:06 - train: epoch 0031, iter [00050, 00390], lr: 0.000960, loss: 1.5571
2023-07-01 19:04:09 - train: epoch 0031, iter [00100, 00390], lr: 0.000960, loss: 1.8578
2023-07-01 19:04:11 - train: epoch 0031, iter [00150, 00390], lr: 0.000959, loss: 1.6444
2023-07-01 19:04:14 - train: epoch 0031, iter [00200, 00390], lr: 0.000959, loss: 1.7207
2023-07-01 19:04:17 - train: epoch 0031, iter [00250, 00390], lr: 0.000958, loss: 1.7400
2023-07-01 19:04:19 - train: epoch 0031, iter [00300, 00390], lr: 0.000958, loss: 1.7311
2023-07-01 19:04:22 - train: epoch 0031, iter [00350, 00390], lr: 0.000958, loss: 1.4969
2023-07-01 19:04:24 - train: epoch 031, train_loss: 1.5859
2023-07-01 19:04:25 - eval: epoch: 031, acc1: 34.700%, acc5: 63.380%, test_loss: 2.9224, per_image_load_time: 0.070ms, per_image_inference_time: 0.082ms
2023-07-01 19:04:26 - until epoch: 031, best_acc1: 34.700%
2023-07-01 19:04:26 - epoch 032 lr: 0.000957
2023-07-01 19:04:29 - train: epoch 0032, iter [00050, 00390], lr: 0.000957, loss: 1.5825
2023-07-01 19:04:32 - train: epoch 0032, iter [00100, 00390], lr: 0.000956, loss: 1.6752
2023-07-01 19:04:34 - train: epoch 0032, iter [00150, 00390], lr: 0.000956, loss: 1.3877
2023-07-01 19:04:37 - train: epoch 0032, iter [00200, 00390], lr: 0.000956, loss: 1.3803
2023-07-01 19:04:40 - train: epoch 0032, iter [00250, 00390], lr: 0.000955, loss: 1.5798
2023-07-01 19:04:42 - train: epoch 0032, iter [00300, 00390], lr: 0.000955, loss: 1.6653
2023-07-01 19:04:45 - train: epoch 0032, iter [00350, 00390], lr: 0.000954, loss: 1.3519
2023-07-01 19:04:47 - train: epoch 032, train_loss: 1.4946
2023-07-01 19:04:48 - eval: epoch: 032, acc1: 34.470%, acc5: 62.870%, test_loss: 3.0159, per_image_load_time: 0.067ms, per_image_inference_time: 0.080ms
2023-07-01 19:04:49 - until epoch: 032, best_acc1: 34.700%
2023-07-01 19:04:49 - epoch 033 lr: 0.000954
2023-07-01 19:04:52 - train: epoch 0033, iter [00050, 00390], lr: 0.000953, loss: 1.2869
2023-07-01 19:04:55 - train: epoch 0033, iter [00100, 00390], lr: 0.000953, loss: 1.2519
2023-07-01 19:04:57 - train: epoch 0033, iter [00150, 00390], lr: 0.000953, loss: 1.3687
2023-07-01 19:05:00 - train: epoch 0033, iter [00200, 00390], lr: 0.000952, loss: 1.5054
2023-07-01 19:05:02 - train: epoch 0033, iter [00250, 00390], lr: 0.000952, loss: 1.5524
2023-07-01 19:05:05 - train: epoch 0033, iter [00300, 00390], lr: 0.000951, loss: 1.7923
2023-07-01 19:05:07 - train: epoch 0033, iter [00350, 00390], lr: 0.000951, loss: 1.3470
2023-07-01 19:05:10 - train: epoch 033, train_loss: 1.4073
2023-07-01 19:05:11 - eval: epoch: 033, acc1: 33.610%, acc5: 62.520%, test_loss: 3.0832, per_image_load_time: 0.069ms, per_image_inference_time: 0.082ms
2023-07-01 19:05:13 - until epoch: 033, best_acc1: 34.700%
2023-07-01 19:05:13 - epoch 034 lr: 0.000950
2023-07-01 19:05:16 - train: epoch 0034, iter [00050, 00390], lr: 0.000950, loss: 1.1744
2023-07-01 19:05:18 - train: epoch 0034, iter [00100, 00390], lr: 0.000950, loss: 1.3929
2023-07-01 19:05:21 - train: epoch 0034, iter [00150, 00390], lr: 0.000949, loss: 1.3663
2023-07-01 19:05:24 - train: epoch 0034, iter [00200, 00390], lr: 0.000949, loss: 1.1050
2023-07-01 19:05:26 - train: epoch 0034, iter [00250, 00390], lr: 0.000948, loss: 1.2441
2023-07-01 19:05:29 - train: epoch 0034, iter [00300, 00390], lr: 0.000948, loss: 1.1812
2023-07-01 19:05:31 - train: epoch 0034, iter [00350, 00390], lr: 0.000947, loss: 1.2201
2023-07-01 19:05:33 - train: epoch 034, train_loss: 1.3345
2023-07-01 19:05:35 - eval: epoch: 034, acc1: 34.460%, acc5: 62.890%, test_loss: 3.0640, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 19:05:36 - until epoch: 034, best_acc1: 34.700%
2023-07-01 19:05:36 - epoch 035 lr: 0.000947
2023-07-01 19:05:39 - train: epoch 0035, iter [00050, 00390], lr: 0.000946, loss: 0.8639
2023-07-01 19:05:42 - train: epoch 0035, iter [00100, 00390], lr: 0.000946, loss: 1.2837
2023-07-01 19:05:45 - train: epoch 0035, iter [00150, 00390], lr: 0.000946, loss: 1.4191
2023-07-01 19:05:47 - train: epoch 0035, iter [00200, 00390], lr: 0.000945, loss: 1.1454
2023-07-01 19:05:50 - train: epoch 0035, iter [00250, 00390], lr: 0.000945, loss: 1.1525
2023-07-01 19:05:52 - train: epoch 0035, iter [00300, 00390], lr: 0.000944, loss: 1.1877
2023-07-01 19:05:55 - train: epoch 0035, iter [00350, 00390], lr: 0.000944, loss: 1.5578
2023-07-01 19:05:57 - train: epoch 035, train_loss: 1.2534
2023-07-01 19:05:59 - eval: epoch: 035, acc1: 33.860%, acc5: 62.370%, test_loss: 3.1686, per_image_load_time: 0.080ms, per_image_inference_time: 0.081ms
2023-07-01 19:05:59 - until epoch: 035, best_acc1: 34.700%
2023-07-01 19:05:59 - epoch 036 lr: 0.000943
2023-07-01 19:06:02 - train: epoch 0036, iter [00050, 00390], lr: 0.000943, loss: 1.1130
2023-07-01 19:06:05 - train: epoch 0036, iter [00100, 00390], lr: 0.000942, loss: 1.2312
2023-07-01 19:06:08 - train: epoch 0036, iter [00150, 00390], lr: 0.000942, loss: 1.2285
2023-07-01 19:06:11 - train: epoch 0036, iter [00200, 00390], lr: 0.000941, loss: 1.0899
2023-07-01 19:06:13 - train: epoch 0036, iter [00250, 00390], lr: 0.000941, loss: 1.2986
2023-07-01 19:06:16 - train: epoch 0036, iter [00300, 00390], lr: 0.000940, loss: 1.4023
2023-07-01 19:06:19 - train: epoch 0036, iter [00350, 00390], lr: 0.000940, loss: 1.0796
2023-07-01 19:06:21 - train: epoch 036, train_loss: 1.1846
2023-07-01 19:06:22 - eval: epoch: 036, acc1: 34.040%, acc5: 62.010%, test_loss: 3.2778, per_image_load_time: 0.074ms, per_image_inference_time: 0.080ms
2023-07-01 19:06:24 - until epoch: 036, best_acc1: 34.700%
2023-07-01 19:06:24 - epoch 037 lr: 0.000940
2023-07-01 19:06:27 - train: epoch 0037, iter [00050, 00390], lr: 0.000939, loss: 1.1142
2023-07-01 19:06:30 - train: epoch 0037, iter [00100, 00390], lr: 0.000939, loss: 0.9277
2023-07-01 19:06:32 - train: epoch 0037, iter [00150, 00390], lr: 0.000938, loss: 1.2111
2023-07-01 19:06:35 - train: epoch 0037, iter [00200, 00390], lr: 0.000938, loss: 1.2284
2023-07-01 19:06:37 - train: epoch 0037, iter [00250, 00390], lr: 0.000937, loss: 0.9688
2023-07-01 19:06:40 - train: epoch 0037, iter [00300, 00390], lr: 0.000937, loss: 1.2575
2023-07-01 19:06:42 - train: epoch 0037, iter [00350, 00390], lr: 0.000936, loss: 1.2260
2023-07-01 19:06:44 - train: epoch 037, train_loss: 1.1029
2023-07-01 19:06:46 - eval: epoch: 037, acc1: 34.120%, acc5: 61.740%, test_loss: 3.3009, per_image_load_time: 0.070ms, per_image_inference_time: 0.082ms
2023-07-01 19:06:47 - until epoch: 037, best_acc1: 34.700%
2023-07-01 19:06:47 - epoch 038 lr: 0.000936
2023-07-01 19:06:50 - train: epoch 0038, iter [00050, 00390], lr: 0.000935, loss: 0.7347
2023-07-01 19:06:53 - train: epoch 0038, iter [00100, 00390], lr: 0.000935, loss: 1.0746
2023-07-01 19:06:56 - train: epoch 0038, iter [00150, 00390], lr: 0.000934, loss: 1.0753
2023-07-01 19:06:58 - train: epoch 0038, iter [00200, 00390], lr: 0.000934, loss: 1.0588
2023-07-01 19:07:01 - train: epoch 0038, iter [00250, 00390], lr: 0.000933, loss: 1.3678
2023-07-01 19:07:04 - train: epoch 0038, iter [00300, 00390], lr: 0.000933, loss: 1.1439
2023-07-01 19:07:06 - train: epoch 0038, iter [00350, 00390], lr: 0.000932, loss: 1.0810
2023-07-01 19:07:08 - train: epoch 038, train_loss: 1.0412
2023-07-01 19:07:10 - eval: epoch: 038, acc1: 33.820%, acc5: 61.620%, test_loss: 3.4309, per_image_load_time: 0.067ms, per_image_inference_time: 0.083ms
2023-07-01 19:07:11 - until epoch: 038, best_acc1: 34.700%
2023-07-01 19:07:11 - epoch 039 lr: 0.000932
2023-07-01 19:07:15 - train: epoch 0039, iter [00050, 00390], lr: 0.000931, loss: 0.8895
2023-07-01 19:07:17 - train: epoch 0039, iter [00100, 00390], lr: 0.000931, loss: 1.0856
2023-07-01 19:07:20 - train: epoch 0039, iter [00150, 00390], lr: 0.000930, loss: 0.8288
2023-07-01 19:07:22 - train: epoch 0039, iter [00200, 00390], lr: 0.000930, loss: 0.8354
2023-07-01 19:07:25 - train: epoch 0039, iter [00250, 00390], lr: 0.000929, loss: 0.8388
2023-07-01 19:07:27 - train: epoch 0039, iter [00300, 00390], lr: 0.000929, loss: 0.8854
2023-07-01 19:07:30 - train: epoch 0039, iter [00350, 00390], lr: 0.000928, loss: 1.0382
2023-07-01 19:07:32 - train: epoch 039, train_loss: 0.9862
2023-07-01 19:07:34 - eval: epoch: 039, acc1: 34.360%, acc5: 61.990%, test_loss: 3.3716, per_image_load_time: 0.067ms, per_image_inference_time: 0.083ms
2023-07-01 19:07:34 - until epoch: 039, best_acc1: 34.700%
2023-07-01 19:07:34 - epoch 040 lr: 0.000928
2023-07-01 19:07:38 - train: epoch 0040, iter [00050, 00390], lr: 0.000927, loss: 0.9654
2023-07-01 19:07:40 - train: epoch 0040, iter [00100, 00390], lr: 0.000927, loss: 0.7768
2023-07-01 19:07:43 - train: epoch 0040, iter [00150, 00390], lr: 0.000926, loss: 0.9474
2023-07-01 19:07:45 - train: epoch 0040, iter [00200, 00390], lr: 0.000925, loss: 0.9179
2023-07-01 19:07:48 - train: epoch 0040, iter [00250, 00390], lr: 0.000925, loss: 0.8159
2023-07-01 19:07:50 - train: epoch 0040, iter [00300, 00390], lr: 0.000924, loss: 0.8421
2023-07-01 19:07:53 - train: epoch 0040, iter [00350, 00390], lr: 0.000924, loss: 1.1523
2023-07-01 19:07:55 - train: epoch 040, train_loss: 0.9297
2023-07-01 19:07:57 - eval: epoch: 040, acc1: 34.090%, acc5: 61.580%, test_loss: 3.5336, per_image_load_time: 0.073ms, per_image_inference_time: 0.082ms
2023-07-01 19:07:58 - until epoch: 040, best_acc1: 34.700%
2023-07-01 19:07:58 - epoch 041 lr: 0.000923
2023-07-01 19:08:01 - train: epoch 0041, iter [00050, 00390], lr: 0.000923, loss: 0.8545
2023-07-01 19:08:04 - train: epoch 0041, iter [00100, 00390], lr: 0.000922, loss: 0.7453
2023-07-01 19:08:06 - train: epoch 0041, iter [00150, 00390], lr: 0.000922, loss: 0.9157
2023-07-01 19:08:09 - train: epoch 0041, iter [00200, 00390], lr: 0.000921, loss: 0.9697
2023-07-01 19:08:11 - train: epoch 0041, iter [00250, 00390], lr: 0.000921, loss: 1.0313
2023-07-01 19:08:14 - train: epoch 0041, iter [00300, 00390], lr: 0.000920, loss: 1.0081
2023-07-01 19:08:16 - train: epoch 0041, iter [00350, 00390], lr: 0.000920, loss: 0.9778
2023-07-01 19:08:18 - train: epoch 041, train_loss: 0.8755
2023-07-01 19:08:20 - eval: epoch: 041, acc1: 34.740%, acc5: 61.730%, test_loss: 3.5392, per_image_load_time: 0.069ms, per_image_inference_time: 0.082ms
2023-07-01 19:08:20 - until epoch: 041, best_acc1: 34.740%
2023-07-01 19:08:20 - epoch 042 lr: 0.000919
2023-07-01 19:08:24 - train: epoch 0042, iter [00050, 00390], lr: 0.000918, loss: 0.5118
2023-07-01 19:08:27 - train: epoch 0042, iter [00100, 00390], lr: 0.000918, loss: 0.7842
2023-07-01 19:08:29 - train: epoch 0042, iter [00150, 00390], lr: 0.000917, loss: 0.6902
2023-07-01 19:08:32 - train: epoch 0042, iter [00200, 00390], lr: 0.000917, loss: 0.8475
2023-07-01 19:08:35 - train: epoch 0042, iter [00250, 00390], lr: 0.000916, loss: 0.8283
2023-07-01 19:08:38 - train: epoch 0042, iter [00300, 00390], lr: 0.000916, loss: 0.6167
2023-07-01 19:08:41 - train: epoch 0042, iter [00350, 00390], lr: 0.000915, loss: 0.8050
2023-07-01 19:08:43 - train: epoch 042, train_loss: 0.8219
2023-07-01 19:08:44 - eval: epoch: 042, acc1: 34.000%, acc5: 61.660%, test_loss: 3.6678, per_image_load_time: 0.074ms, per_image_inference_time: 0.081ms
2023-07-01 19:08:45 - until epoch: 042, best_acc1: 34.740%
2023-07-01 19:08:45 - epoch 043 lr: 0.000915
2023-07-01 19:08:48 - train: epoch 0043, iter [00050, 00390], lr: 0.000914, loss: 0.6797
2023-07-01 19:08:51 - train: epoch 0043, iter [00100, 00390], lr: 0.000913, loss: 0.4890
2023-07-01 19:08:54 - train: epoch 0043, iter [00150, 00390], lr: 0.000913, loss: 0.7106
2023-07-01 19:08:56 - train: epoch 0043, iter [00200, 00390], lr: 0.000912, loss: 0.6675
2023-07-01 19:08:59 - train: epoch 0043, iter [00250, 00390], lr: 0.000912, loss: 0.9053
2023-07-01 19:09:01 - train: epoch 0043, iter [00300, 00390], lr: 0.000911, loss: 0.7680
2023-07-01 19:09:04 - train: epoch 0043, iter [00350, 00390], lr: 0.000911, loss: 0.7494
2023-07-01 19:09:06 - train: epoch 043, train_loss: 0.7676
2023-07-01 19:09:08 - eval: epoch: 043, acc1: 33.850%, acc5: 60.670%, test_loss: 3.7582, per_image_load_time: 0.073ms, per_image_inference_time: 0.082ms
2023-07-01 19:09:08 - until epoch: 043, best_acc1: 34.740%
2023-07-01 19:09:08 - epoch 044 lr: 0.000910
2023-07-01 19:09:12 - train: epoch 0044, iter [00050, 00390], lr: 0.000910, loss: 0.6941
2023-07-01 19:09:15 - train: epoch 0044, iter [00100, 00390], lr: 0.000909, loss: 0.7751
2023-07-01 19:09:18 - train: epoch 0044, iter [00150, 00390], lr: 0.000908, loss: 0.7147
2023-07-01 19:09:20 - train: epoch 0044, iter [00200, 00390], lr: 0.000908, loss: 0.7916
2023-07-01 19:09:23 - train: epoch 0044, iter [00250, 00390], lr: 0.000907, loss: 0.8993
2023-07-01 19:09:26 - train: epoch 0044, iter [00300, 00390], lr: 0.000907, loss: 0.5651
2023-07-01 19:09:29 - train: epoch 0044, iter [00350, 00390], lr: 0.000906, loss: 0.7830
2023-07-01 19:09:31 - train: epoch 044, train_loss: 0.7374
2023-07-01 19:09:33 - eval: epoch: 044, acc1: 34.150%, acc5: 61.390%, test_loss: 3.6951, per_image_load_time: 0.085ms, per_image_inference_time: 0.083ms
2023-07-01 19:09:33 - until epoch: 044, best_acc1: 34.740%
2023-07-01 19:09:33 - epoch 045 lr: 0.000905
2023-07-01 19:09:37 - train: epoch 0045, iter [00050, 00390], lr: 0.000905, loss: 0.5914
2023-07-01 19:09:40 - train: epoch 0045, iter [00100, 00390], lr: 0.000904, loss: 0.5794
2023-07-01 19:09:42 - train: epoch 0045, iter [00150, 00390], lr: 0.000904, loss: 0.8495
2023-07-01 19:09:45 - train: epoch 0045, iter [00200, 00390], lr: 0.000903, loss: 0.7669
2023-07-01 19:09:48 - train: epoch 0045, iter [00250, 00390], lr: 0.000902, loss: 0.6602
2023-07-01 19:09:50 - train: epoch 0045, iter [00300, 00390], lr: 0.000902, loss: 0.7053
2023-07-01 19:09:53 - train: epoch 0045, iter [00350, 00390], lr: 0.000901, loss: 0.7427
2023-07-01 19:09:55 - train: epoch 045, train_loss: 0.6862
2023-07-01 19:09:57 - eval: epoch: 045, acc1: 34.560%, acc5: 61.140%, test_loss: 3.8725, per_image_load_time: 0.086ms, per_image_inference_time: 0.084ms
2023-07-01 19:09:58 - until epoch: 045, best_acc1: 34.740%
2023-07-01 19:09:58 - epoch 046 lr: 0.000901
2023-07-01 19:10:01 - train: epoch 0046, iter [00050, 00390], lr: 0.000900, loss: 0.5757
2023-07-01 19:10:04 - train: epoch 0046, iter [00100, 00390], lr: 0.000899, loss: 0.4929
2023-07-01 19:10:07 - train: epoch 0046, iter [00150, 00390], lr: 0.000899, loss: 0.5460
2023-07-01 19:10:09 - train: epoch 0046, iter [00200, 00390], lr: 0.000898, loss: 0.5592
2023-07-01 19:10:12 - train: epoch 0046, iter [00250, 00390], lr: 0.000898, loss: 0.8116
2023-07-01 19:10:15 - train: epoch 0046, iter [00300, 00390], lr: 0.000897, loss: 0.6176
2023-07-01 19:10:17 - train: epoch 0046, iter [00350, 00390], lr: 0.000896, loss: 0.5514
2023-07-01 19:10:20 - train: epoch 046, train_loss: 0.6625
2023-07-01 19:10:21 - eval: epoch: 046, acc1: 34.110%, acc5: 61.420%, test_loss: 3.8658, per_image_load_time: 0.081ms, per_image_inference_time: 0.082ms
2023-07-01 19:10:22 - until epoch: 046, best_acc1: 34.740%
2023-07-01 19:10:22 - epoch 047 lr: 0.000896
2023-07-01 19:10:25 - train: epoch 0047, iter [00050, 00390], lr: 0.000895, loss: 0.5413
2023-07-01 19:10:28 - train: epoch 0047, iter [00100, 00390], lr: 0.000895, loss: 0.4216
2023-07-01 19:10:31 - train: epoch 0047, iter [00150, 00390], lr: 0.000894, loss: 0.5003
2023-07-01 19:10:34 - train: epoch 0047, iter [00200, 00390], lr: 0.000893, loss: 0.5208
2023-07-01 19:10:37 - train: epoch 0047, iter [00250, 00390], lr: 0.000893, loss: 0.6895
2023-07-01 19:10:40 - train: epoch 0047, iter [00300, 00390], lr: 0.000892, loss: 0.8284
2023-07-01 19:10:43 - train: epoch 0047, iter [00350, 00390], lr: 0.000891, loss: 0.7300
2023-07-01 19:10:45 - train: epoch 047, train_loss: 0.6211
2023-07-01 19:10:47 - eval: epoch: 047, acc1: 33.840%, acc5: 60.260%, test_loss: 4.0084, per_image_load_time: 0.083ms, per_image_inference_time: 0.085ms
2023-07-01 19:10:47 - until epoch: 047, best_acc1: 34.740%
2023-07-01 19:10:47 - epoch 048 lr: 0.000891
2023-07-01 19:10:51 - train: epoch 0048, iter [00050, 00390], lr: 0.000890, loss: 0.5173
2023-07-01 19:10:53 - train: epoch 0048, iter [00100, 00390], lr: 0.000890, loss: 0.5935
2023-07-01 19:10:56 - train: epoch 0048, iter [00150, 00390], lr: 0.000889, loss: 0.5819
2023-07-01 19:10:58 - train: epoch 0048, iter [00200, 00390], lr: 0.000888, loss: 0.6091
2023-07-01 19:11:01 - train: epoch 0048, iter [00250, 00390], lr: 0.000888, loss: 0.6938
2023-07-01 19:11:03 - train: epoch 0048, iter [00300, 00390], lr: 0.000887, loss: 0.3926
2023-07-01 19:11:06 - train: epoch 0048, iter [00350, 00390], lr: 0.000886, loss: 0.4710
2023-07-01 19:11:08 - train: epoch 048, train_loss: 0.5946
2023-07-01 19:11:10 - eval: epoch: 048, acc1: 34.000%, acc5: 60.610%, test_loss: 4.0436, per_image_load_time: 0.074ms, per_image_inference_time: 0.084ms
2023-07-01 19:11:10 - until epoch: 048, best_acc1: 34.740%
2023-07-01 19:11:10 - epoch 049 lr: 0.000886
2023-07-01 19:11:14 - train: epoch 0049, iter [00050, 00390], lr: 0.000885, loss: 0.3678
2023-07-01 19:11:16 - train: epoch 0049, iter [00100, 00390], lr: 0.000885, loss: 0.4696
2023-07-01 19:11:19 - train: epoch 0049, iter [00150, 00390], lr: 0.000884, loss: 0.6040
2023-07-01 19:11:21 - train: epoch 0049, iter [00200, 00390], lr: 0.000883, loss: 0.3947
2023-07-01 19:11:24 - train: epoch 0049, iter [00250, 00390], lr: 0.000883, loss: 0.5080
2023-07-01 19:11:27 - train: epoch 0049, iter [00300, 00390], lr: 0.000882, loss: 0.5022
2023-07-01 19:11:30 - train: epoch 0049, iter [00350, 00390], lr: 0.000881, loss: 0.5848
2023-07-01 19:11:32 - train: epoch 049, train_loss: 0.5566
2023-07-01 19:11:34 - eval: epoch: 049, acc1: 34.010%, acc5: 61.220%, test_loss: 4.0956, per_image_load_time: 0.069ms, per_image_inference_time: 0.084ms
2023-07-01 19:11:34 - until epoch: 049, best_acc1: 34.740%
2023-07-01 19:11:34 - epoch 050 lr: 0.000881
2023-07-01 19:11:38 - train: epoch 0050, iter [00050, 00390], lr: 0.000880, loss: 0.5136
2023-07-01 19:11:40 - train: epoch 0050, iter [00100, 00390], lr: 0.000879, loss: 0.6533
2023-07-01 19:11:43 - train: epoch 0050, iter [00150, 00390], lr: 0.000879, loss: 0.4757
2023-07-01 19:11:45 - train: epoch 0050, iter [00200, 00390], lr: 0.000878, loss: 0.5942
2023-07-01 19:11:48 - train: epoch 0050, iter [00250, 00390], lr: 0.000877, loss: 0.3945
2023-07-01 19:11:51 - train: epoch 0050, iter [00300, 00390], lr: 0.000877, loss: 0.4499
2023-07-01 19:11:53 - train: epoch 0050, iter [00350, 00390], lr: 0.000876, loss: 0.4585
2023-07-01 19:11:56 - train: epoch 050, train_loss: 0.5502
2023-07-01 19:11:57 - eval: epoch: 050, acc1: 34.040%, acc5: 61.360%, test_loss: 4.0928, per_image_load_time: 0.074ms, per_image_inference_time: 0.082ms
2023-07-01 19:11:58 - until epoch: 050, best_acc1: 34.740%
2023-07-01 19:11:58 - epoch 051 lr: 0.000876
2023-07-01 19:12:01 - train: epoch 0051, iter [00050, 00390], lr: 0.000875, loss: 0.4348
2023-07-01 19:12:04 - train: epoch 0051, iter [00100, 00390], lr: 0.000874, loss: 0.4503
2023-07-01 19:12:06 - train: epoch 0051, iter [00150, 00390], lr: 0.000873, loss: 0.4210
2023-07-01 19:12:09 - train: epoch 0051, iter [00200, 00390], lr: 0.000873, loss: 0.5708
2023-07-01 19:12:11 - train: epoch 0051, iter [00250, 00390], lr: 0.000872, loss: 0.6867
2023-07-01 19:12:14 - train: epoch 0051, iter [00300, 00390], lr: 0.000871, loss: 0.6255
2023-07-01 19:12:17 - train: epoch 0051, iter [00350, 00390], lr: 0.000871, loss: 0.8496
2023-07-01 19:12:19 - train: epoch 051, train_loss: 0.5135
2023-07-01 19:12:21 - eval: epoch: 051, acc1: 33.510%, acc5: 60.630%, test_loss: 4.1825, per_image_load_time: 0.070ms, per_image_inference_time: 0.081ms
2023-07-01 19:12:21 - until epoch: 051, best_acc1: 34.740%
2023-07-01 19:12:21 - epoch 052 lr: 0.000870
2023-07-01 19:12:24 - train: epoch 0052, iter [00050, 00390], lr: 0.000869, loss: 0.4199
2023-07-01 19:12:27 - train: epoch 0052, iter [00100, 00390], lr: 0.000869, loss: 0.4792
2023-07-01 19:12:30 - train: epoch 0052, iter [00150, 00390], lr: 0.000868, loss: 0.4180
2023-07-01 19:12:32 - train: epoch 0052, iter [00200, 00390], lr: 0.000867, loss: 0.5154
2023-07-01 19:12:35 - train: epoch 0052, iter [00250, 00390], lr: 0.000867, loss: 0.4784
2023-07-01 19:12:37 - train: epoch 0052, iter [00300, 00390], lr: 0.000866, loss: 0.4811
2023-07-01 19:12:40 - train: epoch 0052, iter [00350, 00390], lr: 0.000865, loss: 0.5265
2023-07-01 19:12:42 - train: epoch 052, train_loss: 0.4948
2023-07-01 19:12:44 - eval: epoch: 052, acc1: 34.320%, acc5: 60.690%, test_loss: 4.2319, per_image_load_time: 0.068ms, per_image_inference_time: 0.081ms
2023-07-01 19:12:44 - until epoch: 052, best_acc1: 34.740%
2023-07-01 19:12:44 - epoch 053 lr: 0.000865
2023-07-01 19:12:48 - train: epoch 0053, iter [00050, 00390], lr: 0.000864, loss: 0.4647
2023-07-01 19:12:50 - train: epoch 0053, iter [00100, 00390], lr: 0.000863, loss: 0.4140
2023-07-01 19:12:53 - train: epoch 0053, iter [00150, 00390], lr: 0.000863, loss: 0.6129
2023-07-01 19:12:55 - train: epoch 0053, iter [00200, 00390], lr: 0.000862, loss: 0.4877
2023-07-01 19:12:58 - train: epoch 0053, iter [00250, 00390], lr: 0.000861, loss: 0.4567
2023-07-01 19:13:00 - train: epoch 0053, iter [00300, 00390], lr: 0.000861, loss: 0.4011
2023-07-01 19:13:03 - train: epoch 0053, iter [00350, 00390], lr: 0.000860, loss: 0.6112
2023-07-01 19:13:05 - train: epoch 053, train_loss: 0.4766
2023-07-01 19:13:07 - eval: epoch: 053, acc1: 33.920%, acc5: 60.390%, test_loss: 4.2900, per_image_load_time: 0.067ms, per_image_inference_time: 0.082ms
2023-07-01 19:13:08 - until epoch: 053, best_acc1: 34.740%
2023-07-01 19:13:08 - epoch 054 lr: 0.000859
2023-07-01 19:13:11 - train: epoch 0054, iter [00050, 00390], lr: 0.000859, loss: 0.4014
2023-07-01 19:13:13 - train: epoch 0054, iter [00100, 00390], lr: 0.000858, loss: 0.4512
2023-07-01 19:13:16 - train: epoch 0054, iter [00150, 00390], lr: 0.000857, loss: 0.4358
2023-07-01 19:13:18 - train: epoch 0054, iter [00200, 00390], lr: 0.000856, loss: 0.5036
2023-07-01 19:13:21 - train: epoch 0054, iter [00250, 00390], lr: 0.000856, loss: 0.5658
2023-07-01 19:13:24 - train: epoch 0054, iter [00300, 00390], lr: 0.000855, loss: 0.5756
2023-07-01 19:13:26 - train: epoch 0054, iter [00350, 00390], lr: 0.000854, loss: 0.4275
2023-07-01 19:13:28 - train: epoch 054, train_loss: 0.4531
2023-07-01 19:13:30 - eval: epoch: 054, acc1: 33.770%, acc5: 59.760%, test_loss: 4.4035, per_image_load_time: 0.071ms, per_image_inference_time: 0.081ms
2023-07-01 19:13:30 - until epoch: 054, best_acc1: 34.740%
2023-07-01 19:13:30 - epoch 055 lr: 0.000854
2023-07-01 19:13:33 - train: epoch 0055, iter [00050, 00390], lr: 0.000853, loss: 0.2810
2023-07-01 19:13:36 - train: epoch 0055, iter [00100, 00390], lr: 0.000852, loss: 0.3416
2023-07-01 19:13:39 - train: epoch 0055, iter [00150, 00390], lr: 0.000851, loss: 0.3611
2023-07-01 19:13:41 - train: epoch 0055, iter [00200, 00390], lr: 0.000851, loss: 0.5797
2023-07-01 19:13:44 - train: epoch 0055, iter [00250, 00390], lr: 0.000850, loss: 0.6007
2023-07-01 19:13:46 - train: epoch 0055, iter [00300, 00390], lr: 0.000849, loss: 0.4881
2023-07-01 19:13:49 - train: epoch 0055, iter [00350, 00390], lr: 0.000848, loss: 0.3054
2023-07-01 19:13:51 - train: epoch 055, train_loss: 0.4390
2023-07-01 19:13:53 - eval: epoch: 055, acc1: 34.570%, acc5: 61.090%, test_loss: 4.3314, per_image_load_time: 0.069ms, per_image_inference_time: 0.082ms
2023-07-01 19:13:53 - until epoch: 055, best_acc1: 34.740%
2023-07-01 19:13:53 - epoch 056 lr: 0.000848
2023-07-01 19:13:56 - train: epoch 0056, iter [00050, 00390], lr: 0.000847, loss: 0.2739
2023-07-01 19:13:59 - train: epoch 0056, iter [00100, 00390], lr: 0.000846, loss: 0.3684
2023-07-01 19:14:01 - train: epoch 0056, iter [00150, 00390], lr: 0.000846, loss: 0.3465
2023-07-01 19:14:04 - train: epoch 0056, iter [00200, 00390], lr: 0.000845, loss: 0.4106
2023-07-01 19:14:06 - train: epoch 0056, iter [00250, 00390], lr: 0.000844, loss: 0.3420
2023-07-01 19:14:09 - train: epoch 0056, iter [00300, 00390], lr: 0.000843, loss: 0.3600
2023-07-01 19:14:11 - train: epoch 0056, iter [00350, 00390], lr: 0.000843, loss: 0.4388
2023-07-01 19:14:14 - train: epoch 056, train_loss: 0.4125
2023-07-01 19:14:15 - eval: epoch: 056, acc1: 33.960%, acc5: 60.630%, test_loss: 4.4337, per_image_load_time: 0.076ms, per_image_inference_time: 0.081ms
2023-07-01 19:14:16 - until epoch: 056, best_acc1: 34.740%
2023-07-01 19:14:16 - epoch 057 lr: 0.000842
2023-07-01 19:14:20 - train: epoch 0057, iter [00050, 00390], lr: 0.000841, loss: 0.4038
2023-07-01 19:14:22 - train: epoch 0057, iter [00100, 00390], lr: 0.000841, loss: 0.3890
2023-07-01 19:14:25 - train: epoch 0057, iter [00150, 00390], lr: 0.000840, loss: 0.3289
2023-07-01 19:14:27 - train: epoch 0057, iter [00200, 00390], lr: 0.000839, loss: 0.3203
2023-07-01 19:14:30 - train: epoch 0057, iter [00250, 00390], lr: 0.000838, loss: 0.5910
2023-07-01 19:14:32 - train: epoch 0057, iter [00300, 00390], lr: 0.000838, loss: 0.5470
2023-07-01 19:14:35 - train: epoch 0057, iter [00350, 00390], lr: 0.000837, loss: 0.4191
2023-07-01 19:14:37 - train: epoch 057, train_loss: 0.3980
2023-07-01 19:14:39 - eval: epoch: 057, acc1: 34.100%, acc5: 60.560%, test_loss: 4.5251, per_image_load_time: 0.072ms, per_image_inference_time: 0.082ms
2023-07-01 19:14:40 - until epoch: 057, best_acc1: 34.740%
2023-07-01 19:14:40 - epoch 058 lr: 0.000836
2023-07-01 19:14:43 - train: epoch 0058, iter [00050, 00390], lr: 0.000835, loss: 0.4282
2023-07-01 19:14:45 - train: epoch 0058, iter [00100, 00390], lr: 0.000835, loss: 0.3810
2023-07-01 19:14:48 - train: epoch 0058, iter [00150, 00390], lr: 0.000834, loss: 0.2726
2023-07-01 19:14:51 - train: epoch 0058, iter [00200, 00390], lr: 0.000833, loss: 0.3859
2023-07-01 19:14:53 - train: epoch 0058, iter [00250, 00390], lr: 0.000832, loss: 0.5213
2023-07-01 19:14:56 - train: epoch 0058, iter [00300, 00390], lr: 0.000832, loss: 0.3353
2023-07-01 19:14:59 - train: epoch 0058, iter [00350, 00390], lr: 0.000831, loss: 0.5213
2023-07-01 19:15:01 - train: epoch 058, train_loss: 0.3838
2023-07-01 19:15:03 - eval: epoch: 058, acc1: 33.990%, acc5: 60.920%, test_loss: 4.5533, per_image_load_time: 0.071ms, per_image_inference_time: 0.082ms
2023-07-01 19:15:03 - until epoch: 058, best_acc1: 34.740%
2023-07-01 19:15:03 - epoch 059 lr: 0.000830
2023-07-01 19:15:06 - train: epoch 0059, iter [00050, 00390], lr: 0.000829, loss: 0.3867
2023-07-01 19:15:09 - train: epoch 0059, iter [00100, 00390], lr: 0.000829, loss: 0.3540
2023-07-01 19:15:11 - train: epoch 0059, iter [00150, 00390], lr: 0.000828, loss: 0.2266
2023-07-01 19:15:14 - train: epoch 0059, iter [00200, 00390], lr: 0.000827, loss: 0.3870
2023-07-01 19:15:16 - train: epoch 0059, iter [00250, 00390], lr: 0.000826, loss: 0.4985
2023-07-01 19:15:19 - train: epoch 0059, iter [00300, 00390], lr: 0.000826, loss: 0.3651
2023-07-01 19:15:21 - train: epoch 0059, iter [00350, 00390], lr: 0.000825, loss: 0.4512
2023-07-01 19:15:23 - train: epoch 059, train_loss: 0.3714
2023-07-01 19:15:25 - eval: epoch: 059, acc1: 34.340%, acc5: 60.680%, test_loss: 4.6004, per_image_load_time: 0.068ms, per_image_inference_time: 0.080ms
2023-07-01 19:15:26 - until epoch: 059, best_acc1: 34.740%
2023-07-01 19:15:26 - epoch 060 lr: 0.000824
2023-07-01 19:15:29 - train: epoch 0060, iter [00050, 00390], lr: 0.000823, loss: 0.2399
2023-07-01 19:15:31 - train: epoch 0060, iter [00100, 00390], lr: 0.000823, loss: 0.2610
2023-07-01 19:15:34 - train: epoch 0060, iter [00150, 00390], lr: 0.000822, loss: 0.2558
2023-07-01 19:15:37 - train: epoch 0060, iter [00200, 00390], lr: 0.000821, loss: 0.2998
2023-07-01 19:15:39 - train: epoch 0060, iter [00250, 00390], lr: 0.000820, loss: 0.3110
2023-07-01 19:15:42 - train: epoch 0060, iter [00300, 00390], lr: 0.000819, loss: 0.2793
2023-07-01 19:15:44 - train: epoch 0060, iter [00350, 00390], lr: 0.000819, loss: 0.4092
2023-07-01 19:15:46 - train: epoch 060, train_loss: 0.3583
2023-07-01 19:15:48 - eval: epoch: 060, acc1: 33.770%, acc5: 60.560%, test_loss: 4.6620, per_image_load_time: 0.069ms, per_image_inference_time: 0.080ms
2023-07-01 19:15:49 - until epoch: 060, best_acc1: 34.740%
2023-07-01 19:15:49 - epoch 061 lr: 0.000818
2023-07-01 19:15:52 - train: epoch 0061, iter [00050, 00390], lr: 0.000817, loss: 0.3502
2023-07-01 19:15:55 - train: epoch 0061, iter [00100, 00390], lr: 0.000816, loss: 0.2272
2023-07-01 19:15:58 - train: epoch 0061, iter [00150, 00390], lr: 0.000816, loss: 0.3811
2023-07-01 19:16:00 - train: epoch 0061, iter [00200, 00390], lr: 0.000815, loss: 0.4179
2023-07-01 19:16:03 - train: epoch 0061, iter [00250, 00390], lr: 0.000814, loss: 0.3015
2023-07-01 19:16:05 - train: epoch 0061, iter [00300, 00390], lr: 0.000813, loss: 0.3975
2023-07-01 19:16:08 - train: epoch 0061, iter [00350, 00390], lr: 0.000812, loss: 0.2877
2023-07-01 19:16:10 - train: epoch 061, train_loss: 0.3420
2023-07-01 19:16:12 - eval: epoch: 061, acc1: 34.030%, acc5: 60.180%, test_loss: 4.6593, per_image_load_time: 0.067ms, per_image_inference_time: 0.082ms
2023-07-01 19:16:12 - until epoch: 061, best_acc1: 34.740%
2023-07-01 19:16:12 - epoch 062 lr: 0.000812
2023-07-01 19:16:16 - train: epoch 0062, iter [00050, 00390], lr: 0.000811, loss: 0.2828
2023-07-01 19:16:18 - train: epoch 0062, iter [00100, 00390], lr: 0.000810, loss: 0.2266
2023-07-01 19:16:21 - train: epoch 0062, iter [00150, 00390], lr: 0.000809, loss: 0.5892
2023-07-01 19:16:24 - train: epoch 0062, iter [00200, 00390], lr: 0.000809, loss: 0.2386
2023-07-01 19:16:26 - train: epoch 0062, iter [00250, 00390], lr: 0.000808, loss: 0.3085
2023-07-01 19:16:29 - train: epoch 0062, iter [00300, 00390], lr: 0.000807, loss: 0.3630
2023-07-01 19:16:32 - train: epoch 0062, iter [00350, 00390], lr: 0.000806, loss: 0.3610
2023-07-01 19:16:34 - train: epoch 062, train_loss: 0.3383
2023-07-01 19:16:35 - eval: epoch: 062, acc1: 34.200%, acc5: 60.990%, test_loss: 4.6184, per_image_load_time: 0.067ms, per_image_inference_time: 0.083ms
2023-07-01 19:16:37 - until epoch: 062, best_acc1: 34.740%
2023-07-01 19:16:37 - epoch 063 lr: 0.000806
2023-07-01 19:16:40 - train: epoch 0063, iter [00050, 00390], lr: 0.000805, loss: 0.2798
2023-07-01 19:16:43 - train: epoch 0063, iter [00100, 00390], lr: 0.000804, loss: 0.2818
2023-07-01 19:16:45 - train: epoch 0063, iter [00150, 00390], lr: 0.000803, loss: 0.4375
2023-07-01 19:16:48 - train: epoch 0063, iter [00200, 00390], lr: 0.000802, loss: 0.4136
2023-07-01 19:16:51 - train: epoch 0063, iter [00250, 00390], lr: 0.000801, loss: 0.3846
2023-07-01 19:16:53 - train: epoch 0063, iter [00300, 00390], lr: 0.000801, loss: 0.4278
2023-07-01 19:16:56 - train: epoch 0063, iter [00350, 00390], lr: 0.000800, loss: 0.3488
2023-07-01 19:16:58 - train: epoch 063, train_loss: 0.3245
2023-07-01 19:17:00 - eval: epoch: 063, acc1: 34.310%, acc5: 61.000%, test_loss: 4.7348, per_image_load_time: 0.082ms, per_image_inference_time: 0.082ms
2023-07-01 19:17:00 - until epoch: 063, best_acc1: 34.740%
2023-07-01 19:17:00 - epoch 064 lr: 0.000799
2023-07-01 19:17:03 - train: epoch 0064, iter [00050, 00390], lr: 0.000798, loss: 0.2561
2023-07-01 19:17:06 - train: epoch 0064, iter [00100, 00390], lr: 0.000798, loss: 0.3372
2023-07-01 19:17:09 - train: epoch 0064, iter [00150, 00390], lr: 0.000797, loss: 0.2882
2023-07-01 19:17:12 - train: epoch 0064, iter [00200, 00390], lr: 0.000796, loss: 0.3223
2023-07-01 19:17:14 - train: epoch 0064, iter [00250, 00390], lr: 0.000795, loss: 0.4142
2023-07-01 19:17:17 - train: epoch 0064, iter [00300, 00390], lr: 0.000794, loss: 0.3061
2023-07-01 19:17:20 - train: epoch 0064, iter [00350, 00390], lr: 0.000793, loss: 0.2724
2023-07-01 19:17:22 - train: epoch 064, train_loss: 0.3069
2023-07-01 19:17:24 - eval: epoch: 064, acc1: 34.590%, acc5: 60.810%, test_loss: 4.6354, per_image_load_time: 0.087ms, per_image_inference_time: 0.095ms
2023-07-01 19:17:24 - until epoch: 064, best_acc1: 34.740%
2023-07-01 19:17:24 - epoch 065 lr: 0.000793
2023-07-01 19:17:28 - train: epoch 0065, iter [00050, 00390], lr: 0.000792, loss: 0.3315
2023-07-01 19:17:30 - train: epoch 0065, iter [00100, 00390], lr: 0.000791, loss: 0.3066
2023-07-01 19:17:33 - train: epoch 0065, iter [00150, 00390], lr: 0.000790, loss: 0.4041
2023-07-01 19:17:36 - train: epoch 0065, iter [00200, 00390], lr: 0.000789, loss: 0.3838
2023-07-01 19:17:39 - train: epoch 0065, iter [00250, 00390], lr: 0.000789, loss: 0.2834
2023-07-01 19:17:41 - train: epoch 0065, iter [00300, 00390], lr: 0.000788, loss: 0.2513
2023-07-01 19:17:44 - train: epoch 0065, iter [00350, 00390], lr: 0.000787, loss: 0.3353
2023-07-01 19:17:46 - train: epoch 065, train_loss: 0.3023
2023-07-01 19:17:48 - eval: epoch: 065, acc1: 33.970%, acc5: 60.180%, test_loss: 4.7991, per_image_load_time: 0.083ms, per_image_inference_time: 0.083ms
2023-07-01 19:17:49 - until epoch: 065, best_acc1: 34.740%
2023-07-01 19:17:49 - epoch 066 lr: 0.000786
2023-07-01 19:17:52 - train: epoch 0066, iter [00050, 00390], lr: 0.000785, loss: 0.2357
2023-07-01 19:17:55 - train: epoch 0066, iter [00100, 00390], lr: 0.000785, loss: 0.2064
2023-07-01 19:17:58 - train: epoch 0066, iter [00150, 00390], lr: 0.000784, loss: 0.3595
2023-07-01 19:18:01 - train: epoch 0066, iter [00200, 00390], lr: 0.000783, loss: 0.3212
2023-07-01 19:18:03 - train: epoch 0066, iter [00250, 00390], lr: 0.000782, loss: 0.3717
2023-07-01 19:18:06 - train: epoch 0066, iter [00300, 00390], lr: 0.000781, loss: 0.2687
2023-07-01 19:18:09 - train: epoch 0066, iter [00350, 00390], lr: 0.000780, loss: 0.1783
2023-07-01 19:18:12 - train: epoch 066, train_loss: 0.2810
2023-07-01 19:18:14 - eval: epoch: 066, acc1: 35.070%, acc5: 61.040%, test_loss: 4.8357, per_image_load_time: 0.080ms, per_image_inference_time: 0.082ms
2023-07-01 19:18:14 - until epoch: 066, best_acc1: 35.070%
2023-07-01 19:18:14 - epoch 067 lr: 0.000780
2023-07-01 19:18:19 - train: epoch 0067, iter [00050, 00390], lr: 0.000779, loss: 0.4168
2023-07-01 19:18:22 - train: epoch 0067, iter [00100, 00390], lr: 0.000778, loss: 0.3407
2023-07-01 19:18:25 - train: epoch 0067, iter [00150, 00390], lr: 0.000777, loss: 0.2736
2023-07-01 19:18:27 - train: epoch 0067, iter [00200, 00390], lr: 0.000776, loss: 0.2136
2023-07-01 19:18:30 - train: epoch 0067, iter [00250, 00390], lr: 0.000775, loss: 0.3197
2023-07-01 19:18:33 - train: epoch 0067, iter [00300, 00390], lr: 0.000774, loss: 0.2539
2023-07-01 19:18:36 - train: epoch 0067, iter [00350, 00390], lr: 0.000774, loss: 0.1807
2023-07-01 19:18:38 - train: epoch 067, train_loss: 0.2818
2023-07-01 19:18:40 - eval: epoch: 067, acc1: 34.450%, acc5: 60.630%, test_loss: 4.8677, per_image_load_time: 0.081ms, per_image_inference_time: 0.083ms
2023-07-01 19:18:40 - until epoch: 067, best_acc1: 35.070%
2023-07-01 19:18:40 - epoch 068 lr: 0.000773
2023-07-01 19:18:44 - train: epoch 0068, iter [00050, 00390], lr: 0.000772, loss: 0.1727
2023-07-01 19:18:46 - train: epoch 0068, iter [00100, 00390], lr: 0.000771, loss: 0.1404
2023-07-01 19:18:49 - train: epoch 0068, iter [00150, 00390], lr: 0.000770, loss: 0.2478
2023-07-01 19:18:52 - train: epoch 0068, iter [00200, 00390], lr: 0.000769, loss: 0.2592
2023-07-01 19:18:55 - train: epoch 0068, iter [00250, 00390], lr: 0.000769, loss: 0.1776
2023-07-01 19:18:57 - train: epoch 0068, iter [00300, 00390], lr: 0.000768, loss: 0.2305
2023-07-01 19:19:00 - train: epoch 0068, iter [00350, 00390], lr: 0.000767, loss: 0.2756
2023-07-01 19:19:02 - train: epoch 068, train_loss: 0.2660
2023-07-01 19:19:04 - eval: epoch: 068, acc1: 34.500%, acc5: 60.280%, test_loss: 4.9645, per_image_load_time: 0.084ms, per_image_inference_time: 0.083ms
2023-07-01 19:19:04 - until epoch: 068, best_acc1: 35.070%
2023-07-01 19:19:04 - epoch 069 lr: 0.000766
2023-07-01 19:19:08 - train: epoch 0069, iter [00050, 00390], lr: 0.000765, loss: 0.2421
2023-07-01 19:19:11 - train: epoch 0069, iter [00100, 00390], lr: 0.000764, loss: 0.1693
2023-07-01 19:19:14 - train: epoch 0069, iter [00150, 00390], lr: 0.000764, loss: 0.3599
2023-07-01 19:19:17 - train: epoch 0069, iter [00200, 00390], lr: 0.000763, loss: 0.3767
2023-07-01 19:19:20 - train: epoch 0069, iter [00250, 00390], lr: 0.000762, loss: 0.4482
2023-07-01 19:19:23 - train: epoch 0069, iter [00300, 00390], lr: 0.000761, loss: 0.2838
2023-07-01 19:19:26 - train: epoch 0069, iter [00350, 00390], lr: 0.000760, loss: 0.2730
2023-07-01 19:19:28 - train: epoch 069, train_loss: 0.2605
2023-07-01 19:19:30 - eval: epoch: 069, acc1: 34.440%, acc5: 61.150%, test_loss: 4.9205, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 19:19:30 - until epoch: 069, best_acc1: 35.070%
2023-07-01 19:19:30 - epoch 070 lr: 0.000759
2023-07-01 19:19:34 - train: epoch 0070, iter [00050, 00390], lr: 0.000758, loss: 0.1707
2023-07-01 19:19:37 - train: epoch 0070, iter [00100, 00390], lr: 0.000758, loss: 0.3652
2023-07-01 19:19:39 - train: epoch 0070, iter [00150, 00390], lr: 0.000757, loss: 0.1702
2023-07-01 19:19:42 - train: epoch 0070, iter [00200, 00390], lr: 0.000756, loss: 0.1924
2023-07-01 19:19:45 - train: epoch 0070, iter [00250, 00390], lr: 0.000755, loss: 0.2195
2023-07-01 19:19:48 - train: epoch 0070, iter [00300, 00390], lr: 0.000754, loss: 0.2544
2023-07-01 19:19:51 - train: epoch 0070, iter [00350, 00390], lr: 0.000753, loss: 0.2562
2023-07-01 19:19:53 - train: epoch 070, train_loss: 0.2500
2023-07-01 19:19:55 - eval: epoch: 070, acc1: 34.610%, acc5: 60.790%, test_loss: 4.8746, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 19:19:56 - until epoch: 070, best_acc1: 35.070%
2023-07-01 19:19:56 - epoch 071 lr: 0.000753
2023-07-01 19:20:00 - train: epoch 0071, iter [00050, 00390], lr: 0.000752, loss: 0.3399
2023-07-01 19:20:03 - train: epoch 0071, iter [00100, 00390], lr: 0.000751, loss: 0.2111
2023-07-01 19:20:05 - train: epoch 0071, iter [00150, 00390], lr: 0.000750, loss: 0.2010
2023-07-01 19:20:08 - train: epoch 0071, iter [00200, 00390], lr: 0.000749, loss: 0.2217
2023-07-01 19:20:11 - train: epoch 0071, iter [00250, 00390], lr: 0.000748, loss: 0.1640
2023-07-01 19:20:14 - train: epoch 0071, iter [00300, 00390], lr: 0.000747, loss: 0.2766
2023-07-01 19:20:16 - train: epoch 0071, iter [00350, 00390], lr: 0.000746, loss: 0.2654
2023-07-01 19:20:18 - train: epoch 071, train_loss: 0.2421
2023-07-01 19:20:20 - eval: epoch: 071, acc1: 34.580%, acc5: 60.480%, test_loss: 5.0336, per_image_load_time: 0.083ms, per_image_inference_time: 0.084ms
2023-07-01 19:20:21 - until epoch: 071, best_acc1: 35.070%
2023-07-01 19:20:21 - epoch 072 lr: 0.000746
2023-07-01 19:20:24 - train: epoch 0072, iter [00050, 00390], lr: 0.000745, loss: 0.2598
2023-07-01 19:20:27 - train: epoch 0072, iter [00100, 00390], lr: 0.000744, loss: 0.1830
2023-07-01 19:20:30 - train: epoch 0072, iter [00150, 00390], lr: 0.000743, loss: 0.2600
2023-07-01 19:20:32 - train: epoch 0072, iter [00200, 00390], lr: 0.000742, loss: 0.1522
2023-07-01 19:20:35 - train: epoch 0072, iter [00250, 00390], lr: 0.000741, loss: 0.2098
2023-07-01 19:20:38 - train: epoch 0072, iter [00300, 00390], lr: 0.000740, loss: 0.1834
2023-07-01 19:20:41 - train: epoch 0072, iter [00350, 00390], lr: 0.000739, loss: 0.1795
2023-07-01 19:20:43 - train: epoch 072, train_loss: 0.2366
2023-07-01 19:20:45 - eval: epoch: 072, acc1: 34.250%, acc5: 60.820%, test_loss: 5.0684, per_image_load_time: 0.081ms, per_image_inference_time: 0.086ms
2023-07-01 19:20:46 - until epoch: 072, best_acc1: 35.070%
2023-07-01 19:20:46 - epoch 073 lr: 0.000739
2023-07-01 19:20:49 - train: epoch 0073, iter [00050, 00390], lr: 0.000738, loss: 0.2962
2023-07-01 19:20:52 - train: epoch 0073, iter [00100, 00390], lr: 0.000737, loss: 0.2994
2023-07-01 19:20:55 - train: epoch 0073, iter [00150, 00390], lr: 0.000736, loss: 0.2059
2023-07-01 19:20:58 - train: epoch 0073, iter [00200, 00390], lr: 0.000735, loss: 0.2892
2023-07-01 19:21:01 - train: epoch 0073, iter [00250, 00390], lr: 0.000734, loss: 0.2697
2023-07-01 19:21:04 - train: epoch 0073, iter [00300, 00390], lr: 0.000733, loss: 0.2582
2023-07-01 19:21:06 - train: epoch 0073, iter [00350, 00390], lr: 0.000732, loss: 0.2185
2023-07-01 19:21:09 - train: epoch 073, train_loss: 0.2337
2023-07-01 19:21:11 - eval: epoch: 073, acc1: 34.960%, acc5: 60.940%, test_loss: 5.0007, per_image_load_time: 0.082ms, per_image_inference_time: 0.084ms
2023-07-01 19:21:11 - until epoch: 073, best_acc1: 35.070%
2023-07-01 19:21:11 - epoch 074 lr: 0.000731
2023-07-01 19:21:15 - train: epoch 0074, iter [00050, 00390], lr: 0.000731, loss: 0.3663
2023-07-01 19:21:17 - train: epoch 0074, iter [00100, 00390], lr: 0.000730, loss: 0.2030
2023-07-01 19:21:20 - train: epoch 0074, iter [00150, 00390], lr: 0.000729, loss: 0.2179
2023-07-01 19:21:23 - train: epoch 0074, iter [00200, 00390], lr: 0.000728, loss: 0.2009
2023-07-01 19:21:26 - train: epoch 0074, iter [00250, 00390], lr: 0.000727, loss: 0.2276
2023-07-01 19:21:29 - train: epoch 0074, iter [00300, 00390], lr: 0.000726, loss: 0.1102
2023-07-01 19:21:32 - train: epoch 0074, iter [00350, 00390], lr: 0.000725, loss: 0.1925
2023-07-01 19:21:34 - train: epoch 074, train_loss: 0.2208
2023-07-01 19:21:36 - eval: epoch: 074, acc1: 34.770%, acc5: 60.660%, test_loss: 5.1018, per_image_load_time: 0.084ms, per_image_inference_time: 0.088ms
2023-07-01 19:21:37 - until epoch: 074, best_acc1: 35.070%
2023-07-01 19:21:37 - epoch 075 lr: 0.000724
2023-07-01 19:21:40 - train: epoch 0075, iter [00050, 00390], lr: 0.000723, loss: 0.2253
2023-07-01 19:21:43 - train: epoch 0075, iter [00100, 00390], lr: 0.000723, loss: 0.1236
2023-07-01 19:21:46 - train: epoch 0075, iter [00150, 00390], lr: 0.000722, loss: 0.0907
2023-07-01 19:21:48 - train: epoch 0075, iter [00200, 00390], lr: 0.000721, loss: 0.2399
2023-07-01 19:21:51 - train: epoch 0075, iter [00250, 00390], lr: 0.000720, loss: 0.3174
2023-07-01 19:21:54 - train: epoch 0075, iter [00300, 00390], lr: 0.000719, loss: 0.1731
2023-07-01 19:21:56 - train: epoch 0075, iter [00350, 00390], lr: 0.000718, loss: 0.1912
2023-07-01 19:21:59 - train: epoch 075, train_loss: 0.2154
2023-07-01 19:22:00 - eval: epoch: 075, acc1: 34.330%, acc5: 60.610%, test_loss: 5.1486, per_image_load_time: 0.081ms, per_image_inference_time: 0.084ms
2023-07-01 19:22:01 - until epoch: 075, best_acc1: 35.070%
2023-07-01 19:22:01 - epoch 076 lr: 0.000717
2023-07-01 19:22:05 - train: epoch 0076, iter [00050, 00390], lr: 0.000716, loss: 0.1298
2023-07-01 19:22:08 - train: epoch 0076, iter [00100, 00390], lr: 0.000715, loss: 0.2242
2023-07-01 19:22:10 - train: epoch 0076, iter [00150, 00390], lr: 0.000714, loss: 0.3451
2023-07-01 19:22:13 - train: epoch 0076, iter [00200, 00390], lr: 0.000714, loss: 0.1885
2023-07-01 19:22:16 - train: epoch 0076, iter [00250, 00390], lr: 0.000713, loss: 0.1742
2023-07-01 19:22:18 - train: epoch 0076, iter [00300, 00390], lr: 0.000712, loss: 0.1735
2023-07-01 19:22:21 - train: epoch 0076, iter [00350, 00390], lr: 0.000711, loss: 0.3701
2023-07-01 19:22:23 - train: epoch 076, train_loss: 0.2126
2023-07-01 19:22:25 - eval: epoch: 076, acc1: 34.450%, acc5: 60.490%, test_loss: 5.1607, per_image_load_time: 0.084ms, per_image_inference_time: 0.082ms
2023-07-01 19:22:25 - until epoch: 076, best_acc1: 35.070%
2023-07-01 19:22:25 - epoch 077 lr: 0.000710
2023-07-01 19:22:29 - train: epoch 0077, iter [00050, 00390], lr: 0.000709, loss: 0.0907
2023-07-01 19:22:32 - train: epoch 0077, iter [00100, 00390], lr: 0.000708, loss: 0.2822
2023-07-01 19:22:34 - train: epoch 0077, iter [00150, 00390], lr: 0.000707, loss: 0.2404
2023-07-01 19:22:37 - train: epoch 0077, iter [00200, 00390], lr: 0.000706, loss: 0.2116
2023-07-01 19:22:40 - train: epoch 0077, iter [00250, 00390], lr: 0.000705, loss: 0.1976
2023-07-01 19:22:42 - train: epoch 0077, iter [00300, 00390], lr: 0.000704, loss: 0.2272
2023-07-01 19:22:45 - train: epoch 0077, iter [00350, 00390], lr: 0.000703, loss: 0.3271
2023-07-01 19:22:48 - train: epoch 077, train_loss: 0.1990
2023-07-01 19:22:49 - eval: epoch: 077, acc1: 34.650%, acc5: 60.190%, test_loss: 5.2282, per_image_load_time: 0.082ms, per_image_inference_time: 0.082ms
2023-07-01 19:22:50 - until epoch: 077, best_acc1: 35.070%
2023-07-01 19:22:50 - epoch 078 lr: 0.000703
2023-07-01 19:22:53 - train: epoch 0078, iter [00050, 00390], lr: 0.000702, loss: 0.3351
2023-07-01 19:22:56 - train: epoch 0078, iter [00100, 00390], lr: 0.000701, loss: 0.1560
2023-07-01 19:22:59 - train: epoch 0078, iter [00150, 00390], lr: 0.000700, loss: 0.1708
2023-07-01 19:23:02 - train: epoch 0078, iter [00200, 00390], lr: 0.000699, loss: 0.2770
2023-07-01 19:23:04 - train: epoch 0078, iter [00250, 00390], lr: 0.000698, loss: 0.3136
2023-07-01 19:23:07 - train: epoch 0078, iter [00300, 00390], lr: 0.000697, loss: 0.3394
2023-07-01 19:23:10 - train: epoch 0078, iter [00350, 00390], lr: 0.000696, loss: 0.1478
2023-07-01 19:23:13 - train: epoch 078, train_loss: 0.1954
2023-07-01 19:23:15 - eval: epoch: 078, acc1: 34.750%, acc5: 60.600%, test_loss: 5.1896, per_image_load_time: 0.082ms, per_image_inference_time: 0.083ms
2023-07-01 19:23:16 - until epoch: 078, best_acc1: 35.070%
2023-07-01 19:23:16 - epoch 079 lr: 0.000695
2023-07-01 19:23:20 - train: epoch 0079, iter [00050, 00390], lr: 0.000694, loss: 0.2323
2023-07-01 19:23:22 - train: epoch 0079, iter [00100, 00390], lr: 0.000693, loss: 0.2463
2023-07-01 19:23:25 - train: epoch 0079, iter [00150, 00390], lr: 0.000693, loss: 0.1681
2023-07-01 19:23:28 - train: epoch 0079, iter [00200, 00390], lr: 0.000692, loss: 0.0596
2023-07-01 19:23:30 - train: epoch 0079, iter [00250, 00390], lr: 0.000691, loss: 0.3351
2023-07-01 19:23:33 - train: epoch 0079, iter [00300, 00390], lr: 0.000690, loss: 0.2306
2023-07-01 19:23:36 - train: epoch 0079, iter [00350, 00390], lr: 0.000689, loss: 0.2739
2023-07-01 19:23:38 - train: epoch 079, train_loss: 0.1894
2023-07-01 19:23:40 - eval: epoch: 079, acc1: 34.480%, acc5: 60.720%, test_loss: 5.3038, per_image_load_time: 0.081ms, per_image_inference_time: 0.082ms
2023-07-01 19:23:40 - until epoch: 079, best_acc1: 35.070%
2023-07-01 19:23:40 - epoch 080 lr: 0.000688
2023-07-01 19:23:44 - train: epoch 0080, iter [00050, 00390], lr: 0.000687, loss: 0.1571
2023-07-01 19:23:46 - train: epoch 0080, iter [00100, 00390], lr: 0.000686, loss: 0.1676
2023-07-01 19:23:49 - train: epoch 0080, iter [00150, 00390], lr: 0.000685, loss: 0.1269
2023-07-01 19:23:52 - train: epoch 0080, iter [00200, 00390], lr: 0.000684, loss: 0.1365
2023-07-01 19:23:55 - train: epoch 0080, iter [00250, 00390], lr: 0.000683, loss: 0.1754
2023-07-01 19:23:57 - train: epoch 0080, iter [00300, 00390], lr: 0.000682, loss: 0.2058
2023-07-01 19:24:00 - train: epoch 0080, iter [00350, 00390], lr: 0.000681, loss: 0.2543
2023-07-01 19:24:02 - train: epoch 080, train_loss: 0.1834
2023-07-01 19:24:04 - eval: epoch: 080, acc1: 34.280%, acc5: 60.510%, test_loss: 5.2710, per_image_load_time: 0.080ms, per_image_inference_time: 0.089ms
2023-07-01 19:24:05 - until epoch: 080, best_acc1: 35.070%
2023-07-01 19:24:05 - epoch 081 lr: 0.000681
2023-07-01 19:24:08 - train: epoch 0081, iter [00050, 00390], lr: 0.000680, loss: 0.1988
2023-07-01 19:24:11 - train: epoch 0081, iter [00100, 00390], lr: 0.000679, loss: 0.0899
2023-07-01 19:24:14 - train: epoch 0081, iter [00150, 00390], lr: 0.000678, loss: 0.1389
2023-07-01 19:29:11 - network: vit_tiny_patch16
2023-07-01 19:29:11 - num_classes: 100
2023-07-01 19:29:11 - input_image_size: 32
2023-07-01 19:29:11 - trained_model_path: 
2023-07-01 19:29:11 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 19:29:11 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 19:29:11 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f40ba5d2520>
2023-07-01 19:29:11 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f40ba5d2490>
2023-07-01 19:29:11 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f40ba5d2580>
2023-07-01 19:29:11 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f40ba5d25b0>
2023-07-01 19:29:11 - seed: 0
2023-07-01 19:29:11 - batch_size: 128
2023-07-01 19:29:11 - num_workers: 16
2023-07-01 19:29:11 - accumulation_steps: 1
2023-07-01 19:29:11 - optimizer: ('SGD', {'lr': 0.01, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-01 19:29:11 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-07-01 19:29:11 - epochs: 200
2023-07-01 19:29:11 - print_interval: 50
2023-07-01 19:29:11 - sync_bn: False
2023-07-01 19:29:11 - apex: True
2023-07-01 19:29:11 - use_ema_model: False
2023-07-01 19:29:11 - ema_model_decay: 0.9999
2023-07-01 19:29:11 - AUG: none
2023-07-01 19:29:11 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-01 19:29:11 - gpus_num: 1
2023-07-01 19:29:11 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f40ba6f5330>
2023-07-01 19:29:11 - --------------------parameters--------------------
2023-07-01 19:29:11 - name: cls_token, grad: True
2023-07-01 19:29:11 - name: position_encoding, grad: True
2023-07-01 19:29:11 - name: patch_embedding.conv.weight, grad: True
2023-07-01 19:29:11 - name: patch_embedding.conv.bias, grad: True
2023-07-01 19:29:11 - name: blocks.0.norm1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.0.norm1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.0.attention.qkv_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.0.attention.qkv_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.0.attention.out_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.0.attention.out_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.0.norm2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.0.norm2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.0.feed_forward.fc1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.0.feed_forward.fc1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.0.feed_forward.fc2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.0.feed_forward.fc2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.1.norm1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.1.norm1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.1.attention.qkv_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.1.attention.qkv_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.1.attention.out_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.1.attention.out_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.1.norm2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.1.norm2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.1.feed_forward.fc1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.1.feed_forward.fc1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.1.feed_forward.fc2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.1.feed_forward.fc2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.2.norm1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.2.norm1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.2.attention.qkv_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.2.attention.qkv_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.2.attention.out_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.2.attention.out_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.2.norm2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.2.norm2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.2.feed_forward.fc1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.2.feed_forward.fc1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.2.feed_forward.fc2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.2.feed_forward.fc2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.3.norm1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.3.norm1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.3.attention.qkv_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.3.attention.qkv_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.3.attention.out_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.3.attention.out_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.3.norm2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.3.norm2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.3.feed_forward.fc1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.3.feed_forward.fc1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.3.feed_forward.fc2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.3.feed_forward.fc2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.4.norm1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.4.norm1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.4.attention.qkv_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.4.attention.qkv_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.4.attention.out_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.4.attention.out_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.4.norm2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.4.norm2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.4.feed_forward.fc1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.4.feed_forward.fc1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.4.feed_forward.fc2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.4.feed_forward.fc2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.5.norm1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.5.norm1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.5.attention.qkv_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.5.attention.qkv_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.5.attention.out_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.5.attention.out_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.5.norm2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.5.norm2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.5.feed_forward.fc1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.5.feed_forward.fc1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.5.feed_forward.fc2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.5.feed_forward.fc2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.6.norm1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.6.norm1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.6.attention.qkv_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.6.attention.qkv_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.6.attention.out_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.6.attention.out_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.6.norm2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.6.norm2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.6.feed_forward.fc1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.6.feed_forward.fc1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.6.feed_forward.fc2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.6.feed_forward.fc2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.7.norm1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.7.norm1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.7.attention.qkv_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.7.attention.qkv_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.7.attention.out_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.7.attention.out_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.7.norm2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.7.norm2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.7.feed_forward.fc1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.7.feed_forward.fc1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.7.feed_forward.fc2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.7.feed_forward.fc2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.8.norm1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.8.norm1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.8.attention.qkv_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.8.attention.qkv_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.8.attention.out_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.8.attention.out_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.8.norm2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.8.norm2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.8.feed_forward.fc1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.8.feed_forward.fc1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.8.feed_forward.fc2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.8.feed_forward.fc2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.9.norm1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.9.norm1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.9.attention.qkv_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.9.attention.qkv_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.9.attention.out_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.9.attention.out_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.9.norm2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.9.norm2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.9.feed_forward.fc1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.9.feed_forward.fc1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.9.feed_forward.fc2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.9.feed_forward.fc2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.10.norm1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.10.norm1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.10.attention.qkv_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.10.attention.qkv_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.10.attention.out_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.10.attention.out_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.10.norm2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.10.norm2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.10.feed_forward.fc1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.10.feed_forward.fc1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.10.feed_forward.fc2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.10.feed_forward.fc2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.11.norm1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.11.norm1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.11.attention.qkv_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.11.attention.qkv_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.11.attention.out_linear.weight, grad: True
2023-07-01 19:29:11 - name: blocks.11.attention.out_linear.bias, grad: True
2023-07-01 19:29:11 - name: blocks.11.norm2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.11.norm2.bias, grad: True
2023-07-01 19:29:11 - name: blocks.11.feed_forward.fc1.weight, grad: True
2023-07-01 19:29:11 - name: blocks.11.feed_forward.fc1.bias, grad: True
2023-07-01 19:29:11 - name: blocks.11.feed_forward.fc2.weight, grad: True
2023-07-01 19:29:11 - name: blocks.11.feed_forward.fc2.bias, grad: True
2023-07-01 19:29:11 - name: norm.weight, grad: True
2023-07-01 19:29:11 - name: norm.bias, grad: True
2023-07-01 19:29:11 - name: fc.weight, grad: True
2023-07-01 19:29:11 - name: fc.bias, grad: True
2023-07-01 19:29:11 - --------------------buffers--------------------
2023-07-01 19:29:11 - -----------no weight decay layers--------------
2023-07-01 19:29:11 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.7.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.7.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.7.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.7.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.7.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.7.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.7.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.7.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.8.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.8.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.8.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.8.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.8.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.8.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.8.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.8.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.9.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.9.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.9.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.9.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.9.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.9.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.9.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.9.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.10.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.10.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.10.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.10.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.10.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.10.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.10.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.10.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.11.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.11.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.11.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.11.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.11.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.11.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.11.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.11.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: norm.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: norm.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 19:29:11 - -------------weight decay layers---------------
2023-07-01 19:29:11 - name: cls_token, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: position_encoding, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: patch_embedding.conv.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.7.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.7.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.7.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.7.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.8.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.8.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.8.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.8.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.9.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.9.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.9.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.9.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.10.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.10.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.10.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.10.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.11.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.11.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.11.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: blocks.11.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 19:29:11 - epoch 001 lr: 0.010000
2023-07-01 19:29:19 - train: epoch 0001, iter [00050, 00390], lr: 0.010000, loss: 4.1588
2023-07-01 19:29:21 - train: epoch 0001, iter [00100, 00390], lr: 0.010000, loss: 4.1429
2023-07-01 19:29:23 - train: epoch 0001, iter [00150, 00390], lr: 0.010000, loss: 4.0958
2023-07-01 19:29:26 - train: epoch 0001, iter [00200, 00390], lr: 0.010000, loss: 3.9647
2023-07-01 19:29:28 - train: epoch 0001, iter [00250, 00390], lr: 0.010000, loss: 4.0863
2023-07-01 19:29:30 - train: epoch 0001, iter [00300, 00390], lr: 0.010000, loss: 3.9419
2023-07-01 19:29:32 - train: epoch 0001, iter [00350, 00390], lr: 0.010000, loss: 3.8559
2023-07-01 19:29:34 - train: epoch 001, train_loss: 4.0821
2023-07-01 19:29:36 - eval: epoch: 001, acc1: 10.690%, acc5: 31.210%, test_loss: 3.8622, per_image_load_time: 0.067ms, per_image_inference_time: 0.084ms
2023-07-01 19:29:37 - until epoch: 001, best_acc1: 10.690%
2023-07-01 19:29:37 - epoch 002 lr: 0.010000
2023-07-01 19:29:40 - train: epoch 0002, iter [00050, 00390], lr: 0.010000, loss: 3.9138
2023-07-01 19:29:42 - train: epoch 0002, iter [00100, 00390], lr: 0.010000, loss: 3.9209
2023-07-01 19:29:44 - train: epoch 0002, iter [00150, 00390], lr: 0.010000, loss: 3.8355
2023-07-01 19:29:46 - train: epoch 0002, iter [00200, 00390], lr: 0.010000, loss: 3.9385
2023-07-01 19:29:49 - train: epoch 0002, iter [00250, 00390], lr: 0.010000, loss: 3.7079
2023-07-01 19:29:51 - train: epoch 0002, iter [00300, 00390], lr: 0.010000, loss: 3.8851
2023-07-01 19:29:53 - train: epoch 0002, iter [00350, 00390], lr: 0.010000, loss: 3.6538
2023-07-01 19:29:55 - train: epoch 002, train_loss: 3.8111
2023-07-01 19:29:56 - eval: epoch: 002, acc1: 13.320%, acc5: 36.700%, test_loss: 3.6782, per_image_load_time: 0.066ms, per_image_inference_time: 0.083ms
2023-07-01 19:29:57 - until epoch: 002, best_acc1: 13.320%
2023-07-01 19:29:57 - epoch 003 lr: 0.010000
2023-07-01 19:30:00 - train: epoch 0003, iter [00050, 00390], lr: 0.010000, loss: 3.6340
2023-07-01 19:30:03 - train: epoch 0003, iter [00100, 00390], lr: 0.010000, loss: 3.5938
2023-07-01 19:30:05 - train: epoch 0003, iter [00150, 00390], lr: 0.010000, loss: 3.8912
2023-07-01 19:30:07 - train: epoch 0003, iter [00200, 00390], lr: 0.010000, loss: 3.4604
2023-07-01 19:30:09 - train: epoch 0003, iter [00250, 00390], lr: 0.010000, loss: 3.8646
2023-07-01 19:30:11 - train: epoch 0003, iter [00300, 00390], lr: 0.010000, loss: 3.8210
2023-07-01 19:30:13 - train: epoch 0003, iter [00350, 00390], lr: 0.010000, loss: 3.7794
2023-07-01 19:30:15 - train: epoch 003, train_loss: 3.6686
2023-07-01 19:30:17 - eval: epoch: 003, acc1: 14.830%, acc5: 38.810%, test_loss: 3.5974, per_image_load_time: 0.066ms, per_image_inference_time: 0.082ms
2023-07-01 19:30:17 - until epoch: 003, best_acc1: 14.830%
2023-07-01 19:30:17 - epoch 004 lr: 0.010000
2023-07-01 19:30:20 - train: epoch 0004, iter [00050, 00390], lr: 0.010000, loss: 3.5580
2023-07-01 19:30:22 - train: epoch 0004, iter [00100, 00390], lr: 0.010000, loss: 3.6670
2023-07-01 19:30:25 - train: epoch 0004, iter [00150, 00390], lr: 0.010000, loss: 3.6486
2023-07-01 19:30:27 - train: epoch 0004, iter [00200, 00390], lr: 0.010000, loss: 3.7612
2023-07-01 19:30:29 - train: epoch 0004, iter [00250, 00390], lr: 0.010000, loss: 3.4323
2023-07-01 19:30:31 - train: epoch 0004, iter [00300, 00390], lr: 0.010000, loss: 3.6413
2023-07-01 19:30:33 - train: epoch 0004, iter [00350, 00390], lr: 0.010000, loss: 3.3206
2023-07-01 19:30:35 - train: epoch 004, train_loss: 3.5693
2023-07-01 19:30:37 - eval: epoch: 004, acc1: 16.790%, acc5: 42.370%, test_loss: 3.4941, per_image_load_time: 0.067ms, per_image_inference_time: 0.081ms
2023-07-01 19:30:38 - until epoch: 004, best_acc1: 16.790%
2023-07-01 19:30:38 - epoch 005 lr: 0.010000
2023-07-01 19:30:41 - train: epoch 0005, iter [00050, 00390], lr: 0.010000, loss: 3.5039
2023-07-01 19:30:43 - train: epoch 0005, iter [00100, 00390], lr: 0.010000, loss: 3.3173
2023-07-01 19:30:45 - train: epoch 0005, iter [00150, 00390], lr: 0.010000, loss: 3.2723
2023-07-01 19:30:47 - train: epoch 0005, iter [00200, 00390], lr: 0.010000, loss: 3.6154
2023-07-01 19:30:50 - train: epoch 0005, iter [00250, 00390], lr: 0.010000, loss: 3.4478
2023-07-01 19:30:52 - train: epoch 0005, iter [00300, 00390], lr: 0.010000, loss: 3.3660
2023-07-01 19:30:54 - train: epoch 0005, iter [00350, 00390], lr: 0.010000, loss: 3.4077
2023-07-01 19:30:56 - train: epoch 005, train_loss: 3.4920
2023-07-01 19:30:57 - eval: epoch: 005, acc1: 18.660%, acc5: 45.580%, test_loss: 3.3912, per_image_load_time: 0.069ms, per_image_inference_time: 0.084ms
2023-07-01 19:30:58 - until epoch: 005, best_acc1: 18.660%
2023-07-01 19:30:58 - epoch 006 lr: 0.010000
2023-07-01 19:31:01 - train: epoch 0006, iter [00050, 00390], lr: 0.010000, loss: 3.4556
2023-07-01 19:31:03 - train: epoch 0006, iter [00100, 00390], lr: 0.010000, loss: 3.3279
2023-07-01 19:31:06 - train: epoch 0006, iter [00150, 00390], lr: 0.010000, loss: 3.3904
2023-07-01 19:31:08 - train: epoch 0006, iter [00200, 00390], lr: 0.010000, loss: 3.3012
2023-07-01 19:31:10 - train: epoch 0006, iter [00250, 00390], lr: 0.010000, loss: 3.3657
2023-07-01 19:31:12 - train: epoch 0006, iter [00300, 00390], lr: 0.010000, loss: 3.2675
2023-07-01 19:31:14 - train: epoch 0006, iter [00350, 00390], lr: 0.010000, loss: 3.5038
2023-07-01 19:31:16 - train: epoch 006, train_loss: 3.4266
2023-07-01 19:31:18 - eval: epoch: 006, acc1: 19.610%, acc5: 46.560%, test_loss: 3.3372, per_image_load_time: 0.071ms, per_image_inference_time: 0.083ms
2023-07-01 19:31:18 - until epoch: 006, best_acc1: 19.610%
2023-07-01 19:31:18 - epoch 007 lr: 0.010000
2023-07-01 19:31:21 - train: epoch 0007, iter [00050, 00390], lr: 0.010000, loss: 3.4375
2023-07-01 19:31:23 - train: epoch 0007, iter [00100, 00390], lr: 0.010000, loss: 3.4151
2023-07-01 19:31:25 - train: epoch 0007, iter [00150, 00390], lr: 0.010000, loss: 3.3182
2023-07-01 19:31:28 - train: epoch 0007, iter [00200, 00390], lr: 0.010000, loss: 3.2830
2023-07-01 19:31:30 - train: epoch 0007, iter [00250, 00390], lr: 0.010000, loss: 3.2164
2023-07-01 19:31:32 - train: epoch 0007, iter [00300, 00390], lr: 0.010000, loss: 3.1836
2023-07-01 19:31:34 - train: epoch 0007, iter [00350, 00390], lr: 0.010000, loss: 3.3023
2023-07-01 19:31:36 - train: epoch 007, train_loss: 3.3683
2023-07-01 19:31:38 - eval: epoch: 007, acc1: 20.980%, acc5: 47.930%, test_loss: 3.2816, per_image_load_time: 0.067ms, per_image_inference_time: 0.081ms
2023-07-01 19:31:38 - until epoch: 007, best_acc1: 20.980%
2023-07-01 19:31:38 - epoch 008 lr: 0.010000
2023-07-01 19:31:41 - train: epoch 0008, iter [00050, 00390], lr: 0.010000, loss: 3.4804
2023-07-01 19:31:43 - train: epoch 0008, iter [00100, 00390], lr: 0.010000, loss: 3.4384
2023-07-01 19:31:45 - train: epoch 0008, iter [00150, 00390], lr: 0.010000, loss: 3.3933
2023-07-01 19:31:48 - train: epoch 0008, iter [00200, 00390], lr: 0.010000, loss: 3.2359
2023-07-01 19:31:50 - train: epoch 0008, iter [00250, 00390], lr: 0.010000, loss: 3.2091
2023-07-01 19:31:52 - train: epoch 0008, iter [00300, 00390], lr: 0.010000, loss: 3.2970
2023-07-01 19:31:54 - train: epoch 0008, iter [00350, 00390], lr: 0.010000, loss: 3.3326
2023-07-01 19:31:56 - train: epoch 008, train_loss: 3.3053
2023-07-01 19:31:58 - eval: epoch: 008, acc1: 20.750%, acc5: 48.940%, test_loss: 3.2605, per_image_load_time: 0.066ms, per_image_inference_time: 0.088ms
2023-07-01 19:31:58 - until epoch: 008, best_acc1: 20.980%
2023-07-01 19:31:58 - epoch 009 lr: 0.010000
2023-07-01 19:32:01 - train: epoch 0009, iter [00050, 00390], lr: 0.010000, loss: 3.0947
2023-07-01 19:32:03 - train: epoch 0009, iter [00100, 00390], lr: 0.010000, loss: 3.4606
2023-07-01 19:32:05 - train: epoch 0009, iter [00150, 00390], lr: 0.010000, loss: 3.0832
2023-07-01 19:32:07 - train: epoch 0009, iter [00200, 00390], lr: 0.010000, loss: 3.2411
2023-07-01 19:32:10 - train: epoch 0009, iter [00250, 00390], lr: 0.010000, loss: 3.1840
2023-07-01 19:32:12 - train: epoch 0009, iter [00300, 00390], lr: 0.010000, loss: 3.4502
2023-07-01 19:32:14 - train: epoch 0009, iter [00350, 00390], lr: 0.010000, loss: 3.3944
2023-07-01 19:32:16 - train: epoch 009, train_loss: 3.2529
2023-07-01 19:32:17 - eval: epoch: 009, acc1: 22.260%, acc5: 50.750%, test_loss: 3.1848, per_image_load_time: 0.070ms, per_image_inference_time: 0.080ms
2023-07-01 19:32:18 - until epoch: 009, best_acc1: 22.260%
2023-07-01 19:32:18 - epoch 010 lr: 0.010000
2023-07-01 19:32:21 - train: epoch 0010, iter [00050, 00390], lr: 0.010000, loss: 3.3856
2023-07-01 19:32:23 - train: epoch 0010, iter [00100, 00390], lr: 0.010000, loss: 3.3040
2023-07-01 19:32:26 - train: epoch 0010, iter [00150, 00390], lr: 0.010000, loss: 3.1617
2023-07-01 19:32:28 - train: epoch 0010, iter [00200, 00390], lr: 0.010000, loss: 3.2826
2023-07-01 19:32:30 - train: epoch 0010, iter [00250, 00390], lr: 0.010000, loss: 3.3759
2023-07-01 19:32:32 - train: epoch 0010, iter [00300, 00390], lr: 0.010000, loss: 2.8719
2023-07-01 19:32:34 - train: epoch 0010, iter [00350, 00390], lr: 0.010000, loss: 3.1253
2023-07-01 19:32:36 - train: epoch 010, train_loss: 3.2088
2023-07-01 19:32:38 - eval: epoch: 010, acc1: 23.110%, acc5: 51.110%, test_loss: 3.1597, per_image_load_time: 0.066ms, per_image_inference_time: 0.082ms
2023-07-01 19:32:38 - until epoch: 010, best_acc1: 23.110%
2023-07-01 19:32:38 - epoch 011 lr: 0.010000
2023-07-01 19:32:41 - train: epoch 0011, iter [00050, 00390], lr: 0.010000, loss: 3.1963
2023-07-01 19:32:43 - train: epoch 0011, iter [00100, 00390], lr: 0.010000, loss: 3.0311
2023-07-01 19:32:45 - train: epoch 0011, iter [00150, 00390], lr: 0.010000, loss: 3.2102
2023-07-01 19:32:47 - train: epoch 0011, iter [00200, 00390], lr: 0.010000, loss: 3.3839
2023-07-01 19:32:50 - train: epoch 0011, iter [00250, 00390], lr: 0.010000, loss: 3.2100
2023-07-01 19:32:52 - train: epoch 0011, iter [00300, 00390], lr: 0.010000, loss: 2.9481
2023-07-01 19:32:54 - train: epoch 0011, iter [00350, 00390], lr: 0.010000, loss: 3.0772
2023-07-01 19:32:56 - train: epoch 011, train_loss: 3.1733
2023-07-01 19:32:58 - eval: epoch: 011, acc1: 23.470%, acc5: 52.340%, test_loss: 3.1401, per_image_load_time: 0.067ms, per_image_inference_time: 0.082ms
2023-07-01 19:32:59 - until epoch: 011, best_acc1: 23.470%
2023-07-01 19:32:59 - epoch 012 lr: 0.010000
2023-07-01 19:33:02 - train: epoch 0012, iter [00050, 00390], lr: 0.010000, loss: 3.1207
2023-07-01 19:33:04 - train: epoch 0012, iter [00100, 00390], lr: 0.010000, loss: 3.3068
2023-07-01 19:33:06 - train: epoch 0012, iter [00150, 00390], lr: 0.010000, loss: 3.2581
2023-07-01 19:33:08 - train: epoch 0012, iter [00200, 00390], lr: 0.010000, loss: 3.2447
2023-07-01 19:33:11 - train: epoch 0012, iter [00250, 00390], lr: 0.010000, loss: 3.0217
2023-07-01 19:33:13 - train: epoch 0012, iter [00300, 00390], lr: 0.010000, loss: 3.1247
2023-07-01 19:33:15 - train: epoch 0012, iter [00350, 00390], lr: 0.010000, loss: 3.2237
2023-07-01 19:33:17 - train: epoch 012, train_loss: 3.1355
2023-07-01 19:33:18 - eval: epoch: 012, acc1: 23.820%, acc5: 52.790%, test_loss: 3.1061, per_image_load_time: 0.066ms, per_image_inference_time: 0.081ms
2023-07-01 19:33:19 - until epoch: 012, best_acc1: 23.820%
2023-07-01 19:33:19 - epoch 013 lr: 0.010000
2023-07-01 19:33:22 - train: epoch 0013, iter [00050, 00390], lr: 0.010000, loss: 3.0768
2023-07-01 19:33:24 - train: epoch 0013, iter [00100, 00390], lr: 0.010000, loss: 3.1805
2023-07-01 19:33:26 - train: epoch 0013, iter [00150, 00390], lr: 0.010000, loss: 3.1580
2023-07-01 19:33:29 - train: epoch 0013, iter [00200, 00390], lr: 0.010000, loss: 2.9166
2023-07-01 19:33:31 - train: epoch 0013, iter [00250, 00390], lr: 0.010000, loss: 3.0330
2023-07-01 19:33:33 - train: epoch 0013, iter [00300, 00390], lr: 0.010000, loss: 3.2150
2023-07-01 19:33:35 - train: epoch 0013, iter [00350, 00390], lr: 0.010000, loss: 2.9228
2023-07-01 19:33:37 - train: epoch 013, train_loss: 3.1006
2023-07-01 19:33:39 - eval: epoch: 013, acc1: 24.770%, acc5: 53.590%, test_loss: 3.0717, per_image_load_time: 0.065ms, per_image_inference_time: 0.081ms
2023-07-01 19:33:39 - until epoch: 013, best_acc1: 24.770%
2023-07-01 19:33:39 - epoch 014 lr: 0.010000
2023-07-01 19:33:42 - train: epoch 0014, iter [00050, 00390], lr: 0.010000, loss: 3.0552
2023-07-01 19:33:45 - train: epoch 0014, iter [00100, 00390], lr: 0.010000, loss: 2.9043
2023-07-01 19:33:47 - train: epoch 0014, iter [00150, 00390], lr: 0.010000, loss: 3.0051
2023-07-01 19:33:49 - train: epoch 0014, iter [00200, 00390], lr: 0.010000, loss: 3.1105
2023-07-01 19:33:51 - train: epoch 0014, iter [00250, 00390], lr: 0.010000, loss: 3.0163
2023-07-01 19:33:53 - train: epoch 0014, iter [00300, 00390], lr: 0.010000, loss: 3.2393
2023-07-01 19:33:56 - train: epoch 0014, iter [00350, 00390], lr: 0.010000, loss: 3.0366
2023-07-01 19:33:58 - train: epoch 014, train_loss: 3.0663
2023-07-01 19:33:59 - eval: epoch: 014, acc1: 25.830%, acc5: 54.620%, test_loss: 3.0331, per_image_load_time: 0.067ms, per_image_inference_time: 0.080ms
2023-07-01 19:33:59 - until epoch: 014, best_acc1: 25.830%
2023-07-01 19:33:59 - epoch 015 lr: 0.010000
2023-07-01 19:34:02 - train: epoch 0015, iter [00050, 00390], lr: 0.010000, loss: 2.7100
2023-07-01 19:34:05 - train: epoch 0015, iter [00100, 00390], lr: 0.010000, loss: 3.1861
2023-07-01 19:34:07 - train: epoch 0015, iter [00150, 00390], lr: 0.010000, loss: 3.2562
2023-07-01 19:34:09 - train: epoch 0015, iter [00200, 00390], lr: 0.010000, loss: 2.9499
2023-07-01 19:34:12 - train: epoch 0015, iter [00250, 00390], lr: 0.010000, loss: 3.0734
2023-07-01 19:34:14 - train: epoch 0015, iter [00300, 00390], lr: 0.010000, loss: 2.9046
2023-07-01 19:34:16 - train: epoch 0015, iter [00350, 00390], lr: 0.010000, loss: 2.8695
2023-07-01 19:34:18 - train: epoch 015, train_loss: 3.0346
2023-07-01 19:34:20 - eval: epoch: 015, acc1: 26.230%, acc5: 55.610%, test_loss: 3.0054, per_image_load_time: 0.083ms, per_image_inference_time: 0.088ms
2023-07-01 19:34:21 - until epoch: 015, best_acc1: 26.230%
2023-07-01 19:34:21 - epoch 016 lr: 0.010000
2023-07-01 19:34:24 - train: epoch 0016, iter [00050, 00390], lr: 0.010000, loss: 3.1414
2023-07-01 19:34:26 - train: epoch 0016, iter [00100, 00390], lr: 0.010000, loss: 2.9774
2023-07-01 19:34:28 - train: epoch 0016, iter [00150, 00390], lr: 0.010000, loss: 3.0872
2023-07-01 19:34:30 - train: epoch 0016, iter [00200, 00390], lr: 0.010000, loss: 3.1946
2023-07-01 19:34:33 - train: epoch 0016, iter [00250, 00390], lr: 0.010000, loss: 2.8061
2023-07-01 19:34:35 - train: epoch 0016, iter [00300, 00390], lr: 0.010000, loss: 2.9996
2023-07-01 19:34:37 - train: epoch 0016, iter [00350, 00390], lr: 0.010000, loss: 2.7687
2023-07-01 19:34:39 - train: epoch 016, train_loss: 3.0073
2023-07-01 19:34:41 - eval: epoch: 016, acc1: 26.530%, acc5: 55.600%, test_loss: 2.9826, per_image_load_time: 0.066ms, per_image_inference_time: 0.081ms
2023-07-01 19:34:42 - until epoch: 016, best_acc1: 26.530%
2023-07-01 19:34:42 - epoch 017 lr: 0.010000
2023-07-01 19:34:45 - train: epoch 0017, iter [00050, 00390], lr: 0.010000, loss: 3.1925
2023-07-01 19:34:48 - train: epoch 0017, iter [00100, 00390], lr: 0.010000, loss: 3.0373
2023-07-01 19:34:50 - train: epoch 0017, iter [00150, 00390], lr: 0.010000, loss: 2.6063
2023-07-01 19:34:52 - train: epoch 0017, iter [00200, 00390], lr: 0.010000, loss: 3.0643
2023-07-01 19:34:55 - train: epoch 0017, iter [00250, 00390], lr: 0.010000, loss: 3.0027
2023-07-01 19:34:57 - train: epoch 0017, iter [00300, 00390], lr: 0.010000, loss: 3.2104
2023-07-01 19:34:59 - train: epoch 0017, iter [00350, 00390], lr: 0.010000, loss: 2.6915
2023-07-01 19:35:01 - train: epoch 017, train_loss: 2.9764
2023-07-01 19:35:03 - eval: epoch: 017, acc1: 27.140%, acc5: 56.430%, test_loss: 2.9654, per_image_load_time: 0.072ms, per_image_inference_time: 0.081ms
2023-07-01 19:35:04 - until epoch: 017, best_acc1: 27.140%
2023-07-01 19:35:04 - epoch 018 lr: 0.010000
2023-07-01 19:35:07 - train: epoch 0018, iter [00050, 00390], lr: 0.010000, loss: 2.9882
2023-07-01 19:35:09 - train: epoch 0018, iter [00100, 00390], lr: 0.010000, loss: 3.2044
2023-07-01 19:35:12 - train: epoch 0018, iter [00150, 00390], lr: 0.010000, loss: 3.2276
2023-07-01 19:35:14 - train: epoch 0018, iter [00200, 00390], lr: 0.010000, loss: 2.9722
2023-07-01 19:35:16 - train: epoch 0018, iter [00250, 00390], lr: 0.010000, loss: 3.0124
2023-07-01 19:35:19 - train: epoch 0018, iter [00300, 00390], lr: 0.010000, loss: 3.0259
2023-07-01 19:35:21 - train: epoch 0018, iter [00350, 00390], lr: 0.010000, loss: 2.9939
2023-07-01 19:35:23 - train: epoch 018, train_loss: 2.9465
2023-07-01 19:35:25 - eval: epoch: 018, acc1: 28.010%, acc5: 57.720%, test_loss: 2.9037, per_image_load_time: 0.068ms, per_image_inference_time: 0.112ms
2023-07-01 19:35:25 - until epoch: 018, best_acc1: 28.010%
2023-07-01 19:35:25 - epoch 019 lr: 0.010000
2023-07-01 19:35:28 - train: epoch 0019, iter [00050, 00390], lr: 0.010000, loss: 2.7578
2023-07-01 19:35:31 - train: epoch 0019, iter [00100, 00390], lr: 0.010000, loss: 2.9960
2023-07-01 19:35:34 - train: epoch 0019, iter [00150, 00390], lr: 0.010000, loss: 3.0716
2023-07-01 19:35:36 - train: epoch 0019, iter [00200, 00390], lr: 0.010000, loss: 2.9746
2023-07-01 19:35:38 - train: epoch 0019, iter [00250, 00390], lr: 0.010000, loss: 3.1056
2023-07-01 19:35:41 - train: epoch 0019, iter [00300, 00390], lr: 0.010000, loss: 3.1287
2023-07-01 19:35:43 - train: epoch 0019, iter [00350, 00390], lr: 0.010000, loss: 2.7688
2023-07-01 19:35:45 - train: epoch 019, train_loss: 2.9126
2023-07-01 19:35:46 - eval: epoch: 019, acc1: 27.900%, acc5: 58.460%, test_loss: 2.9010, per_image_load_time: 0.067ms, per_image_inference_time: 0.082ms
2023-07-01 19:35:47 - until epoch: 019, best_acc1: 28.010%
2023-07-01 19:35:47 - epoch 020 lr: 0.010000
2023-07-01 19:35:50 - train: epoch 0020, iter [00050, 00390], lr: 0.010000, loss: 2.9768
2023-07-01 19:35:53 - train: epoch 0020, iter [00100, 00390], lr: 0.010000, loss: 3.0986
2023-07-01 19:35:55 - train: epoch 0020, iter [00150, 00390], lr: 0.010000, loss: 3.0076
2023-07-01 19:35:57 - train: epoch 0020, iter [00200, 00390], lr: 0.010000, loss: 2.9477
2023-07-01 19:36:00 - train: epoch 0020, iter [00250, 00390], lr: 0.010000, loss: 2.8632
2023-07-01 19:36:02 - train: epoch 0020, iter [00300, 00390], lr: 0.010000, loss: 3.0860
2023-07-01 19:36:04 - train: epoch 0020, iter [00350, 00390], lr: 0.010000, loss: 2.8804
2023-07-01 19:36:06 - train: epoch 020, train_loss: 2.8855
2023-07-01 19:36:08 - eval: epoch: 020, acc1: 28.430%, acc5: 58.470%, test_loss: 2.8894, per_image_load_time: 0.067ms, per_image_inference_time: 0.081ms
2023-07-01 19:36:09 - until epoch: 020, best_acc1: 28.430%
2023-07-01 19:36:09 - epoch 021 lr: 0.010000
2023-07-01 19:36:12 - train: epoch 0021, iter [00050, 00390], lr: 0.010000, loss: 2.7238
2023-07-01 19:36:14 - train: epoch 0021, iter [00100, 00390], lr: 0.010000, loss: 3.0058
2023-07-01 19:36:16 - train: epoch 0021, iter [00150, 00390], lr: 0.010000, loss: 3.0263
2023-07-01 19:36:19 - train: epoch 0021, iter [00200, 00390], lr: 0.010000, loss: 3.2376
2023-07-01 19:36:21 - train: epoch 0021, iter [00250, 00390], lr: 0.010000, loss: 2.8760
2023-07-01 19:36:23 - train: epoch 0021, iter [00300, 00390], lr: 0.010000, loss: 2.9368
2023-07-01 19:36:25 - train: epoch 0021, iter [00350, 00390], lr: 0.010000, loss: 2.7054
2023-07-01 19:36:27 - train: epoch 021, train_loss: 2.8596
2023-07-01 19:36:29 - eval: epoch: 021, acc1: 28.490%, acc5: 58.740%, test_loss: 2.8676, per_image_load_time: 0.068ms, per_image_inference_time: 0.081ms
2023-07-01 19:36:30 - until epoch: 021, best_acc1: 28.490%
2023-07-01 19:36:30 - epoch 022 lr: 0.010000
2023-07-01 19:36:33 - train: epoch 0022, iter [00050, 00390], lr: 0.010000, loss: 2.9708
2023-07-01 19:36:35 - train: epoch 0022, iter [00100, 00390], lr: 0.010000, loss: 2.6864
2023-07-01 19:36:38 - train: epoch 0022, iter [00150, 00390], lr: 0.010000, loss: 2.9562
2023-07-01 19:36:40 - train: epoch 0022, iter [00200, 00390], lr: 0.010000, loss: 2.9509
2023-07-01 19:36:42 - train: epoch 0022, iter [00250, 00390], lr: 0.010000, loss: 2.9102
2023-07-01 19:36:44 - train: epoch 0022, iter [00300, 00390], lr: 0.010000, loss: 2.8666
2023-07-01 19:36:47 - train: epoch 0022, iter [00350, 00390], lr: 0.010000, loss: 2.7581
2023-07-01 19:36:49 - train: epoch 022, train_loss: 2.8321
2023-07-01 19:36:50 - eval: epoch: 022, acc1: 29.030%, acc5: 58.660%, test_loss: 2.8619, per_image_load_time: 0.066ms, per_image_inference_time: 0.081ms
2023-07-01 19:36:51 - until epoch: 022, best_acc1: 29.030%
2023-07-01 19:36:51 - epoch 023 lr: 0.010000
2023-07-01 19:36:54 - train: epoch 0023, iter [00050, 00390], lr: 0.010000, loss: 2.7342
2023-07-01 19:36:56 - train: epoch 0023, iter [00100, 00390], lr: 0.010000, loss: 2.7972
2023-07-01 19:36:59 - train: epoch 0023, iter [00150, 00390], lr: 0.010000, loss: 2.7722
2023-07-01 19:37:01 - train: epoch 0023, iter [00200, 00390], lr: 0.010000, loss: 2.8860
2023-07-01 19:37:03 - train: epoch 0023, iter [00250, 00390], lr: 0.010000, loss: 2.7506
2023-07-01 19:37:06 - train: epoch 0023, iter [00300, 00390], lr: 0.010000, loss: 2.8408
2023-07-01 19:37:08 - train: epoch 0023, iter [00350, 00390], lr: 0.010000, loss: 2.6956
2023-07-01 19:37:10 - train: epoch 023, train_loss: 2.7994
2023-07-01 19:37:12 - eval: epoch: 023, acc1: 30.230%, acc5: 60.440%, test_loss: 2.8102, per_image_load_time: 0.070ms, per_image_inference_time: 0.081ms
2023-07-01 19:37:13 - until epoch: 023, best_acc1: 30.230%
2023-07-01 19:37:13 - epoch 024 lr: 0.010000
2023-07-01 19:37:16 - train: epoch 0024, iter [00050, 00390], lr: 0.010000, loss: 2.6937
2023-07-01 19:37:18 - train: epoch 0024, iter [00100, 00390], lr: 0.010000, loss: 2.7389
2023-07-01 19:37:21 - train: epoch 0024, iter [00150, 00390], lr: 0.010000, loss: 2.5299
2023-07-01 19:37:23 - train: epoch 0024, iter [00200, 00390], lr: 0.010000, loss: 2.9967
2023-07-01 19:37:25 - train: epoch 0024, iter [00250, 00390], lr: 0.010000, loss: 2.7460
2023-07-01 19:37:27 - train: epoch 0024, iter [00300, 00390], lr: 0.010000, loss: 2.6095
2023-07-01 19:37:30 - train: epoch 0024, iter [00350, 00390], lr: 0.010000, loss: 2.7450
2023-07-01 19:37:31 - train: epoch 024, train_loss: 2.7756
2023-07-01 19:37:33 - eval: epoch: 024, acc1: 29.830%, acc5: 59.820%, test_loss: 2.8167, per_image_load_time: 0.089ms, per_image_inference_time: 0.084ms
2023-07-01 19:37:34 - until epoch: 024, best_acc1: 30.230%
2023-07-01 19:37:34 - epoch 025 lr: 0.010000
2023-07-01 19:37:37 - train: epoch 0025, iter [00050, 00390], lr: 0.010000, loss: 2.7896
2023-07-01 19:37:39 - train: epoch 0025, iter [00100, 00390], lr: 0.010000, loss: 2.5620
2023-07-01 19:37:41 - train: epoch 0025, iter [00150, 00390], lr: 0.010000, loss: 2.8989
2023-07-01 19:37:44 - train: epoch 0025, iter [00200, 00390], lr: 0.010000, loss: 2.7492
2023-07-01 19:37:46 - train: epoch 0025, iter [00250, 00390], lr: 0.010000, loss: 2.7523
2023-07-01 19:37:48 - train: epoch 0025, iter [00300, 00390], lr: 0.010000, loss: 2.8195
2023-07-01 19:37:51 - train: epoch 0025, iter [00350, 00390], lr: 0.010000, loss: 2.6411
2023-07-01 19:37:52 - train: epoch 025, train_loss: 2.7484
2023-07-01 19:37:54 - eval: epoch: 025, acc1: 30.350%, acc5: 60.880%, test_loss: 2.7899, per_image_load_time: 0.069ms, per_image_inference_time: 0.082ms
2023-07-01 19:37:54 - until epoch: 025, best_acc1: 30.350%
2023-07-01 19:37:54 - epoch 026 lr: 0.010000
2023-07-01 19:37:58 - train: epoch 0026, iter [00050, 00390], lr: 0.010000, loss: 2.5457
2023-07-01 19:38:00 - train: epoch 0026, iter [00100, 00390], lr: 0.010000, loss: 2.8313
2023-07-01 19:38:02 - train: epoch 0026, iter [00150, 00390], lr: 0.010000, loss: 2.6808
2023-07-01 19:38:04 - train: epoch 0026, iter [00200, 00390], lr: 0.010000, loss: 2.8439
2023-07-01 19:38:07 - train: epoch 0026, iter [00250, 00390], lr: 0.010000, loss: 2.7734
2023-07-01 19:38:09 - train: epoch 0026, iter [00300, 00390], lr: 0.010000, loss: 2.6901
2023-07-01 19:38:11 - train: epoch 0026, iter [00350, 00390], lr: 0.010000, loss: 2.8500
2023-07-01 19:38:13 - train: epoch 026, train_loss: 2.7199
2023-07-01 19:38:15 - eval: epoch: 026, acc1: 30.910%, acc5: 60.910%, test_loss: 2.7763, per_image_load_time: 0.069ms, per_image_inference_time: 0.082ms
2023-07-01 19:38:15 - until epoch: 026, best_acc1: 30.910%
2023-07-01 19:38:15 - epoch 027 lr: 0.010000
2023-07-01 19:38:18 - train: epoch 0027, iter [00050, 00390], lr: 0.010000, loss: 2.5389
2023-07-01 19:38:21 - train: epoch 0027, iter [00100, 00390], lr: 0.010000, loss: 2.6949
2023-07-01 19:38:23 - train: epoch 0027, iter [00150, 00390], lr: 0.010000, loss: 2.6634
2023-07-01 19:38:25 - train: epoch 0027, iter [00200, 00390], lr: 0.010000, loss: 2.8457
2023-07-01 19:38:27 - train: epoch 0027, iter [00250, 00390], lr: 0.010000, loss: 2.9120
2023-07-01 19:38:30 - train: epoch 0027, iter [00300, 00390], lr: 0.010000, loss: 2.7479
2023-07-01 19:38:33 - train: epoch 0027, iter [00350, 00390], lr: 0.010000, loss: 2.8680
2023-07-01 19:38:34 - train: epoch 027, train_loss: 2.6999
2023-07-01 19:38:36 - eval: epoch: 027, acc1: 31.580%, acc5: 61.940%, test_loss: 2.7414, per_image_load_time: 0.088ms, per_image_inference_time: 0.085ms
2023-07-01 19:38:37 - until epoch: 027, best_acc1: 31.580%
2023-07-01 19:38:37 - epoch 028 lr: 0.010000
2023-07-01 19:38:40 - train: epoch 0028, iter [00050, 00390], lr: 0.010000, loss: 2.7741
2023-07-01 19:38:43 - train: epoch 0028, iter [00100, 00390], lr: 0.010000, loss: 2.5564
2023-07-01 19:38:45 - train: epoch 0028, iter [00150, 00390], lr: 0.010000, loss: 2.4420
2023-07-01 19:38:47 - train: epoch 0028, iter [00200, 00390], lr: 0.010000, loss: 2.8361
2023-07-01 19:38:50 - train: epoch 0028, iter [00250, 00390], lr: 0.010000, loss: 2.6185
2023-07-01 19:38:52 - train: epoch 0028, iter [00300, 00390], lr: 0.010000, loss: 2.8144
2023-07-01 19:38:54 - train: epoch 0028, iter [00350, 00390], lr: 0.010000, loss: 2.6998
2023-07-01 19:38:56 - train: epoch 028, train_loss: 2.6660
2023-07-01 19:38:58 - eval: epoch: 028, acc1: 31.350%, acc5: 61.550%, test_loss: 2.7512, per_image_load_time: 0.074ms, per_image_inference_time: 0.082ms
2023-07-01 19:38:58 - until epoch: 028, best_acc1: 31.580%
2023-07-01 19:38:58 - epoch 029 lr: 0.010000
2023-07-01 19:39:01 - train: epoch 0029, iter [00050, 00390], lr: 0.010000, loss: 2.6369
2023-07-01 19:39:04 - train: epoch 0029, iter [00100, 00390], lr: 0.010000, loss: 2.6985
2023-07-01 19:39:06 - train: epoch 0029, iter [00150, 00390], lr: 0.010000, loss: 2.8004
2023-07-01 19:39:08 - train: epoch 0029, iter [00200, 00390], lr: 0.010000, loss: 2.5890
2023-07-01 19:39:10 - train: epoch 0029, iter [00250, 00390], lr: 0.010000, loss: 2.4930
2023-07-01 19:39:12 - train: epoch 0029, iter [00300, 00390], lr: 0.010000, loss: 2.7638
2023-07-01 19:39:15 - train: epoch 0029, iter [00350, 00390], lr: 0.010000, loss: 2.6417
2023-07-01 19:39:17 - train: epoch 029, train_loss: 2.6445
2023-07-01 19:39:18 - eval: epoch: 029, acc1: 30.890%, acc5: 61.450%, test_loss: 2.7473, per_image_load_time: 0.069ms, per_image_inference_time: 0.081ms
2023-07-01 19:39:19 - until epoch: 029, best_acc1: 31.580%
2023-07-01 19:39:19 - epoch 030 lr: 0.010000
2023-07-01 19:39:22 - train: epoch 0030, iter [00050, 00390], lr: 0.010000, loss: 2.5598
2023-07-01 19:39:24 - train: epoch 0030, iter [00100, 00390], lr: 0.010000, loss: 2.7290
2023-07-01 19:39:27 - train: epoch 0030, iter [00150, 00390], lr: 0.010000, loss: 2.5736
2023-07-01 19:39:29 - train: epoch 0030, iter [00200, 00390], lr: 0.010000, loss: 2.5264
2023-07-01 19:39:31 - train: epoch 0030, iter [00250, 00390], lr: 0.010000, loss: 2.6164
2023-07-01 19:39:33 - train: epoch 0030, iter [00300, 00390], lr: 0.010000, loss: 2.6074
2023-07-01 19:39:36 - train: epoch 0030, iter [00350, 00390], lr: 0.010000, loss: 2.5470
2023-07-01 19:39:38 - train: epoch 030, train_loss: 2.6196
2023-07-01 19:39:39 - eval: epoch: 030, acc1: 32.150%, acc5: 62.770%, test_loss: 2.6970, per_image_load_time: 0.067ms, per_image_inference_time: 0.082ms
2023-07-01 19:39:40 - until epoch: 030, best_acc1: 32.150%
2023-07-01 19:39:40 - epoch 031 lr: 0.010000
2023-07-01 19:39:43 - train: epoch 0031, iter [00050, 00390], lr: 0.010000, loss: 2.8425
2023-07-01 19:39:45 - train: epoch 0031, iter [00100, 00390], lr: 0.010000, loss: 2.9560
2023-07-01 19:39:47 - train: epoch 0031, iter [00150, 00390], lr: 0.010000, loss: 2.6220
2023-07-01 19:39:50 - train: epoch 0031, iter [00200, 00390], lr: 0.010000, loss: 2.7286
2023-07-01 19:39:52 - train: epoch 0031, iter [00250, 00390], lr: 0.010000, loss: 2.6931
2023-07-01 19:39:54 - train: epoch 0031, iter [00300, 00390], lr: 0.010000, loss: 2.6597
2023-07-01 19:39:57 - train: epoch 0031, iter [00350, 00390], lr: 0.010000, loss: 2.3602
2023-07-01 19:39:59 - train: epoch 031, train_loss: 2.5966
2023-07-01 19:40:00 - eval: epoch: 031, acc1: 33.200%, acc5: 63.000%, test_loss: 2.6751, per_image_load_time: 0.068ms, per_image_inference_time: 0.081ms
2023-07-01 19:40:01 - until epoch: 031, best_acc1: 33.200%
2023-07-01 19:40:01 - epoch 032 lr: 0.010000
2023-07-01 19:40:04 - train: epoch 0032, iter [00050, 00390], lr: 0.010000, loss: 2.7083
2023-07-01 19:40:06 - train: epoch 0032, iter [00100, 00390], lr: 0.010000, loss: 2.5823
2023-07-01 19:40:09 - train: epoch 0032, iter [00150, 00390], lr: 0.010000, loss: 2.6306
2023-07-01 19:40:11 - train: epoch 0032, iter [00200, 00390], lr: 0.010000, loss: 2.7711
2023-07-01 19:40:13 - train: epoch 0032, iter [00250, 00390], lr: 0.010000, loss: 2.7502
2023-07-01 19:40:16 - train: epoch 0032, iter [00300, 00390], lr: 0.010000, loss: 2.7132
2023-07-01 19:40:18 - train: epoch 0032, iter [00350, 00390], lr: 0.010000, loss: 2.4112
2023-07-01 19:40:20 - train: epoch 032, train_loss: 2.5721
2023-07-01 19:40:22 - eval: epoch: 032, acc1: 33.030%, acc5: 63.560%, test_loss: 2.6709, per_image_load_time: 0.066ms, per_image_inference_time: 0.083ms
2023-07-01 19:40:22 - until epoch: 032, best_acc1: 33.200%
2023-07-01 19:40:22 - epoch 033 lr: 0.010000
2023-07-01 19:40:25 - train: epoch 0033, iter [00050, 00390], lr: 0.010000, loss: 2.3688
2023-07-01 19:40:27 - train: epoch 0033, iter [00100, 00390], lr: 0.010000, loss: 2.5032
2023-07-01 19:40:30 - train: epoch 0033, iter [00150, 00390], lr: 0.010000, loss: 2.7351
2023-07-01 19:40:32 - train: epoch 0033, iter [00200, 00390], lr: 0.010000, loss: 2.5804
2023-07-01 19:40:34 - train: epoch 0033, iter [00250, 00390], lr: 0.010000, loss: 2.5926
2023-07-01 19:40:36 - train: epoch 0033, iter [00300, 00390], lr: 0.010000, loss: 2.8857
2023-07-01 19:40:39 - train: epoch 0033, iter [00350, 00390], lr: 0.010000, loss: 2.5194
2023-07-01 19:40:41 - train: epoch 033, train_loss: 2.5425
2023-07-01 19:40:42 - eval: epoch: 033, acc1: 33.520%, acc5: 63.270%, test_loss: 2.6541, per_image_load_time: 0.067ms, per_image_inference_time: 0.083ms
2023-07-01 19:40:43 - until epoch: 033, best_acc1: 33.520%
2023-07-01 19:40:43 - epoch 034 lr: 0.010000
2023-07-01 19:40:46 - train: epoch 0034, iter [00050, 00390], lr: 0.010000, loss: 2.5951
2023-07-01 19:40:48 - train: epoch 0034, iter [00100, 00390], lr: 0.010000, loss: 2.4182
2023-07-01 19:40:50 - train: epoch 0034, iter [00150, 00390], lr: 0.010000, loss: 2.4600
2023-07-01 19:40:53 - train: epoch 0034, iter [00200, 00390], lr: 0.010000, loss: 2.4468
2023-07-01 19:40:55 - train: epoch 0034, iter [00250, 00390], lr: 0.010000, loss: 2.5132
2023-07-01 19:40:57 - train: epoch 0034, iter [00300, 00390], lr: 0.010000, loss: 2.5995
2023-07-01 19:40:59 - train: epoch 0034, iter [00350, 00390], lr: 0.010000, loss: 2.2602
2023-07-01 19:41:01 - train: epoch 034, train_loss: 2.5245
2023-07-01 19:41:03 - eval: epoch: 034, acc1: 32.810%, acc5: 63.780%, test_loss: 2.6639, per_image_load_time: 0.066ms, per_image_inference_time: 0.082ms
2023-07-01 19:41:03 - until epoch: 034, best_acc1: 33.520%
2023-07-01 19:41:03 - epoch 035 lr: 0.010000
2023-07-01 19:41:06 - train: epoch 0035, iter [00050, 00390], lr: 0.010000, loss: 2.2589
2023-07-01 19:41:09 - train: epoch 0035, iter [00100, 00390], lr: 0.010000, loss: 2.4427
2023-07-01 19:41:11 - train: epoch 0035, iter [00150, 00390], lr: 0.010000, loss: 2.5537
2023-07-01 19:41:13 - train: epoch 0035, iter [00200, 00390], lr: 0.010000, loss: 2.3557
2023-07-01 19:41:15 - train: epoch 0035, iter [00250, 00390], lr: 0.010000, loss: 2.4229
2023-07-01 19:41:18 - train: epoch 0035, iter [00300, 00390], lr: 0.010000, loss: 2.3712
2023-07-01 19:41:20 - train: epoch 0035, iter [00350, 00390], lr: 0.010000, loss: 2.7847
2023-07-01 19:41:22 - train: epoch 035, train_loss: 2.4908
2023-07-01 19:41:24 - eval: epoch: 035, acc1: 34.210%, acc5: 64.300%, test_loss: 2.6258, per_image_load_time: 0.068ms, per_image_inference_time: 0.082ms
2023-07-01 19:41:24 - until epoch: 035, best_acc1: 34.210%
2023-07-01 19:41:24 - epoch 036 lr: 0.010000
2023-07-01 19:41:27 - train: epoch 0036, iter [00050, 00390], lr: 0.010000, loss: 2.4853
2023-07-01 19:41:29 - train: epoch 0036, iter [00100, 00390], lr: 0.010000, loss: 2.4027
2023-07-01 19:41:32 - train: epoch 0036, iter [00150, 00390], lr: 0.010000, loss: 2.3190
2023-07-01 19:41:34 - train: epoch 0036, iter [00200, 00390], lr: 0.010000, loss: 2.6271
2023-07-01 19:41:36 - train: epoch 0036, iter [00250, 00390], lr: 0.010000, loss: 2.4571
2023-07-01 19:41:39 - train: epoch 0036, iter [00300, 00390], lr: 0.010000, loss: 2.5182
2023-07-01 19:41:41 - train: epoch 0036, iter [00350, 00390], lr: 0.010000, loss: 2.1901
2023-07-01 19:41:43 - train: epoch 036, train_loss: 2.4787
2023-07-01 19:41:44 - eval: epoch: 036, acc1: 33.860%, acc5: 64.410%, test_loss: 2.6304, per_image_load_time: 0.065ms, per_image_inference_time: 0.084ms
2023-07-01 19:41:45 - until epoch: 036, best_acc1: 34.210%
2023-07-01 19:41:45 - epoch 037 lr: 0.010000
2023-07-01 19:41:48 - train: epoch 0037, iter [00050, 00390], lr: 0.010000, loss: 2.5227
2023-07-01 19:41:50 - train: epoch 0037, iter [00100, 00390], lr: 0.010000, loss: 2.3641
2023-07-01 19:41:53 - train: epoch 0037, iter [00150, 00390], lr: 0.010000, loss: 2.5476
2023-07-01 19:41:55 - train: epoch 0037, iter [00200, 00390], lr: 0.010000, loss: 2.5946
2023-07-01 19:41:57 - train: epoch 0037, iter [00250, 00390], lr: 0.010000, loss: 2.1308
2023-07-01 19:41:59 - train: epoch 0037, iter [00300, 00390], lr: 0.010000, loss: 2.6042
2023-07-01 19:42:02 - train: epoch 0037, iter [00350, 00390], lr: 0.010000, loss: 2.4957
2023-07-01 19:42:04 - train: epoch 037, train_loss: 2.4500
2023-07-01 19:42:05 - eval: epoch: 037, acc1: 34.400%, acc5: 65.040%, test_loss: 2.6203, per_image_load_time: 0.067ms, per_image_inference_time: 0.083ms
2023-07-01 19:42:05 - until epoch: 037, best_acc1: 34.400%
2023-07-01 19:42:05 - epoch 038 lr: 0.010000
2023-07-01 19:42:09 - train: epoch 0038, iter [00050, 00390], lr: 0.010000, loss: 2.1583
2023-07-01 19:42:11 - train: epoch 0038, iter [00100, 00390], lr: 0.010000, loss: 2.3501
2023-07-01 19:42:13 - train: epoch 0038, iter [00150, 00390], lr: 0.010000, loss: 2.6737
2023-07-01 19:42:15 - train: epoch 0038, iter [00200, 00390], lr: 0.010000, loss: 2.3492
2023-07-01 19:42:18 - train: epoch 0038, iter [00250, 00390], lr: 0.010000, loss: 2.5911
2023-07-01 19:42:20 - train: epoch 0038, iter [00300, 00390], lr: 0.010000, loss: 2.4292
2023-07-01 19:42:22 - train: epoch 0038, iter [00350, 00390], lr: 0.010000, loss: 2.5821
2023-07-01 19:42:24 - train: epoch 038, train_loss: 2.4277
2023-07-01 19:42:26 - eval: epoch: 038, acc1: 34.450%, acc5: 64.730%, test_loss: 2.6167, per_image_load_time: 0.067ms, per_image_inference_time: 0.083ms
2023-07-01 19:42:27 - until epoch: 038, best_acc1: 34.450%
2023-07-01 19:42:27 - epoch 039 lr: 0.010000
2023-07-01 19:42:30 - train: epoch 0039, iter [00050, 00390], lr: 0.010000, loss: 2.3333
2023-07-01 19:42:32 - train: epoch 0039, iter [00100, 00390], lr: 0.010000, loss: 2.3959
2023-07-01 19:42:34 - train: epoch 0039, iter [00150, 00390], lr: 0.010000, loss: 2.3117
2023-07-01 19:42:36 - train: epoch 0039, iter [00200, 00390], lr: 0.010000, loss: 2.2458
2023-07-01 19:42:39 - train: epoch 0039, iter [00250, 00390], lr: 0.010000, loss: 2.5030
2023-07-01 19:42:41 - train: epoch 0039, iter [00300, 00390], lr: 0.010000, loss: 2.2374
2023-07-01 19:42:43 - train: epoch 0039, iter [00350, 00390], lr: 0.010000, loss: 2.5134
2023-07-01 19:42:45 - train: epoch 039, train_loss: 2.4132
2023-07-01 19:42:47 - eval: epoch: 039, acc1: 34.980%, acc5: 65.780%, test_loss: 2.5876, per_image_load_time: 0.066ms, per_image_inference_time: 0.082ms
2023-07-01 19:42:47 - until epoch: 039, best_acc1: 34.980%
2023-07-01 19:42:47 - epoch 040 lr: 0.010000
2023-07-01 19:42:50 - train: epoch 0040, iter [00050, 00390], lr: 0.010000, loss: 2.4666
2023-07-01 19:42:52 - train: epoch 0040, iter [00100, 00390], lr: 0.010000, loss: 2.1812
2023-07-01 19:42:54 - train: epoch 0040, iter [00150, 00390], lr: 0.010000, loss: 2.3053
2023-07-01 19:42:57 - train: epoch 0040, iter [00200, 00390], lr: 0.010000, loss: 2.4796
2023-07-01 19:42:59 - train: epoch 0040, iter [00250, 00390], lr: 0.010000, loss: 2.4799
2023-07-01 19:43:01 - train: epoch 0040, iter [00300, 00390], lr: 0.010000, loss: 2.1424
2023-07-01 19:43:03 - train: epoch 0040, iter [00350, 00390], lr: 0.010000, loss: 2.3762
2023-07-01 19:43:05 - train: epoch 040, train_loss: 2.3858
2023-07-01 19:43:07 - eval: epoch: 040, acc1: 34.920%, acc5: 65.520%, test_loss: 2.5871, per_image_load_time: 0.068ms, per_image_inference_time: 0.082ms
2023-07-01 19:43:07 - until epoch: 040, best_acc1: 34.980%
2023-07-01 19:43:07 - epoch 041 lr: 0.010000
2023-07-01 19:43:10 - train: epoch 0041, iter [00050, 00390], lr: 0.010000, loss: 2.2553
2023-07-01 19:43:12 - train: epoch 0041, iter [00100, 00390], lr: 0.010000, loss: 2.1042
2023-07-01 19:43:14 - train: epoch 0041, iter [00150, 00390], lr: 0.010000, loss: 2.3192
2023-07-01 19:43:16 - train: epoch 0041, iter [00200, 00390], lr: 0.010000, loss: 2.6705
2023-07-01 19:43:19 - train: epoch 0041, iter [00250, 00390], lr: 0.010000, loss: 2.5088
2023-07-01 19:43:21 - train: epoch 0041, iter [00300, 00390], lr: 0.010000, loss: 2.4563
2023-07-01 19:43:23 - train: epoch 0041, iter [00350, 00390], lr: 0.010000, loss: 2.3090
2023-07-01 19:43:26 - train: epoch 041, train_loss: 2.3651
2023-07-01 19:43:28 - eval: epoch: 041, acc1: 35.670%, acc5: 65.950%, test_loss: 2.5564, per_image_load_time: 0.066ms, per_image_inference_time: 0.081ms
2023-07-01 19:43:28 - until epoch: 041, best_acc1: 35.670%
2023-07-01 19:43:28 - epoch 042 lr: 0.010000
2023-07-01 19:43:31 - train: epoch 0042, iter [00050, 00390], lr: 0.010000, loss: 2.1268
2023-07-01 19:43:33 - train: epoch 0042, iter [00100, 00390], lr: 0.010000, loss: 2.3647
2023-07-01 19:43:36 - train: epoch 0042, iter [00150, 00390], lr: 0.010000, loss: 2.1097
2023-07-01 19:43:38 - train: epoch 0042, iter [00200, 00390], lr: 0.010000, loss: 2.1253
2023-07-01 19:43:41 - train: epoch 0042, iter [00250, 00390], lr: 0.010000, loss: 2.2583
2023-07-01 19:43:43 - train: epoch 0042, iter [00300, 00390], lr: 0.010000, loss: 2.1399
2023-07-01 19:43:46 - train: epoch 0042, iter [00350, 00390], lr: 0.010000, loss: 2.0594
2023-07-01 19:43:47 - train: epoch 042, train_loss: 2.3428
2023-07-01 19:43:49 - eval: epoch: 042, acc1: 35.440%, acc5: 65.600%, test_loss: 2.5842, per_image_load_time: 0.067ms, per_image_inference_time: 0.081ms
2023-07-01 19:43:49 - until epoch: 042, best_acc1: 35.670%
2023-07-01 19:43:49 - epoch 043 lr: 0.010000
2023-07-01 19:43:52 - train: epoch 0043, iter [00050, 00390], lr: 0.010000, loss: 2.4433
2023-07-01 19:43:54 - train: epoch 0043, iter [00100, 00390], lr: 0.010000, loss: 2.1371
2023-07-01 19:43:57 - train: epoch 0043, iter [00150, 00390], lr: 0.010000, loss: 2.1183
2023-07-01 19:43:59 - train: epoch 0043, iter [00200, 00390], lr: 0.010000, loss: 2.6001
2023-07-01 19:44:01 - train: epoch 0043, iter [00250, 00390], lr: 0.010000, loss: 2.3460
2023-07-01 19:44:03 - train: epoch 0043, iter [00300, 00390], lr: 0.010000, loss: 2.3475
2023-07-01 19:44:05 - train: epoch 0043, iter [00350, 00390], lr: 0.010000, loss: 2.2776
2023-07-01 19:44:07 - train: epoch 043, train_loss: 2.3192
2023-07-01 19:44:09 - eval: epoch: 043, acc1: 35.280%, acc5: 65.310%, test_loss: 2.5758, per_image_load_time: 0.066ms, per_image_inference_time: 0.084ms
2023-07-01 19:44:09 - until epoch: 043, best_acc1: 35.670%
2023-07-01 19:44:09 - epoch 044 lr: 0.010000
2023-07-01 19:44:12 - train: epoch 0044, iter [00050, 00390], lr: 0.010000, loss: 2.4805
2023-07-01 19:44:14 - train: epoch 0044, iter [00100, 00390], lr: 0.010000, loss: 2.4318
2023-07-01 19:44:16 - train: epoch 0044, iter [00150, 00390], lr: 0.010000, loss: 2.2684
2023-07-01 19:44:18 - train: epoch 0044, iter [00200, 00390], lr: 0.010000, loss: 2.3015
2023-07-01 19:44:21 - train: epoch 0044, iter [00250, 00390], lr: 0.010000, loss: 2.5632
2023-07-01 19:44:23 - train: epoch 0044, iter [00300, 00390], lr: 0.010000, loss: 1.9090
2023-07-01 19:44:25 - train: epoch 0044, iter [00350, 00390], lr: 0.010000, loss: 2.1828
2023-07-01 19:44:27 - train: epoch 044, train_loss: 2.2995
2023-07-01 19:44:28 - eval: epoch: 044, acc1: 35.750%, acc5: 65.820%, test_loss: 2.5598, per_image_load_time: 0.065ms, per_image_inference_time: 0.082ms
2023-07-01 19:44:29 - until epoch: 044, best_acc1: 35.750%
2023-07-01 19:44:29 - epoch 045 lr: 0.010000
2023-07-01 19:44:32 - train: epoch 0045, iter [00050, 00390], lr: 0.010000, loss: 2.2152
2023-07-01 19:44:34 - train: epoch 0045, iter [00100, 00390], lr: 0.010000, loss: 2.3801
2023-07-01 19:44:36 - train: epoch 0045, iter [00150, 00390], lr: 0.010000, loss: 2.2029
2023-07-01 19:44:39 - train: epoch 0045, iter [00200, 00390], lr: 0.010000, loss: 2.2997
2023-07-01 19:44:41 - train: epoch 0045, iter [00250, 00390], lr: 0.010000, loss: 2.1300
2023-07-01 19:44:43 - train: epoch 0045, iter [00300, 00390], lr: 0.010000, loss: 2.2617
2023-07-01 19:44:45 - train: epoch 0045, iter [00350, 00390], lr: 0.010000, loss: 2.4628
2023-07-01 19:44:47 - train: epoch 045, train_loss: 2.2721
2023-07-01 19:44:48 - eval: epoch: 045, acc1: 36.070%, acc5: 66.750%, test_loss: 2.5505, per_image_load_time: 0.066ms, per_image_inference_time: 0.083ms
2023-07-01 19:44:49 - until epoch: 045, best_acc1: 36.070%
2023-07-01 19:44:49 - epoch 046 lr: 0.010000
2023-07-01 19:44:52 - train: epoch 0046, iter [00050, 00390], lr: 0.010000, loss: 2.4892
2023-07-01 19:44:54 - train: epoch 0046, iter [00100, 00390], lr: 0.010000, loss: 2.2581
2023-07-01 19:44:56 - train: epoch 0046, iter [00150, 00390], lr: 0.010000, loss: 1.9922
2023-07-01 19:44:59 - train: epoch 0046, iter [00200, 00390], lr: 0.010000, loss: 2.1668
2023-07-01 19:45:01 - train: epoch 0046, iter [00250, 00390], lr: 0.010000, loss: 2.1383
2023-07-01 19:45:03 - train: epoch 0046, iter [00300, 00390], lr: 0.010000, loss: 2.2244
2023-07-01 19:45:05 - train: epoch 0046, iter [00350, 00390], lr: 0.010000, loss: 2.1049
2023-07-01 19:45:07 - train: epoch 046, train_loss: 2.2523
2023-07-01 19:45:09 - eval: epoch: 046, acc1: 35.570%, acc5: 65.710%, test_loss: 2.5576, per_image_load_time: 0.067ms, per_image_inference_time: 0.081ms
2023-07-01 19:45:09 - until epoch: 046, best_acc1: 36.070%
2023-07-01 19:45:09 - epoch 047 lr: 0.010000
2023-07-01 19:45:12 - train: epoch 0047, iter [00050, 00390], lr: 0.010000, loss: 2.3240
2023-07-01 19:45:14 - train: epoch 0047, iter [00100, 00390], lr: 0.010000, loss: 2.1955
2023-07-01 19:45:17 - train: epoch 0047, iter [00150, 00390], lr: 0.010000, loss: 2.1166
2023-07-01 19:45:19 - train: epoch 0047, iter [00200, 00390], lr: 0.010000, loss: 2.2125
2023-07-01 19:45:21 - train: epoch 0047, iter [00250, 00390], lr: 0.010000, loss: 2.1465
2023-07-01 19:45:23 - train: epoch 0047, iter [00300, 00390], lr: 0.010000, loss: 1.9884
2023-07-01 19:45:25 - train: epoch 0047, iter [00350, 00390], lr: 0.010000, loss: 2.1425
2023-07-01 19:45:27 - train: epoch 047, train_loss: 2.2285
2023-07-01 19:45:29 - eval: epoch: 047, acc1: 36.220%, acc5: 67.190%, test_loss: 2.5357, per_image_load_time: 0.067ms, per_image_inference_time: 0.082ms
2023-07-01 19:45:29 - until epoch: 047, best_acc1: 36.220%
2023-07-01 19:45:29 - epoch 048 lr: 0.010000
2023-07-01 19:45:32 - train: epoch 0048, iter [00050, 00390], lr: 0.010000, loss: 2.2405
2023-07-01 19:45:34 - train: epoch 0048, iter [00100, 00390], lr: 0.010000, loss: 2.0662
2023-07-01 19:45:37 - train: epoch 0048, iter [00150, 00390], lr: 0.010000, loss: 2.1508
2023-07-01 19:45:39 - train: epoch 0048, iter [00200, 00390], lr: 0.010000, loss: 2.3234
2023-07-01 19:45:41 - train: epoch 0048, iter [00250, 00390], lr: 0.010000, loss: 2.1496
2023-07-01 19:45:43 - train: epoch 0048, iter [00300, 00390], lr: 0.010000, loss: 2.0062
2023-07-01 19:45:45 - train: epoch 0048, iter [00350, 00390], lr: 0.010000, loss: 2.4165
2023-07-01 19:45:47 - train: epoch 048, train_loss: 2.2063
2023-07-01 19:45:49 - eval: epoch: 048, acc1: 36.100%, acc5: 66.820%, test_loss: 2.5466, per_image_load_time: 0.067ms, per_image_inference_time: 0.082ms
2023-07-01 19:45:49 - until epoch: 048, best_acc1: 36.220%
2023-07-01 19:45:49 - epoch 049 lr: 0.010000
2023-07-01 19:45:52 - train: epoch 0049, iter [00050, 00390], lr: 0.010000, loss: 2.4356
2023-07-01 19:45:55 - train: epoch 0049, iter [00100, 00390], lr: 0.010000, loss: 2.0502
2023-07-01 19:45:57 - train: epoch 0049, iter [00150, 00390], lr: 0.010000, loss: 2.1238
2023-07-01 19:45:59 - train: epoch 0049, iter [00200, 00390], lr: 0.010000, loss: 2.0254
2023-07-01 19:46:01 - train: epoch 0049, iter [00250, 00390], lr: 0.010000, loss: 2.1515
2023-07-01 19:46:03 - train: epoch 0049, iter [00300, 00390], lr: 0.010000, loss: 2.0612
2023-07-01 19:46:06 - train: epoch 0049, iter [00350, 00390], lr: 0.010000, loss: 2.1727
2023-07-01 19:46:07 - train: epoch 049, train_loss: 2.1855
2023-07-01 19:46:09 - eval: epoch: 049, acc1: 37.130%, acc5: 66.810%, test_loss: 2.5437, per_image_load_time: 0.068ms, per_image_inference_time: 0.081ms
2023-07-01 19:46:10 - until epoch: 049, best_acc1: 37.130%
2023-07-01 19:46:10 - epoch 050 lr: 0.010000
2023-07-01 19:46:13 - train: epoch 0050, iter [00050, 00390], lr: 0.010000, loss: 2.1708
2023-07-01 19:46:15 - train: epoch 0050, iter [00100, 00390], lr: 0.010000, loss: 2.2110
2023-07-01 19:46:18 - train: epoch 0050, iter [00150, 00390], lr: 0.010000, loss: 2.1758
2023-07-01 19:46:20 - train: epoch 0050, iter [00200, 00390], lr: 0.010000, loss: 2.0113
2023-07-01 19:46:22 - train: epoch 0050, iter [00250, 00390], lr: 0.010000, loss: 2.2479
2023-07-01 19:46:24 - train: epoch 0050, iter [00300, 00390], lr: 0.010000, loss: 2.3048
2023-07-01 19:46:26 - train: epoch 0050, iter [00350, 00390], lr: 0.010000, loss: 2.2928
2023-07-01 19:46:28 - train: epoch 050, train_loss: 2.1633
2023-07-01 19:46:30 - eval: epoch: 050, acc1: 37.220%, acc5: 67.100%, test_loss: 2.5354, per_image_load_time: 0.085ms, per_image_inference_time: 0.089ms
2023-07-01 19:46:30 - until epoch: 050, best_acc1: 37.220%
2023-07-01 19:46:30 - epoch 051 lr: 0.010000
2023-07-01 19:46:33 - train: epoch 0051, iter [00050, 00390], lr: 0.010000, loss: 2.3585
2023-07-01 19:46:36 - train: epoch 0051, iter [00100, 00390], lr: 0.010000, loss: 2.0449
2023-07-01 19:46:38 - train: epoch 0051, iter [00150, 00390], lr: 0.010000, loss: 2.0546
2023-07-01 19:46:40 - train: epoch 0051, iter [00200, 00390], lr: 0.010000, loss: 2.0633
2023-07-01 19:46:43 - train: epoch 0051, iter [00250, 00390], lr: 0.010000, loss: 2.1712
2023-07-01 19:46:45 - train: epoch 0051, iter [00300, 00390], lr: 0.010000, loss: 1.8978
2023-07-01 19:46:47 - train: epoch 0051, iter [00350, 00390], lr: 0.010000, loss: 2.2046
2023-07-01 19:46:49 - train: epoch 051, train_loss: 2.1375
2023-07-01 19:46:51 - eval: epoch: 051, acc1: 37.130%, acc5: 67.000%, test_loss: 2.5220, per_image_load_time: 0.072ms, per_image_inference_time: 0.083ms
2023-07-01 19:46:51 - until epoch: 051, best_acc1: 37.220%
2023-07-01 19:46:51 - epoch 052 lr: 0.010000
2023-07-01 19:46:54 - train: epoch 0052, iter [00050, 00390], lr: 0.010000, loss: 2.3761
2023-07-01 19:46:57 - train: epoch 0052, iter [00100, 00390], lr: 0.010000, loss: 2.1047
2023-07-01 19:46:59 - train: epoch 0052, iter [00150, 00390], lr: 0.010000, loss: 2.3425
2023-07-01 19:47:01 - train: epoch 0052, iter [00200, 00390], lr: 0.010000, loss: 1.9358
2023-07-01 19:47:04 - train: epoch 0052, iter [00250, 00390], lr: 0.010000, loss: 2.1706
2023-07-01 19:47:06 - train: epoch 0052, iter [00300, 00390], lr: 0.010000, loss: 2.0888
2023-07-01 19:47:09 - train: epoch 0052, iter [00350, 00390], lr: 0.010000, loss: 2.0711
2023-07-01 19:47:10 - train: epoch 052, train_loss: 2.1165
2023-07-01 19:47:12 - eval: epoch: 052, acc1: 37.100%, acc5: 67.410%, test_loss: 2.5240, per_image_load_time: 0.086ms, per_image_inference_time: 0.083ms
2023-07-01 19:47:12 - until epoch: 052, best_acc1: 37.220%
2023-07-01 19:47:12 - epoch 053 lr: 0.010000
2023-07-01 19:47:16 - train: epoch 0053, iter [00050, 00390], lr: 0.010000, loss: 2.0171
2023-07-01 19:47:18 - train: epoch 0053, iter [00100, 00390], lr: 0.010000, loss: 1.8658
2023-07-01 19:47:20 - train: epoch 0053, iter [00150, 00390], lr: 0.010000, loss: 1.9044
2023-07-01 19:47:23 - train: epoch 0053, iter [00200, 00390], lr: 0.010000, loss: 2.1149
2023-07-01 19:47:25 - train: epoch 0053, iter [00250, 00390], lr: 0.010000, loss: 2.1446
2023-07-01 19:47:27 - train: epoch 0053, iter [00300, 00390], lr: 0.010000, loss: 1.8257
2023-07-01 19:47:30 - train: epoch 0053, iter [00350, 00390], lr: 0.010000, loss: 1.8681
2023-07-01 19:47:31 - train: epoch 053, train_loss: 2.0916
2023-07-01 19:47:33 - eval: epoch: 053, acc1: 37.030%, acc5: 67.040%, test_loss: 2.5514, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 19:47:34 - until epoch: 053, best_acc1: 37.220%
2023-07-01 19:47:34 - epoch 054 lr: 0.010000
2023-07-01 19:47:37 - train: epoch 0054, iter [00050, 00390], lr: 0.010000, loss: 2.0524
2023-07-01 19:47:39 - train: epoch 0054, iter [00100, 00390], lr: 0.010000, loss: 2.1899
2023-07-01 19:47:42 - train: epoch 0054, iter [00150, 00390], lr: 0.010000, loss: 2.0022
2023-07-01 19:47:44 - train: epoch 0054, iter [00200, 00390], lr: 0.010000, loss: 2.4567
2023-07-01 19:47:46 - train: epoch 0054, iter [00250, 00390], lr: 0.010000, loss: 2.1669
2023-07-01 19:47:49 - train: epoch 0054, iter [00300, 00390], lr: 0.010000, loss: 2.1672
2023-07-01 19:47:51 - train: epoch 0054, iter [00350, 00390], lr: 0.010000, loss: 1.8370
2023-07-01 19:47:53 - train: epoch 054, train_loss: 2.0707
2023-07-01 19:47:55 - eval: epoch: 054, acc1: 37.110%, acc5: 66.540%, test_loss: 2.5546, per_image_load_time: 0.082ms, per_image_inference_time: 0.083ms
2023-07-01 19:47:55 - until epoch: 054, best_acc1: 37.220%
2023-07-01 19:47:55 - epoch 055 lr: 0.010000
2023-07-01 19:47:59 - train: epoch 0055, iter [00050, 00390], lr: 0.010000, loss: 2.0936
2023-07-01 19:48:01 - train: epoch 0055, iter [00100, 00390], lr: 0.010000, loss: 1.9791
2023-07-01 19:48:03 - train: epoch 0055, iter [00150, 00390], lr: 0.010000, loss: 2.0873
2023-07-01 19:48:06 - train: epoch 0055, iter [00200, 00390], lr: 0.010000, loss: 2.1647
2023-07-01 19:48:08 - train: epoch 0055, iter [00250, 00390], lr: 0.010000, loss: 2.0805
2023-07-01 19:48:10 - train: epoch 0055, iter [00300, 00390], lr: 0.010000, loss: 1.6951
2023-07-01 19:48:13 - train: epoch 0055, iter [00350, 00390], lr: 0.010000, loss: 1.8792
2023-07-01 19:48:15 - train: epoch 055, train_loss: 2.0471
2023-07-01 19:48:16 - eval: epoch: 055, acc1: 37.770%, acc5: 67.620%, test_loss: 2.5359, per_image_load_time: 0.081ms, per_image_inference_time: 0.084ms
2023-07-01 19:48:17 - until epoch: 055, best_acc1: 37.770%
2023-07-01 19:48:17 - epoch 056 lr: 0.010000
2023-07-01 19:48:20 - train: epoch 0056, iter [00050, 00390], lr: 0.010000, loss: 2.2688
2023-07-01 19:48:22 - train: epoch 0056, iter [00100, 00390], lr: 0.010000, loss: 1.8871
2023-07-01 19:48:25 - train: epoch 0056, iter [00150, 00390], lr: 0.010000, loss: 1.7621
2023-07-01 19:48:27 - train: epoch 0056, iter [00200, 00390], lr: 0.010000, loss: 1.9239
2023-07-01 19:48:29 - train: epoch 0056, iter [00250, 00390], lr: 0.010000, loss: 1.9187
2023-07-01 19:48:32 - train: epoch 0056, iter [00300, 00390], lr: 0.010000, loss: 2.3847
2023-07-01 19:48:34 - train: epoch 0056, iter [00350, 00390], lr: 0.010000, loss: 1.5754
2023-07-01 19:48:36 - train: epoch 056, train_loss: 2.0248
2023-07-01 19:48:38 - eval: epoch: 056, acc1: 37.920%, acc5: 66.790%, test_loss: 2.5343, per_image_load_time: 0.077ms, per_image_inference_time: 0.083ms
2023-07-01 19:48:39 - until epoch: 056, best_acc1: 37.920%
2023-07-01 19:48:39 - epoch 057 lr: 0.010000
2023-07-01 19:48:42 - train: epoch 0057, iter [00050, 00390], lr: 0.010000, loss: 2.1859
2023-07-01 19:48:44 - train: epoch 0057, iter [00100, 00390], lr: 0.010000, loss: 2.0475
2023-07-01 19:48:47 - train: epoch 0057, iter [00150, 00390], lr: 0.010000, loss: 1.7948
2023-07-01 19:48:49 - train: epoch 0057, iter [00200, 00390], lr: 0.010000, loss: 2.3378
2023-07-01 19:48:51 - train: epoch 0057, iter [00250, 00390], lr: 0.010000, loss: 2.1465
2023-07-01 19:48:54 - train: epoch 0057, iter [00300, 00390], lr: 0.010000, loss: 2.0340
2023-07-01 19:48:56 - train: epoch 0057, iter [00350, 00390], lr: 0.010000, loss: 2.1709
2023-07-01 19:48:58 - train: epoch 057, train_loss: 2.0031
2023-07-01 19:49:00 - eval: epoch: 057, acc1: 36.890%, acc5: 67.000%, test_loss: 2.5616, per_image_load_time: 0.079ms, per_image_inference_time: 0.089ms
2023-07-01 19:49:00 - until epoch: 057, best_acc1: 37.920%
2023-07-01 19:49:00 - epoch 058 lr: 0.010000
2023-07-01 19:49:03 - train: epoch 0058, iter [00050, 00390], lr: 0.010000, loss: 1.9118
2023-07-01 19:49:06 - train: epoch 0058, iter [00100, 00390], lr: 0.010000, loss: 2.0610
2023-07-01 19:49:08 - train: epoch 0058, iter [00150, 00390], lr: 0.010000, loss: 1.8273
2023-07-01 19:49:10 - train: epoch 0058, iter [00200, 00390], lr: 0.010000, loss: 2.0714
2023-07-01 19:49:13 - train: epoch 0058, iter [00250, 00390], lr: 0.010000, loss: 2.1062
2023-07-01 19:49:15 - train: epoch 0058, iter [00300, 00390], lr: 0.010000, loss: 2.1563
2023-07-01 19:49:17 - train: epoch 0058, iter [00350, 00390], lr: 0.010000, loss: 2.1068
2023-07-01 19:49:19 - train: epoch 058, train_loss: 1.9715
2023-07-01 19:49:21 - eval: epoch: 058, acc1: 37.640%, acc5: 67.400%, test_loss: 2.5527, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 19:49:21 - until epoch: 058, best_acc1: 37.920%
2023-07-01 19:49:21 - epoch 059 lr: 0.010000
2023-07-01 19:49:24 - train: epoch 0059, iter [00050, 00390], lr: 0.010000, loss: 1.9348
2023-07-01 19:49:27 - train: epoch 0059, iter [00100, 00390], lr: 0.010000, loss: 1.8347
2023-07-01 19:49:29 - train: epoch 0059, iter [00150, 00390], lr: 0.010000, loss: 1.9143
2023-07-01 19:49:32 - train: epoch 0059, iter [00200, 00390], lr: 0.010000, loss: 1.9475
2023-07-01 19:49:34 - train: epoch 0059, iter [00250, 00390], lr: 0.010000, loss: 2.0303
2023-07-01 19:49:36 - train: epoch 0059, iter [00300, 00390], lr: 0.010000, loss: 2.0104
2023-07-01 19:49:39 - train: epoch 0059, iter [00350, 00390], lr: 0.010000, loss: 2.1384
2023-07-01 19:49:41 - train: epoch 059, train_loss: 1.9480
2023-07-01 19:49:42 - eval: epoch: 059, acc1: 37.160%, acc5: 66.820%, test_loss: 2.5606, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 19:49:43 - until epoch: 059, best_acc1: 37.920%
2023-07-01 19:49:43 - epoch 060 lr: 0.010000
2023-07-01 19:49:46 - train: epoch 0060, iter [00050, 00390], lr: 0.010000, loss: 2.0677
2023-07-01 19:49:49 - train: epoch 0060, iter [00100, 00390], lr: 0.010000, loss: 1.6452
2023-07-01 19:49:51 - train: epoch 0060, iter [00150, 00390], lr: 0.010000, loss: 1.8764
2023-07-01 19:49:54 - train: epoch 0060, iter [00200, 00390], lr: 0.010000, loss: 1.8516
2023-07-01 19:49:56 - train: epoch 0060, iter [00250, 00390], lr: 0.010000, loss: 1.9714
2023-07-01 19:49:58 - train: epoch 0060, iter [00300, 00390], lr: 0.010000, loss: 1.7250
2023-07-01 19:50:01 - train: epoch 0060, iter [00350, 00390], lr: 0.010000, loss: 1.6108
2023-07-01 19:50:03 - train: epoch 060, train_loss: 1.9263
2023-07-01 19:50:05 - eval: epoch: 060, acc1: 37.750%, acc5: 67.440%, test_loss: 2.5534, per_image_load_time: 0.078ms, per_image_inference_time: 0.137ms
2023-07-01 19:50:05 - until epoch: 060, best_acc1: 37.920%
2023-07-01 19:50:05 - epoch 061 lr: 0.002000
2023-07-01 19:50:08 - train: epoch 0061, iter [00050, 00390], lr: 0.002000, loss: 1.6185
2023-07-01 19:50:11 - train: epoch 0061, iter [00100, 00390], lr: 0.002000, loss: 1.7157
2023-07-01 19:50:13 - train: epoch 0061, iter [00150, 00390], lr: 0.002000, loss: 1.7325
2023-07-01 19:50:15 - train: epoch 0061, iter [00200, 00390], lr: 0.002000, loss: 1.7100
2023-07-01 19:50:18 - train: epoch 0061, iter [00250, 00390], lr: 0.002000, loss: 1.4908
2023-07-01 19:50:20 - train: epoch 0061, iter [00300, 00390], lr: 0.002000, loss: 1.5149
2023-07-01 19:50:22 - train: epoch 0061, iter [00350, 00390], lr: 0.002000, loss: 1.5325
2023-07-01 19:50:24 - train: epoch 061, train_loss: 1.6052
2023-07-01 19:50:26 - eval: epoch: 061, acc1: 40.950%, acc5: 69.890%, test_loss: 2.4089, per_image_load_time: 0.080ms, per_image_inference_time: 0.084ms
2023-07-01 19:50:27 - until epoch: 061, best_acc1: 40.950%
2023-07-01 19:50:27 - epoch 062 lr: 0.002000
2023-07-01 19:50:30 - train: epoch 0062, iter [00050, 00390], lr: 0.002000, loss: 1.2515
2023-07-01 19:50:32 - train: epoch 0062, iter [00100, 00390], lr: 0.002000, loss: 1.5195
2023-07-01 19:50:35 - train: epoch 0062, iter [00150, 00390], lr: 0.002000, loss: 1.8524
2023-07-01 19:50:37 - train: epoch 0062, iter [00200, 00390], lr: 0.002000, loss: 1.3707
2023-07-01 19:50:39 - train: epoch 0062, iter [00250, 00390], lr: 0.002000, loss: 1.5440
2023-07-01 19:50:42 - train: epoch 0062, iter [00300, 00390], lr: 0.002000, loss: 1.5208
2023-07-01 19:50:44 - train: epoch 0062, iter [00350, 00390], lr: 0.002000, loss: 1.5191
2023-07-01 19:50:46 - train: epoch 062, train_loss: 1.5038
2023-07-01 19:50:48 - eval: epoch: 062, acc1: 41.510%, acc5: 69.960%, test_loss: 2.4153, per_image_load_time: 0.080ms, per_image_inference_time: 0.082ms
2023-07-01 19:50:49 - until epoch: 062, best_acc1: 41.510%
2023-07-01 19:50:49 - epoch 063 lr: 0.002000
2023-07-01 19:50:52 - train: epoch 0063, iter [00050, 00390], lr: 0.002000, loss: 1.4651
2023-07-01 19:50:54 - train: epoch 0063, iter [00100, 00390], lr: 0.002000, loss: 1.3848
2023-07-01 19:50:57 - train: epoch 0063, iter [00150, 00390], lr: 0.002000, loss: 1.4041
2023-07-01 19:50:59 - train: epoch 0063, iter [00200, 00390], lr: 0.002000, loss: 1.4048
2023-07-01 19:51:01 - train: epoch 0063, iter [00250, 00390], lr: 0.002000, loss: 1.4765
2023-07-01 19:51:04 - train: epoch 0063, iter [00300, 00390], lr: 0.002000, loss: 1.6054
2023-07-01 19:51:06 - train: epoch 0063, iter [00350, 00390], lr: 0.002000, loss: 1.5123
2023-07-01 19:51:08 - train: epoch 063, train_loss: 1.4508
2023-07-01 19:51:10 - eval: epoch: 063, acc1: 41.100%, acc5: 69.490%, test_loss: 2.4520, per_image_load_time: 0.077ms, per_image_inference_time: 0.083ms
2023-07-01 19:51:10 - until epoch: 063, best_acc1: 41.510%
2023-07-01 19:51:10 - epoch 064 lr: 0.002000
2023-07-01 19:51:13 - train: epoch 0064, iter [00050, 00390], lr: 0.002000, loss: 1.4543
2023-07-01 19:51:16 - train: epoch 0064, iter [00100, 00390], lr: 0.002000, loss: 1.3798
2023-07-01 19:51:18 - train: epoch 0064, iter [00150, 00390], lr: 0.002000, loss: 1.4503
2023-07-01 19:51:21 - train: epoch 0064, iter [00200, 00390], lr: 0.002000, loss: 1.3762
2023-07-01 19:51:23 - train: epoch 0064, iter [00250, 00390], lr: 0.002000, loss: 1.7412
2023-07-01 19:51:25 - train: epoch 0064, iter [00300, 00390], lr: 0.002000, loss: 1.2406
2023-07-01 19:51:28 - train: epoch 0064, iter [00350, 00390], lr: 0.002000, loss: 1.2863
2023-07-01 19:51:30 - train: epoch 064, train_loss: 1.4275
2023-07-01 19:51:31 - eval: epoch: 064, acc1: 41.100%, acc5: 69.440%, test_loss: 2.4604, per_image_load_time: 0.077ms, per_image_inference_time: 0.083ms
2023-07-01 19:51:32 - until epoch: 064, best_acc1: 41.510%
2023-07-01 19:51:32 - epoch 065 lr: 0.002000
2023-07-01 19:51:35 - train: epoch 0065, iter [00050, 00390], lr: 0.002000, loss: 1.3570
2023-07-01 19:51:37 - train: epoch 0065, iter [00100, 00390], lr: 0.002000, loss: 1.4015
2023-07-01 19:51:39 - train: epoch 0065, iter [00150, 00390], lr: 0.002000, loss: 1.5975
2023-07-01 19:51:42 - train: epoch 0065, iter [00200, 00390], lr: 0.002000, loss: 1.5989
2023-07-01 19:51:44 - train: epoch 0065, iter [00250, 00390], lr: 0.002000, loss: 1.3603
2023-07-01 19:51:46 - train: epoch 0065, iter [00300, 00390], lr: 0.002000, loss: 1.3875
2023-07-01 19:51:49 - train: epoch 0065, iter [00350, 00390], lr: 0.002000, loss: 1.1997
2023-07-01 19:51:51 - train: epoch 065, train_loss: 1.3938
2023-07-01 19:51:53 - eval: epoch: 065, acc1: 40.950%, acc5: 69.360%, test_loss: 2.4909, per_image_load_time: 0.078ms, per_image_inference_time: 0.084ms
2023-07-01 19:51:53 - until epoch: 065, best_acc1: 41.510%
2023-07-01 19:51:53 - epoch 066 lr: 0.002000
2023-07-01 19:51:57 - train: epoch 0066, iter [00050, 00390], lr: 0.002000, loss: 1.1632
2023-07-01 19:51:59 - train: epoch 0066, iter [00100, 00390], lr: 0.002000, loss: 1.2100
2023-07-01 19:52:01 - train: epoch 0066, iter [00150, 00390], lr: 0.002000, loss: 1.3895
2023-07-01 19:52:04 - train: epoch 0066, iter [00200, 00390], lr: 0.002000, loss: 1.4506
2023-07-01 19:52:07 - train: epoch 0066, iter [00250, 00390], lr: 0.002000, loss: 1.5341
2023-07-01 19:52:09 - train: epoch 0066, iter [00300, 00390], lr: 0.002000, loss: 1.2824
2023-07-01 19:52:11 - train: epoch 0066, iter [00350, 00390], lr: 0.002000, loss: 1.5395
2023-07-01 19:52:13 - train: epoch 066, train_loss: 1.3697
2023-07-01 19:52:15 - eval: epoch: 066, acc1: 40.720%, acc5: 69.540%, test_loss: 2.5100, per_image_load_time: 0.079ms, per_image_inference_time: 0.086ms
2023-07-01 19:52:15 - until epoch: 066, best_acc1: 41.510%
2023-07-01 19:52:15 - epoch 067 lr: 0.002000
2023-07-01 19:52:19 - train: epoch 0067, iter [00050, 00390], lr: 0.002000, loss: 1.3295
2023-07-01 19:52:21 - train: epoch 0067, iter [00100, 00390], lr: 0.002000, loss: 1.2447
2023-07-01 19:52:23 - train: epoch 0067, iter [00150, 00390], lr: 0.002000, loss: 1.3309
2023-07-01 19:52:26 - train: epoch 0067, iter [00200, 00390], lr: 0.002000, loss: 1.3192
2023-07-01 19:52:28 - train: epoch 0067, iter [00250, 00390], lr: 0.002000, loss: 1.2264
2023-07-01 19:52:30 - train: epoch 0067, iter [00300, 00390], lr: 0.002000, loss: 1.1113
2023-07-01 19:52:32 - train: epoch 0067, iter [00350, 00390], lr: 0.002000, loss: 1.2236
2023-07-01 19:52:34 - train: epoch 067, train_loss: 1.3518
2023-07-01 19:52:36 - eval: epoch: 067, acc1: 40.600%, acc5: 68.980%, test_loss: 2.5334, per_image_load_time: 0.080ms, per_image_inference_time: 0.084ms
2023-07-01 19:52:36 - until epoch: 067, best_acc1: 41.510%
2023-07-01 19:52:36 - epoch 068 lr: 0.002000
2023-07-01 19:52:40 - train: epoch 0068, iter [00050, 00390], lr: 0.002000, loss: 1.1420
2023-07-01 19:52:42 - train: epoch 0068, iter [00100, 00390], lr: 0.002000, loss: 1.1717
2023-07-01 19:52:44 - train: epoch 0068, iter [00150, 00390], lr: 0.002000, loss: 1.3229
2023-07-01 19:52:47 - train: epoch 0068, iter [00200, 00390], lr: 0.002000, loss: 1.2226
2023-07-01 19:52:49 - train: epoch 0068, iter [00250, 00390], lr: 0.002000, loss: 1.4139
2023-07-01 19:52:51 - train: epoch 0068, iter [00300, 00390], lr: 0.002000, loss: 1.3757
2023-07-01 19:52:53 - train: epoch 0068, iter [00350, 00390], lr: 0.002000, loss: 1.3905
2023-07-01 19:52:55 - train: epoch 068, train_loss: 1.3252
2023-07-01 19:52:57 - eval: epoch: 068, acc1: 40.200%, acc5: 69.080%, test_loss: 2.5566, per_image_load_time: 0.083ms, per_image_inference_time: 0.083ms
2023-07-01 19:52:58 - until epoch: 068, best_acc1: 41.510%
2023-07-01 19:52:58 - epoch 069 lr: 0.002000
2023-07-01 19:53:01 - train: epoch 0069, iter [00050, 00390], lr: 0.002000, loss: 1.3747
2023-07-01 19:53:03 - train: epoch 0069, iter [00100, 00390], lr: 0.002000, loss: 1.0782
2023-07-01 19:53:06 - train: epoch 0069, iter [00150, 00390], lr: 0.002000, loss: 1.4111
2023-07-01 19:53:08 - train: epoch 0069, iter [00200, 00390], lr: 0.002000, loss: 1.5034
2023-07-01 19:53:10 - train: epoch 0069, iter [00250, 00390], lr: 0.002000, loss: 1.5944
2023-07-01 19:53:12 - train: epoch 0069, iter [00300, 00390], lr: 0.002000, loss: 1.4482
2023-07-01 19:53:15 - train: epoch 0069, iter [00350, 00390], lr: 0.002000, loss: 1.3331
2023-07-01 19:53:17 - train: epoch 069, train_loss: 1.3072
2023-07-01 19:53:18 - eval: epoch: 069, acc1: 40.480%, acc5: 69.230%, test_loss: 2.5592, per_image_load_time: 0.076ms, per_image_inference_time: 0.083ms
2023-07-01 19:53:19 - until epoch: 069, best_acc1: 41.510%
2023-07-01 19:53:19 - epoch 070 lr: 0.002000
2023-07-01 19:53:22 - train: epoch 0070, iter [00050, 00390], lr: 0.002000, loss: 1.1470
2023-07-01 19:53:25 - train: epoch 0070, iter [00100, 00390], lr: 0.002000, loss: 1.3225
2023-07-01 19:53:27 - train: epoch 0070, iter [00150, 00390], lr: 0.002000, loss: 1.2502
2023-07-01 19:53:29 - train: epoch 0070, iter [00200, 00390], lr: 0.002000, loss: 1.1962
2023-07-01 19:53:32 - train: epoch 0070, iter [00250, 00390], lr: 0.002000, loss: 0.9029
2023-07-01 19:53:34 - train: epoch 0070, iter [00300, 00390], lr: 0.002000, loss: 1.2221
2023-07-01 19:53:36 - train: epoch 0070, iter [00350, 00390], lr: 0.002000, loss: 1.1855
2023-07-01 19:53:38 - train: epoch 070, train_loss: 1.2723
2023-07-01 19:53:40 - eval: epoch: 070, acc1: 40.740%, acc5: 69.300%, test_loss: 2.5630, per_image_load_time: 0.076ms, per_image_inference_time: 0.084ms
2023-07-01 19:53:40 - until epoch: 070, best_acc1: 41.510%
2023-07-01 19:53:40 - epoch 071 lr: 0.002000
2023-07-01 19:53:44 - train: epoch 0071, iter [00050, 00390], lr: 0.002000, loss: 1.1706
2023-07-01 19:53:46 - train: epoch 0071, iter [00100, 00390], lr: 0.002000, loss: 1.2153
2023-07-01 19:53:48 - train: epoch 0071, iter [00150, 00390], lr: 0.002000, loss: 1.2636
2023-07-01 19:53:51 - train: epoch 0071, iter [00200, 00390], lr: 0.002000, loss: 1.1488
2023-07-01 19:53:53 - train: epoch 0071, iter [00250, 00390], lr: 0.002000, loss: 1.5063
2023-07-01 19:53:55 - train: epoch 0071, iter [00300, 00390], lr: 0.002000, loss: 1.3339
2023-07-01 19:53:58 - train: epoch 0071, iter [00350, 00390], lr: 0.002000, loss: 1.3989
2023-07-01 19:53:59 - train: epoch 071, train_loss: 1.2615
2023-07-01 19:54:01 - eval: epoch: 071, acc1: 40.050%, acc5: 68.550%, test_loss: 2.6066, per_image_load_time: 0.077ms, per_image_inference_time: 0.083ms
2023-07-01 19:54:02 - until epoch: 071, best_acc1: 41.510%
2023-07-01 19:54:02 - epoch 072 lr: 0.002000
2023-07-01 19:54:05 - train: epoch 0072, iter [00050, 00390], lr: 0.002000, loss: 1.1315
2023-07-01 19:54:08 - train: epoch 0072, iter [00100, 00390], lr: 0.002000, loss: 1.1570
2023-07-01 19:54:10 - train: epoch 0072, iter [00150, 00390], lr: 0.002000, loss: 1.2493
2023-07-01 19:54:12 - train: epoch 0072, iter [00200, 00390], lr: 0.002000, loss: 0.9560
2023-07-01 19:54:15 - train: epoch 0072, iter [00250, 00390], lr: 0.002000, loss: 1.0461
2023-07-01 19:54:17 - train: epoch 0072, iter [00300, 00390], lr: 0.002000, loss: 1.2384
2023-07-01 19:54:20 - train: epoch 0072, iter [00350, 00390], lr: 0.002000, loss: 1.3324
2023-07-01 19:54:22 - train: epoch 072, train_loss: 1.2412
2023-07-01 19:54:24 - eval: epoch: 072, acc1: 40.090%, acc5: 68.770%, test_loss: 2.6078, per_image_load_time: 0.080ms, per_image_inference_time: 0.083ms
2023-07-01 19:54:24 - until epoch: 072, best_acc1: 41.510%
2023-07-01 19:54:24 - epoch 073 lr: 0.002000
2023-07-01 19:54:27 - train: epoch 0073, iter [00050, 00390], lr: 0.002000, loss: 1.2257
2023-07-01 19:54:30 - train: epoch 0073, iter [00100, 00390], lr: 0.002000, loss: 1.2075
2023-07-01 19:54:32 - train: epoch 0073, iter [00150, 00390], lr: 0.002000, loss: 1.2805
2023-07-01 19:54:34 - train: epoch 0073, iter [00200, 00390], lr: 0.002000, loss: 1.2043
2023-07-01 19:54:37 - train: epoch 0073, iter [00250, 00390], lr: 0.002000, loss: 1.4509
2023-07-01 19:54:39 - train: epoch 0073, iter [00300, 00390], lr: 0.002000, loss: 1.1689
2023-07-01 19:54:41 - train: epoch 0073, iter [00350, 00390], lr: 0.002000, loss: 1.0874
2023-07-01 19:54:43 - train: epoch 073, train_loss: 1.2220
2023-07-01 19:54:45 - eval: epoch: 073, acc1: 39.860%, acc5: 68.420%, test_loss: 2.6230, per_image_load_time: 0.077ms, per_image_inference_time: 0.085ms
2023-07-01 19:54:45 - until epoch: 073, best_acc1: 41.510%
2023-07-01 19:54:45 - epoch 074 lr: 0.002000
2023-07-01 19:54:48 - train: epoch 0074, iter [00050, 00390], lr: 0.002000, loss: 1.3210
2023-07-01 19:54:51 - train: epoch 0074, iter [00100, 00390], lr: 0.002000, loss: 1.3096
2023-07-01 19:54:53 - train: epoch 0074, iter [00150, 00390], lr: 0.002000, loss: 1.0519
2023-07-01 19:54:55 - train: epoch 0074, iter [00200, 00390], lr: 0.002000, loss: 1.2410
2023-07-01 19:54:58 - train: epoch 0074, iter [00250, 00390], lr: 0.002000, loss: 1.0467
2023-07-01 19:55:00 - train: epoch 0074, iter [00300, 00390], lr: 0.002000, loss: 1.1687
2023-07-01 19:55:02 - train: epoch 0074, iter [00350, 00390], lr: 0.002000, loss: 1.2543
2023-07-01 19:55:04 - train: epoch 074, train_loss: 1.2048
2023-07-01 19:55:06 - eval: epoch: 074, acc1: 40.290%, acc5: 68.180%, test_loss: 2.6479, per_image_load_time: 0.080ms, per_image_inference_time: 0.083ms
2023-07-01 19:55:07 - until epoch: 074, best_acc1: 41.510%
2023-07-01 19:55:07 - epoch 075 lr: 0.002000
2023-07-01 19:55:10 - train: epoch 0075, iter [00050, 00390], lr: 0.002000, loss: 1.1719
2023-07-01 19:55:12 - train: epoch 0075, iter [00100, 00390], lr: 0.002000, loss: 1.2038
2023-07-01 19:55:15 - train: epoch 0075, iter [00150, 00390], lr: 0.002000, loss: 1.3263
2023-07-01 19:55:17 - train: epoch 0075, iter [00200, 00390], lr: 0.002000, loss: 1.1451
2023-07-01 19:55:19 - train: epoch 0075, iter [00250, 00390], lr: 0.002000, loss: 1.2279
2023-07-01 19:55:22 - train: epoch 0075, iter [00300, 00390], lr: 0.002000, loss: 1.1115
2023-07-01 19:55:24 - train: epoch 0075, iter [00350, 00390], lr: 0.002000, loss: 1.0693
2023-07-01 19:55:26 - train: epoch 075, train_loss: 1.1877
2023-07-01 19:55:28 - eval: epoch: 075, acc1: 40.460%, acc5: 68.410%, test_loss: 2.6442, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 19:55:28 - until epoch: 075, best_acc1: 41.510%
2023-07-01 19:55:28 - epoch 076 lr: 0.002000
2023-07-01 19:55:32 - train: epoch 0076, iter [00050, 00390], lr: 0.002000, loss: 1.0942
2023-07-01 19:55:34 - train: epoch 0076, iter [00100, 00390], lr: 0.002000, loss: 1.1885
2023-07-01 19:55:37 - train: epoch 0076, iter [00150, 00390], lr: 0.002000, loss: 1.0103
2023-07-01 19:55:39 - train: epoch 0076, iter [00200, 00390], lr: 0.002000, loss: 1.2317
2023-07-01 19:55:42 - train: epoch 0076, iter [00250, 00390], lr: 0.002000, loss: 1.1796
2023-07-01 19:55:44 - train: epoch 0076, iter [00300, 00390], lr: 0.002000, loss: 0.8465
2023-07-01 19:55:46 - train: epoch 0076, iter [00350, 00390], lr: 0.002000, loss: 1.4393
2023-07-01 19:55:48 - train: epoch 076, train_loss: 1.1743
2023-07-01 19:55:50 - eval: epoch: 076, acc1: 40.110%, acc5: 67.980%, test_loss: 2.6671, per_image_load_time: 0.078ms, per_image_inference_time: 0.085ms
2023-07-01 19:55:50 - until epoch: 076, best_acc1: 41.510%
2023-07-01 19:55:50 - epoch 077 lr: 0.002000
2023-07-01 19:55:53 - train: epoch 0077, iter [00050, 00390], lr: 0.002000, loss: 0.9078
2023-07-01 19:55:56 - train: epoch 0077, iter [00100, 00390], lr: 0.002000, loss: 1.0257
2023-07-01 19:55:58 - train: epoch 0077, iter [00150, 00390], lr: 0.002000, loss: 1.0484
2023-07-01 19:56:01 - train: epoch 0077, iter [00200, 00390], lr: 0.002000, loss: 1.2815
2023-07-01 19:56:03 - train: epoch 0077, iter [00250, 00390], lr: 0.002000, loss: 1.0493
2023-07-01 19:56:05 - train: epoch 0077, iter [00300, 00390], lr: 0.002000, loss: 1.4434
2023-07-01 19:56:08 - train: epoch 0077, iter [00350, 00390], lr: 0.002000, loss: 1.2946
2023-07-01 19:56:10 - train: epoch 077, train_loss: 1.1517
2023-07-01 19:56:11 - eval: epoch: 077, acc1: 40.050%, acc5: 68.080%, test_loss: 2.6847, per_image_load_time: 0.077ms, per_image_inference_time: 0.083ms
2023-07-01 19:56:12 - until epoch: 077, best_acc1: 41.510%
2023-07-01 19:56:12 - epoch 078 lr: 0.002000
2023-07-01 19:56:15 - train: epoch 0078, iter [00050, 00390], lr: 0.002000, loss: 1.1107
2023-07-01 19:56:17 - train: epoch 0078, iter [00100, 00390], lr: 0.002000, loss: 1.0378
2023-07-01 19:56:20 - train: epoch 0078, iter [00150, 00390], lr: 0.002000, loss: 1.2557
2023-07-01 19:56:22 - train: epoch 0078, iter [00200, 00390], lr: 0.002000, loss: 0.9742
2023-07-01 19:56:24 - train: epoch 0078, iter [00250, 00390], lr: 0.002000, loss: 1.2789
2023-07-01 19:56:27 - train: epoch 0078, iter [00300, 00390], lr: 0.002000, loss: 1.3576
2023-07-01 19:56:29 - train: epoch 0078, iter [00350, 00390], lr: 0.002000, loss: 0.9327
2023-07-01 19:56:31 - train: epoch 078, train_loss: 1.1325
2023-07-01 19:56:33 - eval: epoch: 078, acc1: 39.790%, acc5: 67.710%, test_loss: 2.7258, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 19:56:33 - until epoch: 078, best_acc1: 41.510%
2023-07-01 19:56:33 - epoch 079 lr: 0.002000
2023-07-01 19:56:36 - train: epoch 0079, iter [00050, 00390], lr: 0.002000, loss: 1.0078
2023-07-01 19:56:39 - train: epoch 0079, iter [00100, 00390], lr: 0.002000, loss: 1.1785
2023-07-01 19:56:41 - train: epoch 0079, iter [00150, 00390], lr: 0.002000, loss: 1.0249
2023-07-01 19:56:43 - train: epoch 0079, iter [00200, 00390], lr: 0.002000, loss: 1.1513
2023-07-01 19:56:46 - train: epoch 0079, iter [00250, 00390], lr: 0.002000, loss: 1.1495
2023-07-01 19:56:48 - train: epoch 0079, iter [00300, 00390], lr: 0.002000, loss: 1.5065
2023-07-01 19:56:50 - train: epoch 0079, iter [00350, 00390], lr: 0.002000, loss: 1.0791
2023-07-01 19:56:52 - train: epoch 079, train_loss: 1.1133
2023-07-01 19:56:54 - eval: epoch: 079, acc1: 40.070%, acc5: 67.830%, test_loss: 2.7239, per_image_load_time: 0.078ms, per_image_inference_time: 0.083ms
2023-07-01 19:56:54 - until epoch: 079, best_acc1: 41.510%
2023-07-01 19:56:54 - epoch 080 lr: 0.002000
2023-07-01 19:56:57 - train: epoch 0080, iter [00050, 00390], lr: 0.002000, loss: 1.0920
2023-07-01 19:57:00 - train: epoch 0080, iter [00100, 00390], lr: 0.002000, loss: 0.7891
2023-07-01 19:57:02 - train: epoch 0080, iter [00150, 00390], lr: 0.002000, loss: 1.1376
2023-07-01 19:57:04 - train: epoch 0080, iter [00200, 00390], lr: 0.002000, loss: 1.2214
2023-07-01 19:57:07 - train: epoch 0080, iter [00250, 00390], lr: 0.002000, loss: 0.8981
2023-07-01 19:57:09 - train: epoch 0080, iter [00300, 00390], lr: 0.002000, loss: 1.2958
2023-07-01 19:57:11 - train: epoch 0080, iter [00350, 00390], lr: 0.002000, loss: 1.3817
2023-07-01 19:57:14 - train: epoch 080, train_loss: 1.0931
2023-07-01 19:57:15 - eval: epoch: 080, acc1: 39.140%, acc5: 68.450%, test_loss: 2.7541, per_image_load_time: 0.078ms, per_image_inference_time: 0.083ms
2023-07-01 19:57:15 - until epoch: 080, best_acc1: 41.510%
2023-07-01 19:57:15 - epoch 081 lr: 0.002000
2023-07-01 19:57:19 - train: epoch 0081, iter [00050, 00390], lr: 0.002000, loss: 1.0729
2023-07-01 19:57:21 - train: epoch 0081, iter [00100, 00390], lr: 0.002000, loss: 1.1577
2023-07-01 19:57:23 - train: epoch 0081, iter [00150, 00390], lr: 0.002000, loss: 0.9393
2023-07-01 19:57:26 - train: epoch 0081, iter [00200, 00390], lr: 0.002000, loss: 0.9829
2023-07-01 19:57:28 - train: epoch 0081, iter [00250, 00390], lr: 0.002000, loss: 1.1850
2023-07-01 19:57:30 - train: epoch 0081, iter [00300, 00390], lr: 0.002000, loss: 0.9160
2023-07-01 19:57:33 - train: epoch 0081, iter [00350, 00390], lr: 0.002000, loss: 1.0378
2023-07-01 19:57:35 - train: epoch 081, train_loss: 1.0703
2023-07-01 19:57:36 - eval: epoch: 081, acc1: 39.800%, acc5: 67.770%, test_loss: 2.7687, per_image_load_time: 0.079ms, per_image_inference_time: 0.089ms
2023-07-01 19:57:37 - until epoch: 081, best_acc1: 41.510%
2023-07-01 19:57:37 - epoch 082 lr: 0.002000
2023-07-01 19:57:40 - train: epoch 0082, iter [00050, 00390], lr: 0.002000, loss: 1.0933
2023-07-01 19:57:42 - train: epoch 0082, iter [00100, 00390], lr: 0.002000, loss: 1.0091
2023-07-01 19:57:45 - train: epoch 0082, iter [00150, 00390], lr: 0.002000, loss: 0.9572
2023-07-01 19:57:47 - train: epoch 0082, iter [00200, 00390], lr: 0.002000, loss: 1.0516
2023-07-01 19:57:49 - train: epoch 0082, iter [00250, 00390], lr: 0.002000, loss: 1.3217
2023-07-01 19:57:52 - train: epoch 0082, iter [00300, 00390], lr: 0.002000, loss: 1.1475
2023-07-01 19:57:54 - train: epoch 0082, iter [00350, 00390], lr: 0.002000, loss: 1.0013
2023-07-01 19:57:56 - train: epoch 082, train_loss: 1.0588
2023-07-01 19:57:58 - eval: epoch: 082, acc1: 40.010%, acc5: 67.860%, test_loss: 2.7842, per_image_load_time: 0.077ms, per_image_inference_time: 0.085ms
2023-07-01 19:57:58 - until epoch: 082, best_acc1: 41.510%
2023-07-01 19:57:58 - epoch 083 lr: 0.002000
2023-07-01 19:58:01 - train: epoch 0083, iter [00050, 00390], lr: 0.002000, loss: 0.9745
2023-07-01 19:58:03 - train: epoch 0083, iter [00100, 00390], lr: 0.002000, loss: 1.0439
2023-07-01 19:58:06 - train: epoch 0083, iter [00150, 00390], lr: 0.002000, loss: 0.9462
2023-07-01 19:58:08 - train: epoch 0083, iter [00200, 00390], lr: 0.002000, loss: 0.9776
2023-07-01 19:58:11 - train: epoch 0083, iter [00250, 00390], lr: 0.002000, loss: 1.0163
2023-07-01 19:58:13 - train: epoch 0083, iter [00300, 00390], lr: 0.002000, loss: 1.2332
2023-07-01 19:58:16 - train: epoch 0083, iter [00350, 00390], lr: 0.002000, loss: 1.1407
2023-07-01 19:58:18 - train: epoch 083, train_loss: 1.0350
2023-07-01 19:58:20 - eval: epoch: 083, acc1: 39.460%, acc5: 67.750%, test_loss: 2.8125, per_image_load_time: 0.078ms, per_image_inference_time: 0.083ms
2023-07-01 19:58:21 - until epoch: 083, best_acc1: 41.510%
2023-07-01 19:58:21 - epoch 084 lr: 0.002000
2023-07-01 19:58:25 - train: epoch 0084, iter [00050, 00390], lr: 0.002000, loss: 1.0136
2023-07-01 19:58:27 - train: epoch 0084, iter [00100, 00390], lr: 0.002000, loss: 1.0692
2023-07-01 19:58:30 - train: epoch 0084, iter [00150, 00390], lr: 0.002000, loss: 1.1612
2023-07-01 19:58:32 - train: epoch 0084, iter [00200, 00390], lr: 0.002000, loss: 0.8648
2023-07-01 19:58:34 - train: epoch 0084, iter [00250, 00390], lr: 0.002000, loss: 1.0612
2023-07-01 19:58:37 - train: epoch 0084, iter [00300, 00390], lr: 0.002000, loss: 1.1395
2023-07-01 19:58:39 - train: epoch 0084, iter [00350, 00390], lr: 0.002000, loss: 1.0982
2023-07-01 19:58:41 - train: epoch 084, train_loss: 1.0241
2023-07-01 19:58:43 - eval: epoch: 084, acc1: 39.620%, acc5: 67.770%, test_loss: 2.8116, per_image_load_time: 0.080ms, per_image_inference_time: 0.085ms
2023-07-01 19:58:43 - until epoch: 084, best_acc1: 41.510%
2023-07-01 19:58:43 - epoch 085 lr: 0.002000
2023-07-01 19:58:46 - train: epoch 0085, iter [00050, 00390], lr: 0.002000, loss: 0.8904
2023-07-01 19:58:49 - train: epoch 0085, iter [00100, 00390], lr: 0.002000, loss: 0.9445
2023-07-01 19:58:51 - train: epoch 0085, iter [00150, 00390], lr: 0.002000, loss: 0.9583
2023-07-01 19:58:53 - train: epoch 0085, iter [00200, 00390], lr: 0.002000, loss: 0.8664
2023-07-01 19:58:56 - train: epoch 0085, iter [00250, 00390], lr: 0.002000, loss: 0.9764
2023-07-01 19:58:58 - train: epoch 0085, iter [00300, 00390], lr: 0.002000, loss: 1.1197
2023-07-01 19:59:00 - train: epoch 0085, iter [00350, 00390], lr: 0.002000, loss: 0.9671
2023-07-01 19:59:02 - train: epoch 085, train_loss: 1.0177
2023-07-01 19:59:04 - eval: epoch: 085, acc1: 39.690%, acc5: 67.520%, test_loss: 2.8405, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 19:59:04 - until epoch: 085, best_acc1: 41.510%
2023-07-01 19:59:04 - epoch 086 lr: 0.002000
2023-07-01 19:59:07 - train: epoch 0086, iter [00050, 00390], lr: 0.002000, loss: 0.8018
2023-07-01 19:59:10 - train: epoch 0086, iter [00100, 00390], lr: 0.002000, loss: 0.8830
2023-07-01 19:59:12 - train: epoch 0086, iter [00150, 00390], lr: 0.002000, loss: 0.9088
2023-07-01 19:59:14 - train: epoch 0086, iter [00200, 00390], lr: 0.002000, loss: 0.9012
2023-07-01 19:59:17 - train: epoch 0086, iter [00250, 00390], lr: 0.002000, loss: 1.0741
2023-07-01 19:59:19 - train: epoch 0086, iter [00300, 00390], lr: 0.002000, loss: 0.8250
2023-07-01 19:59:21 - train: epoch 0086, iter [00350, 00390], lr: 0.002000, loss: 1.1623
2023-07-01 19:59:23 - train: epoch 086, train_loss: 0.9818
2023-07-01 19:59:25 - eval: epoch: 086, acc1: 39.240%, acc5: 67.640%, test_loss: 2.8519, per_image_load_time: 0.081ms, per_image_inference_time: 0.084ms
2023-07-01 19:59:26 - until epoch: 086, best_acc1: 41.510%
2023-07-01 19:59:26 - epoch 087 lr: 0.002000
2023-07-01 19:59:29 - train: epoch 0087, iter [00050, 00390], lr: 0.002000, loss: 0.8632
2023-07-01 19:59:31 - train: epoch 0087, iter [00100, 00390], lr: 0.002000, loss: 0.9984
2023-07-01 19:59:33 - train: epoch 0087, iter [00150, 00390], lr: 0.002000, loss: 0.9426
2023-07-01 19:59:36 - train: epoch 0087, iter [00200, 00390], lr: 0.002000, loss: 0.9501
2023-07-01 19:59:38 - train: epoch 0087, iter [00250, 00390], lr: 0.002000, loss: 0.7851
2023-07-01 19:59:40 - train: epoch 0087, iter [00300, 00390], lr: 0.002000, loss: 1.0600
2023-07-01 19:59:43 - train: epoch 0087, iter [00350, 00390], lr: 0.002000, loss: 0.9326
2023-07-01 19:59:45 - train: epoch 087, train_loss: 0.9714
2023-07-01 19:59:46 - eval: epoch: 087, acc1: 39.430%, acc5: 67.650%, test_loss: 2.8471, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 19:59:46 - until epoch: 087, best_acc1: 41.510%
2023-07-01 19:59:46 - epoch 088 lr: 0.002000
2023-07-01 19:59:50 - train: epoch 0088, iter [00050, 00390], lr: 0.002000, loss: 0.9309
2023-07-01 19:59:52 - train: epoch 0088, iter [00100, 00390], lr: 0.002000, loss: 1.0588
2023-07-01 19:59:54 - train: epoch 0088, iter [00150, 00390], lr: 0.002000, loss: 0.8696
2023-07-01 19:59:56 - train: epoch 0088, iter [00200, 00390], lr: 0.002000, loss: 1.0582
2023-07-01 19:59:59 - train: epoch 0088, iter [00250, 00390], lr: 0.002000, loss: 1.0937
2023-07-01 20:00:01 - train: epoch 0088, iter [00300, 00390], lr: 0.002000, loss: 0.9485
2023-07-01 20:00:03 - train: epoch 0088, iter [00350, 00390], lr: 0.002000, loss: 0.9399
2023-07-01 20:00:05 - train: epoch 088, train_loss: 0.9530
2023-07-01 20:00:07 - eval: epoch: 088, acc1: 39.420%, acc5: 67.150%, test_loss: 2.8888, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 20:00:07 - until epoch: 088, best_acc1: 41.510%
2023-07-01 20:00:07 - epoch 089 lr: 0.002000
2023-07-01 20:00:10 - train: epoch 0089, iter [00050, 00390], lr: 0.002000, loss: 0.7929
2023-07-01 20:00:13 - train: epoch 0089, iter [00100, 00390], lr: 0.002000, loss: 0.7893
2023-07-01 20:00:15 - train: epoch 0089, iter [00150, 00390], lr: 0.002000, loss: 0.9744
2023-07-01 20:00:17 - train: epoch 0089, iter [00200, 00390], lr: 0.002000, loss: 0.9910
2023-07-01 20:00:20 - train: epoch 0089, iter [00250, 00390], lr: 0.002000, loss: 0.9904
2023-07-01 20:00:22 - train: epoch 0089, iter [00300, 00390], lr: 0.002000, loss: 1.0857
2023-07-01 20:00:25 - train: epoch 0089, iter [00350, 00390], lr: 0.002000, loss: 0.9875
2023-07-01 20:00:27 - train: epoch 089, train_loss: 0.9401
2023-07-01 20:00:29 - eval: epoch: 089, acc1: 38.900%, acc5: 67.210%, test_loss: 2.9119, per_image_load_time: 0.078ms, per_image_inference_time: 0.083ms
2023-07-01 20:00:29 - until epoch: 089, best_acc1: 41.510%
2023-07-01 20:00:29 - epoch 090 lr: 0.002000
2023-07-01 20:00:33 - train: epoch 0090, iter [00050, 00390], lr: 0.002000, loss: 0.9186
2023-07-01 20:00:35 - train: epoch 0090, iter [00100, 00390], lr: 0.002000, loss: 0.8156
2023-07-01 20:00:37 - train: epoch 0090, iter [00150, 00390], lr: 0.002000, loss: 0.8738
2023-07-01 20:00:40 - train: epoch 0090, iter [00200, 00390], lr: 0.002000, loss: 0.9940
2023-07-01 20:00:42 - train: epoch 0090, iter [00250, 00390], lr: 0.002000, loss: 0.7896
2023-07-01 20:00:44 - train: epoch 0090, iter [00300, 00390], lr: 0.002000, loss: 0.8273
2023-07-01 20:00:46 - train: epoch 0090, iter [00350, 00390], lr: 0.002000, loss: 0.8940
2023-07-01 20:00:48 - train: epoch 090, train_loss: 0.9165
2023-07-01 20:00:50 - eval: epoch: 090, acc1: 39.590%, acc5: 67.480%, test_loss: 2.8865, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 20:00:50 - until epoch: 090, best_acc1: 41.510%
2023-07-01 20:00:50 - epoch 091 lr: 0.002000
2023-07-01 20:00:54 - train: epoch 0091, iter [00050, 00390], lr: 0.002000, loss: 0.8420
2023-07-01 20:00:56 - train: epoch 0091, iter [00100, 00390], lr: 0.002000, loss: 0.9083
2023-07-01 20:00:58 - train: epoch 0091, iter [00150, 00390], lr: 0.002000, loss: 1.0189
2023-07-01 20:01:00 - train: epoch 0091, iter [00200, 00390], lr: 0.002000, loss: 0.9137
2023-07-01 20:01:03 - train: epoch 0091, iter [00250, 00390], lr: 0.002000, loss: 0.9733
2023-07-01 20:01:05 - train: epoch 0091, iter [00300, 00390], lr: 0.002000, loss: 0.8404
2023-07-01 20:01:08 - train: epoch 0091, iter [00350, 00390], lr: 0.002000, loss: 1.0468
2023-07-01 20:01:09 - train: epoch 091, train_loss: 0.9046
2023-07-01 20:01:11 - eval: epoch: 091, acc1: 38.970%, acc5: 67.210%, test_loss: 2.9326, per_image_load_time: 0.078ms, per_image_inference_time: 0.082ms
2023-07-01 20:01:11 - until epoch: 091, best_acc1: 41.510%
2023-07-01 20:01:11 - epoch 092 lr: 0.002000
2023-07-01 20:01:15 - train: epoch 0092, iter [00050, 00390], lr: 0.002000, loss: 0.8880
2023-07-01 20:01:17 - train: epoch 0092, iter [00100, 00390], lr: 0.002000, loss: 0.6922
2023-07-01 20:01:19 - train: epoch 0092, iter [00150, 00390], lr: 0.002000, loss: 0.8222
2023-07-01 20:01:22 - train: epoch 0092, iter [00200, 00390], lr: 0.002000, loss: 0.7384
2023-07-01 20:01:24 - train: epoch 0092, iter [00250, 00390], lr: 0.002000, loss: 0.8165
2023-07-01 20:01:26 - train: epoch 0092, iter [00300, 00390], lr: 0.002000, loss: 0.7289
2023-07-01 20:01:29 - train: epoch 0092, iter [00350, 00390], lr: 0.002000, loss: 0.8154
2023-07-01 20:01:31 - train: epoch 092, train_loss: 0.8856
2023-07-01 20:01:32 - eval: epoch: 092, acc1: 38.630%, acc5: 67.070%, test_loss: 2.9643, per_image_load_time: 0.079ms, per_image_inference_time: 0.082ms
2023-07-01 20:01:33 - until epoch: 092, best_acc1: 41.510%
2023-07-01 20:01:33 - epoch 093 lr: 0.002000
2023-07-01 20:01:36 - train: epoch 0093, iter [00050, 00390], lr: 0.002000, loss: 0.7467
2023-07-01 20:01:38 - train: epoch 0093, iter [00100, 00390], lr: 0.002000, loss: 0.7833
2023-07-01 20:01:41 - train: epoch 0093, iter [00150, 00390], lr: 0.002000, loss: 1.0035
2023-07-01 20:01:43 - train: epoch 0093, iter [00200, 00390], lr: 0.002000, loss: 1.0422
2023-07-01 20:01:46 - train: epoch 0093, iter [00250, 00390], lr: 0.002000, loss: 0.8325
2023-07-01 20:01:48 - train: epoch 0093, iter [00300, 00390], lr: 0.002000, loss: 0.7750
2023-07-01 20:01:50 - train: epoch 0093, iter [00350, 00390], lr: 0.002000, loss: 0.9068
2023-07-01 20:01:52 - train: epoch 093, train_loss: 0.8736
2023-07-01 20:01:54 - eval: epoch: 093, acc1: 38.840%, acc5: 67.000%, test_loss: 2.9517, per_image_load_time: 0.083ms, per_image_inference_time: 0.083ms
2023-07-01 20:01:54 - until epoch: 093, best_acc1: 41.510%
2023-07-01 20:01:54 - epoch 094 lr: 0.002000
2023-07-01 20:01:58 - train: epoch 0094, iter [00050, 00390], lr: 0.002000, loss: 0.6558
2023-07-01 20:02:00 - train: epoch 0094, iter [00100, 00390], lr: 0.002000, loss: 0.6937
2023-07-01 20:02:02 - train: epoch 0094, iter [00150, 00390], lr: 0.002000, loss: 0.8065
2023-07-01 20:02:05 - train: epoch 0094, iter [00200, 00390], lr: 0.002000, loss: 0.8559
2023-07-01 20:02:07 - train: epoch 0094, iter [00250, 00390], lr: 0.002000, loss: 0.9632
2023-07-01 20:02:09 - train: epoch 0094, iter [00300, 00390], lr: 0.002000, loss: 0.7218
2023-07-01 20:02:12 - train: epoch 0094, iter [00350, 00390], lr: 0.002000, loss: 0.8802
2023-07-01 20:02:14 - train: epoch 094, train_loss: 0.8568
2023-07-01 20:02:15 - eval: epoch: 094, acc1: 38.830%, acc5: 66.470%, test_loss: 3.0171, per_image_load_time: 0.083ms, per_image_inference_time: 0.084ms
2023-07-01 20:02:16 - until epoch: 094, best_acc1: 41.510%
2023-07-01 20:02:16 - epoch 095 lr: 0.002000
2023-07-01 20:02:19 - train: epoch 0095, iter [00050, 00390], lr: 0.002000, loss: 0.8756
2023-07-01 20:02:21 - train: epoch 0095, iter [00100, 00390], lr: 0.002000, loss: 0.7659
2023-07-01 20:02:23 - train: epoch 0095, iter [00150, 00390], lr: 0.002000, loss: 0.8014
2023-07-01 20:02:26 - train: epoch 0095, iter [00200, 00390], lr: 0.002000, loss: 0.7582
2023-07-01 20:02:28 - train: epoch 0095, iter [00250, 00390], lr: 0.002000, loss: 0.8893
2023-07-01 20:02:30 - train: epoch 0095, iter [00300, 00390], lr: 0.002000, loss: 0.9144
2023-07-01 20:02:33 - train: epoch 0095, iter [00350, 00390], lr: 0.002000, loss: 0.7913
2023-07-01 20:02:35 - train: epoch 095, train_loss: 0.8369
2023-07-01 20:02:37 - eval: epoch: 095, acc1: 39.060%, acc5: 67.220%, test_loss: 2.9813, per_image_load_time: 0.080ms, per_image_inference_time: 0.083ms
2023-07-01 20:02:37 - until epoch: 095, best_acc1: 41.510%
2023-07-01 20:02:37 - epoch 096 lr: 0.002000
2023-07-01 20:02:40 - train: epoch 0096, iter [00050, 00390], lr: 0.002000, loss: 0.7325
2023-07-01 20:02:42 - train: epoch 0096, iter [00100, 00390], lr: 0.002000, loss: 0.8597
2023-07-01 20:02:44 - train: epoch 0096, iter [00150, 00390], lr: 0.002000, loss: 0.9896
2023-07-01 20:02:47 - train: epoch 0096, iter [00200, 00390], lr: 0.002000, loss: 0.8864
2023-07-01 20:02:49 - train: epoch 0096, iter [00250, 00390], lr: 0.002000, loss: 0.6878
2023-07-01 20:02:51 - train: epoch 0096, iter [00300, 00390], lr: 0.002000, loss: 0.8320
2023-07-01 20:02:54 - train: epoch 0096, iter [00350, 00390], lr: 0.002000, loss: 1.0279
2023-07-01 20:02:56 - train: epoch 096, train_loss: 0.8280
2023-07-01 20:02:57 - eval: epoch: 096, acc1: 38.270%, acc5: 66.330%, test_loss: 3.0417, per_image_load_time: 0.081ms, per_image_inference_time: 0.085ms
2023-07-01 20:02:58 - until epoch: 096, best_acc1: 41.510%
2023-07-01 20:02:58 - epoch 097 lr: 0.002000
2023-07-01 20:03:01 - train: epoch 0097, iter [00050, 00390], lr: 0.002000, loss: 0.8922
2023-07-01 20:03:03 - train: epoch 0097, iter [00100, 00390], lr: 0.002000, loss: 0.7815
2023-07-01 20:03:05 - train: epoch 0097, iter [00150, 00390], lr: 0.002000, loss: 0.6390
2023-07-01 20:03:08 - train: epoch 0097, iter [00200, 00390], lr: 0.002000, loss: 0.8201
2023-07-01 20:03:10 - train: epoch 0097, iter [00250, 00390], lr: 0.002000, loss: 0.8500
2023-07-01 20:03:12 - train: epoch 0097, iter [00300, 00390], lr: 0.002000, loss: 0.7492
2023-07-01 20:03:15 - train: epoch 0097, iter [00350, 00390], lr: 0.002000, loss: 0.7414
2023-07-01 20:03:17 - train: epoch 097, train_loss: 0.7925
2023-07-01 20:03:18 - eval: epoch: 097, acc1: 38.530%, acc5: 66.770%, test_loss: 3.0419, per_image_load_time: 0.077ms, per_image_inference_time: 0.084ms
2023-07-01 20:03:19 - until epoch: 097, best_acc1: 41.510%
2023-07-01 20:03:19 - epoch 098 lr: 0.002000
2023-07-01 20:03:22 - train: epoch 0098, iter [00050, 00390], lr: 0.002000, loss: 0.7939
2023-07-01 20:03:24 - train: epoch 0098, iter [00100, 00390], lr: 0.002000, loss: 0.7403
2023-07-01 20:03:27 - train: epoch 0098, iter [00150, 00390], lr: 0.002000, loss: 0.8589
2023-07-01 20:03:29 - train: epoch 0098, iter [00200, 00390], lr: 0.002000, loss: 0.7968
2023-07-01 20:03:31 - train: epoch 0098, iter [00250, 00390], lr: 0.002000, loss: 0.8368
2023-07-01 20:03:33 - train: epoch 0098, iter [00300, 00390], lr: 0.002000, loss: 0.9814
2023-07-01 20:03:36 - train: epoch 0098, iter [00350, 00390], lr: 0.002000, loss: 0.8540
2023-07-01 20:03:38 - train: epoch 098, train_loss: 0.7841
2023-07-01 20:03:40 - eval: epoch: 098, acc1: 38.170%, acc5: 67.130%, test_loss: 3.0662, per_image_load_time: 0.080ms, per_image_inference_time: 0.082ms
2023-07-01 20:03:40 - until epoch: 098, best_acc1: 41.510%
2023-07-01 20:03:40 - epoch 099 lr: 0.002000
2023-07-01 20:03:43 - train: epoch 0099, iter [00050, 00390], lr: 0.002000, loss: 0.7795
2023-07-01 20:03:45 - train: epoch 0099, iter [00100, 00390], lr: 0.002000, loss: 0.7970
2023-07-01 20:03:48 - train: epoch 0099, iter [00150, 00390], lr: 0.002000, loss: 0.8720
2023-07-01 20:03:50 - train: epoch 0099, iter [00200, 00390], lr: 0.002000, loss: 0.7438
2023-07-01 20:03:52 - train: epoch 0099, iter [00250, 00390], lr: 0.002000, loss: 0.8304
2023-07-01 20:03:54 - train: epoch 0099, iter [00300, 00390], lr: 0.002000, loss: 0.8042
2023-07-01 20:03:57 - train: epoch 0099, iter [00350, 00390], lr: 0.002000, loss: 0.8495
2023-07-01 20:03:58 - train: epoch 099, train_loss: 0.7773
2023-07-01 20:04:00 - eval: epoch: 099, acc1: 38.590%, acc5: 66.800%, test_loss: 3.0882, per_image_load_time: 0.082ms, per_image_inference_time: 0.083ms
2023-07-01 20:04:00 - until epoch: 099, best_acc1: 41.510%
2023-07-01 20:04:00 - epoch 100 lr: 0.002000
2023-07-01 20:04:03 - train: epoch 0100, iter [00050, 00390], lr: 0.002000, loss: 0.7957
2023-07-01 20:04:06 - train: epoch 0100, iter [00100, 00390], lr: 0.002000, loss: 0.5318
2023-07-01 20:04:08 - train: epoch 0100, iter [00150, 00390], lr: 0.002000, loss: 0.8713
2023-07-01 20:04:10 - train: epoch 0100, iter [00200, 00390], lr: 0.002000, loss: 0.6849
2023-07-01 20:04:12 - train: epoch 0100, iter [00250, 00390], lr: 0.002000, loss: 0.7551
2023-07-01 20:04:14 - train: epoch 0100, iter [00300, 00390], lr: 0.002000, loss: 0.7498
2023-07-01 20:04:16 - train: epoch 0100, iter [00350, 00390], lr: 0.002000, loss: 0.6836
2023-07-01 20:04:18 - train: epoch 100, train_loss: 0.7640
2023-07-01 20:04:20 - eval: epoch: 100, acc1: 38.210%, acc5: 66.550%, test_loss: 3.1110, per_image_load_time: 0.085ms, per_image_inference_time: 0.084ms
2023-07-01 20:04:21 - until epoch: 100, best_acc1: 41.510%
2023-07-01 20:04:21 - epoch 101 lr: 0.002000
2023-07-01 20:04:24 - train: epoch 0101, iter [00050, 00390], lr: 0.002000, loss: 0.7768
2023-07-01 20:04:26 - train: epoch 0101, iter [00100, 00390], lr: 0.002000, loss: 0.8296
2023-07-01 20:04:28 - train: epoch 0101, iter [00150, 00390], lr: 0.002000, loss: 0.8315
2023-07-01 20:04:31 - train: epoch 0101, iter [00200, 00390], lr: 0.002000, loss: 0.7460
2023-07-01 20:04:33 - train: epoch 0101, iter [00250, 00390], lr: 0.002000, loss: 0.8224
2023-07-01 20:04:35 - train: epoch 0101, iter [00300, 00390], lr: 0.002000, loss: 0.8382
2023-07-01 20:04:37 - train: epoch 0101, iter [00350, 00390], lr: 0.002000, loss: 0.6479
2023-07-01 20:04:39 - train: epoch 101, train_loss: 0.7386
2023-07-01 20:04:41 - eval: epoch: 101, acc1: 39.050%, acc5: 66.490%, test_loss: 3.1125, per_image_load_time: 0.074ms, per_image_inference_time: 0.082ms
2023-07-01 20:04:41 - until epoch: 101, best_acc1: 41.510%
2023-07-01 20:04:41 - epoch 102 lr: 0.002000
2023-07-01 20:04:44 - train: epoch 0102, iter [00050, 00390], lr: 0.002000, loss: 0.8137
2023-07-01 20:04:46 - train: epoch 0102, iter [00100, 00390], lr: 0.002000, loss: 0.4832
2023-07-01 20:04:48 - train: epoch 0102, iter [00150, 00390], lr: 0.002000, loss: 0.8298
2023-07-01 20:04:51 - train: epoch 0102, iter [00200, 00390], lr: 0.002000, loss: 0.6952
2023-07-01 20:04:53 - train: epoch 0102, iter [00250, 00390], lr: 0.002000, loss: 0.9835
2023-07-01 20:04:55 - train: epoch 0102, iter [00300, 00390], lr: 0.002000, loss: 0.7682
2023-07-01 20:04:57 - train: epoch 0102, iter [00350, 00390], lr: 0.002000, loss: 0.6699
2023-07-01 20:04:59 - train: epoch 102, train_loss: 0.7346
2023-07-01 20:05:01 - eval: epoch: 102, acc1: 38.610%, acc5: 66.850%, test_loss: 3.1239, per_image_load_time: 0.070ms, per_image_inference_time: 0.082ms
2023-07-01 20:05:01 - until epoch: 102, best_acc1: 41.510%
2023-07-01 20:05:01 - epoch 103 lr: 0.002000
2023-07-01 20:05:04 - train: epoch 0103, iter [00050, 00390], lr: 0.002000, loss: 0.6032
2023-07-01 20:05:06 - train: epoch 0103, iter [00100, 00390], lr: 0.002000, loss: 0.8864
2023-07-01 20:05:08 - train: epoch 0103, iter [00150, 00390], lr: 0.002000, loss: 0.6913
2023-07-01 20:05:11 - train: epoch 0103, iter [00200, 00390], lr: 0.002000, loss: 0.8201
2023-07-01 20:05:13 - train: epoch 0103, iter [00250, 00390], lr: 0.002000, loss: 0.6549
2023-07-01 20:05:15 - train: epoch 0103, iter [00300, 00390], lr: 0.002000, loss: 0.8485
2023-07-01 20:05:17 - train: epoch 0103, iter [00350, 00390], lr: 0.002000, loss: 0.7963
2023-07-01 20:05:19 - train: epoch 103, train_loss: 0.7202
2023-07-01 20:05:21 - eval: epoch: 103, acc1: 38.780%, acc5: 66.750%, test_loss: 3.1238, per_image_load_time: 0.069ms, per_image_inference_time: 0.082ms
2023-07-01 20:05:21 - until epoch: 103, best_acc1: 41.510%
2023-07-01 20:05:21 - epoch 104 lr: 0.002000
2023-07-01 20:05:24 - train: epoch 0104, iter [00050, 00390], lr: 0.002000, loss: 0.5918
2023-07-01 20:05:27 - train: epoch 0104, iter [00100, 00390], lr: 0.002000, loss: 0.5831
2023-07-01 20:05:29 - train: epoch 0104, iter [00150, 00390], lr: 0.002000, loss: 0.7505
2023-07-01 20:05:31 - train: epoch 0104, iter [00200, 00390], lr: 0.002000, loss: 0.6430
2023-07-01 20:05:34 - train: epoch 0104, iter [00250, 00390], lr: 0.002000, loss: 0.5086
2023-07-01 20:05:36 - train: epoch 0104, iter [00300, 00390], lr: 0.002000, loss: 0.7858
2023-07-01 20:05:38 - train: epoch 0104, iter [00350, 00390], lr: 0.002000, loss: 0.8210
2023-07-01 20:05:40 - train: epoch 104, train_loss: 0.7133
2023-07-01 20:05:42 - eval: epoch: 104, acc1: 38.510%, acc5: 66.540%, test_loss: 3.1685, per_image_load_time: 0.083ms, per_image_inference_time: 0.084ms
2023-07-01 20:05:42 - until epoch: 104, best_acc1: 41.510%
2023-07-01 20:05:42 - epoch 105 lr: 0.002000
2023-07-01 20:05:46 - train: epoch 0105, iter [00050, 00390], lr: 0.002000, loss: 0.6928
2023-07-01 20:05:48 - train: epoch 0105, iter [00100, 00390], lr: 0.002000, loss: 0.5278
2023-07-01 20:05:50 - train: epoch 0105, iter [00150, 00390], lr: 0.002000, loss: 0.6213
2023-07-01 20:05:53 - train: epoch 0105, iter [00200, 00390], lr: 0.002000, loss: 0.5904
2023-07-01 20:05:55 - train: epoch 0105, iter [00250, 00390], lr: 0.002000, loss: 0.6891
2023-07-01 20:05:57 - train: epoch 0105, iter [00300, 00390], lr: 0.002000, loss: 0.5301
2023-07-01 20:05:59 - train: epoch 0105, iter [00350, 00390], lr: 0.002000, loss: 0.7517
2023-07-01 20:06:01 - train: epoch 105, train_loss: 0.6791
2023-07-01 20:06:03 - eval: epoch: 105, acc1: 38.730%, acc5: 66.550%, test_loss: 3.1711, per_image_load_time: 0.083ms, per_image_inference_time: 0.083ms
2023-07-01 20:06:03 - until epoch: 105, best_acc1: 41.510%
2023-07-01 20:06:03 - epoch 106 lr: 0.002000
2023-07-01 20:06:07 - train: epoch 0106, iter [00050, 00390], lr: 0.002000, loss: 0.5886
2023-07-01 20:06:09 - train: epoch 0106, iter [00100, 00390], lr: 0.002000, loss: 0.8251
2023-07-01 20:06:11 - train: epoch 0106, iter [00150, 00390], lr: 0.002000, loss: 0.5980
2023-07-01 20:06:14 - train: epoch 0106, iter [00200, 00390], lr: 0.002000, loss: 0.6502
2023-07-01 20:06:16 - train: epoch 0106, iter [00250, 00390], lr: 0.002000, loss: 0.5707
2023-07-01 20:06:19 - train: epoch 0106, iter [00300, 00390], lr: 0.002000, loss: 0.7286
2023-07-01 20:06:21 - train: epoch 0106, iter [00350, 00390], lr: 0.002000, loss: 0.5291
2023-07-01 20:06:23 - train: epoch 106, train_loss: 0.6669
2023-07-01 20:06:25 - eval: epoch: 106, acc1: 38.240%, acc5: 66.590%, test_loss: 3.2184, per_image_load_time: 0.081ms, per_image_inference_time: 0.084ms
2023-07-01 20:06:25 - until epoch: 106, best_acc1: 41.510%
2023-07-01 20:06:25 - epoch 107 lr: 0.002000
2023-07-01 20:06:28 - train: epoch 0107, iter [00050, 00390], lr: 0.002000, loss: 0.6251
2023-07-01 20:06:30 - train: epoch 0107, iter [00100, 00390], lr: 0.002000, loss: 0.6401
2023-07-01 20:06:33 - train: epoch 0107, iter [00150, 00390], lr: 0.002000, loss: 0.5884
2023-07-01 20:06:35 - train: epoch 0107, iter [00200, 00390], lr: 0.002000, loss: 0.7071
2023-07-01 20:06:38 - train: epoch 0107, iter [00250, 00390], lr: 0.002000, loss: 0.8994
2023-07-01 20:06:40 - train: epoch 0107, iter [00300, 00390], lr: 0.002000, loss: 0.7065
2023-07-01 20:06:43 - train: epoch 0107, iter [00350, 00390], lr: 0.002000, loss: 0.8855
2023-07-01 20:06:45 - train: epoch 107, train_loss: 0.6562
2023-07-01 20:06:47 - eval: epoch: 107, acc1: 37.930%, acc5: 65.310%, test_loss: 3.2615, per_image_load_time: 0.094ms, per_image_inference_time: 0.083ms
2023-07-01 20:06:48 - until epoch: 107, best_acc1: 41.510%
2023-07-01 20:06:48 - epoch 108 lr: 0.002000
2023-07-01 20:06:51 - train: epoch 0108, iter [00050, 00390], lr: 0.002000, loss: 0.5633
2023-07-01 20:06:53 - train: epoch 0108, iter [00100, 00390], lr: 0.002000, loss: 0.6542
2023-07-01 20:06:56 - train: epoch 0108, iter [00150, 00390], lr: 0.002000, loss: 0.7630
2023-07-01 20:06:58 - train: epoch 0108, iter [00200, 00390], lr: 0.002000, loss: 0.5780
2023-07-01 20:07:01 - train: epoch 0108, iter [00250, 00390], lr: 0.002000, loss: 0.6251
2023-07-01 20:07:03 - train: epoch 0108, iter [00300, 00390], lr: 0.002000, loss: 0.6609
2023-07-01 20:07:05 - train: epoch 0108, iter [00350, 00390], lr: 0.002000, loss: 0.8133
2023-07-01 20:07:07 - train: epoch 108, train_loss: 0.6521
2023-07-01 20:07:09 - eval: epoch: 108, acc1: 38.380%, acc5: 66.030%, test_loss: 3.2573, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 20:07:09 - until epoch: 108, best_acc1: 41.510%
2023-07-01 20:07:09 - epoch 109 lr: 0.002000
2023-07-01 20:07:13 - train: epoch 0109, iter [00050, 00390], lr: 0.002000, loss: 0.4894
2023-07-01 20:07:15 - train: epoch 0109, iter [00100, 00390], lr: 0.002000, loss: 0.5579
2023-07-01 20:07:17 - train: epoch 0109, iter [00150, 00390], lr: 0.002000, loss: 0.5987
2023-07-01 20:07:19 - train: epoch 0109, iter [00200, 00390], lr: 0.002000, loss: 0.6792
2023-07-01 20:07:22 - train: epoch 0109, iter [00250, 00390], lr: 0.002000, loss: 0.5927
2023-07-01 20:07:24 - train: epoch 0109, iter [00300, 00390], lr: 0.002000, loss: 0.7060
2023-07-01 20:07:27 - train: epoch 0109, iter [00350, 00390], lr: 0.002000, loss: 0.7221
2023-07-01 20:07:29 - train: epoch 109, train_loss: 0.6443
2023-07-01 20:07:30 - eval: epoch: 109, acc1: 38.410%, acc5: 66.260%, test_loss: 3.2395, per_image_load_time: 0.077ms, per_image_inference_time: 0.084ms
2023-07-01 20:07:31 - until epoch: 109, best_acc1: 41.510%
2023-07-01 20:07:31 - epoch 110 lr: 0.002000
2023-07-01 20:07:34 - train: epoch 0110, iter [00050, 00390], lr: 0.002000, loss: 0.5461
2023-07-01 20:07:36 - train: epoch 0110, iter [00100, 00390], lr: 0.002000, loss: 0.5596
2023-07-01 20:07:38 - train: epoch 0110, iter [00150, 00390], lr: 0.002000, loss: 0.7714
2023-07-01 20:07:41 - train: epoch 0110, iter [00200, 00390], lr: 0.002000, loss: 0.9660
2023-07-01 20:07:43 - train: epoch 0110, iter [00250, 00390], lr: 0.002000, loss: 0.7314
2023-07-01 20:07:45 - train: epoch 0110, iter [00300, 00390], lr: 0.002000, loss: 0.4669
2023-07-01 20:07:48 - train: epoch 0110, iter [00350, 00390], lr: 0.002000, loss: 0.5740
2023-07-01 20:07:50 - train: epoch 110, train_loss: 0.6169
2023-07-01 20:07:51 - eval: epoch: 110, acc1: 37.780%, acc5: 65.770%, test_loss: 3.2812, per_image_load_time: 0.079ms, per_image_inference_time: 0.085ms
2023-07-01 20:07:52 - until epoch: 110, best_acc1: 41.510%
2023-07-01 20:07:52 - epoch 111 lr: 0.002000
2023-07-01 20:07:55 - train: epoch 0111, iter [00050, 00390], lr: 0.002000, loss: 0.5381
2023-07-01 20:07:58 - train: epoch 0111, iter [00100, 00390], lr: 0.002000, loss: 0.6104
2023-07-01 20:08:00 - train: epoch 0111, iter [00150, 00390], lr: 0.002000, loss: 0.6824
2023-07-01 20:08:02 - train: epoch 0111, iter [00200, 00390], lr: 0.002000, loss: 0.6982
2023-07-01 20:08:05 - train: epoch 0111, iter [00250, 00390], lr: 0.002000, loss: 0.7236
2023-07-01 20:08:07 - train: epoch 0111, iter [00300, 00390], lr: 0.002000, loss: 0.6541
2023-07-01 20:08:09 - train: epoch 0111, iter [00350, 00390], lr: 0.002000, loss: 0.6933
2023-07-01 20:08:11 - train: epoch 111, train_loss: 0.6076
2023-07-01 20:08:13 - eval: epoch: 111, acc1: 38.140%, acc5: 66.060%, test_loss: 3.2819, per_image_load_time: 0.079ms, per_image_inference_time: 0.089ms
2023-07-01 20:08:13 - until epoch: 111, best_acc1: 41.510%
2023-07-01 20:08:13 - epoch 112 lr: 0.002000
2023-07-01 20:08:16 - train: epoch 0112, iter [00050, 00390], lr: 0.002000, loss: 0.5384
2023-07-01 20:08:19 - train: epoch 0112, iter [00100, 00390], lr: 0.002000, loss: 0.5687
2023-07-01 20:08:21 - train: epoch 0112, iter [00150, 00390], lr: 0.002000, loss: 0.5220
2023-07-01 20:08:23 - train: epoch 0112, iter [00200, 00390], lr: 0.002000, loss: 0.5729
2023-07-01 20:08:26 - train: epoch 0112, iter [00250, 00390], lr: 0.002000, loss: 0.4700
2023-07-01 20:08:28 - train: epoch 0112, iter [00300, 00390], lr: 0.002000, loss: 0.6843
2023-07-01 20:08:30 - train: epoch 0112, iter [00350, 00390], lr: 0.002000, loss: 0.6946
2023-07-01 20:08:32 - train: epoch 112, train_loss: 0.5985
2023-07-01 20:08:34 - eval: epoch: 112, acc1: 38.340%, acc5: 65.790%, test_loss: 3.3101, per_image_load_time: 0.081ms, per_image_inference_time: 0.083ms
2023-07-01 20:08:34 - until epoch: 112, best_acc1: 41.510%
2023-07-01 20:08:34 - epoch 113 lr: 0.002000
2023-07-01 20:08:38 - train: epoch 0113, iter [00050, 00390], lr: 0.002000, loss: 0.5624
2023-07-01 20:08:40 - train: epoch 0113, iter [00100, 00390], lr: 0.002000, loss: 0.6124
2023-07-01 20:08:42 - train: epoch 0113, iter [00150, 00390], lr: 0.002000, loss: 0.5116
2023-07-01 20:08:44 - train: epoch 0113, iter [00200, 00390], lr: 0.002000, loss: 0.4392
2023-07-01 20:08:47 - train: epoch 0113, iter [00250, 00390], lr: 0.002000, loss: 0.6562
2023-07-01 20:08:49 - train: epoch 0113, iter [00300, 00390], lr: 0.002000, loss: 0.5786
2023-07-01 20:08:51 - train: epoch 0113, iter [00350, 00390], lr: 0.002000, loss: 0.5760
2023-07-01 20:08:53 - train: epoch 113, train_loss: 0.5825
2023-07-01 20:08:55 - eval: epoch: 113, acc1: 38.270%, acc5: 65.900%, test_loss: 3.3109, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 20:08:55 - until epoch: 113, best_acc1: 41.510%
2023-07-01 20:08:55 - epoch 114 lr: 0.002000
2023-07-01 20:08:58 - train: epoch 0114, iter [00050, 00390], lr: 0.002000, loss: 0.4452
2023-07-01 20:09:01 - train: epoch 0114, iter [00100, 00390], lr: 0.002000, loss: 0.7510
2023-07-01 20:09:03 - train: epoch 0114, iter [00150, 00390], lr: 0.002000, loss: 0.4650
2023-07-01 20:09:05 - train: epoch 0114, iter [00200, 00390], lr: 0.002000, loss: 0.5971
2023-07-01 20:09:08 - train: epoch 0114, iter [00250, 00390], lr: 0.002000, loss: 0.5525
2023-07-01 20:09:10 - train: epoch 0114, iter [00300, 00390], lr: 0.002000, loss: 0.5777
2023-07-01 20:09:12 - train: epoch 0114, iter [00350, 00390], lr: 0.002000, loss: 0.6417
2023-07-01 20:09:14 - train: epoch 114, train_loss: 0.5675
2023-07-01 20:09:16 - eval: epoch: 114, acc1: 37.720%, acc5: 65.830%, test_loss: 3.3627, per_image_load_time: 0.080ms, per_image_inference_time: 0.085ms
2023-07-01 20:09:16 - until epoch: 114, best_acc1: 41.510%
2023-07-01 20:09:16 - epoch 115 lr: 0.002000
2023-07-01 20:09:20 - train: epoch 0115, iter [00050, 00390], lr: 0.002000, loss: 0.3490
2023-07-01 20:09:22 - train: epoch 0115, iter [00100, 00390], lr: 0.002000, loss: 0.5878
2023-07-01 20:09:24 - train: epoch 0115, iter [00150, 00390], lr: 0.002000, loss: 0.4264
2023-07-01 20:09:27 - train: epoch 0115, iter [00200, 00390], lr: 0.002000, loss: 0.6390
2023-07-01 20:09:29 - train: epoch 0115, iter [00250, 00390], lr: 0.002000, loss: 0.6801
2023-07-01 20:09:31 - train: epoch 0115, iter [00300, 00390], lr: 0.002000, loss: 0.7419
2023-07-01 20:09:34 - train: epoch 0115, iter [00350, 00390], lr: 0.002000, loss: 0.7003
2023-07-01 20:09:36 - train: epoch 115, train_loss: 0.5638
2023-07-01 20:09:38 - eval: epoch: 115, acc1: 38.790%, acc5: 65.910%, test_loss: 3.3591, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 20:09:38 - until epoch: 115, best_acc1: 41.510%
2023-07-01 20:09:38 - epoch 116 lr: 0.002000
2023-07-01 20:09:42 - train: epoch 0116, iter [00050, 00390], lr: 0.002000, loss: 0.5676
2023-07-01 20:09:44 - train: epoch 0116, iter [00100, 00390], lr: 0.002000, loss: 0.4127
2023-07-01 20:09:46 - train: epoch 0116, iter [00150, 00390], lr: 0.002000, loss: 0.7346
2023-07-01 20:09:49 - train: epoch 0116, iter [00200, 00390], lr: 0.002000, loss: 0.5925
2023-07-01 20:09:51 - train: epoch 0116, iter [00250, 00390], lr: 0.002000, loss: 0.5927
2023-07-01 20:09:53 - train: epoch 0116, iter [00300, 00390], lr: 0.002000, loss: 0.6249
2023-07-01 20:09:55 - train: epoch 0116, iter [00350, 00390], lr: 0.002000, loss: 0.6071
2023-07-01 20:09:57 - train: epoch 116, train_loss: 0.5600
2023-07-01 20:09:59 - eval: epoch: 116, acc1: 38.210%, acc5: 65.880%, test_loss: 3.3754, per_image_load_time: 0.078ms, per_image_inference_time: 0.085ms
2023-07-01 20:10:00 - until epoch: 116, best_acc1: 41.510%
2023-07-01 20:10:00 - epoch 117 lr: 0.002000
2023-07-01 20:10:03 - train: epoch 0117, iter [00050, 00390], lr: 0.002000, loss: 0.3996
2023-07-01 20:10:05 - train: epoch 0117, iter [00100, 00390], lr: 0.002000, loss: 0.5257
2023-07-01 20:10:08 - train: epoch 0117, iter [00150, 00390], lr: 0.002000, loss: 0.5420
2023-07-01 20:10:10 - train: epoch 0117, iter [00200, 00390], lr: 0.002000, loss: 0.4276
2023-07-01 20:10:12 - train: epoch 0117, iter [00250, 00390], lr: 0.002000, loss: 0.6452
2023-07-01 20:10:15 - train: epoch 0117, iter [00300, 00390], lr: 0.002000, loss: 0.6793
2023-07-01 20:10:17 - train: epoch 0117, iter [00350, 00390], lr: 0.002000, loss: 0.4732
2023-07-01 20:10:19 - train: epoch 117, train_loss: 0.5439
2023-07-01 20:10:21 - eval: epoch: 117, acc1: 38.490%, acc5: 65.720%, test_loss: 3.3831, per_image_load_time: 0.085ms, per_image_inference_time: 0.085ms
2023-07-01 20:10:21 - until epoch: 117, best_acc1: 41.510%
2023-07-01 20:10:21 - epoch 118 lr: 0.002000
2023-07-01 20:10:24 - train: epoch 0118, iter [00050, 00390], lr: 0.002000, loss: 0.5567
2023-07-01 20:10:26 - train: epoch 0118, iter [00100, 00390], lr: 0.002000, loss: 0.4942
2023-07-01 20:10:29 - train: epoch 0118, iter [00150, 00390], lr: 0.002000, loss: 0.4880
2023-07-01 20:10:31 - train: epoch 0118, iter [00200, 00390], lr: 0.002000, loss: 0.4903
2023-07-01 20:10:33 - train: epoch 0118, iter [00250, 00390], lr: 0.002000, loss: 0.5218
2023-07-01 20:10:35 - train: epoch 0118, iter [00300, 00390], lr: 0.002000, loss: 0.4467
2023-07-01 20:10:37 - train: epoch 0118, iter [00350, 00390], lr: 0.002000, loss: 0.5419
2023-07-01 20:10:39 - train: epoch 118, train_loss: 0.5323
2023-07-01 20:10:41 - eval: epoch: 118, acc1: 38.770%, acc5: 66.230%, test_loss: 3.3610, per_image_load_time: 0.075ms, per_image_inference_time: 0.081ms
2023-07-01 20:10:41 - until epoch: 118, best_acc1: 41.510%
2023-07-01 20:10:41 - epoch 119 lr: 0.002000
2023-07-01 20:10:45 - train: epoch 0119, iter [00050, 00390], lr: 0.002000, loss: 0.4566
2023-07-01 20:10:47 - train: epoch 0119, iter [00100, 00390], lr: 0.002000, loss: 0.5594
2023-07-01 20:10:50 - train: epoch 0119, iter [00150, 00390], lr: 0.002000, loss: 0.5077
2023-07-01 20:10:52 - train: epoch 0119, iter [00200, 00390], lr: 0.002000, loss: 0.4829
2023-07-01 20:10:54 - train: epoch 0119, iter [00250, 00390], lr: 0.002000, loss: 0.4248
2023-07-01 20:10:57 - train: epoch 0119, iter [00300, 00390], lr: 0.002000, loss: 0.5405
2023-07-01 20:10:59 - train: epoch 0119, iter [00350, 00390], lr: 0.002000, loss: 0.4872
2023-07-01 20:11:01 - train: epoch 119, train_loss: 0.5227
2023-07-01 20:11:03 - eval: epoch: 119, acc1: 38.250%, acc5: 65.700%, test_loss: 3.4209, per_image_load_time: 0.085ms, per_image_inference_time: 0.082ms
2023-07-01 20:11:03 - until epoch: 119, best_acc1: 41.510%
2023-07-01 20:11:03 - epoch 120 lr: 0.002000
2023-07-01 20:11:06 - train: epoch 0120, iter [00050, 00390], lr: 0.002000, loss: 0.3807
2023-07-01 20:11:09 - train: epoch 0120, iter [00100, 00390], lr: 0.002000, loss: 0.4779
2023-07-01 20:11:11 - train: epoch 0120, iter [00150, 00390], lr: 0.002000, loss: 0.5402
2023-07-01 20:11:13 - train: epoch 0120, iter [00200, 00390], lr: 0.002000, loss: 0.5217
2023-07-01 20:11:16 - train: epoch 0120, iter [00250, 00390], lr: 0.002000, loss: 0.5515
2023-07-01 20:11:18 - train: epoch 0120, iter [00300, 00390], lr: 0.002000, loss: 0.4748
2023-07-01 20:11:20 - train: epoch 0120, iter [00350, 00390], lr: 0.002000, loss: 0.4723
2023-07-01 20:11:22 - train: epoch 120, train_loss: 0.5062
2023-07-01 20:11:24 - eval: epoch: 120, acc1: 38.340%, acc5: 65.920%, test_loss: 3.4316, per_image_load_time: 0.079ms, per_image_inference_time: 0.085ms
2023-07-01 20:11:24 - until epoch: 120, best_acc1: 41.510%
2023-07-01 20:11:24 - epoch 121 lr: 0.000400
2023-07-01 20:11:28 - train: epoch 0121, iter [00050, 00390], lr: 0.000400, loss: 0.3047
2023-07-01 20:11:30 - train: epoch 0121, iter [00100, 00390], lr: 0.000400, loss: 0.3157
2023-07-01 20:11:32 - train: epoch 0121, iter [00150, 00390], lr: 0.000400, loss: 0.3029
2023-07-01 20:11:35 - train: epoch 0121, iter [00200, 00390], lr: 0.000400, loss: 0.4078
2023-07-01 20:11:37 - train: epoch 0121, iter [00250, 00390], lr: 0.000400, loss: 0.3391
2023-07-01 20:11:39 - train: epoch 0121, iter [00300, 00390], lr: 0.000400, loss: 0.3512
2023-07-01 20:11:41 - train: epoch 0121, iter [00350, 00390], lr: 0.000400, loss: 0.1900
2023-07-01 20:11:43 - train: epoch 121, train_loss: 0.3290
2023-07-01 20:11:45 - eval: epoch: 121, acc1: 39.640%, acc5: 66.280%, test_loss: 3.3584, per_image_load_time: 0.082ms, per_image_inference_time: 0.083ms
2023-07-01 20:11:45 - until epoch: 121, best_acc1: 41.510%
2023-07-01 20:11:45 - epoch 122 lr: 0.000400
2023-07-01 20:11:49 - train: epoch 0122, iter [00050, 00390], lr: 0.000400, loss: 0.3102
2023-07-01 20:11:51 - train: epoch 0122, iter [00100, 00390], lr: 0.000400, loss: 0.2951
2023-07-01 20:11:53 - train: epoch 0122, iter [00150, 00390], lr: 0.000400, loss: 0.2564
2023-07-01 20:11:56 - train: epoch 0122, iter [00200, 00390], lr: 0.000400, loss: 0.2943
2023-07-01 20:11:58 - train: epoch 0122, iter [00250, 00390], lr: 0.000400, loss: 0.2484
2023-07-01 20:12:00 - train: epoch 0122, iter [00300, 00390], lr: 0.000400, loss: 0.1611
2023-07-01 20:12:02 - train: epoch 0122, iter [00350, 00390], lr: 0.000400, loss: 0.3446
2023-07-01 20:12:04 - train: epoch 122, train_loss: 0.2720
2023-07-01 20:12:06 - eval: epoch: 122, acc1: 39.730%, acc5: 66.550%, test_loss: 3.3542, per_image_load_time: 0.080ms, per_image_inference_time: 0.085ms
2023-07-01 20:12:07 - until epoch: 122, best_acc1: 41.510%
2023-07-01 20:12:07 - epoch 123 lr: 0.000400
2023-07-01 20:12:10 - train: epoch 0123, iter [00050, 00390], lr: 0.000400, loss: 0.2382
2023-07-01 20:12:12 - train: epoch 0123, iter [00100, 00390], lr: 0.000400, loss: 0.3086
2023-07-01 20:12:14 - train: epoch 0123, iter [00150, 00390], lr: 0.000400, loss: 0.1834
2023-07-01 20:12:17 - train: epoch 0123, iter [00200, 00390], lr: 0.000400, loss: 0.2170
2023-07-01 20:12:19 - train: epoch 0123, iter [00250, 00390], lr: 0.000400, loss: 0.2576
2023-07-01 20:12:21 - train: epoch 0123, iter [00300, 00390], lr: 0.000400, loss: 0.2873
2023-07-01 20:12:24 - train: epoch 0123, iter [00350, 00390], lr: 0.000400, loss: 0.1244
2023-07-01 20:12:26 - train: epoch 123, train_loss: 0.2508
2023-07-01 20:12:27 - eval: epoch: 123, acc1: 39.890%, acc5: 66.590%, test_loss: 3.3564, per_image_load_time: 0.080ms, per_image_inference_time: 0.084ms
2023-07-01 20:12:28 - until epoch: 123, best_acc1: 41.510%
2023-07-01 20:12:28 - epoch 124 lr: 0.000400
2023-07-01 20:12:31 - train: epoch 0124, iter [00050, 00390], lr: 0.000400, loss: 0.2097
2023-07-01 20:12:33 - train: epoch 0124, iter [00100, 00390], lr: 0.000400, loss: 0.2542
2023-07-01 20:12:36 - train: epoch 0124, iter [00150, 00390], lr: 0.000400, loss: 0.2048
2023-07-01 20:12:38 - train: epoch 0124, iter [00200, 00390], lr: 0.000400, loss: 0.3754
2023-07-01 20:12:40 - train: epoch 0124, iter [00250, 00390], lr: 0.000400, loss: 0.1992
2023-07-01 20:12:42 - train: epoch 0124, iter [00300, 00390], lr: 0.000400, loss: 0.2548
2023-07-01 20:12:45 - train: epoch 0124, iter [00350, 00390], lr: 0.000400, loss: 0.1734
2023-07-01 20:12:47 - train: epoch 124, train_loss: 0.2371
2023-07-01 20:12:48 - eval: epoch: 124, acc1: 39.920%, acc5: 66.530%, test_loss: 3.3771, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 20:12:49 - until epoch: 124, best_acc1: 41.510%
2023-07-01 20:12:49 - epoch 125 lr: 0.000400
2023-07-01 20:12:52 - train: epoch 0125, iter [00050, 00390], lr: 0.000400, loss: 0.2462
2023-07-01 20:12:54 - train: epoch 0125, iter [00100, 00390], lr: 0.000400, loss: 0.1863
2023-07-01 20:12:57 - train: epoch 0125, iter [00150, 00390], lr: 0.000400, loss: 0.2221
2023-07-01 20:13:00 - train: epoch 0125, iter [00200, 00390], lr: 0.000400, loss: 0.1951
2023-07-01 20:13:03 - train: epoch 0125, iter [00250, 00390], lr: 0.000400, loss: 0.2720
2023-07-01 20:13:06 - train: epoch 0125, iter [00300, 00390], lr: 0.000400, loss: 0.2941
2023-07-01 20:13:08 - train: epoch 0125, iter [00350, 00390], lr: 0.000400, loss: 0.2477
2023-07-01 20:13:10 - train: epoch 125, train_loss: 0.2285
2023-07-01 20:13:12 - eval: epoch: 125, acc1: 39.700%, acc5: 66.210%, test_loss: 3.4008, per_image_load_time: 0.078ms, per_image_inference_time: 0.084ms
2023-07-01 20:13:12 - until epoch: 125, best_acc1: 41.510%
2023-07-01 20:13:12 - epoch 126 lr: 0.000400
2023-07-01 20:13:16 - train: epoch 0126, iter [00050, 00390], lr: 0.000400, loss: 0.2698
2023-07-01 20:13:18 - train: epoch 0126, iter [00100, 00390], lr: 0.000400, loss: 0.1882
2023-07-01 20:13:20 - train: epoch 0126, iter [00150, 00390], lr: 0.000400, loss: 0.2343
2023-07-01 20:13:23 - train: epoch 0126, iter [00200, 00390], lr: 0.000400, loss: 0.1979
2023-07-01 20:13:25 - train: epoch 0126, iter [00250, 00390], lr: 0.000400, loss: 0.1823
2023-07-01 20:13:27 - train: epoch 0126, iter [00300, 00390], lr: 0.000400, loss: 0.1826
2023-07-01 20:13:30 - train: epoch 0126, iter [00350, 00390], lr: 0.000400, loss: 0.1973
2023-07-01 20:13:31 - train: epoch 126, train_loss: 0.2179
2023-07-01 20:13:33 - eval: epoch: 126, acc1: 39.790%, acc5: 66.650%, test_loss: 3.4075, per_image_load_time: 0.078ms, per_image_inference_time: 0.082ms
2023-07-01 20:13:34 - until epoch: 126, best_acc1: 41.510%
2023-07-01 20:13:34 - epoch 127 lr: 0.000400
2023-07-01 20:13:37 - train: epoch 0127, iter [00050, 00390], lr: 0.000400, loss: 0.1961
2023-07-01 20:13:40 - train: epoch 0127, iter [00100, 00390], lr: 0.000400, loss: 0.2983
2023-07-01 20:13:43 - train: epoch 0127, iter [00150, 00390], lr: 0.000400, loss: 0.1687
2023-07-01 20:13:46 - train: epoch 0127, iter [00200, 00390], lr: 0.000400, loss: 0.1900
2023-07-01 20:13:48 - train: epoch 0127, iter [00250, 00390], lr: 0.000400, loss: 0.1931
2023-07-01 20:13:50 - train: epoch 0127, iter [00300, 00390], lr: 0.000400, loss: 0.2470
2023-07-01 20:13:53 - train: epoch 0127, iter [00350, 00390], lr: 0.000400, loss: 0.1866
2023-07-01 20:13:55 - train: epoch 127, train_loss: 0.2139
2023-07-01 20:13:57 - eval: epoch: 127, acc1: 39.930%, acc5: 66.700%, test_loss: 3.4221, per_image_load_time: 0.079ms, per_image_inference_time: 0.090ms
2023-07-01 20:13:57 - until epoch: 127, best_acc1: 41.510%
2023-07-01 20:13:57 - epoch 128 lr: 0.000400
2023-07-01 20:14:00 - train: epoch 0128, iter [00050, 00390], lr: 0.000400, loss: 0.1917
2023-07-01 20:14:03 - train: epoch 0128, iter [00100, 00390], lr: 0.000400, loss: 0.2337
2023-07-01 20:14:05 - train: epoch 0128, iter [00150, 00390], lr: 0.000400, loss: 0.2366
2023-07-01 20:14:08 - train: epoch 0128, iter [00200, 00390], lr: 0.000400, loss: 0.2312
2023-07-01 20:14:10 - train: epoch 0128, iter [00250, 00390], lr: 0.000400, loss: 0.3008
2023-07-01 20:14:12 - train: epoch 0128, iter [00300, 00390], lr: 0.000400, loss: 0.2273
2023-07-01 20:14:14 - train: epoch 0128, iter [00350, 00390], lr: 0.000400, loss: 0.1990
2023-07-01 20:14:16 - train: epoch 128, train_loss: 0.2079
2023-07-01 20:14:18 - eval: epoch: 128, acc1: 39.790%, acc5: 66.480%, test_loss: 3.4364, per_image_load_time: 0.078ms, per_image_inference_time: 0.084ms
2023-07-01 20:14:18 - until epoch: 128, best_acc1: 41.510%
2023-07-01 20:14:18 - epoch 129 lr: 0.000400
2023-07-01 20:14:22 - train: epoch 0129, iter [00050, 00390], lr: 0.000400, loss: 0.1607
2023-07-01 20:14:24 - train: epoch 0129, iter [00100, 00390], lr: 0.000400, loss: 0.2052
2023-07-01 20:14:26 - train: epoch 0129, iter [00150, 00390], lr: 0.000400, loss: 0.2193
2023-07-01 20:14:29 - train: epoch 0129, iter [00200, 00390], lr: 0.000400, loss: 0.1310
2023-07-01 20:14:31 - train: epoch 0129, iter [00250, 00390], lr: 0.000400, loss: 0.1453
2023-07-01 20:14:33 - train: epoch 0129, iter [00300, 00390], lr: 0.000400, loss: 0.1965
2023-07-01 20:14:36 - train: epoch 0129, iter [00350, 00390], lr: 0.000400, loss: 0.2175
2023-07-01 20:14:38 - train: epoch 129, train_loss: 0.1976
2023-07-01 20:14:39 - eval: epoch: 129, acc1: 39.840%, acc5: 66.300%, test_loss: 3.4465, per_image_load_time: 0.081ms, per_image_inference_time: 0.083ms
2023-07-01 20:14:40 - until epoch: 129, best_acc1: 41.510%
2023-07-01 20:14:40 - epoch 130 lr: 0.000400
2023-07-01 20:14:43 - train: epoch 0130, iter [00050, 00390], lr: 0.000400, loss: 0.1930
2023-07-01 20:14:45 - train: epoch 0130, iter [00100, 00390], lr: 0.000400, loss: 0.2091
2023-07-01 20:14:48 - train: epoch 0130, iter [00150, 00390], lr: 0.000400, loss: 0.1758
2023-07-01 20:14:50 - train: epoch 0130, iter [00200, 00390], lr: 0.000400, loss: 0.1517
2023-07-01 20:14:53 - train: epoch 0130, iter [00250, 00390], lr: 0.000400, loss: 0.1518
2023-07-01 20:14:55 - train: epoch 0130, iter [00300, 00390], lr: 0.000400, loss: 0.1919
2023-07-01 20:14:58 - train: epoch 0130, iter [00350, 00390], lr: 0.000400, loss: 0.1373
2023-07-01 20:15:00 - train: epoch 130, train_loss: 0.1945
2023-07-01 20:15:01 - eval: epoch: 130, acc1: 39.520%, acc5: 66.030%, test_loss: 3.4727, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 20:15:02 - until epoch: 130, best_acc1: 41.510%
2023-07-01 20:15:02 - epoch 131 lr: 0.000400
2023-07-01 20:15:05 - train: epoch 0131, iter [00050, 00390], lr: 0.000400, loss: 0.1698
2023-07-01 20:15:07 - train: epoch 0131, iter [00100, 00390], lr: 0.000400, loss: 0.1480
2023-07-01 20:15:10 - train: epoch 0131, iter [00150, 00390], lr: 0.000400, loss: 0.1839
2023-07-01 20:15:12 - train: epoch 0131, iter [00200, 00390], lr: 0.000400, loss: 0.1335
2023-07-01 20:15:14 - train: epoch 0131, iter [00250, 00390], lr: 0.000400, loss: 0.1701
2023-07-01 20:15:17 - train: epoch 0131, iter [00300, 00390], lr: 0.000400, loss: 0.2057
2023-07-01 20:15:19 - train: epoch 0131, iter [00350, 00390], lr: 0.000400, loss: 0.2197
2023-07-01 20:15:21 - train: epoch 131, train_loss: 0.1960
2023-07-01 20:15:23 - eval: epoch: 131, acc1: 39.550%, acc5: 66.120%, test_loss: 3.4707, per_image_load_time: 0.078ms, per_image_inference_time: 0.083ms
2023-07-01 20:15:23 - until epoch: 131, best_acc1: 41.510%
2023-07-01 20:15:23 - epoch 132 lr: 0.000400
2023-07-01 20:15:27 - train: epoch 0132, iter [00050, 00390], lr: 0.000400, loss: 0.1541
2023-07-01 20:15:29 - train: epoch 0132, iter [00100, 00390], lr: 0.000400, loss: 0.2541
2023-07-01 20:15:32 - train: epoch 0132, iter [00150, 00390], lr: 0.000400, loss: 0.1813
2023-07-01 20:15:34 - train: epoch 0132, iter [00200, 00390], lr: 0.000400, loss: 0.1283
2023-07-01 20:15:36 - train: epoch 0132, iter [00250, 00390], lr: 0.000400, loss: 0.1799
2023-07-01 20:15:38 - train: epoch 0132, iter [00300, 00390], lr: 0.000400, loss: 0.1556
2023-07-01 20:15:41 - train: epoch 0132, iter [00350, 00390], lr: 0.000400, loss: 0.1361
2023-07-01 20:15:43 - train: epoch 132, train_loss: 0.1872
2023-07-01 20:15:44 - eval: epoch: 132, acc1: 39.570%, acc5: 66.180%, test_loss: 3.4860, per_image_load_time: 0.077ms, per_image_inference_time: 0.084ms
2023-07-01 20:15:45 - until epoch: 132, best_acc1: 41.510%
2023-07-01 20:15:45 - epoch 133 lr: 0.000400
2023-07-01 20:15:48 - train: epoch 0133, iter [00050, 00390], lr: 0.000400, loss: 0.1465
2023-07-01 20:15:50 - train: epoch 0133, iter [00100, 00390], lr: 0.000400, loss: 0.1836
2023-07-01 20:15:52 - train: epoch 0133, iter [00150, 00390], lr: 0.000400, loss: 0.1554
2023-07-01 20:15:55 - train: epoch 0133, iter [00200, 00390], lr: 0.000400, loss: 0.2771
2023-07-01 20:15:57 - train: epoch 0133, iter [00250, 00390], lr: 0.000400, loss: 0.2241
2023-07-01 20:15:59 - train: epoch 0133, iter [00300, 00390], lr: 0.000400, loss: 0.1816
2023-07-01 20:16:02 - train: epoch 0133, iter [00350, 00390], lr: 0.000400, loss: 0.1782
2023-07-01 20:16:04 - train: epoch 133, train_loss: 0.1808
2023-07-01 20:16:05 - eval: epoch: 133, acc1: 39.800%, acc5: 66.250%, test_loss: 3.4994, per_image_load_time: 0.078ms, per_image_inference_time: 0.086ms
2023-07-01 20:16:06 - until epoch: 133, best_acc1: 41.510%
2023-07-01 20:16:06 - epoch 134 lr: 0.000400
2023-07-01 20:16:09 - train: epoch 0134, iter [00050, 00390], lr: 0.000400, loss: 0.2244
2023-07-01 20:16:11 - train: epoch 0134, iter [00100, 00390], lr: 0.000400, loss: 0.1482
2023-07-01 20:16:13 - train: epoch 0134, iter [00150, 00390], lr: 0.000400, loss: 0.2268
2023-07-01 20:16:16 - train: epoch 0134, iter [00200, 00390], lr: 0.000400, loss: 0.1443
2023-07-01 20:16:18 - train: epoch 0134, iter [00250, 00390], lr: 0.000400, loss: 0.1303
2023-07-01 20:16:20 - train: epoch 0134, iter [00300, 00390], lr: 0.000400, loss: 0.1822
2023-07-01 20:16:23 - train: epoch 0134, iter [00350, 00390], lr: 0.000400, loss: 0.2287
2023-07-01 20:16:25 - train: epoch 134, train_loss: 0.1801
2023-07-01 20:16:26 - eval: epoch: 134, acc1: 39.520%, acc5: 66.370%, test_loss: 3.5027, per_image_load_time: 0.080ms, per_image_inference_time: 0.084ms
2023-07-01 20:16:27 - until epoch: 134, best_acc1: 41.510%
2023-07-01 20:16:27 - epoch 135 lr: 0.000400
2023-07-01 20:16:30 - train: epoch 0135, iter [00050, 00390], lr: 0.000400, loss: 0.1880
2023-07-01 20:16:32 - train: epoch 0135, iter [00100, 00390], lr: 0.000400, loss: 0.1716
2023-07-01 20:16:34 - train: epoch 0135, iter [00150, 00390], lr: 0.000400, loss: 0.1959
2023-07-01 20:16:37 - train: epoch 0135, iter [00200, 00390], lr: 0.000400, loss: 0.1846
2023-07-01 20:16:39 - train: epoch 0135, iter [00250, 00390], lr: 0.000400, loss: 0.2003
2023-07-01 20:16:41 - train: epoch 0135, iter [00300, 00390], lr: 0.000400, loss: 0.2272
2023-07-01 20:16:44 - train: epoch 0135, iter [00350, 00390], lr: 0.000400, loss: 0.1703
2023-07-01 20:16:46 - train: epoch 135, train_loss: 0.1729
2023-07-01 20:16:47 - eval: epoch: 135, acc1: 39.530%, acc5: 66.250%, test_loss: 3.5019, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 20:16:48 - until epoch: 135, best_acc1: 41.510%
2023-07-01 20:16:48 - epoch 136 lr: 0.000400
2023-07-01 20:16:52 - train: epoch 0136, iter [00050, 00390], lr: 0.000400, loss: 0.1655
2023-07-01 20:16:54 - train: epoch 0136, iter [00100, 00390], lr: 0.000400, loss: 0.1418
2023-07-01 20:16:56 - train: epoch 0136, iter [00150, 00390], lr: 0.000400, loss: 0.1660
2023-07-01 20:16:58 - train: epoch 0136, iter [00200, 00390], lr: 0.000400, loss: 0.1722
2023-07-01 20:17:01 - train: epoch 0136, iter [00250, 00390], lr: 0.000400, loss: 0.1883
2023-07-01 20:17:03 - train: epoch 0136, iter [00300, 00390], lr: 0.000400, loss: 0.2093
2023-07-01 20:17:05 - train: epoch 0136, iter [00350, 00390], lr: 0.000400, loss: 0.1494
2023-07-01 20:17:07 - train: epoch 136, train_loss: 0.1746
2023-07-01 20:17:09 - eval: epoch: 136, acc1: 39.500%, acc5: 66.280%, test_loss: 3.5184, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 20:17:10 - until epoch: 136, best_acc1: 41.510%
2023-07-01 20:17:10 - epoch 137 lr: 0.000400
2023-07-01 20:17:13 - train: epoch 0137, iter [00050, 00390], lr: 0.000400, loss: 0.1455
2023-07-01 20:17:16 - train: epoch 0137, iter [00100, 00390], lr: 0.000400, loss: 0.1556
2023-07-01 20:17:18 - train: epoch 0137, iter [00150, 00390], lr: 0.000400, loss: 0.1126
2023-07-01 20:17:20 - train: epoch 0137, iter [00200, 00390], lr: 0.000400, loss: 0.1407
2023-07-01 20:17:23 - train: epoch 0137, iter [00250, 00390], lr: 0.000400, loss: 0.1837
2023-07-01 20:17:25 - train: epoch 0137, iter [00300, 00390], lr: 0.000400, loss: 0.1472
2023-07-01 20:17:27 - train: epoch 0137, iter [00350, 00390], lr: 0.000400, loss: 0.2022
2023-07-01 20:17:29 - train: epoch 137, train_loss: 0.1697
2023-07-01 20:17:31 - eval: epoch: 137, acc1: 39.430%, acc5: 66.270%, test_loss: 3.5400, per_image_load_time: 0.081ms, per_image_inference_time: 0.084ms
2023-07-01 20:17:31 - until epoch: 137, best_acc1: 41.510%
2023-07-01 20:17:31 - epoch 138 lr: 0.000400
2023-07-01 20:17:35 - train: epoch 0138, iter [00050, 00390], lr: 0.000400, loss: 0.1338
2023-07-01 20:17:38 - train: epoch 0138, iter [00100, 00390], lr: 0.000400, loss: 0.1274
2023-07-01 20:17:40 - train: epoch 0138, iter [00150, 00390], lr: 0.000400, loss: 0.1584
2023-07-01 20:17:42 - train: epoch 0138, iter [00200, 00390], lr: 0.000400, loss: 0.2035
2023-07-01 20:17:45 - train: epoch 0138, iter [00250, 00390], lr: 0.000400, loss: 0.1533
2023-07-01 20:17:47 - train: epoch 0138, iter [00300, 00390], lr: 0.000400, loss: 0.1697
2023-07-01 20:17:49 - train: epoch 0138, iter [00350, 00390], lr: 0.000400, loss: 0.1900
2023-07-01 20:17:51 - train: epoch 138, train_loss: 0.1690
2023-07-01 20:17:53 - eval: epoch: 138, acc1: 39.400%, acc5: 66.280%, test_loss: 3.5475, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 20:17:54 - until epoch: 138, best_acc1: 41.510%
2023-07-01 20:17:54 - epoch 139 lr: 0.000400
2023-07-01 20:17:57 - train: epoch 0139, iter [00050, 00390], lr: 0.000400, loss: 0.1767
2023-07-01 20:17:59 - train: epoch 0139, iter [00100, 00390], lr: 0.000400, loss: 0.2275
2023-07-01 20:18:02 - train: epoch 0139, iter [00150, 00390], lr: 0.000400, loss: 0.1983
2023-07-01 20:18:04 - train: epoch 0139, iter [00200, 00390], lr: 0.000400, loss: 0.2027
2023-07-01 20:18:06 - train: epoch 0139, iter [00250, 00390], lr: 0.000400, loss: 0.1307
2023-07-01 20:18:09 - train: epoch 0139, iter [00300, 00390], lr: 0.000400, loss: 0.2053
2023-07-01 20:18:11 - train: epoch 0139, iter [00350, 00390], lr: 0.000400, loss: 0.1498
2023-07-01 20:18:13 - train: epoch 139, train_loss: 0.1646
2023-07-01 20:18:15 - eval: epoch: 139, acc1: 39.520%, acc5: 66.450%, test_loss: 3.5472, per_image_load_time: 0.078ms, per_image_inference_time: 0.083ms
2023-07-01 20:18:15 - until epoch: 139, best_acc1: 41.510%
2023-07-01 20:18:15 - epoch 140 lr: 0.000400
2023-07-01 20:18:18 - train: epoch 0140, iter [00050, 00390], lr: 0.000400, loss: 0.1507
2023-07-01 20:18:20 - train: epoch 0140, iter [00100, 00390], lr: 0.000400, loss: 0.1545
2023-07-01 20:18:23 - train: epoch 0140, iter [00150, 00390], lr: 0.000400, loss: 0.1904
2023-07-01 20:18:25 - train: epoch 0140, iter [00200, 00390], lr: 0.000400, loss: 0.2198
2023-07-01 20:18:28 - train: epoch 0140, iter [00250, 00390], lr: 0.000400, loss: 0.2173
2023-07-01 20:18:31 - train: epoch 0140, iter [00300, 00390], lr: 0.000400, loss: 0.1378
2023-07-01 20:18:33 - train: epoch 0140, iter [00350, 00390], lr: 0.000400, loss: 0.1645
2023-07-01 20:18:35 - train: epoch 140, train_loss: 0.1627
2023-07-01 20:18:37 - eval: epoch: 140, acc1: 39.810%, acc5: 66.200%, test_loss: 3.5613, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 20:18:37 - until epoch: 140, best_acc1: 41.510%
2023-07-01 20:18:37 - epoch 141 lr: 0.000400
2023-07-01 20:18:41 - train: epoch 0141, iter [00050, 00390], lr: 0.000400, loss: 0.1497
2023-07-01 20:18:43 - train: epoch 0141, iter [00100, 00390], lr: 0.000400, loss: 0.1684
2023-07-01 20:18:45 - train: epoch 0141, iter [00150, 00390], lr: 0.000400, loss: 0.2409
2023-07-01 20:18:48 - train: epoch 0141, iter [00200, 00390], lr: 0.000400, loss: 0.1281
2023-07-01 20:18:50 - train: epoch 0141, iter [00250, 00390], lr: 0.000400, loss: 0.1413
2023-07-01 20:18:52 - train: epoch 0141, iter [00300, 00390], lr: 0.000400, loss: 0.1622
2023-07-01 20:18:54 - train: epoch 0141, iter [00350, 00390], lr: 0.000400, loss: 0.2087
2023-07-01 20:18:56 - train: epoch 141, train_loss: 0.1610
2023-07-01 20:18:58 - eval: epoch: 141, acc1: 39.430%, acc5: 66.090%, test_loss: 3.5714, per_image_load_time: 0.079ms, per_image_inference_time: 0.085ms
2023-07-01 20:18:59 - until epoch: 141, best_acc1: 41.510%
2023-07-01 20:18:59 - epoch 142 lr: 0.000400
2023-07-01 20:19:02 - train: epoch 0142, iter [00050, 00390], lr: 0.000400, loss: 0.1798
2023-07-01 20:19:05 - train: epoch 0142, iter [00100, 00390], lr: 0.000400, loss: 0.1793
2023-07-01 20:19:07 - train: epoch 0142, iter [00150, 00390], lr: 0.000400, loss: 0.1725
2023-07-01 20:19:09 - train: epoch 0142, iter [00200, 00390], lr: 0.000400, loss: 0.1867
2023-07-01 20:19:12 - train: epoch 0142, iter [00250, 00390], lr: 0.000400, loss: 0.1388
2023-07-01 20:19:14 - train: epoch 0142, iter [00300, 00390], lr: 0.000400, loss: 0.1654
2023-07-01 20:19:16 - train: epoch 0142, iter [00350, 00390], lr: 0.000400, loss: 0.1359
2023-07-01 20:19:18 - train: epoch 142, train_loss: 0.1548
2023-07-01 20:19:20 - eval: epoch: 142, acc1: 39.460%, acc5: 65.980%, test_loss: 3.5852, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 20:19:20 - until epoch: 142, best_acc1: 41.510%
2023-07-01 20:19:20 - epoch 143 lr: 0.000400
2023-07-01 20:19:24 - train: epoch 0143, iter [00050, 00390], lr: 0.000400, loss: 0.1922
2023-07-01 20:19:26 - train: epoch 0143, iter [00100, 00390], lr: 0.000400, loss: 0.1061
2023-07-01 20:19:29 - train: epoch 0143, iter [00150, 00390], lr: 0.000400, loss: 0.1449
2023-07-01 20:19:31 - train: epoch 0143, iter [00200, 00390], lr: 0.000400, loss: 0.1283
2023-07-01 20:19:33 - train: epoch 0143, iter [00250, 00390], lr: 0.000400, loss: 0.1993
2023-07-01 20:19:36 - train: epoch 0143, iter [00300, 00390], lr: 0.000400, loss: 0.1788
2023-07-01 20:19:38 - train: epoch 0143, iter [00350, 00390], lr: 0.000400, loss: 0.2178
2023-07-01 20:19:40 - train: epoch 143, train_loss: 0.1591
2023-07-01 20:19:42 - eval: epoch: 143, acc1: 39.410%, acc5: 66.060%, test_loss: 3.5987, per_image_load_time: 0.078ms, per_image_inference_time: 0.085ms
2023-07-01 20:19:42 - until epoch: 143, best_acc1: 41.510%
2023-07-01 20:19:42 - epoch 144 lr: 0.000400
2023-07-01 20:19:45 - train: epoch 0144, iter [00050, 00390], lr: 0.000400, loss: 0.2086
2023-07-01 20:19:47 - train: epoch 0144, iter [00100, 00390], lr: 0.000400, loss: 0.0941
2023-07-01 20:19:50 - train: epoch 0144, iter [00150, 00390], lr: 0.000400, loss: 0.1494
2023-07-01 20:19:52 - train: epoch 0144, iter [00200, 00390], lr: 0.000400, loss: 0.2018
2023-07-01 20:19:54 - train: epoch 0144, iter [00250, 00390], lr: 0.000400, loss: 0.2593
2023-07-01 20:19:56 - train: epoch 0144, iter [00300, 00390], lr: 0.000400, loss: 0.1979
2023-07-01 20:19:59 - train: epoch 0144, iter [00350, 00390], lr: 0.000400, loss: 0.1361
2023-07-01 20:20:00 - train: epoch 144, train_loss: 0.1517
2023-07-01 20:20:02 - eval: epoch: 144, acc1: 39.380%, acc5: 65.880%, test_loss: 3.5949, per_image_load_time: 0.085ms, per_image_inference_time: 0.084ms
2023-07-01 20:20:03 - until epoch: 144, best_acc1: 41.510%
2023-07-01 20:20:03 - epoch 145 lr: 0.000400
2023-07-01 20:20:06 - train: epoch 0145, iter [00050, 00390], lr: 0.000400, loss: 0.2383
2023-07-01 20:20:08 - train: epoch 0145, iter [00100, 00390], lr: 0.000400, loss: 0.1023
2023-07-01 20:20:11 - train: epoch 0145, iter [00150, 00390], lr: 0.000400, loss: 0.1362
2023-07-01 20:20:13 - train: epoch 0145, iter [00200, 00390], lr: 0.000400, loss: 0.1660
2023-07-01 20:20:16 - train: epoch 0145, iter [00250, 00390], lr: 0.000400, loss: 0.1721
2023-07-01 20:20:18 - train: epoch 0145, iter [00300, 00390], lr: 0.000400, loss: 0.1419
2023-07-01 20:20:20 - train: epoch 0145, iter [00350, 00390], lr: 0.000400, loss: 0.2156
2023-07-01 20:20:22 - train: epoch 145, train_loss: 0.1503
2023-07-01 20:20:24 - eval: epoch: 145, acc1: 39.280%, acc5: 65.910%, test_loss: 3.6099, per_image_load_time: 0.084ms, per_image_inference_time: 0.084ms
2023-07-01 20:20:24 - until epoch: 145, best_acc1: 41.510%
2023-07-01 20:20:24 - epoch 146 lr: 0.000400
2023-07-01 20:20:27 - train: epoch 0146, iter [00050, 00390], lr: 0.000400, loss: 0.2193
2023-07-01 20:20:30 - train: epoch 0146, iter [00100, 00390], lr: 0.000400, loss: 0.1356
2023-07-01 20:20:32 - train: epoch 0146, iter [00150, 00390], lr: 0.000400, loss: 0.1205
2023-07-01 20:20:35 - train: epoch 0146, iter [00200, 00390], lr: 0.000400, loss: 0.1393
2023-07-01 20:20:37 - train: epoch 0146, iter [00250, 00390], lr: 0.000400, loss: 0.1479
2023-07-01 20:20:40 - train: epoch 0146, iter [00300, 00390], lr: 0.000400, loss: 0.1317
2023-07-01 20:20:42 - train: epoch 0146, iter [00350, 00390], lr: 0.000400, loss: 0.1945
2023-07-01 20:20:44 - train: epoch 146, train_loss: 0.1512
2023-07-01 20:20:46 - eval: epoch: 146, acc1: 39.380%, acc5: 65.990%, test_loss: 3.6115, per_image_load_time: 0.081ms, per_image_inference_time: 0.091ms
2023-07-01 20:20:46 - until epoch: 146, best_acc1: 41.510%
2023-07-01 20:20:46 - epoch 147 lr: 0.000400
2023-07-01 20:20:50 - train: epoch 0147, iter [00050, 00390], lr: 0.000400, loss: 0.1490
2023-07-01 20:20:52 - train: epoch 0147, iter [00100, 00390], lr: 0.000400, loss: 0.1184
2023-07-01 20:20:54 - train: epoch 0147, iter [00150, 00390], lr: 0.000400, loss: 0.1587
2023-07-01 20:20:57 - train: epoch 0147, iter [00200, 00390], lr: 0.000400, loss: 0.2160
2023-07-01 20:20:59 - train: epoch 0147, iter [00250, 00390], lr: 0.000400, loss: 0.0886
2023-07-01 20:21:01 - train: epoch 0147, iter [00300, 00390], lr: 0.000400, loss: 0.0902
2023-07-01 20:21:04 - train: epoch 0147, iter [00350, 00390], lr: 0.000400, loss: 0.0903
2023-07-01 20:21:06 - train: epoch 147, train_loss: 0.1465
2023-07-01 20:21:07 - eval: epoch: 147, acc1: 39.460%, acc5: 66.180%, test_loss: 3.6078, per_image_load_time: 0.081ms, per_image_inference_time: 0.082ms
2023-07-01 20:21:08 - until epoch: 147, best_acc1: 41.510%
2023-07-01 20:21:08 - epoch 148 lr: 0.000400
2023-07-01 20:21:11 - train: epoch 0148, iter [00050, 00390], lr: 0.000400, loss: 0.1487
2023-07-01 20:21:14 - train: epoch 0148, iter [00100, 00390], lr: 0.000400, loss: 0.1156
2023-07-01 20:21:16 - train: epoch 0148, iter [00150, 00390], lr: 0.000400, loss: 0.1097
2023-07-01 20:21:18 - train: epoch 0148, iter [00200, 00390], lr: 0.000400, loss: 0.0810
2023-07-01 20:21:21 - train: epoch 0148, iter [00250, 00390], lr: 0.000400, loss: 0.1664
2023-07-01 20:21:23 - train: epoch 0148, iter [00300, 00390], lr: 0.000400, loss: 0.1435
2023-07-01 20:21:25 - train: epoch 0148, iter [00350, 00390], lr: 0.000400, loss: 0.1167
2023-07-01 20:21:27 - train: epoch 148, train_loss: 0.1434
2023-07-01 20:21:29 - eval: epoch: 148, acc1: 39.350%, acc5: 66.030%, test_loss: 3.6277, per_image_load_time: 0.081ms, per_image_inference_time: 0.085ms
2023-07-01 20:21:29 - until epoch: 148, best_acc1: 41.510%
2023-07-01 20:21:29 - epoch 149 lr: 0.000400
2023-07-01 20:21:32 - train: epoch 0149, iter [00050, 00390], lr: 0.000400, loss: 0.1704
2023-07-01 20:21:35 - train: epoch 0149, iter [00100, 00390], lr: 0.000400, loss: 0.1152
2023-07-01 20:21:37 - train: epoch 0149, iter [00150, 00390], lr: 0.000400, loss: 0.2062
2023-07-01 20:21:39 - train: epoch 0149, iter [00200, 00390], lr: 0.000400, loss: 0.1101
2023-07-01 20:21:42 - train: epoch 0149, iter [00250, 00390], lr: 0.000400, loss: 0.0966
2023-07-01 20:21:44 - train: epoch 0149, iter [00300, 00390], lr: 0.000400, loss: 0.0811
2023-07-01 20:21:46 - train: epoch 0149, iter [00350, 00390], lr: 0.000400, loss: 0.1343
2023-07-01 20:21:48 - train: epoch 149, train_loss: 0.1427
2023-07-01 20:21:50 - eval: epoch: 149, acc1: 39.760%, acc5: 65.820%, test_loss: 3.6442, per_image_load_time: 0.083ms, per_image_inference_time: 0.085ms
2023-07-01 20:21:50 - until epoch: 149, best_acc1: 41.510%
2023-07-01 20:21:50 - epoch 150 lr: 0.000400
2023-07-01 20:21:53 - train: epoch 0150, iter [00050, 00390], lr: 0.000400, loss: 0.1650
2023-07-01 20:21:55 - train: epoch 0150, iter [00100, 00390], lr: 0.000400, loss: 0.1299
2023-07-01 20:21:58 - train: epoch 0150, iter [00150, 00390], lr: 0.000400, loss: 0.1360
2023-07-01 20:22:00 - train: epoch 0150, iter [00200, 00390], lr: 0.000400, loss: 0.0998
2023-07-01 20:22:02 - train: epoch 0150, iter [00250, 00390], lr: 0.000400, loss: 0.1269
2023-07-01 20:22:05 - train: epoch 0150, iter [00300, 00390], lr: 0.000400, loss: 0.1479
2023-07-01 20:22:07 - train: epoch 0150, iter [00350, 00390], lr: 0.000400, loss: 0.1353
2023-07-01 20:22:09 - train: epoch 150, train_loss: 0.1406
2023-07-01 20:22:11 - eval: epoch: 150, acc1: 39.830%, acc5: 65.830%, test_loss: 3.6531, per_image_load_time: 0.081ms, per_image_inference_time: 0.084ms
2023-07-01 20:22:12 - until epoch: 150, best_acc1: 41.510%
2023-07-01 20:22:12 - epoch 151 lr: 0.000400
2023-07-01 20:22:15 - train: epoch 0151, iter [00050, 00390], lr: 0.000400, loss: 0.1124
2023-07-01 20:22:17 - train: epoch 0151, iter [00100, 00390], lr: 0.000400, loss: 0.1059
2023-07-01 20:22:20 - train: epoch 0151, iter [00150, 00390], lr: 0.000400, loss: 0.1231
2023-07-01 20:22:22 - train: epoch 0151, iter [00200, 00390], lr: 0.000400, loss: 0.1449
2023-07-01 20:22:25 - train: epoch 0151, iter [00250, 00390], lr: 0.000400, loss: 0.1358
2023-07-01 20:22:27 - train: epoch 0151, iter [00300, 00390], lr: 0.000400, loss: 0.1301
2023-07-01 20:22:30 - train: epoch 0151, iter [00350, 00390], lr: 0.000400, loss: 0.0859
2023-07-01 20:22:32 - train: epoch 151, train_loss: 0.1382
2023-07-01 20:22:33 - eval: epoch: 151, acc1: 39.310%, acc5: 65.920%, test_loss: 3.6704, per_image_load_time: 0.079ms, per_image_inference_time: 0.090ms
2023-07-01 20:22:34 - until epoch: 151, best_acc1: 41.510%
2023-07-01 20:22:34 - epoch 152 lr: 0.000400
2023-07-01 20:22:37 - train: epoch 0152, iter [00050, 00390], lr: 0.000400, loss: 0.1343
2023-07-01 20:22:39 - train: epoch 0152, iter [00100, 00390], lr: 0.000400, loss: 0.1580
2023-07-01 20:22:42 - train: epoch 0152, iter [00150, 00390], lr: 0.000400, loss: 0.1292
2023-07-01 20:22:44 - train: epoch 0152, iter [00200, 00390], lr: 0.000400, loss: 0.1037
2023-07-01 20:22:46 - train: epoch 0152, iter [00250, 00390], lr: 0.000400, loss: 0.1413
2023-07-01 20:22:49 - train: epoch 0152, iter [00300, 00390], lr: 0.000400, loss: 0.1292
2023-07-01 20:22:51 - train: epoch 0152, iter [00350, 00390], lr: 0.000400, loss: 0.1241
2023-07-01 20:22:53 - train: epoch 152, train_loss: 0.1387
2023-07-01 20:22:55 - eval: epoch: 152, acc1: 39.340%, acc5: 65.830%, test_loss: 3.6697, per_image_load_time: 0.082ms, per_image_inference_time: 0.084ms
2023-07-01 20:22:55 - until epoch: 152, best_acc1: 41.510%
2023-07-01 20:22:55 - epoch 153 lr: 0.000400
2023-07-01 20:22:58 - train: epoch 0153, iter [00050, 00390], lr: 0.000400, loss: 0.1478
2023-07-01 20:23:01 - train: epoch 0153, iter [00100, 00390], lr: 0.000400, loss: 0.1020
2023-07-01 20:23:03 - train: epoch 0153, iter [00150, 00390], lr: 0.000400, loss: 0.1171
2023-07-01 20:23:05 - train: epoch 0153, iter [00200, 00390], lr: 0.000400, loss: 0.1372
2023-07-01 20:23:08 - train: epoch 0153, iter [00250, 00390], lr: 0.000400, loss: 0.1135
2023-07-01 20:23:10 - train: epoch 0153, iter [00300, 00390], lr: 0.000400, loss: 0.1271
2023-07-01 20:23:13 - train: epoch 0153, iter [00350, 00390], lr: 0.000400, loss: 0.1232
2023-07-01 20:23:16 - train: epoch 153, train_loss: 0.1337
2023-07-01 20:23:18 - eval: epoch: 153, acc1: 39.210%, acc5: 66.060%, test_loss: 3.6744, per_image_load_time: 0.079ms, per_image_inference_time: 0.085ms
2023-07-01 20:23:19 - until epoch: 153, best_acc1: 41.510%
2023-07-01 20:23:19 - epoch 154 lr: 0.000400
2023-07-01 20:23:22 - train: epoch 0154, iter [00050, 00390], lr: 0.000400, loss: 0.1077
2023-07-01 20:23:24 - train: epoch 0154, iter [00100, 00390], lr: 0.000400, loss: 0.1476
2023-07-01 20:23:27 - train: epoch 0154, iter [00150, 00390], lr: 0.000400, loss: 0.1447
2023-07-01 20:23:29 - train: epoch 0154, iter [00200, 00390], lr: 0.000400, loss: 0.1332
2023-07-01 20:23:31 - train: epoch 0154, iter [00250, 00390], lr: 0.000400, loss: 0.2074
2023-07-01 20:23:34 - train: epoch 0154, iter [00300, 00390], lr: 0.000400, loss: 0.1576
2023-07-01 20:23:36 - train: epoch 0154, iter [00350, 00390], lr: 0.000400, loss: 0.1923
2023-07-01 20:23:38 - train: epoch 154, train_loss: 0.1353
2023-07-01 20:23:40 - eval: epoch: 154, acc1: 39.410%, acc5: 66.000%, test_loss: 3.6771, per_image_load_time: 0.080ms, per_image_inference_time: 0.084ms
2023-07-01 20:23:40 - until epoch: 154, best_acc1: 41.510%
2023-07-01 20:23:40 - epoch 155 lr: 0.000400
2023-07-01 20:23:43 - train: epoch 0155, iter [00050, 00390], lr: 0.000400, loss: 0.1380
2023-07-01 20:23:46 - train: epoch 0155, iter [00100, 00390], lr: 0.000400, loss: 0.0984
2023-07-01 20:23:48 - train: epoch 0155, iter [00150, 00390], lr: 0.000400, loss: 0.0995
2023-07-01 20:23:50 - train: epoch 0155, iter [00200, 00390], lr: 0.000400, loss: 0.1608
2023-07-01 20:23:53 - train: epoch 0155, iter [00250, 00390], lr: 0.000400, loss: 0.1773
2023-07-01 20:23:55 - train: epoch 0155, iter [00300, 00390], lr: 0.000400, loss: 0.1481
2023-07-01 20:23:57 - train: epoch 0155, iter [00350, 00390], lr: 0.000400, loss: 0.1162
2023-07-01 20:23:59 - train: epoch 155, train_loss: 0.1338
2023-07-01 20:24:01 - eval: epoch: 155, acc1: 39.370%, acc5: 65.950%, test_loss: 3.6814, per_image_load_time: 0.080ms, per_image_inference_time: 0.083ms
2023-07-01 20:24:01 - until epoch: 155, best_acc1: 41.510%
2023-07-01 20:24:01 - epoch 156 lr: 0.000400
2023-07-01 20:24:04 - train: epoch 0156, iter [00050, 00390], lr: 0.000400, loss: 0.1105
2023-07-01 20:24:07 - train: epoch 0156, iter [00100, 00390], lr: 0.000400, loss: 0.1407
2023-07-01 20:24:09 - train: epoch 0156, iter [00150, 00390], lr: 0.000400, loss: 0.1623
2023-07-01 20:24:11 - train: epoch 0156, iter [00200, 00390], lr: 0.000400, loss: 0.1316
2023-07-01 20:24:13 - train: epoch 0156, iter [00250, 00390], lr: 0.000400, loss: 0.1882
2023-07-01 20:24:16 - train: epoch 0156, iter [00300, 00390], lr: 0.000400, loss: 0.0989
2023-07-01 20:24:18 - train: epoch 0156, iter [00350, 00390], lr: 0.000400, loss: 0.1144
2023-07-01 20:24:20 - train: epoch 156, train_loss: 0.1304
2023-07-01 20:24:22 - eval: epoch: 156, acc1: 39.400%, acc5: 65.710%, test_loss: 3.6973, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 20:24:22 - until epoch: 156, best_acc1: 41.510%
2023-07-01 20:24:22 - epoch 157 lr: 0.000400
2023-07-01 20:24:25 - train: epoch 0157, iter [00050, 00390], lr: 0.000400, loss: 0.0579
2023-07-01 20:24:28 - train: epoch 0157, iter [00100, 00390], lr: 0.000400, loss: 0.1676
2023-07-01 20:24:30 - train: epoch 0157, iter [00150, 00390], lr: 0.000400, loss: 0.1403
2023-07-01 20:24:32 - train: epoch 0157, iter [00200, 00390], lr: 0.000400, loss: 0.1329
2023-07-01 20:24:34 - train: epoch 0157, iter [00250, 00390], lr: 0.000400, loss: 0.0982
2023-07-01 20:24:37 - train: epoch 0157, iter [00300, 00390], lr: 0.000400, loss: 0.1074
2023-07-01 20:24:39 - train: epoch 0157, iter [00350, 00390], lr: 0.000400, loss: 0.0989
2023-07-01 20:24:41 - train: epoch 157, train_loss: 0.1278
2023-07-01 20:24:43 - eval: epoch: 157, acc1: 39.330%, acc5: 65.770%, test_loss: 3.7033, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 20:24:43 - until epoch: 157, best_acc1: 41.510%
2023-07-01 20:24:43 - epoch 158 lr: 0.000400
2023-07-01 20:24:46 - train: epoch 0158, iter [00050, 00390], lr: 0.000400, loss: 0.1033
2023-07-01 20:24:48 - train: epoch 0158, iter [00100, 00390], lr: 0.000400, loss: 0.1655
2023-07-01 20:24:51 - train: epoch 0158, iter [00150, 00390], lr: 0.000400, loss: 0.0937
2023-07-01 20:24:53 - train: epoch 0158, iter [00200, 00390], lr: 0.000400, loss: 0.1063
2023-07-01 20:24:56 - train: epoch 0158, iter [00250, 00390], lr: 0.000400, loss: 0.0980
2023-07-01 20:24:58 - train: epoch 0158, iter [00300, 00390], lr: 0.000400, loss: 0.1290
2023-07-01 20:25:00 - train: epoch 0158, iter [00350, 00390], lr: 0.000400, loss: 0.1231
2023-07-01 20:25:02 - train: epoch 158, train_loss: 0.1257
2023-07-01 20:25:04 - eval: epoch: 158, acc1: 39.360%, acc5: 65.840%, test_loss: 3.6979, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 20:25:04 - until epoch: 158, best_acc1: 41.510%
2023-07-01 20:25:04 - epoch 159 lr: 0.000400
2023-07-01 20:25:07 - train: epoch 0159, iter [00050, 00390], lr: 0.000400, loss: 0.0922
2023-07-01 20:25:09 - train: epoch 0159, iter [00100, 00390], lr: 0.000400, loss: 0.1431
2023-07-01 20:25:12 - train: epoch 0159, iter [00150, 00390], lr: 0.000400, loss: 0.1001
2023-07-01 20:25:14 - train: epoch 0159, iter [00200, 00390], lr: 0.000400, loss: 0.1416
2023-07-01 20:25:16 - train: epoch 0159, iter [00250, 00390], lr: 0.000400, loss: 0.1473
2023-07-01 20:25:18 - train: epoch 0159, iter [00300, 00390], lr: 0.000400, loss: 0.1273
2023-07-01 20:25:20 - train: epoch 0159, iter [00350, 00390], lr: 0.000400, loss: 0.1385
2023-07-01 20:25:22 - train: epoch 159, train_loss: 0.1265
2023-07-01 20:25:24 - eval: epoch: 159, acc1: 39.400%, acc5: 65.880%, test_loss: 3.7220, per_image_load_time: 0.071ms, per_image_inference_time: 0.081ms
2023-07-01 20:25:24 - until epoch: 159, best_acc1: 41.510%
2023-07-01 20:25:24 - epoch 160 lr: 0.000400
2023-07-01 20:25:27 - train: epoch 0160, iter [00050, 00390], lr: 0.000400, loss: 0.1268
2023-07-01 20:25:30 - train: epoch 0160, iter [00100, 00390], lr: 0.000400, loss: 0.1716
2023-07-01 20:25:32 - train: epoch 0160, iter [00150, 00390], lr: 0.000400, loss: 0.0978
2023-07-01 20:25:34 - train: epoch 0160, iter [00200, 00390], lr: 0.000400, loss: 0.1171
2023-07-01 20:25:37 - train: epoch 0160, iter [00250, 00390], lr: 0.000400, loss: 0.2490
2023-07-01 20:25:39 - train: epoch 0160, iter [00300, 00390], lr: 0.000400, loss: 0.0999
2023-07-01 20:25:41 - train: epoch 0160, iter [00350, 00390], lr: 0.000400, loss: 0.1188
2023-07-01 20:25:43 - train: epoch 160, train_loss: 0.1234
2023-07-01 20:25:45 - eval: epoch: 160, acc1: 39.680%, acc5: 65.730%, test_loss: 3.7203, per_image_load_time: 0.080ms, per_image_inference_time: 0.085ms
2023-07-01 20:25:45 - until epoch: 160, best_acc1: 41.510%
2023-07-01 20:25:45 - epoch 161 lr: 0.000080
2023-07-01 20:25:48 - train: epoch 0161, iter [00050, 00390], lr: 0.000080, loss: 0.1005
2023-07-01 20:25:51 - train: epoch 0161, iter [00100, 00390], lr: 0.000080, loss: 0.1209
2023-07-01 20:25:53 - train: epoch 0161, iter [00150, 00390], lr: 0.000080, loss: 0.1239
2023-07-01 20:25:55 - train: epoch 0161, iter [00200, 00390], lr: 0.000080, loss: 0.1342
2023-07-01 20:25:58 - train: epoch 0161, iter [00250, 00390], lr: 0.000080, loss: 0.1370
2023-07-01 20:26:00 - train: epoch 0161, iter [00300, 00390], lr: 0.000080, loss: 0.0849
2023-07-01 20:26:02 - train: epoch 0161, iter [00350, 00390], lr: 0.000080, loss: 0.1219
2023-07-01 20:26:04 - train: epoch 161, train_loss: 0.1126
2023-07-01 20:26:06 - eval: epoch: 161, acc1: 39.690%, acc5: 65.910%, test_loss: 3.7132, per_image_load_time: 0.085ms, per_image_inference_time: 0.083ms
2023-07-01 20:26:06 - until epoch: 161, best_acc1: 41.510%
2023-07-01 20:26:06 - epoch 162 lr: 0.000080
2023-07-01 20:26:10 - train: epoch 0162, iter [00050, 00390], lr: 0.000080, loss: 0.1270
2023-07-01 20:26:12 - train: epoch 0162, iter [00100, 00390], lr: 0.000080, loss: 0.1324
2023-07-01 20:26:14 - train: epoch 0162, iter [00150, 00390], lr: 0.000080, loss: 0.1059
2023-07-01 20:26:17 - train: epoch 0162, iter [00200, 00390], lr: 0.000080, loss: 0.1064
2023-07-01 20:26:19 - train: epoch 0162, iter [00250, 00390], lr: 0.000080, loss: 0.1661
2023-07-01 20:26:21 - train: epoch 0162, iter [00300, 00390], lr: 0.000080, loss: 0.1394
2023-07-01 20:26:24 - train: epoch 0162, iter [00350, 00390], lr: 0.000080, loss: 0.0850
2023-07-01 20:26:25 - train: epoch 162, train_loss: 0.1066
2023-07-01 20:26:27 - eval: epoch: 162, acc1: 39.520%, acc5: 65.850%, test_loss: 3.7114, per_image_load_time: 0.081ms, per_image_inference_time: 0.085ms
2023-07-01 20:26:28 - until epoch: 162, best_acc1: 41.510%
2023-07-01 20:26:28 - epoch 163 lr: 0.000080
2023-07-01 20:26:31 - train: epoch 0163, iter [00050, 00390], lr: 0.000080, loss: 0.1223
2023-07-01 20:26:33 - train: epoch 0163, iter [00100, 00390], lr: 0.000080, loss: 0.0660
2023-07-01 20:26:35 - train: epoch 0163, iter [00150, 00390], lr: 0.000080, loss: 0.1084
2023-07-01 20:26:38 - train: epoch 0163, iter [00200, 00390], lr: 0.000080, loss: 0.0961
2023-07-01 20:26:40 - train: epoch 0163, iter [00250, 00390], lr: 0.000080, loss: 0.0759
2023-07-01 20:26:42 - train: epoch 0163, iter [00300, 00390], lr: 0.000080, loss: 0.0989
2023-07-01 20:26:45 - train: epoch 0163, iter [00350, 00390], lr: 0.000080, loss: 0.1155
2023-07-01 20:26:47 - train: epoch 163, train_loss: 0.1055
2023-07-01 20:26:48 - eval: epoch: 163, acc1: 39.540%, acc5: 65.740%, test_loss: 3.7188, per_image_load_time: 0.080ms, per_image_inference_time: 0.084ms
2023-07-01 20:26:49 - until epoch: 163, best_acc1: 41.510%
2023-07-01 20:26:49 - epoch 164 lr: 0.000080
2023-07-01 20:26:52 - train: epoch 0164, iter [00050, 00390], lr: 0.000080, loss: 0.1285
2023-07-01 20:26:54 - train: epoch 0164, iter [00100, 00390], lr: 0.000080, loss: 0.0801
2023-07-01 20:26:57 - train: epoch 0164, iter [00150, 00390], lr: 0.000080, loss: 0.0934
2023-07-01 20:26:59 - train: epoch 0164, iter [00200, 00390], lr: 0.000080, loss: 0.0771
2023-07-01 20:27:01 - train: epoch 0164, iter [00250, 00390], lr: 0.000080, loss: 0.1002
2023-07-01 20:27:03 - train: epoch 0164, iter [00300, 00390], lr: 0.000080, loss: 0.1345
2023-07-01 20:27:06 - train: epoch 0164, iter [00350, 00390], lr: 0.000080, loss: 0.1328
2023-07-01 20:27:08 - train: epoch 164, train_loss: 0.1026
2023-07-01 20:27:10 - eval: epoch: 164, acc1: 39.700%, acc5: 65.900%, test_loss: 3.7253, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 20:27:10 - until epoch: 164, best_acc1: 41.510%
2023-07-01 20:27:10 - epoch 165 lr: 0.000080
2023-07-01 20:27:13 - train: epoch 0165, iter [00050, 00390], lr: 0.000080, loss: 0.0672
2023-07-01 20:27:16 - train: epoch 0165, iter [00100, 00390], lr: 0.000080, loss: 0.0814
2023-07-01 20:27:18 - train: epoch 0165, iter [00150, 00390], lr: 0.000080, loss: 0.0693
2023-07-01 20:27:20 - train: epoch 0165, iter [00200, 00390], lr: 0.000080, loss: 0.0900
2023-07-01 20:27:23 - train: epoch 0165, iter [00250, 00390], lr: 0.000080, loss: 0.0639
2023-07-01 20:27:25 - train: epoch 0165, iter [00300, 00390], lr: 0.000080, loss: 0.1194
2023-07-01 20:27:27 - train: epoch 0165, iter [00350, 00390], lr: 0.000080, loss: 0.0812
2023-07-01 20:27:29 - train: epoch 165, train_loss: 0.1013
2023-07-01 20:27:31 - eval: epoch: 165, acc1: 39.450%, acc5: 65.670%, test_loss: 3.7275, per_image_load_time: 0.081ms, per_image_inference_time: 0.085ms
2023-07-01 20:27:31 - until epoch: 165, best_acc1: 41.510%
2023-07-01 20:27:31 - epoch 166 lr: 0.000080
2023-07-01 20:27:35 - train: epoch 0166, iter [00050, 00390], lr: 0.000080, loss: 0.1075
2023-07-01 20:27:37 - train: epoch 0166, iter [00100, 00390], lr: 0.000080, loss: 0.1199
2023-07-01 20:27:39 - train: epoch 0166, iter [00150, 00390], lr: 0.000080, loss: 0.1214
2023-07-01 20:27:42 - train: epoch 0166, iter [00200, 00390], lr: 0.000080, loss: 0.0910
2023-07-01 20:27:44 - train: epoch 0166, iter [00250, 00390], lr: 0.000080, loss: 0.1380
2023-07-01 20:27:46 - train: epoch 0166, iter [00300, 00390], lr: 0.000080, loss: 0.1046
2023-07-01 20:27:49 - train: epoch 0166, iter [00350, 00390], lr: 0.000080, loss: 0.0875
2023-07-01 20:27:51 - train: epoch 166, train_loss: 0.1022
2023-07-01 20:27:52 - eval: epoch: 166, acc1: 39.450%, acc5: 65.840%, test_loss: 3.7298, per_image_load_time: 0.078ms, per_image_inference_time: 0.083ms
2023-07-01 20:27:53 - until epoch: 166, best_acc1: 41.510%
2023-07-01 20:27:53 - epoch 167 lr: 0.000080
2023-07-01 20:27:56 - train: epoch 0167, iter [00050, 00390], lr: 0.000080, loss: 0.1006
2023-07-01 20:27:58 - train: epoch 0167, iter [00100, 00390], lr: 0.000080, loss: 0.0827
2023-07-01 20:28:01 - train: epoch 0167, iter [00150, 00390], lr: 0.000080, loss: 0.1111
2023-07-01 20:28:03 - train: epoch 0167, iter [00200, 00390], lr: 0.000080, loss: 0.1122
2023-07-01 20:28:05 - train: epoch 0167, iter [00250, 00390], lr: 0.000080, loss: 0.0525
2023-07-01 20:28:08 - train: epoch 0167, iter [00300, 00390], lr: 0.000080, loss: 0.1333
2023-07-01 20:28:10 - train: epoch 0167, iter [00350, 00390], lr: 0.000080, loss: 0.1583
2023-07-01 20:28:12 - train: epoch 167, train_loss: 0.1022
2023-07-01 20:28:14 - eval: epoch: 167, acc1: 39.490%, acc5: 65.730%, test_loss: 3.7262, per_image_load_time: 0.082ms, per_image_inference_time: 0.083ms
2023-07-01 20:28:14 - until epoch: 167, best_acc1: 41.510%
2023-07-01 20:28:14 - epoch 168 lr: 0.000080
2023-07-01 20:28:17 - train: epoch 0168, iter [00050, 00390], lr: 0.000080, loss: 0.0900
2023-07-01 20:28:20 - train: epoch 0168, iter [00100, 00390], lr: 0.000080, loss: 0.0906
2023-07-01 20:28:22 - train: epoch 0168, iter [00150, 00390], lr: 0.000080, loss: 0.1006
2023-07-01 20:28:24 - train: epoch 0168, iter [00200, 00390], lr: 0.000080, loss: 0.1152
2023-07-01 20:28:27 - train: epoch 0168, iter [00250, 00390], lr: 0.000080, loss: 0.0776
2023-07-01 20:28:29 - train: epoch 0168, iter [00300, 00390], lr: 0.000080, loss: 0.1026
2023-07-01 20:28:31 - train: epoch 0168, iter [00350, 00390], lr: 0.000080, loss: 0.0830
2023-07-01 20:28:33 - train: epoch 168, train_loss: 0.0983
2023-07-01 20:28:35 - eval: epoch: 168, acc1: 39.490%, acc5: 65.840%, test_loss: 3.7276, per_image_load_time: 0.080ms, per_image_inference_time: 0.084ms
2023-07-01 20:28:35 - until epoch: 168, best_acc1: 41.510%
2023-07-01 20:28:35 - epoch 169 lr: 0.000080
2023-07-01 20:28:38 - train: epoch 0169, iter [00050, 00390], lr: 0.000080, loss: 0.1056
2023-07-01 20:28:41 - train: epoch 0169, iter [00100, 00390], lr: 0.000080, loss: 0.0692
2023-07-01 20:28:43 - train: epoch 0169, iter [00150, 00390], lr: 0.000080, loss: 0.1160
2023-07-01 20:28:45 - train: epoch 0169, iter [00200, 00390], lr: 0.000080, loss: 0.0949
2023-07-01 20:28:48 - train: epoch 0169, iter [00250, 00390], lr: 0.000080, loss: 0.0874
2023-07-01 20:28:50 - train: epoch 0169, iter [00300, 00390], lr: 0.000080, loss: 0.0899
2023-07-01 20:28:52 - train: epoch 0169, iter [00350, 00390], lr: 0.000080, loss: 0.0819
2023-07-01 20:28:54 - train: epoch 169, train_loss: 0.0990
2023-07-01 20:28:56 - eval: epoch: 169, acc1: 39.430%, acc5: 65.760%, test_loss: 3.7286, per_image_load_time: 0.078ms, per_image_inference_time: 0.084ms
2023-07-01 20:28:56 - until epoch: 169, best_acc1: 41.510%
2023-07-01 20:28:56 - epoch 170 lr: 0.000080
2023-07-01 20:29:00 - train: epoch 0170, iter [00050, 00390], lr: 0.000080, loss: 0.0700
2023-07-01 20:29:02 - train: epoch 0170, iter [00100, 00390], lr: 0.000080, loss: 0.0892
2023-07-01 20:29:04 - train: epoch 0170, iter [00150, 00390], lr: 0.000080, loss: 0.1198
2023-07-01 20:29:06 - train: epoch 0170, iter [00200, 00390], lr: 0.000080, loss: 0.1047
2023-07-01 20:29:09 - train: epoch 0170, iter [00250, 00390], lr: 0.000080, loss: 0.0697
2023-07-01 20:29:11 - train: epoch 0170, iter [00300, 00390], lr: 0.000080, loss: 0.0759
2023-07-01 20:29:13 - train: epoch 0170, iter [00350, 00390], lr: 0.000080, loss: 0.1407
2023-07-01 20:29:15 - train: epoch 170, train_loss: 0.0984
2023-07-01 20:29:17 - eval: epoch: 170, acc1: 39.570%, acc5: 65.650%, test_loss: 3.7359, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 20:29:17 - until epoch: 170, best_acc1: 41.510%
2023-07-01 20:29:17 - epoch 171 lr: 0.000080
2023-07-01 20:29:21 - train: epoch 0171, iter [00050, 00390], lr: 0.000080, loss: 0.0716
2023-07-01 20:29:23 - train: epoch 0171, iter [00100, 00390], lr: 0.000080, loss: 0.1169
2023-07-01 20:29:25 - train: epoch 0171, iter [00150, 00390], lr: 0.000080, loss: 0.1263
2023-07-01 20:29:28 - train: epoch 0171, iter [00200, 00390], lr: 0.000080, loss: 0.0629
2023-07-01 20:29:30 - train: epoch 0171, iter [00250, 00390], lr: 0.000080, loss: 0.1164
2023-07-01 20:29:32 - train: epoch 0171, iter [00300, 00390], lr: 0.000080, loss: 0.1227
2023-07-01 20:29:35 - train: epoch 0171, iter [00350, 00390], lr: 0.000080, loss: 0.0712
2023-07-01 20:29:36 - train: epoch 171, train_loss: 0.0991
2023-07-01 20:29:38 - eval: epoch: 171, acc1: 39.500%, acc5: 65.780%, test_loss: 3.7366, per_image_load_time: 0.080ms, per_image_inference_time: 0.083ms
2023-07-01 20:29:39 - until epoch: 171, best_acc1: 41.510%
2023-07-01 20:29:39 - epoch 172 lr: 0.000080
2023-07-01 20:29:42 - train: epoch 0172, iter [00050, 00390], lr: 0.000080, loss: 0.0721
2023-07-01 20:29:44 - train: epoch 0172, iter [00100, 00390], lr: 0.000080, loss: 0.0706
2023-07-01 20:29:47 - train: epoch 0172, iter [00150, 00390], lr: 0.000080, loss: 0.0675
2023-07-01 20:29:49 - train: epoch 0172, iter [00200, 00390], lr: 0.000080, loss: 0.0933
2023-07-01 20:29:51 - train: epoch 0172, iter [00250, 00390], lr: 0.000080, loss: 0.1117
2023-07-01 20:29:53 - train: epoch 0172, iter [00300, 00390], lr: 0.000080, loss: 0.0646
2023-07-01 20:29:56 - train: epoch 0172, iter [00350, 00390], lr: 0.000080, loss: 0.1027
2023-07-01 20:29:58 - train: epoch 172, train_loss: 0.0987
2023-07-01 20:30:00 - eval: epoch: 172, acc1: 39.520%, acc5: 65.800%, test_loss: 3.7421, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 20:30:00 - until epoch: 172, best_acc1: 41.510%
2023-07-01 20:30:00 - epoch 173 lr: 0.000080
2023-07-01 20:30:03 - train: epoch 0173, iter [00050, 00390], lr: 0.000080, loss: 0.1229
2023-07-01 20:30:06 - train: epoch 0173, iter [00100, 00390], lr: 0.000080, loss: 0.0822
2023-07-01 20:30:08 - train: epoch 0173, iter [00150, 00390], lr: 0.000080, loss: 0.1121
2023-07-01 20:30:10 - train: epoch 0173, iter [00200, 00390], lr: 0.000080, loss: 0.0866
2023-07-01 20:30:13 - train: epoch 0173, iter [00250, 00390], lr: 0.000080, loss: 0.0722
2023-07-01 20:30:15 - train: epoch 0173, iter [00300, 00390], lr: 0.000080, loss: 0.0968
2023-07-01 20:30:17 - train: epoch 0173, iter [00350, 00390], lr: 0.000080, loss: 0.0730
2023-07-01 20:30:19 - train: epoch 173, train_loss: 0.0990
2023-07-01 20:30:21 - eval: epoch: 173, acc1: 39.450%, acc5: 65.780%, test_loss: 3.7381, per_image_load_time: 0.083ms, per_image_inference_time: 0.082ms
2023-07-01 20:30:22 - until epoch: 173, best_acc1: 41.510%
2023-07-01 20:30:22 - epoch 174 lr: 0.000080
2023-07-01 20:30:25 - train: epoch 0174, iter [00050, 00390], lr: 0.000080, loss: 0.1055
2023-07-01 20:30:27 - train: epoch 0174, iter [00100, 00390], lr: 0.000080, loss: 0.0758
2023-07-01 20:30:29 - train: epoch 0174, iter [00150, 00390], lr: 0.000080, loss: 0.0750
2023-07-01 20:30:32 - train: epoch 0174, iter [00200, 00390], lr: 0.000080, loss: 0.0787
2023-07-01 20:30:34 - train: epoch 0174, iter [00250, 00390], lr: 0.000080, loss: 0.1139
2023-07-01 20:30:37 - train: epoch 0174, iter [00300, 00390], lr: 0.000080, loss: 0.0883
2023-07-01 20:30:40 - train: epoch 0174, iter [00350, 00390], lr: 0.000080, loss: 0.0821
2023-07-01 20:30:42 - train: epoch 174, train_loss: 0.0976
2023-07-01 20:30:44 - eval: epoch: 174, acc1: 39.470%, acc5: 65.570%, test_loss: 3.7426, per_image_load_time: 0.096ms, per_image_inference_time: 0.084ms
2023-07-01 20:30:44 - until epoch: 174, best_acc1: 41.510%
2023-07-01 20:30:44 - epoch 175 lr: 0.000080
2023-07-01 20:30:48 - train: epoch 0175, iter [00050, 00390], lr: 0.000080, loss: 0.0965
2023-07-01 20:30:50 - train: epoch 0175, iter [00100, 00390], lr: 0.000080, loss: 0.1205
2023-07-01 20:30:52 - train: epoch 0175, iter [00150, 00390], lr: 0.000080, loss: 0.1063
2023-07-01 20:30:55 - train: epoch 0175, iter [00200, 00390], lr: 0.000080, loss: 0.1519
2023-07-01 20:30:57 - train: epoch 0175, iter [00250, 00390], lr: 0.000080, loss: 0.0694
2023-07-01 20:30:59 - train: epoch 0175, iter [00300, 00390], lr: 0.000080, loss: 0.1156
2023-07-01 20:31:02 - train: epoch 0175, iter [00350, 00390], lr: 0.000080, loss: 0.1260
2023-07-01 20:31:04 - train: epoch 175, train_loss: 0.0979
2023-07-01 20:31:05 - eval: epoch: 175, acc1: 39.430%, acc5: 65.590%, test_loss: 3.7458, per_image_load_time: 0.084ms, per_image_inference_time: 0.084ms
2023-07-01 20:31:06 - until epoch: 175, best_acc1: 41.510%
2023-07-01 20:31:06 - epoch 176 lr: 0.000080
2023-07-01 20:31:09 - train: epoch 0176, iter [00050, 00390], lr: 0.000080, loss: 0.1515
2023-07-01 20:31:11 - train: epoch 0176, iter [00100, 00390], lr: 0.000080, loss: 0.1449
2023-07-01 20:31:14 - train: epoch 0176, iter [00150, 00390], lr: 0.000080, loss: 0.1183
2023-07-01 20:31:16 - train: epoch 0176, iter [00200, 00390], lr: 0.000080, loss: 0.0692
2023-07-01 20:31:18 - train: epoch 0176, iter [00250, 00390], lr: 0.000080, loss: 0.0790
2023-07-01 20:31:21 - train: epoch 0176, iter [00300, 00390], lr: 0.000080, loss: 0.0834
2023-07-01 20:31:23 - train: epoch 0176, iter [00350, 00390], lr: 0.000080, loss: 0.0579
2023-07-01 20:31:25 - train: epoch 176, train_loss: 0.0969
2023-07-01 20:31:27 - eval: epoch: 176, acc1: 39.450%, acc5: 65.670%, test_loss: 3.7468, per_image_load_time: 0.080ms, per_image_inference_time: 0.083ms
2023-07-01 20:31:27 - until epoch: 176, best_acc1: 41.510%
2023-07-01 20:31:27 - epoch 177 lr: 0.000080
2023-07-01 20:31:30 - train: epoch 0177, iter [00050, 00390], lr: 0.000080, loss: 0.0887
2023-07-01 20:31:32 - train: epoch 0177, iter [00100, 00390], lr: 0.000080, loss: 0.0634
2023-07-01 20:31:35 - train: epoch 0177, iter [00150, 00390], lr: 0.000080, loss: 0.0788
2023-07-01 20:31:37 - train: epoch 0177, iter [00200, 00390], lr: 0.000080, loss: 0.1206
2023-07-01 20:31:39 - train: epoch 0177, iter [00250, 00390], lr: 0.000080, loss: 0.1412
2023-07-01 20:31:42 - train: epoch 0177, iter [00300, 00390], lr: 0.000080, loss: 0.1434
2023-07-01 20:31:44 - train: epoch 0177, iter [00350, 00390], lr: 0.000080, loss: 0.1057
2023-07-01 20:31:46 - train: epoch 177, train_loss: 0.0973
2023-07-01 20:31:48 - eval: epoch: 177, acc1: 39.570%, acc5: 65.730%, test_loss: 3.7505, per_image_load_time: 0.078ms, per_image_inference_time: 0.083ms
2023-07-01 20:31:48 - until epoch: 177, best_acc1: 41.510%
2023-07-01 20:31:48 - epoch 178 lr: 0.000080
2023-07-01 20:31:51 - train: epoch 0178, iter [00050, 00390], lr: 0.000080, loss: 0.0959
2023-07-01 20:31:53 - train: epoch 0178, iter [00100, 00390], lr: 0.000080, loss: 0.0967
2023-07-01 20:31:56 - train: epoch 0178, iter [00150, 00390], lr: 0.000080, loss: 0.0904
2023-07-01 20:31:58 - train: epoch 0178, iter [00200, 00390], lr: 0.000080, loss: 0.0808
2023-07-01 20:32:00 - train: epoch 0178, iter [00250, 00390], lr: 0.000080, loss: 0.0906
2023-07-01 20:32:03 - train: epoch 0178, iter [00300, 00390], lr: 0.000080, loss: 0.0511
2023-07-01 20:32:05 - train: epoch 0178, iter [00350, 00390], lr: 0.000080, loss: 0.0825
2023-07-01 20:32:07 - train: epoch 178, train_loss: 0.0958
2023-07-01 20:32:09 - eval: epoch: 178, acc1: 39.470%, acc5: 65.740%, test_loss: 3.7525, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 20:32:09 - until epoch: 178, best_acc1: 41.510%
2023-07-01 20:32:09 - epoch 179 lr: 0.000080
2023-07-01 20:32:12 - train: epoch 0179, iter [00050, 00390], lr: 0.000080, loss: 0.1186
2023-07-01 20:32:14 - train: epoch 0179, iter [00100, 00390], lr: 0.000080, loss: 0.0906
2023-07-01 20:32:17 - train: epoch 0179, iter [00150, 00390], lr: 0.000080, loss: 0.0827
2023-07-01 20:32:20 - train: epoch 0179, iter [00200, 00390], lr: 0.000080, loss: 0.1214
2023-07-01 20:32:22 - train: epoch 0179, iter [00250, 00390], lr: 0.000080, loss: 0.0736
2023-07-01 20:32:25 - train: epoch 0179, iter [00300, 00390], lr: 0.000080, loss: 0.1208
2023-07-01 20:32:28 - train: epoch 0179, iter [00350, 00390], lr: 0.000080, loss: 0.1082
2023-07-01 20:32:31 - train: epoch 179, train_loss: 0.0958
2023-07-01 20:32:32 - eval: epoch: 179, acc1: 39.430%, acc5: 65.570%, test_loss: 3.7528, per_image_load_time: 0.079ms, per_image_inference_time: 0.082ms
2023-07-01 20:32:32 - until epoch: 179, best_acc1: 41.510%
2023-07-01 20:32:32 - epoch 180 lr: 0.000080
2023-07-01 20:32:36 - train: epoch 0180, iter [00050, 00390], lr: 0.000080, loss: 0.1095
2023-07-01 20:32:38 - train: epoch 0180, iter [00100, 00390], lr: 0.000080, loss: 0.1003
2023-07-01 20:32:41 - train: epoch 0180, iter [00150, 00390], lr: 0.000080, loss: 0.1195
2023-07-01 20:32:43 - train: epoch 0180, iter [00200, 00390], lr: 0.000080, loss: 0.1104
2023-07-01 20:32:45 - train: epoch 0180, iter [00250, 00390], lr: 0.000080, loss: 0.1268
2023-07-01 20:32:48 - train: epoch 0180, iter [00300, 00390], lr: 0.000080, loss: 0.0988
2023-07-01 20:32:50 - train: epoch 0180, iter [00350, 00390], lr: 0.000080, loss: 0.0928
2023-07-01 20:32:52 - train: epoch 180, train_loss: 0.0958
2023-07-01 20:32:54 - eval: epoch: 180, acc1: 39.510%, acc5: 65.740%, test_loss: 3.7465, per_image_load_time: 0.078ms, per_image_inference_time: 0.091ms
2023-07-01 20:32:54 - until epoch: 180, best_acc1: 41.510%
2023-07-01 20:32:54 - epoch 181 lr: 0.000080
2023-07-01 20:32:57 - train: epoch 0181, iter [00050, 00390], lr: 0.000080, loss: 0.1442
2023-07-01 20:32:59 - train: epoch 0181, iter [00100, 00390], lr: 0.000080, loss: 0.0663
2023-07-01 20:33:02 - train: epoch 0181, iter [00150, 00390], lr: 0.000080, loss: 0.0865
2023-07-01 20:33:04 - train: epoch 0181, iter [00200, 00390], lr: 0.000080, loss: 0.0883
2023-07-01 20:33:06 - train: epoch 0181, iter [00250, 00390], lr: 0.000080, loss: 0.0608
2023-07-01 20:33:09 - train: epoch 0181, iter [00300, 00390], lr: 0.000080, loss: 0.0834
2023-07-01 20:33:11 - train: epoch 0181, iter [00350, 00390], lr: 0.000080, loss: 0.1058
2023-07-01 20:33:13 - train: epoch 181, train_loss: 0.0947
2023-07-01 20:33:15 - eval: epoch: 181, acc1: 39.460%, acc5: 65.700%, test_loss: 3.7555, per_image_load_time: 0.078ms, per_image_inference_time: 0.083ms
2023-07-01 20:33:15 - until epoch: 181, best_acc1: 41.510%
2023-07-01 20:33:15 - epoch 182 lr: 0.000080
2023-07-01 20:33:18 - train: epoch 0182, iter [00050, 00390], lr: 0.000080, loss: 0.0700
2023-07-01 20:33:20 - train: epoch 0182, iter [00100, 00390], lr: 0.000080, loss: 0.1179
2023-07-01 20:33:23 - train: epoch 0182, iter [00150, 00390], lr: 0.000080, loss: 0.1226
2023-07-01 20:33:25 - train: epoch 0182, iter [00200, 00390], lr: 0.000080, loss: 0.0603
2023-07-01 20:33:27 - train: epoch 0182, iter [00250, 00390], lr: 0.000080, loss: 0.1295
2023-07-01 20:33:30 - train: epoch 0182, iter [00300, 00390], lr: 0.000080, loss: 0.0976
2023-07-01 20:33:32 - train: epoch 0182, iter [00350, 00390], lr: 0.000080, loss: 0.0750
2023-07-01 20:33:34 - train: epoch 182, train_loss: 0.0944
2023-07-01 20:33:36 - eval: epoch: 182, acc1: 39.440%, acc5: 65.640%, test_loss: 3.7540, per_image_load_time: 0.081ms, per_image_inference_time: 0.083ms
2023-07-01 20:33:36 - until epoch: 182, best_acc1: 41.510%
2023-07-01 20:33:36 - epoch 183 lr: 0.000080
2023-07-01 20:33:39 - train: epoch 0183, iter [00050, 00390], lr: 0.000080, loss: 0.0671
2023-07-01 20:33:41 - train: epoch 0183, iter [00100, 00390], lr: 0.000080, loss: 0.0951
2023-07-01 20:33:44 - train: epoch 0183, iter [00150, 00390], lr: 0.000080, loss: 0.0655
2023-07-01 20:33:46 - train: epoch 0183, iter [00200, 00390], lr: 0.000080, loss: 0.0499
2023-07-01 20:33:48 - train: epoch 0183, iter [00250, 00390], lr: 0.000080, loss: 0.1345
2023-07-01 20:33:51 - train: epoch 0183, iter [00300, 00390], lr: 0.000080, loss: 0.1003
2023-07-01 20:33:53 - train: epoch 0183, iter [00350, 00390], lr: 0.000080, loss: 0.0755
2023-07-01 20:33:55 - train: epoch 183, train_loss: 0.0935
2023-07-01 20:33:57 - eval: epoch: 183, acc1: 39.540%, acc5: 65.610%, test_loss: 3.7585, per_image_load_time: 0.080ms, per_image_inference_time: 0.084ms
2023-07-01 20:33:57 - until epoch: 183, best_acc1: 41.510%
2023-07-01 20:33:57 - epoch 184 lr: 0.000080
2023-07-01 20:34:00 - train: epoch 0184, iter [00050, 00390], lr: 0.000080, loss: 0.0860
2023-07-01 20:34:02 - train: epoch 0184, iter [00100, 00390], lr: 0.000080, loss: 0.0774
2023-07-01 20:34:05 - train: epoch 0184, iter [00150, 00390], lr: 0.000080, loss: 0.0819
2023-07-01 20:34:07 - train: epoch 0184, iter [00200, 00390], lr: 0.000080, loss: 0.0839
2023-07-01 20:34:09 - train: epoch 0184, iter [00250, 00390], lr: 0.000080, loss: 0.0694
2023-07-01 20:34:12 - train: epoch 0184, iter [00300, 00390], lr: 0.000080, loss: 0.0506
2023-07-01 20:34:14 - train: epoch 0184, iter [00350, 00390], lr: 0.000080, loss: 0.0903
2023-07-01 20:34:16 - train: epoch 184, train_loss: 0.0916
2023-07-01 20:34:18 - eval: epoch: 184, acc1: 39.480%, acc5: 65.460%, test_loss: 3.7654, per_image_load_time: 0.082ms, per_image_inference_time: 0.083ms
2023-07-01 20:34:18 - until epoch: 184, best_acc1: 41.510%
2023-07-01 20:34:18 - epoch 185 lr: 0.000080
2023-07-01 20:34:21 - train: epoch 0185, iter [00050, 00390], lr: 0.000080, loss: 0.0605
2023-07-01 20:34:24 - train: epoch 0185, iter [00100, 00390], lr: 0.000080, loss: 0.0951
2023-07-01 20:34:26 - train: epoch 0185, iter [00150, 00390], lr: 0.000080, loss: 0.0910
2023-07-01 20:34:28 - train: epoch 0185, iter [00200, 00390], lr: 0.000080, loss: 0.0755
2023-07-01 20:34:31 - train: epoch 0185, iter [00250, 00390], lr: 0.000080, loss: 0.1027
2023-07-01 20:34:33 - train: epoch 0185, iter [00300, 00390], lr: 0.000080, loss: 0.0620
2023-07-01 20:34:35 - train: epoch 0185, iter [00350, 00390], lr: 0.000080, loss: 0.1136
2023-07-01 20:34:37 - train: epoch 185, train_loss: 0.0934
2023-07-01 20:34:39 - eval: epoch: 185, acc1: 39.430%, acc5: 65.690%, test_loss: 3.7591, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 20:34:39 - until epoch: 185, best_acc1: 41.510%
2023-07-01 20:34:39 - epoch 186 lr: 0.000080
2023-07-01 20:34:42 - train: epoch 0186, iter [00050, 00390], lr: 0.000080, loss: 0.0598
2023-07-01 20:34:45 - train: epoch 0186, iter [00100, 00390], lr: 0.000080, loss: 0.0706
2023-07-01 20:34:47 - train: epoch 0186, iter [00150, 00390], lr: 0.000080, loss: 0.0515
2023-07-01 20:34:49 - train: epoch 0186, iter [00200, 00390], lr: 0.000080, loss: 0.2100
2023-07-01 20:34:52 - train: epoch 0186, iter [00250, 00390], lr: 0.000080, loss: 0.1428
2023-07-01 20:34:54 - train: epoch 0186, iter [00300, 00390], lr: 0.000080, loss: 0.0867
2023-07-01 20:34:56 - train: epoch 0186, iter [00350, 00390], lr: 0.000080, loss: 0.0652
2023-07-01 20:34:58 - train: epoch 186, train_loss: 0.0934
2023-07-01 20:35:00 - eval: epoch: 186, acc1: 39.390%, acc5: 65.570%, test_loss: 3.7657, per_image_load_time: 0.080ms, per_image_inference_time: 0.084ms
2023-07-01 20:35:00 - until epoch: 186, best_acc1: 41.510%
2023-07-01 20:35:00 - epoch 187 lr: 0.000080
2023-07-01 20:35:04 - train: epoch 0187, iter [00050, 00390], lr: 0.000080, loss: 0.0612
2023-07-01 20:35:06 - train: epoch 0187, iter [00100, 00390], lr: 0.000080, loss: 0.0587
2023-07-01 20:35:08 - train: epoch 0187, iter [00150, 00390], lr: 0.000080, loss: 0.1374
2023-07-01 20:35:11 - train: epoch 0187, iter [00200, 00390], lr: 0.000080, loss: 0.1399
2023-07-01 20:35:13 - train: epoch 0187, iter [00250, 00390], lr: 0.000080, loss: 0.0905
2023-07-01 20:35:15 - train: epoch 0187, iter [00300, 00390], lr: 0.000080, loss: 0.0844
2023-07-01 20:35:18 - train: epoch 0187, iter [00350, 00390], lr: 0.000080, loss: 0.0720
2023-07-01 20:35:19 - train: epoch 187, train_loss: 0.0956
2023-07-01 20:35:21 - eval: epoch: 187, acc1: 39.410%, acc5: 65.710%, test_loss: 3.7605, per_image_load_time: 0.078ms, per_image_inference_time: 0.083ms
2023-07-01 20:35:22 - until epoch: 187, best_acc1: 41.510%
2023-07-01 20:35:22 - epoch 188 lr: 0.000080
2023-07-01 20:35:25 - train: epoch 0188, iter [00050, 00390], lr: 0.000080, loss: 0.1769
2023-07-01 20:35:27 - train: epoch 0188, iter [00100, 00390], lr: 0.000080, loss: 0.0705
2023-07-01 20:35:30 - train: epoch 0188, iter [00150, 00390], lr: 0.000080, loss: 0.1050
2023-07-01 20:35:32 - train: epoch 0188, iter [00200, 00390], lr: 0.000080, loss: 0.0793
2023-07-01 20:35:34 - train: epoch 0188, iter [00250, 00390], lr: 0.000080, loss: 0.1067
2023-07-01 20:35:37 - train: epoch 0188, iter [00300, 00390], lr: 0.000080, loss: 0.0838
2023-07-01 20:35:39 - train: epoch 0188, iter [00350, 00390], lr: 0.000080, loss: 0.0721
2023-07-01 20:35:41 - train: epoch 188, train_loss: 0.0919
2023-07-01 20:35:42 - eval: epoch: 188, acc1: 39.470%, acc5: 65.560%, test_loss: 3.7593, per_image_load_time: 0.079ms, per_image_inference_time: 0.088ms
2023-07-01 20:35:43 - until epoch: 188, best_acc1: 41.510%
2023-07-01 20:35:43 - epoch 189 lr: 0.000080
2023-07-01 20:35:46 - train: epoch 0189, iter [00050, 00390], lr: 0.000080, loss: 0.0774
2023-07-01 20:35:48 - train: epoch 0189, iter [00100, 00390], lr: 0.000080, loss: 0.0777
2023-07-01 20:35:50 - train: epoch 0189, iter [00150, 00390], lr: 0.000080, loss: 0.0803
2023-07-01 20:35:53 - train: epoch 0189, iter [00200, 00390], lr: 0.000080, loss: 0.0764
2023-07-01 20:35:55 - train: epoch 0189, iter [00250, 00390], lr: 0.000080, loss: 0.1168
2023-07-01 20:35:57 - train: epoch 0189, iter [00300, 00390], lr: 0.000080, loss: 0.0904
2023-07-01 20:35:59 - train: epoch 0189, iter [00350, 00390], lr: 0.000080, loss: 0.0840
2023-07-01 20:36:01 - train: epoch 189, train_loss: 0.0931
2023-07-01 20:36:03 - eval: epoch: 189, acc1: 39.460%, acc5: 65.730%, test_loss: 3.7614, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 20:36:03 - until epoch: 189, best_acc1: 41.510%
2023-07-01 20:36:03 - epoch 190 lr: 0.000080
2023-07-01 20:36:07 - train: epoch 0190, iter [00050, 00390], lr: 0.000080, loss: 0.0835
2023-07-01 20:36:09 - train: epoch 0190, iter [00100, 00390], lr: 0.000080, loss: 0.0808
2023-07-01 20:36:11 - train: epoch 0190, iter [00150, 00390], lr: 0.000080, loss: 0.1109
2023-07-01 20:36:14 - train: epoch 0190, iter [00200, 00390], lr: 0.000080, loss: 0.1436
2023-07-01 20:36:16 - train: epoch 0190, iter [00250, 00390], lr: 0.000080, loss: 0.0747
2023-07-01 20:36:18 - train: epoch 0190, iter [00300, 00390], lr: 0.000080, loss: 0.0901
2023-07-01 20:36:20 - train: epoch 0190, iter [00350, 00390], lr: 0.000080, loss: 0.0560
2023-07-01 20:36:22 - train: epoch 190, train_loss: 0.0902
2023-07-01 20:36:24 - eval: epoch: 190, acc1: 39.400%, acc5: 65.750%, test_loss: 3.7648, per_image_load_time: 0.079ms, per_image_inference_time: 0.082ms
2023-07-01 20:36:25 - until epoch: 190, best_acc1: 41.510%
2023-07-01 20:36:25 - epoch 191 lr: 0.000080
2023-07-01 20:36:28 - train: epoch 0191, iter [00050, 00390], lr: 0.000080, loss: 0.1250
2023-07-01 20:36:30 - train: epoch 0191, iter [00100, 00390], lr: 0.000080, loss: 0.1005
2023-07-01 20:36:32 - train: epoch 0191, iter [00150, 00390], lr: 0.000080, loss: 0.0736
2023-07-01 20:36:34 - train: epoch 0191, iter [00200, 00390], lr: 0.000080, loss: 0.0837
2023-07-01 20:36:37 - train: epoch 0191, iter [00250, 00390], lr: 0.000080, loss: 0.0882
2023-07-01 20:36:39 - train: epoch 0191, iter [00300, 00390], lr: 0.000080, loss: 0.1329
2023-07-01 20:36:41 - train: epoch 0191, iter [00350, 00390], lr: 0.000080, loss: 0.0568
2023-07-01 20:36:43 - train: epoch 191, train_loss: 0.0892
2023-07-01 20:36:45 - eval: epoch: 191, acc1: 39.570%, acc5: 65.500%, test_loss: 3.7649, per_image_load_time: 0.079ms, per_image_inference_time: 0.083ms
2023-07-01 20:36:45 - until epoch: 191, best_acc1: 41.510%
2023-07-01 20:36:45 - epoch 192 lr: 0.000080
2023-07-01 20:36:48 - train: epoch 0192, iter [00050, 00390], lr: 0.000080, loss: 0.0954
2023-07-01 20:36:51 - train: epoch 0192, iter [00100, 00390], lr: 0.000080, loss: 0.0672
2023-07-01 20:36:53 - train: epoch 0192, iter [00150, 00390], lr: 0.000080, loss: 0.0967
2023-07-01 20:36:55 - train: epoch 0192, iter [00200, 00390], lr: 0.000080, loss: 0.1105
2023-07-01 20:36:58 - train: epoch 0192, iter [00250, 00390], lr: 0.000080, loss: 0.0891
2023-07-01 20:37:00 - train: epoch 0192, iter [00300, 00390], lr: 0.000080, loss: 0.0671
2023-07-01 20:37:02 - train: epoch 0192, iter [00350, 00390], lr: 0.000080, loss: 0.0616
2023-07-01 20:37:04 - train: epoch 192, train_loss: 0.0910
2023-07-01 20:37:06 - eval: epoch: 192, acc1: 39.280%, acc5: 65.560%, test_loss: 3.7668, per_image_load_time: 0.077ms, per_image_inference_time: 0.084ms
2023-07-01 20:37:06 - until epoch: 192, best_acc1: 41.510%
2023-07-01 20:37:06 - epoch 193 lr: 0.000080
2023-07-01 20:37:09 - train: epoch 0193, iter [00050, 00390], lr: 0.000080, loss: 0.0971
2023-07-01 20:37:12 - train: epoch 0193, iter [00100, 00390], lr: 0.000080, loss: 0.0934
2023-07-01 20:37:14 - train: epoch 0193, iter [00150, 00390], lr: 0.000080, loss: 0.1037
2023-07-01 20:37:16 - train: epoch 0193, iter [00200, 00390], lr: 0.000080, loss: 0.0793
2023-07-01 20:37:19 - train: epoch 0193, iter [00250, 00390], lr: 0.000080, loss: 0.1093
2023-07-01 20:37:21 - train: epoch 0193, iter [00300, 00390], lr: 0.000080, loss: 0.0834
2023-07-01 20:37:23 - train: epoch 0193, iter [00350, 00390], lr: 0.000080, loss: 0.1036
2023-07-01 20:37:25 - train: epoch 193, train_loss: 0.0888
2023-07-01 20:37:27 - eval: epoch: 193, acc1: 39.520%, acc5: 65.480%, test_loss: 3.7699, per_image_load_time: 0.080ms, per_image_inference_time: 0.083ms
2023-07-01 20:37:27 - until epoch: 193, best_acc1: 41.510%
2023-07-01 20:37:27 - epoch 194 lr: 0.000080
2023-07-01 20:37:31 - train: epoch 0194, iter [00050, 00390], lr: 0.000080, loss: 0.0925
2023-07-01 20:37:33 - train: epoch 0194, iter [00100, 00390], lr: 0.000080, loss: 0.0510
2023-07-01 20:37:35 - train: epoch 0194, iter [00150, 00390], lr: 0.000080, loss: 0.0754
2023-07-01 20:37:38 - train: epoch 0194, iter [00200, 00390], lr: 0.000080, loss: 0.0658
2023-07-01 20:37:41 - train: epoch 0194, iter [00250, 00390], lr: 0.000080, loss: 0.0481
2023-07-01 20:37:43 - train: epoch 0194, iter [00300, 00390], lr: 0.000080, loss: 0.0733
2023-07-01 20:37:46 - train: epoch 0194, iter [00350, 00390], lr: 0.000080, loss: 0.0968
2023-07-01 20:37:48 - train: epoch 194, train_loss: 0.0885
2023-07-01 20:37:49 - eval: epoch: 194, acc1: 39.480%, acc5: 65.480%, test_loss: 3.7683, per_image_load_time: 0.080ms, per_image_inference_time: 0.083ms
2023-07-01 20:37:50 - until epoch: 194, best_acc1: 41.510%
2023-07-01 20:37:50 - epoch 195 lr: 0.000080
2023-07-01 20:37:53 - train: epoch 0195, iter [00050, 00390], lr: 0.000080, loss: 0.0618
2023-07-01 20:37:55 - train: epoch 0195, iter [00100, 00390], lr: 0.000080, loss: 0.0577
2023-07-01 20:37:57 - train: epoch 0195, iter [00150, 00390], lr: 0.000080, loss: 0.0990
2023-07-01 20:37:59 - train: epoch 0195, iter [00200, 00390], lr: 0.000080, loss: 0.0845
2023-07-01 20:38:02 - train: epoch 0195, iter [00250, 00390], lr: 0.000080, loss: 0.0900
2023-07-01 20:38:04 - train: epoch 0195, iter [00300, 00390], lr: 0.000080, loss: 0.0758
2023-07-01 20:38:06 - train: epoch 0195, iter [00350, 00390], lr: 0.000080, loss: 0.0743
2023-07-01 20:38:08 - train: epoch 195, train_loss: 0.0884
2023-07-01 20:38:10 - eval: epoch: 195, acc1: 39.290%, acc5: 65.500%, test_loss: 3.7692, per_image_load_time: 0.079ms, per_image_inference_time: 0.085ms
2023-07-01 20:38:10 - until epoch: 195, best_acc1: 41.510%
2023-07-01 20:38:10 - epoch 196 lr: 0.000080
2023-07-01 20:38:13 - train: epoch 0196, iter [00050, 00390], lr: 0.000080, loss: 0.1312
2023-07-01 20:38:15 - train: epoch 0196, iter [00100, 00390], lr: 0.000080, loss: 0.0807
2023-07-01 20:38:18 - train: epoch 0196, iter [00150, 00390], lr: 0.000080, loss: 0.1172
2023-07-01 20:38:20 - train: epoch 0196, iter [00200, 00390], lr: 0.000080, loss: 0.1251
2023-07-01 20:38:22 - train: epoch 0196, iter [00250, 00390], lr: 0.000080, loss: 0.0879
2023-07-01 20:38:25 - train: epoch 0196, iter [00300, 00390], lr: 0.000080, loss: 0.0976
2023-07-01 20:38:27 - train: epoch 0196, iter [00350, 00390], lr: 0.000080, loss: 0.0575
2023-07-01 20:38:29 - train: epoch 196, train_loss: 0.0881
2023-07-01 20:38:30 - eval: epoch: 196, acc1: 39.310%, acc5: 65.490%, test_loss: 3.7738, per_image_load_time: 0.078ms, per_image_inference_time: 0.085ms
2023-07-01 20:38:31 - until epoch: 196, best_acc1: 41.510%
2023-07-01 20:38:31 - epoch 197 lr: 0.000080
2023-07-01 20:38:34 - train: epoch 0197, iter [00050, 00390], lr: 0.000080, loss: 0.0715
2023-07-01 20:38:36 - train: epoch 0197, iter [00100, 00390], lr: 0.000080, loss: 0.1383
2023-07-01 20:38:38 - train: epoch 0197, iter [00150, 00390], lr: 0.000080, loss: 0.1088
2023-07-01 20:38:41 - train: epoch 0197, iter [00200, 00390], lr: 0.000080, loss: 0.0863
2023-07-01 20:38:43 - train: epoch 0197, iter [00250, 00390], lr: 0.000080, loss: 0.0878
2023-07-01 20:38:45 - train: epoch 0197, iter [00300, 00390], lr: 0.000080, loss: 0.1056
2023-07-01 20:38:47 - train: epoch 0197, iter [00350, 00390], lr: 0.000080, loss: 0.0522
2023-07-01 20:38:49 - train: epoch 197, train_loss: 0.0893
2023-07-01 20:38:51 - eval: epoch: 197, acc1: 39.490%, acc5: 65.570%, test_loss: 3.7749, per_image_load_time: 0.077ms, per_image_inference_time: 0.083ms
2023-07-01 20:38:51 - until epoch: 197, best_acc1: 41.510%
2023-07-01 20:38:51 - epoch 198 lr: 0.000080
2023-07-01 20:38:54 - train: epoch 0198, iter [00050, 00390], lr: 0.000080, loss: 0.0739
2023-07-01 20:38:57 - train: epoch 0198, iter [00100, 00390], lr: 0.000080, loss: 0.0560
2023-07-01 20:38:59 - train: epoch 0198, iter [00150, 00390], lr: 0.000080, loss: 0.1168
2023-07-01 20:39:01 - train: epoch 0198, iter [00200, 00390], lr: 0.000080, loss: 0.0765
2023-07-01 20:39:03 - train: epoch 0198, iter [00250, 00390], lr: 0.000080, loss: 0.1323
2023-07-01 20:39:06 - train: epoch 0198, iter [00300, 00390], lr: 0.000080, loss: 0.1253
2023-07-01 20:39:08 - train: epoch 0198, iter [00350, 00390], lr: 0.000080, loss: 0.0575
2023-07-01 20:39:10 - train: epoch 198, train_loss: 0.0877
2023-07-01 20:39:12 - eval: epoch: 198, acc1: 39.500%, acc5: 65.660%, test_loss: 3.7732, per_image_load_time: 0.078ms, per_image_inference_time: 0.085ms
2023-07-01 20:39:12 - until epoch: 198, best_acc1: 41.510%
2023-07-01 20:39:12 - epoch 199 lr: 0.000080
2023-07-01 20:39:15 - train: epoch 0199, iter [00050, 00390], lr: 0.000080, loss: 0.1008
2023-07-01 20:39:17 - train: epoch 0199, iter [00100, 00390], lr: 0.000080, loss: 0.0846
2023-07-01 20:39:20 - train: epoch 0199, iter [00150, 00390], lr: 0.000080, loss: 0.0854
2023-07-01 20:39:22 - train: epoch 0199, iter [00200, 00390], lr: 0.000080, loss: 0.1072
2023-07-01 20:39:24 - train: epoch 0199, iter [00250, 00390], lr: 0.000080, loss: 0.1002
2023-07-01 20:39:26 - train: epoch 0199, iter [00300, 00390], lr: 0.000080, loss: 0.0732
2023-07-01 20:39:28 - train: epoch 0199, iter [00350, 00390], lr: 0.000080, loss: 0.0989
2023-07-01 20:39:30 - train: epoch 199, train_loss: 0.0881
2023-07-01 20:39:32 - eval: epoch: 199, acc1: 39.490%, acc5: 65.590%, test_loss: 3.7765, per_image_load_time: 0.078ms, per_image_inference_time: 0.084ms
2023-07-01 20:39:33 - until epoch: 199, best_acc1: 41.510%
2023-07-01 20:39:33 - epoch 200 lr: 0.000080
2023-07-01 20:39:36 - train: epoch 0200, iter [00050, 00390], lr: 0.000080, loss: 0.1205
2023-07-01 20:39:38 - train: epoch 0200, iter [00100, 00390], lr: 0.000080, loss: 0.1017
2023-07-01 20:39:41 - train: epoch 0200, iter [00150, 00390], lr: 0.000080, loss: 0.1226
2023-07-01 20:39:43 - train: epoch 0200, iter [00200, 00390], lr: 0.000080, loss: 0.0627
2023-07-01 20:39:45 - train: epoch 0200, iter [00250, 00390], lr: 0.000080, loss: 0.0516
2023-07-01 20:39:48 - train: epoch 0200, iter [00300, 00390], lr: 0.000080, loss: 0.0397
2023-07-01 20:39:50 - train: epoch 0200, iter [00350, 00390], lr: 0.000080, loss: 0.1408
2023-07-01 20:39:52 - train: epoch 200, train_loss: 0.0872
2023-07-01 20:39:54 - eval: epoch: 200, acc1: 39.500%, acc5: 65.510%, test_loss: 3.7834, per_image_load_time: 0.079ms, per_image_inference_time: 0.084ms
2023-07-01 20:39:54 - until epoch: 200, best_acc1: 41.510%
2023-07-01 20:39:54 - train done. model: vit_tiny_patch16, train time: 1.155 hours, best_acc1: 41.510%
2023-07-01 21:32:30 - network: vit_tiny_patch16
2023-07-01 21:32:30 - num_classes: 100
2023-07-01 21:32:30 - input_image_size: 32
2023-07-01 21:32:30 - trained_model_path: 
2023-07-01 21:32:30 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 21:32:30 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 21:32:30 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fc76d98a280>
2023-07-01 21:32:30 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fc76d98a490>
2023-07-01 21:32:30 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fc76d98a580>
2023-07-01 21:32:30 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fc76d98a640>
2023-07-01 21:32:30 - seed: 0
2023-07-01 21:32:30 - batch_size: 128
2023-07-01 21:32:30 - num_workers: 16
2023-07-01 21:32:30 - accumulation_steps: 1
2023-07-01 21:32:30 - optimizer: ('SGD', {'lr': 0.01, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-01 21:32:30 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-07-01 21:32:30 - epochs: 200
2023-07-01 21:32:30 - print_interval: 50
2023-07-01 21:32:30 - sync_bn: False
2023-07-01 21:32:30 - apex: True
2023-07-01 21:32:30 - use_ema_model: False
2023-07-01 21:32:30 - ema_model_decay: 0.9999
2023-07-01 21:32:30 - AUG: cutmix
2023-07-01 21:32:30 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-01 21:32:30 - gpus_num: 1
2023-07-01 21:32:30 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7fc76d997770>
2023-07-01 21:32:30 - --------------------parameters--------------------
2023-07-01 21:32:30 - name: cls_token, grad: True
2023-07-01 21:32:30 - name: position_encoding, grad: True
2023-07-01 21:32:30 - name: patch_embedding.conv.weight, grad: True
2023-07-01 21:32:30 - name: patch_embedding.conv.bias, grad: True
2023-07-01 21:32:30 - name: blocks.0.norm1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.0.norm1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.0.attention.qkv_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.0.attention.qkv_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.0.attention.out_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.0.attention.out_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.0.norm2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.0.norm2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.0.feed_forward.fc1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.0.feed_forward.fc1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.0.feed_forward.fc2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.0.feed_forward.fc2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.1.norm1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.1.norm1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.1.attention.qkv_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.1.attention.qkv_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.1.attention.out_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.1.attention.out_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.1.norm2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.1.norm2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.1.feed_forward.fc1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.1.feed_forward.fc1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.1.feed_forward.fc2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.1.feed_forward.fc2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.2.norm1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.2.norm1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.2.attention.qkv_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.2.attention.qkv_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.2.attention.out_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.2.attention.out_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.2.norm2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.2.norm2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.2.feed_forward.fc1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.2.feed_forward.fc1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.2.feed_forward.fc2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.2.feed_forward.fc2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.3.norm1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.3.norm1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.3.attention.qkv_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.3.attention.qkv_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.3.attention.out_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.3.attention.out_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.3.norm2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.3.norm2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.3.feed_forward.fc1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.3.feed_forward.fc1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.3.feed_forward.fc2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.3.feed_forward.fc2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.4.norm1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.4.norm1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.4.attention.qkv_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.4.attention.qkv_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.4.attention.out_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.4.attention.out_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.4.norm2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.4.norm2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.4.feed_forward.fc1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.4.feed_forward.fc1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.4.feed_forward.fc2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.4.feed_forward.fc2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.5.norm1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.5.norm1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.5.attention.qkv_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.5.attention.qkv_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.5.attention.out_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.5.attention.out_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.5.norm2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.5.norm2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.5.feed_forward.fc1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.5.feed_forward.fc1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.5.feed_forward.fc2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.5.feed_forward.fc2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.6.norm1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.6.norm1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.6.attention.qkv_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.6.attention.qkv_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.6.attention.out_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.6.attention.out_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.6.norm2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.6.norm2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.6.feed_forward.fc1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.6.feed_forward.fc1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.6.feed_forward.fc2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.6.feed_forward.fc2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.7.norm1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.7.norm1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.7.attention.qkv_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.7.attention.qkv_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.7.attention.out_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.7.attention.out_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.7.norm2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.7.norm2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.7.feed_forward.fc1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.7.feed_forward.fc1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.7.feed_forward.fc2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.7.feed_forward.fc2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.8.norm1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.8.norm1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.8.attention.qkv_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.8.attention.qkv_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.8.attention.out_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.8.attention.out_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.8.norm2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.8.norm2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.8.feed_forward.fc1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.8.feed_forward.fc1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.8.feed_forward.fc2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.8.feed_forward.fc2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.9.norm1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.9.norm1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.9.attention.qkv_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.9.attention.qkv_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.9.attention.out_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.9.attention.out_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.9.norm2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.9.norm2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.9.feed_forward.fc1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.9.feed_forward.fc1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.9.feed_forward.fc2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.9.feed_forward.fc2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.10.norm1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.10.norm1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.10.attention.qkv_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.10.attention.qkv_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.10.attention.out_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.10.attention.out_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.10.norm2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.10.norm2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.10.feed_forward.fc1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.10.feed_forward.fc1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.10.feed_forward.fc2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.10.feed_forward.fc2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.11.norm1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.11.norm1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.11.attention.qkv_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.11.attention.qkv_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.11.attention.out_linear.weight, grad: True
2023-07-01 21:32:30 - name: blocks.11.attention.out_linear.bias, grad: True
2023-07-01 21:32:30 - name: blocks.11.norm2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.11.norm2.bias, grad: True
2023-07-01 21:32:30 - name: blocks.11.feed_forward.fc1.weight, grad: True
2023-07-01 21:32:30 - name: blocks.11.feed_forward.fc1.bias, grad: True
2023-07-01 21:32:30 - name: blocks.11.feed_forward.fc2.weight, grad: True
2023-07-01 21:32:30 - name: blocks.11.feed_forward.fc2.bias, grad: True
2023-07-01 21:32:30 - name: norm.weight, grad: True
2023-07-01 21:32:30 - name: norm.bias, grad: True
2023-07-01 21:32:30 - name: fc.weight, grad: True
2023-07-01 21:32:30 - name: fc.bias, grad: True
2023-07-01 21:32:30 - --------------------buffers--------------------
2023-07-01 21:32:30 - -----------no weight decay layers--------------
2023-07-01 21:32:30 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.7.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.7.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.7.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.7.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.7.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.7.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.7.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.7.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.8.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.8.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.8.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.8.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.8.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.8.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.8.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.8.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.9.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.9.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.9.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.9.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.9.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.9.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.9.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.9.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.10.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.10.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.10.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.10.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.10.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.10.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.10.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.10.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.11.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.11.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.11.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.11.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.11.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.11.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.11.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.11.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: norm.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: norm.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:32:30 - -------------weight decay layers---------------
2023-07-01 21:32:30 - name: cls_token, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: position_encoding, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: patch_embedding.conv.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.7.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.7.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.7.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.7.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.8.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.8.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.8.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.8.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.9.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.9.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.9.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.9.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.10.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.10.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.10.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.10.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.11.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.11.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.11.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: blocks.11.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:32:30 - epoch 001 lr: 0.010000
2023-07-01 21:32:38 - train: epoch 0001, iter [00050, 00390], lr: 0.010000, loss: 4.4657
2023-07-01 21:32:40 - train: epoch 0001, iter [00100, 00390], lr: 0.010000, loss: 4.4790
2023-07-01 21:32:43 - train: epoch 0001, iter [00150, 00390], lr: 0.010000, loss: 4.1725
2023-07-01 21:32:45 - train: epoch 0001, iter [00200, 00390], lr: 0.010000, loss: 4.2732
2023-07-01 21:32:47 - train: epoch 0001, iter [00250, 00390], lr: 0.010000, loss: 4.3768
2023-07-01 21:32:49 - train: epoch 0001, iter [00300, 00390], lr: 0.010000, loss: 4.4681
2023-07-01 21:32:52 - train: epoch 0001, iter [00350, 00390], lr: 0.010000, loss: 4.3768
2023-07-01 21:32:54 - train: epoch 001, train_loss: 4.3509
2023-07-01 21:32:56 - eval: epoch: 001, acc1: 8.130%, acc5: 26.790%, test_loss: 4.0400, per_image_load_time: 0.102ms, per_image_inference_time: 0.087ms
2023-07-01 21:32:57 - until epoch: 001, best_acc1: 8.130%
2023-07-01 21:32:57 - epoch 002 lr: 0.010000
2023-07-01 21:38:52 - network: vit_small_patch16
2023-07-01 21:38:52 - num_classes: 100
2023-07-01 21:38:52 - input_image_size: 32
2023-07-01 21:38:52 - num_params: 21630436
2023-07-01 21:38:52 - trained_model_path: 
2023-07-01 21:38:52 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 21:38:52 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 21:38:52 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fae4839c4f0>
2023-07-01 21:38:52 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fae4839c460>
2023-07-01 21:38:52 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fae4839c550>
2023-07-01 21:38:52 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fae4839c580>
2023-07-01 21:38:52 - seed: 0
2023-07-01 21:38:52 - batch_size: 128
2023-07-01 21:38:52 - num_workers: 16
2023-07-01 21:38:52 - accumulation_steps: 1
2023-07-01 21:38:52 - optimizer: ('SGD', {'lr': 0.01, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-01 21:38:52 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-07-01 21:38:52 - epochs: 200
2023-07-01 21:38:52 - print_interval: 50
2023-07-01 21:38:52 - sync_bn: False
2023-07-01 21:38:52 - apex: True
2023-07-01 21:38:52 - use_ema_model: False
2023-07-01 21:38:52 - ema_model_decay: 0.9999
2023-07-01 21:38:52 - AUG: none
2023-07-01 21:38:52 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-01 21:38:52 - gpus_num: 1
2023-07-01 21:38:52 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7fae484ffa30>
2023-07-01 21:38:53 - --------------------parameters--------------------
2023-07-01 21:38:53 - name: cls_token, grad: True
2023-07-01 21:38:53 - name: position_encoding, grad: True
2023-07-01 21:38:53 - name: patch_embedding.conv.weight, grad: True
2023-07-01 21:38:53 - name: patch_embedding.conv.bias, grad: True
2023-07-01 21:38:53 - name: blocks.0.norm1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.0.norm1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.0.attention.qkv_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.0.attention.qkv_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.0.attention.out_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.0.attention.out_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.0.norm2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.0.norm2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.0.feed_forward.fc1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.0.feed_forward.fc1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.0.feed_forward.fc2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.0.feed_forward.fc2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.1.norm1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.1.norm1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.1.attention.qkv_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.1.attention.qkv_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.1.attention.out_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.1.attention.out_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.1.norm2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.1.norm2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.1.feed_forward.fc1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.1.feed_forward.fc1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.1.feed_forward.fc2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.1.feed_forward.fc2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.2.norm1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.2.norm1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.2.attention.qkv_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.2.attention.qkv_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.2.attention.out_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.2.attention.out_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.2.norm2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.2.norm2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.2.feed_forward.fc1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.2.feed_forward.fc1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.2.feed_forward.fc2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.2.feed_forward.fc2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.3.norm1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.3.norm1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.3.attention.qkv_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.3.attention.qkv_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.3.attention.out_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.3.attention.out_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.3.norm2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.3.norm2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.3.feed_forward.fc1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.3.feed_forward.fc1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.3.feed_forward.fc2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.3.feed_forward.fc2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.4.norm1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.4.norm1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.4.attention.qkv_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.4.attention.qkv_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.4.attention.out_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.4.attention.out_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.4.norm2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.4.norm2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.4.feed_forward.fc1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.4.feed_forward.fc1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.4.feed_forward.fc2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.4.feed_forward.fc2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.5.norm1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.5.norm1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.5.attention.qkv_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.5.attention.qkv_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.5.attention.out_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.5.attention.out_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.5.norm2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.5.norm2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.5.feed_forward.fc1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.5.feed_forward.fc1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.5.feed_forward.fc2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.5.feed_forward.fc2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.6.norm1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.6.norm1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.6.attention.qkv_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.6.attention.qkv_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.6.attention.out_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.6.attention.out_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.6.norm2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.6.norm2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.6.feed_forward.fc1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.6.feed_forward.fc1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.6.feed_forward.fc2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.6.feed_forward.fc2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.7.norm1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.7.norm1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.7.attention.qkv_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.7.attention.qkv_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.7.attention.out_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.7.attention.out_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.7.norm2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.7.norm2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.7.feed_forward.fc1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.7.feed_forward.fc1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.7.feed_forward.fc2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.7.feed_forward.fc2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.8.norm1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.8.norm1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.8.attention.qkv_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.8.attention.qkv_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.8.attention.out_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.8.attention.out_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.8.norm2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.8.norm2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.8.feed_forward.fc1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.8.feed_forward.fc1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.8.feed_forward.fc2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.8.feed_forward.fc2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.9.norm1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.9.norm1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.9.attention.qkv_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.9.attention.qkv_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.9.attention.out_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.9.attention.out_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.9.norm2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.9.norm2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.9.feed_forward.fc1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.9.feed_forward.fc1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.9.feed_forward.fc2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.9.feed_forward.fc2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.10.norm1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.10.norm1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.10.attention.qkv_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.10.attention.qkv_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.10.attention.out_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.10.attention.out_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.10.norm2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.10.norm2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.10.feed_forward.fc1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.10.feed_forward.fc1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.10.feed_forward.fc2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.10.feed_forward.fc2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.11.norm1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.11.norm1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.11.attention.qkv_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.11.attention.qkv_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.11.attention.out_linear.weight, grad: True
2023-07-01 21:38:53 - name: blocks.11.attention.out_linear.bias, grad: True
2023-07-01 21:38:53 - name: blocks.11.norm2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.11.norm2.bias, grad: True
2023-07-01 21:38:53 - name: blocks.11.feed_forward.fc1.weight, grad: True
2023-07-01 21:38:53 - name: blocks.11.feed_forward.fc1.bias, grad: True
2023-07-01 21:38:53 - name: blocks.11.feed_forward.fc2.weight, grad: True
2023-07-01 21:38:53 - name: blocks.11.feed_forward.fc2.bias, grad: True
2023-07-01 21:38:53 - name: norm.weight, grad: True
2023-07-01 21:38:53 - name: norm.bias, grad: True
2023-07-01 21:38:53 - name: fc.weight, grad: True
2023-07-01 21:38:53 - name: fc.bias, grad: True
2023-07-01 21:38:53 - --------------------buffers--------------------
2023-07-01 21:38:53 - -----------no weight decay layers--------------
2023-07-01 21:38:53 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.7.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.7.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.7.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.7.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.7.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.7.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.7.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.7.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.8.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.8.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.8.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.8.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.8.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.8.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.8.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.8.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.9.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.9.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.9.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.9.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.9.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.9.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.9.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.9.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.10.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.10.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.10.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.10.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.10.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.10.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.10.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.10.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.11.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.11.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.11.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.11.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.11.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.11.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.11.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.11.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: norm.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: norm.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:38:53 - -------------weight decay layers---------------
2023-07-01 21:38:53 - name: cls_token, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: position_encoding, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: patch_embedding.conv.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.7.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.7.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.7.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.7.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.8.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.8.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.8.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.8.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.9.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.9.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.9.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.9.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.10.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.10.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.10.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.10.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.11.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.11.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.11.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: blocks.11.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:38:53 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - network: vit_small_patch16
2023-07-01 21:41:30 - num_classes: 100
2023-07-01 21:41:30 - input_image_size: 32
2023-07-01 21:41:30 - num_params: 21630436
2023-07-01 21:41:30 - trained_model_path: 
2023-07-01 21:41:30 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 21:41:30 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 21:41:30 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f39059264f0>
2023-07-01 21:41:30 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f3905926460>
2023-07-01 21:41:30 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f3905926550>
2023-07-01 21:41:30 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f3905926580>
2023-07-01 21:41:30 - seed: 0
2023-07-01 21:41:30 - batch_size: 128
2023-07-01 21:41:30 - num_workers: 16
2023-07-01 21:41:30 - accumulation_steps: 1
2023-07-01 21:41:30 - optimizer: ('SGD', {'lr': 0.01, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-01 21:41:30 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-07-01 21:41:30 - epochs: 200
2023-07-01 21:41:30 - print_interval: 50
2023-07-01 21:41:30 - sync_bn: False
2023-07-01 21:41:30 - apex: True
2023-07-01 21:41:30 - use_ema_model: False
2023-07-01 21:41:30 - ema_model_decay: 0.9999
2023-07-01 21:41:30 - AUG: none
2023-07-01 21:41:30 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-01 21:41:30 - gpus_num: 1
2023-07-01 21:41:30 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f390591c270>
2023-07-01 21:41:30 - --------------------parameters--------------------
2023-07-01 21:41:30 - name: cls_token, grad: True
2023-07-01 21:41:30 - name: position_encoding, grad: True
2023-07-01 21:41:30 - name: patch_embedding.conv.weight, grad: True
2023-07-01 21:41:30 - name: patch_embedding.conv.bias, grad: True
2023-07-01 21:41:30 - name: blocks.0.norm1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.0.norm1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.0.attention.qkv_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.0.attention.qkv_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.0.attention.out_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.0.attention.out_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.0.norm2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.0.norm2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.0.feed_forward.fc1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.0.feed_forward.fc1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.0.feed_forward.fc2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.0.feed_forward.fc2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.1.norm1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.1.norm1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.1.attention.qkv_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.1.attention.qkv_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.1.attention.out_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.1.attention.out_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.1.norm2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.1.norm2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.1.feed_forward.fc1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.1.feed_forward.fc1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.1.feed_forward.fc2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.1.feed_forward.fc2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.2.norm1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.2.norm1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.2.attention.qkv_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.2.attention.qkv_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.2.attention.out_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.2.attention.out_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.2.norm2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.2.norm2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.2.feed_forward.fc1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.2.feed_forward.fc1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.2.feed_forward.fc2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.2.feed_forward.fc2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.3.norm1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.3.norm1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.3.attention.qkv_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.3.attention.qkv_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.3.attention.out_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.3.attention.out_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.3.norm2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.3.norm2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.3.feed_forward.fc1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.3.feed_forward.fc1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.3.feed_forward.fc2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.3.feed_forward.fc2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.4.norm1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.4.norm1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.4.attention.qkv_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.4.attention.qkv_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.4.attention.out_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.4.attention.out_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.4.norm2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.4.norm2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.4.feed_forward.fc1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.4.feed_forward.fc1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.4.feed_forward.fc2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.4.feed_forward.fc2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.5.norm1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.5.norm1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.5.attention.qkv_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.5.attention.qkv_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.5.attention.out_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.5.attention.out_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.5.norm2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.5.norm2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.5.feed_forward.fc1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.5.feed_forward.fc1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.5.feed_forward.fc2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.5.feed_forward.fc2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.6.norm1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.6.norm1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.6.attention.qkv_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.6.attention.qkv_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.6.attention.out_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.6.attention.out_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.6.norm2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.6.norm2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.6.feed_forward.fc1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.6.feed_forward.fc1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.6.feed_forward.fc2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.6.feed_forward.fc2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.7.norm1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.7.norm1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.7.attention.qkv_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.7.attention.qkv_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.7.attention.out_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.7.attention.out_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.7.norm2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.7.norm2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.7.feed_forward.fc1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.7.feed_forward.fc1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.7.feed_forward.fc2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.7.feed_forward.fc2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.8.norm1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.8.norm1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.8.attention.qkv_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.8.attention.qkv_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.8.attention.out_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.8.attention.out_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.8.norm2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.8.norm2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.8.feed_forward.fc1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.8.feed_forward.fc1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.8.feed_forward.fc2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.8.feed_forward.fc2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.9.norm1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.9.norm1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.9.attention.qkv_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.9.attention.qkv_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.9.attention.out_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.9.attention.out_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.9.norm2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.9.norm2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.9.feed_forward.fc1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.9.feed_forward.fc1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.9.feed_forward.fc2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.9.feed_forward.fc2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.10.norm1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.10.norm1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.10.attention.qkv_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.10.attention.qkv_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.10.attention.out_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.10.attention.out_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.10.norm2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.10.norm2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.10.feed_forward.fc1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.10.feed_forward.fc1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.10.feed_forward.fc2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.10.feed_forward.fc2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.11.norm1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.11.norm1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.11.attention.qkv_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.11.attention.qkv_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.11.attention.out_linear.weight, grad: True
2023-07-01 21:41:30 - name: blocks.11.attention.out_linear.bias, grad: True
2023-07-01 21:41:30 - name: blocks.11.norm2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.11.norm2.bias, grad: True
2023-07-01 21:41:30 - name: blocks.11.feed_forward.fc1.weight, grad: True
2023-07-01 21:41:30 - name: blocks.11.feed_forward.fc1.bias, grad: True
2023-07-01 21:41:30 - name: blocks.11.feed_forward.fc2.weight, grad: True
2023-07-01 21:41:30 - name: blocks.11.feed_forward.fc2.bias, grad: True
2023-07-01 21:41:30 - name: norm.weight, grad: True
2023-07-01 21:41:30 - name: norm.bias, grad: True
2023-07-01 21:41:30 - name: fc.weight, grad: True
2023-07-01 21:41:30 - name: fc.bias, grad: True
2023-07-01 21:41:30 - --------------------buffers--------------------
2023-07-01 21:41:30 - -----------no weight decay layers--------------
2023-07-01 21:41:30 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.7.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.7.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.7.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.7.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.7.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.7.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.7.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.7.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.8.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.8.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.8.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.8.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.8.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.8.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.8.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.8.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.9.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.9.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.9.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.9.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.9.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.9.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.9.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.9.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.10.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.10.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.10.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.10.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.10.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.10.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.10.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.10.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.11.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.11.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.11.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.11.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.11.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.11.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.11.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.11.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: norm.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: norm.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 21:41:30 - -------------weight decay layers---------------
2023-07-01 21:41:30 - name: cls_token, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: position_encoding, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: patch_embedding.conv.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.7.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.7.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.7.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.7.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.8.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.8.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.8.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.8.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.9.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.9.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.9.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.9.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.10.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.10.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.10.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.10.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.11.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.11.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.11.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: blocks.11.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 21:41:30 - epoch 001 lr: 0.010000
2023-07-01 21:41:38 - train: epoch 0001, iter [00050, 00390], lr: 0.010000, loss: 4.1015
2023-07-01 21:41:40 - train: epoch 0001, iter [00100, 00390], lr: 0.010000, loss: 4.0857
2023-07-01 21:41:42 - train: epoch 0001, iter [00150, 00390], lr: 0.010000, loss: 4.0600
2023-07-01 21:41:45 - train: epoch 0001, iter [00200, 00390], lr: 0.010000, loss: 3.8497
2023-07-01 21:41:47 - train: epoch 0001, iter [00250, 00390], lr: 0.010000, loss: 3.9979
2023-07-01 21:41:49 - train: epoch 0001, iter [00300, 00390], lr: 0.010000, loss: 3.7529
2023-07-01 21:41:52 - train: epoch 0001, iter [00350, 00390], lr: 0.010000, loss: 3.7572
2023-07-01 21:41:53 - train: epoch 001, train_loss: 4.0113
2023-07-01 21:41:55 - eval: epoch: 001, acc1: 12.790%, acc5: 34.640%, test_loss: 3.7530, per_image_load_time: 0.074ms, per_image_inference_time: 0.091ms
2023-07-01 21:41:56 - until epoch: 001, best_acc1: 12.790%
2023-07-01 21:41:56 - epoch 002 lr: 0.010000
2023-07-01 21:41:59 - train: epoch 0002, iter [00050, 00390], lr: 0.010000, loss: 3.7877
2023-07-01 21:42:02 - train: epoch 0002, iter [00100, 00390], lr: 0.010000, loss: 3.7489
2023-07-01 21:42:04 - train: epoch 0002, iter [00150, 00390], lr: 0.010000, loss: 3.7007
2023-07-01 21:42:06 - train: epoch 0002, iter [00200, 00390], lr: 0.010000, loss: 3.8187
2023-07-01 21:42:08 - train: epoch 0002, iter [00250, 00390], lr: 0.010000, loss: 3.6568
2023-07-01 21:42:11 - train: epoch 0002, iter [00300, 00390], lr: 0.010000, loss: 3.7640
2023-07-01 21:42:13 - train: epoch 0002, iter [00350, 00390], lr: 0.010000, loss: 3.5418
2023-07-01 21:42:15 - train: epoch 002, train_loss: 3.6917
2023-07-01 21:42:17 - eval: epoch: 002, acc1: 16.230%, acc5: 40.740%, test_loss: 3.5348, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 21:42:18 - until epoch: 002, best_acc1: 16.230%
2023-07-01 21:42:18 - epoch 003 lr: 0.010000
2023-07-01 21:42:21 - train: epoch 0003, iter [00050, 00390], lr: 0.010000, loss: 3.4973
2023-07-01 21:42:23 - train: epoch 0003, iter [00100, 00390], lr: 0.010000, loss: 3.4443
2023-07-01 21:42:25 - train: epoch 0003, iter [00150, 00390], lr: 0.010000, loss: 3.6574
2023-07-01 21:42:28 - train: epoch 0003, iter [00200, 00390], lr: 0.010000, loss: 3.2832
2023-07-01 21:42:30 - train: epoch 0003, iter [00250, 00390], lr: 0.010000, loss: 3.8200
2023-07-01 21:42:32 - train: epoch 0003, iter [00300, 00390], lr: 0.010000, loss: 3.6790
2023-07-01 21:42:35 - train: epoch 0003, iter [00350, 00390], lr: 0.010000, loss: 3.6096
2023-07-01 21:42:37 - train: epoch 003, train_loss: 3.5437
2023-07-01 21:42:39 - eval: epoch: 003, acc1: 17.750%, acc5: 43.020%, test_loss: 3.4383, per_image_load_time: 0.071ms, per_image_inference_time: 0.088ms
2023-07-01 21:42:40 - until epoch: 003, best_acc1: 17.750%
2023-07-01 21:42:40 - epoch 004 lr: 0.010000
2023-07-01 21:42:43 - train: epoch 0004, iter [00050, 00390], lr: 0.010000, loss: 3.4555
2023-07-01 21:42:45 - train: epoch 0004, iter [00100, 00390], lr: 0.010000, loss: 3.5229
2023-07-01 21:42:48 - train: epoch 0004, iter [00150, 00390], lr: 0.010000, loss: 3.5507
2023-07-01 21:42:50 - train: epoch 0004, iter [00200, 00390], lr: 0.010000, loss: 3.5839
2023-07-01 21:42:52 - train: epoch 0004, iter [00250, 00390], lr: 0.010000, loss: 3.3609
2023-07-01 21:42:55 - train: epoch 0004, iter [00300, 00390], lr: 0.010000, loss: 3.5860
2023-07-01 21:42:57 - train: epoch 0004, iter [00350, 00390], lr: 0.010000, loss: 3.1832
2023-07-01 21:42:59 - train: epoch 004, train_loss: 3.4384
2023-07-01 21:43:00 - eval: epoch: 004, acc1: 19.780%, acc5: 46.190%, test_loss: 3.3416, per_image_load_time: 0.071ms, per_image_inference_time: 0.088ms
2023-07-01 21:43:03 - until epoch: 004, best_acc1: 19.780%
2023-07-01 21:43:03 - epoch 005 lr: 0.010000
2023-07-01 21:43:06 - train: epoch 0005, iter [00050, 00390], lr: 0.010000, loss: 3.2595
2023-07-01 21:43:08 - train: epoch 0005, iter [00100, 00390], lr: 0.010000, loss: 3.2410
2023-07-01 21:43:10 - train: epoch 0005, iter [00150, 00390], lr: 0.010000, loss: 3.1246
2023-07-01 21:43:12 - train: epoch 0005, iter [00200, 00390], lr: 0.010000, loss: 3.5005
2023-07-01 21:43:15 - train: epoch 0005, iter [00250, 00390], lr: 0.010000, loss: 3.2182
2023-07-01 21:43:17 - train: epoch 0005, iter [00300, 00390], lr: 0.010000, loss: 3.1707
2023-07-01 21:43:19 - train: epoch 0005, iter [00350, 00390], lr: 0.010000, loss: 3.2280
2023-07-01 21:43:21 - train: epoch 005, train_loss: 3.3439
2023-07-01 21:43:23 - eval: epoch: 005, acc1: 21.640%, acc5: 49.210%, test_loss: 3.2299, per_image_load_time: 0.072ms, per_image_inference_time: 0.087ms
2023-07-01 21:43:24 - until epoch: 005, best_acc1: 21.640%
2023-07-01 21:43:24 - epoch 006 lr: 0.010000
2023-07-01 21:43:27 - train: epoch 0006, iter [00050, 00390], lr: 0.010000, loss: 3.2650
2023-07-01 21:43:29 - train: epoch 0006, iter [00100, 00390], lr: 0.010000, loss: 3.2168
2023-07-01 21:43:31 - train: epoch 0006, iter [00150, 00390], lr: 0.010000, loss: 3.3036
2023-07-01 21:43:34 - train: epoch 0006, iter [00200, 00390], lr: 0.010000, loss: 3.0727
2023-07-01 21:43:36 - train: epoch 0006, iter [00250, 00390], lr: 0.010000, loss: 3.2573
2023-07-01 21:43:38 - train: epoch 0006, iter [00300, 00390], lr: 0.010000, loss: 3.0084
2023-07-01 21:43:40 - train: epoch 0006, iter [00350, 00390], lr: 0.010000, loss: 3.3055
2023-07-01 21:43:42 - train: epoch 006, train_loss: 3.2698
2023-07-01 21:43:44 - eval: epoch: 006, acc1: 22.400%, acc5: 50.700%, test_loss: 3.1831, per_image_load_time: 0.070ms, per_image_inference_time: 0.088ms
2023-07-01 21:43:45 - until epoch: 006, best_acc1: 22.400%
2023-07-01 21:43:45 - epoch 007 lr: 0.010000
2023-07-01 21:43:48 - train: epoch 0007, iter [00050, 00390], lr: 0.010000, loss: 3.2571
2023-07-01 21:43:50 - train: epoch 0007, iter [00100, 00390], lr: 0.010000, loss: 3.2584
2023-07-01 21:43:53 - train: epoch 0007, iter [00150, 00390], lr: 0.010000, loss: 3.2344
2023-07-01 21:43:55 - train: epoch 0007, iter [00200, 00390], lr: 0.010000, loss: 3.1394
2023-07-01 21:43:57 - train: epoch 0007, iter [00250, 00390], lr: 0.010000, loss: 3.0313
2023-07-01 21:43:59 - train: epoch 0007, iter [00300, 00390], lr: 0.010000, loss: 2.9934
2023-07-01 21:44:02 - train: epoch 0007, iter [00350, 00390], lr: 0.010000, loss: 3.1653
2023-07-01 21:44:03 - train: epoch 007, train_loss: 3.2070
2023-07-01 21:44:05 - eval: epoch: 007, acc1: 24.030%, acc5: 52.660%, test_loss: 3.1020, per_image_load_time: 0.074ms, per_image_inference_time: 0.088ms
2023-07-01 21:44:06 - until epoch: 007, best_acc1: 24.030%
2023-07-01 21:44:06 - epoch 008 lr: 0.010000
2023-07-01 21:44:09 - train: epoch 0008, iter [00050, 00390], lr: 0.010000, loss: 3.2696
2023-07-01 21:44:12 - train: epoch 0008, iter [00100, 00390], lr: 0.010000, loss: 3.1775
2023-07-01 21:44:14 - train: epoch 0008, iter [00150, 00390], lr: 0.010000, loss: 3.1881
2023-07-01 21:44:16 - train: epoch 0008, iter [00200, 00390], lr: 0.010000, loss: 2.9338
2023-07-01 21:44:18 - train: epoch 0008, iter [00250, 00390], lr: 0.010000, loss: 3.1225
2023-07-01 21:44:21 - train: epoch 0008, iter [00300, 00390], lr: 0.010000, loss: 3.1334
2023-07-01 21:44:23 - train: epoch 0008, iter [00350, 00390], lr: 0.010000, loss: 3.2287
2023-07-01 21:44:25 - train: epoch 008, train_loss: 3.1420
2023-07-01 21:44:27 - eval: epoch: 008, acc1: 23.950%, acc5: 52.760%, test_loss: 3.1094, per_image_load_time: 0.073ms, per_image_inference_time: 0.099ms
2023-07-01 21:44:27 - until epoch: 008, best_acc1: 24.030%
2023-07-01 21:44:27 - epoch 009 lr: 0.010000
2023-07-01 21:44:30 - train: epoch 0009, iter [00050, 00390], lr: 0.010000, loss: 2.9825
2023-07-01 21:44:33 - train: epoch 0009, iter [00100, 00390], lr: 0.010000, loss: 3.2390
2023-07-01 21:44:35 - train: epoch 0009, iter [00150, 00390], lr: 0.010000, loss: 2.9386
2023-07-01 21:44:37 - train: epoch 0009, iter [00200, 00390], lr: 0.010000, loss: 3.1506
2023-07-01 21:44:40 - train: epoch 0009, iter [00250, 00390], lr: 0.010000, loss: 3.0251
2023-07-01 21:44:42 - train: epoch 0009, iter [00300, 00390], lr: 0.010000, loss: 3.2327
2023-07-01 21:44:44 - train: epoch 0009, iter [00350, 00390], lr: 0.010000, loss: 3.1908
2023-07-01 21:44:46 - train: epoch 009, train_loss: 3.0861
2023-07-01 21:44:48 - eval: epoch: 009, acc1: 25.960%, acc5: 54.730%, test_loss: 3.0279, per_image_load_time: 0.074ms, per_image_inference_time: 0.091ms
2023-07-01 21:44:49 - until epoch: 009, best_acc1: 25.960%
2023-07-01 21:44:49 - epoch 010 lr: 0.010000
2023-07-01 21:44:52 - train: epoch 0010, iter [00050, 00390], lr: 0.010000, loss: 3.1314
2023-07-01 21:44:54 - train: epoch 0010, iter [00100, 00390], lr: 0.010000, loss: 3.1745
2023-07-01 21:44:56 - train: epoch 0010, iter [00150, 00390], lr: 0.010000, loss: 3.0907
2023-07-01 21:44:59 - train: epoch 0010, iter [00200, 00390], lr: 0.010000, loss: 3.0928
2023-07-01 21:45:01 - train: epoch 0010, iter [00250, 00390], lr: 0.010000, loss: 3.1677
2023-07-01 21:45:03 - train: epoch 0010, iter [00300, 00390], lr: 0.010000, loss: 2.7361
2023-07-01 21:45:06 - train: epoch 0010, iter [00350, 00390], lr: 0.010000, loss: 2.9670
2023-07-01 21:45:07 - train: epoch 010, train_loss: 3.0330
2023-07-01 21:45:09 - eval: epoch: 010, acc1: 26.700%, acc5: 55.680%, test_loss: 2.9872, per_image_load_time: 0.075ms, per_image_inference_time: 0.087ms
2023-07-01 21:45:10 - until epoch: 010, best_acc1: 26.700%
2023-07-01 21:45:10 - epoch 011 lr: 0.010000
2023-07-01 21:45:13 - train: epoch 0011, iter [00050, 00390], lr: 0.010000, loss: 3.1227
2023-07-01 21:45:16 - train: epoch 0011, iter [00100, 00390], lr: 0.010000, loss: 2.9803
2023-07-01 21:45:18 - train: epoch 0011, iter [00150, 00390], lr: 0.010000, loss: 3.0669
2023-07-01 21:45:20 - train: epoch 0011, iter [00200, 00390], lr: 0.010000, loss: 3.0486
2023-07-01 21:45:22 - train: epoch 0011, iter [00250, 00390], lr: 0.010000, loss: 2.9968
2023-07-01 21:45:25 - train: epoch 0011, iter [00300, 00390], lr: 0.010000, loss: 2.8244
2023-07-01 21:45:27 - train: epoch 0011, iter [00350, 00390], lr: 0.010000, loss: 2.9158
2023-07-01 21:45:29 - train: epoch 011, train_loss: 2.9862
2023-07-01 21:45:31 - eval: epoch: 011, acc1: 26.970%, acc5: 56.330%, test_loss: 2.9612, per_image_load_time: 0.072ms, per_image_inference_time: 0.087ms
2023-07-01 21:45:31 - until epoch: 011, best_acc1: 26.970%
2023-07-01 21:45:31 - epoch 012 lr: 0.010000
2023-07-01 21:45:34 - train: epoch 0012, iter [00050, 00390], lr: 0.010000, loss: 2.9698
2023-07-01 21:45:37 - train: epoch 0012, iter [00100, 00390], lr: 0.010000, loss: 2.9560
2023-07-01 21:45:40 - train: epoch 0012, iter [00150, 00390], lr: 0.010000, loss: 2.9758
2023-07-01 21:45:43 - train: epoch 0012, iter [00200, 00390], lr: 0.010000, loss: 3.1002
2023-07-01 21:45:46 - train: epoch 0012, iter [00250, 00390], lr: 0.010000, loss: 2.8615
2023-07-01 21:45:48 - train: epoch 0012, iter [00300, 00390], lr: 0.010000, loss: 2.9956
2023-07-01 21:45:50 - train: epoch 0012, iter [00350, 00390], lr: 0.010000, loss: 2.9379
2023-07-01 21:45:52 - train: epoch 012, train_loss: 2.9456
2023-07-01 21:45:54 - eval: epoch: 012, acc1: 27.390%, acc5: 57.310%, test_loss: 2.9211, per_image_load_time: 0.074ms, per_image_inference_time: 0.087ms
2023-07-01 21:45:55 - until epoch: 012, best_acc1: 27.390%
2023-07-01 21:45:55 - epoch 013 lr: 0.010000
2023-07-01 21:45:58 - train: epoch 0013, iter [00050, 00390], lr: 0.010000, loss: 2.8271
2023-07-01 21:46:00 - train: epoch 0013, iter [00100, 00390], lr: 0.010000, loss: 2.9337
2023-07-01 21:46:02 - train: epoch 0013, iter [00150, 00390], lr: 0.010000, loss: 2.9393
2023-07-01 21:46:04 - train: epoch 0013, iter [00200, 00390], lr: 0.010000, loss: 2.7873
2023-07-01 21:46:07 - train: epoch 0013, iter [00250, 00390], lr: 0.010000, loss: 2.9532
2023-07-01 21:46:09 - train: epoch 0013, iter [00300, 00390], lr: 0.010000, loss: 3.0000
2023-07-01 21:46:11 - train: epoch 0013, iter [00350, 00390], lr: 0.010000, loss: 2.6507
2023-07-01 21:46:13 - train: epoch 013, train_loss: 2.8959
2023-07-01 21:46:15 - eval: epoch: 013, acc1: 28.170%, acc5: 58.070%, test_loss: 2.8900, per_image_load_time: 0.072ms, per_image_inference_time: 0.087ms
2023-07-01 21:46:16 - until epoch: 013, best_acc1: 28.170%
2023-07-01 21:46:16 - epoch 014 lr: 0.010000
2023-07-01 21:46:19 - train: epoch 0014, iter [00050, 00390], lr: 0.010000, loss: 2.9328
2023-07-01 21:46:21 - train: epoch 0014, iter [00100, 00390], lr: 0.010000, loss: 2.6119
2023-07-01 21:46:23 - train: epoch 0014, iter [00150, 00390], lr: 0.010000, loss: 2.7572
2023-07-01 21:46:25 - train: epoch 0014, iter [00200, 00390], lr: 0.010000, loss: 2.9539
2023-07-01 21:46:28 - train: epoch 0014, iter [00250, 00390], lr: 0.010000, loss: 2.7369
2023-07-01 21:46:30 - train: epoch 0014, iter [00300, 00390], lr: 0.010000, loss: 2.9664
2023-07-01 21:46:32 - train: epoch 0014, iter [00350, 00390], lr: 0.010000, loss: 2.8772
2023-07-01 21:46:34 - train: epoch 014, train_loss: 2.8491
2023-07-01 21:46:36 - eval: epoch: 014, acc1: 29.200%, acc5: 57.920%, test_loss: 2.8499, per_image_load_time: 0.074ms, per_image_inference_time: 0.090ms
2023-07-01 21:46:37 - until epoch: 014, best_acc1: 29.200%
2023-07-01 21:46:37 - epoch 015 lr: 0.010000
2023-07-01 21:46:40 - train: epoch 0015, iter [00050, 00390], lr: 0.010000, loss: 2.4736
2023-07-01 21:46:42 - train: epoch 0015, iter [00100, 00390], lr: 0.010000, loss: 2.8986
2023-07-01 21:46:45 - train: epoch 0015, iter [00150, 00390], lr: 0.010000, loss: 3.1135
2023-07-01 21:46:47 - train: epoch 0015, iter [00200, 00390], lr: 0.010000, loss: 2.8028
2023-07-01 21:46:49 - train: epoch 0015, iter [00250, 00390], lr: 0.010000, loss: 2.7837
2023-07-01 21:46:51 - train: epoch 0015, iter [00300, 00390], lr: 0.010000, loss: 2.7051
2023-07-01 21:46:54 - train: epoch 0015, iter [00350, 00390], lr: 0.010000, loss: 2.7904
2023-07-01 21:46:55 - train: epoch 015, train_loss: 2.8070
2023-07-01 21:46:57 - eval: epoch: 015, acc1: 29.640%, acc5: 59.070%, test_loss: 2.8302, per_image_load_time: 0.076ms, per_image_inference_time: 0.087ms
2023-07-01 21:46:58 - until epoch: 015, best_acc1: 29.640%
2023-07-01 21:46:58 - epoch 016 lr: 0.010000
2023-07-01 21:47:01 - train: epoch 0016, iter [00050, 00390], lr: 0.010000, loss: 2.9112
2023-07-01 21:47:03 - train: epoch 0016, iter [00100, 00390], lr: 0.010000, loss: 2.7079
2023-07-01 21:47:06 - train: epoch 0016, iter [00150, 00390], lr: 0.010000, loss: 2.9746
2023-07-01 21:47:08 - train: epoch 0016, iter [00200, 00390], lr: 0.010000, loss: 2.9167
2023-07-01 21:47:10 - train: epoch 0016, iter [00250, 00390], lr: 0.010000, loss: 2.5835
2023-07-01 21:47:12 - train: epoch 0016, iter [00300, 00390], lr: 0.010000, loss: 2.7318
2023-07-01 21:47:15 - train: epoch 0016, iter [00350, 00390], lr: 0.010000, loss: 2.6298
2023-07-01 21:47:16 - train: epoch 016, train_loss: 2.7657
2023-07-01 21:47:18 - eval: epoch: 016, acc1: 29.910%, acc5: 60.350%, test_loss: 2.7847, per_image_load_time: 0.072ms, per_image_inference_time: 0.094ms
2023-07-01 21:47:19 - until epoch: 016, best_acc1: 29.910%
2023-07-01 21:47:19 - epoch 017 lr: 0.010000
2023-07-01 21:47:22 - train: epoch 0017, iter [00050, 00390], lr: 0.010000, loss: 2.8575
2023-07-01 21:47:24 - train: epoch 0017, iter [00100, 00390], lr: 0.010000, loss: 2.7677
2023-07-01 21:47:27 - train: epoch 0017, iter [00150, 00390], lr: 0.010000, loss: 2.3534
2023-07-01 21:47:29 - train: epoch 0017, iter [00200, 00390], lr: 0.010000, loss: 2.7923
2023-07-01 21:47:31 - train: epoch 0017, iter [00250, 00390], lr: 0.010000, loss: 2.7809
2023-07-01 21:47:34 - train: epoch 0017, iter [00300, 00390], lr: 0.010000, loss: 2.9656
2023-07-01 21:47:36 - train: epoch 0017, iter [00350, 00390], lr: 0.010000, loss: 2.3430
2023-07-01 21:47:38 - train: epoch 017, train_loss: 2.7324
2023-07-01 21:47:40 - eval: epoch: 017, acc1: 30.940%, acc5: 60.740%, test_loss: 2.7787, per_image_load_time: 0.071ms, per_image_inference_time: 0.088ms
2023-07-01 21:47:40 - until epoch: 017, best_acc1: 30.940%
2023-07-01 21:47:40 - epoch 018 lr: 0.010000
2023-07-01 21:47:43 - train: epoch 0018, iter [00050, 00390], lr: 0.010000, loss: 2.7882
2023-07-01 21:47:46 - train: epoch 0018, iter [00100, 00390], lr: 0.010000, loss: 2.7975
2023-07-01 21:47:48 - train: epoch 0018, iter [00150, 00390], lr: 0.010000, loss: 3.0882
2023-07-01 21:47:50 - train: epoch 0018, iter [00200, 00390], lr: 0.010000, loss: 2.6621
2023-07-01 21:47:52 - train: epoch 0018, iter [00250, 00390], lr: 0.010000, loss: 2.7326
2023-07-01 21:47:55 - train: epoch 0018, iter [00300, 00390], lr: 0.010000, loss: 2.7790
2023-07-01 21:47:57 - train: epoch 0018, iter [00350, 00390], lr: 0.010000, loss: 2.7674
2023-07-01 21:47:59 - train: epoch 018, train_loss: 2.6899
2023-07-01 21:48:00 - eval: epoch: 018, acc1: 31.440%, acc5: 62.260%, test_loss: 2.7306, per_image_load_time: 0.071ms, per_image_inference_time: 0.089ms
2023-07-01 21:48:01 - until epoch: 018, best_acc1: 31.440%
2023-07-01 21:48:01 - epoch 019 lr: 0.010000
2023-07-01 21:48:04 - train: epoch 0019, iter [00050, 00390], lr: 0.010000, loss: 2.5513
2023-07-01 21:48:07 - train: epoch 0019, iter [00100, 00390], lr: 0.010000, loss: 2.6512
2023-07-01 21:48:09 - train: epoch 0019, iter [00150, 00390], lr: 0.010000, loss: 2.7258
2023-07-01 21:48:11 - train: epoch 0019, iter [00200, 00390], lr: 0.010000, loss: 2.7070
2023-07-01 21:48:13 - train: epoch 0019, iter [00250, 00390], lr: 0.010000, loss: 2.7828
2023-07-01 21:48:16 - train: epoch 0019, iter [00300, 00390], lr: 0.010000, loss: 2.9155
2023-07-01 21:48:18 - train: epoch 0019, iter [00350, 00390], lr: 0.010000, loss: 2.5668
2023-07-01 21:48:20 - train: epoch 019, train_loss: 2.6496
2023-07-01 21:48:21 - eval: epoch: 019, acc1: 31.730%, acc5: 62.380%, test_loss: 2.7196, per_image_load_time: 0.070ms, per_image_inference_time: 0.088ms
2023-07-01 21:48:22 - until epoch: 019, best_acc1: 31.730%
2023-07-01 21:48:22 - epoch 020 lr: 0.010000
2023-07-01 21:48:26 - train: epoch 0020, iter [00050, 00390], lr: 0.010000, loss: 2.6639
2023-07-01 21:48:28 - train: epoch 0020, iter [00100, 00390], lr: 0.010000, loss: 2.7119
2023-07-01 21:48:31 - train: epoch 0020, iter [00150, 00390], lr: 0.010000, loss: 2.5959
2023-07-01 21:48:33 - train: epoch 0020, iter [00200, 00390], lr: 0.010000, loss: 2.6526
2023-07-01 21:48:35 - train: epoch 0020, iter [00250, 00390], lr: 0.010000, loss: 2.4962
2023-07-01 21:48:38 - train: epoch 0020, iter [00300, 00390], lr: 0.010000, loss: 2.8292
2023-07-01 21:48:40 - train: epoch 0020, iter [00350, 00390], lr: 0.010000, loss: 2.6081
2023-07-01 21:48:42 - train: epoch 020, train_loss: 2.6173
2023-07-01 21:48:44 - eval: epoch: 020, acc1: 32.340%, acc5: 62.840%, test_loss: 2.6989, per_image_load_time: 0.073ms, per_image_inference_time: 0.089ms
2023-07-01 21:48:44 - until epoch: 020, best_acc1: 32.340%
2023-07-01 21:48:44 - epoch 021 lr: 0.010000
2023-07-01 21:48:47 - train: epoch 0021, iter [00050, 00390], lr: 0.010000, loss: 2.4177
2023-07-01 21:48:50 - train: epoch 0021, iter [00100, 00390], lr: 0.010000, loss: 2.6130
2023-07-01 21:48:52 - train: epoch 0021, iter [00150, 00390], lr: 0.010000, loss: 2.6233
2023-07-01 21:48:54 - train: epoch 0021, iter [00200, 00390], lr: 0.010000, loss: 2.9480
2023-07-01 21:48:57 - train: epoch 0021, iter [00250, 00390], lr: 0.010000, loss: 2.6559
2023-07-01 21:48:59 - train: epoch 0021, iter [00300, 00390], lr: 0.010000, loss: 2.6595
2023-07-01 21:49:01 - train: epoch 0021, iter [00350, 00390], lr: 0.010000, loss: 2.4882
2023-07-01 21:49:03 - train: epoch 021, train_loss: 2.5805
2023-07-01 21:49:05 - eval: epoch: 021, acc1: 32.910%, acc5: 63.230%, test_loss: 2.6824, per_image_load_time: 0.074ms, per_image_inference_time: 0.088ms
2023-07-01 21:49:07 - until epoch: 021, best_acc1: 32.910%
2023-07-01 21:49:07 - epoch 022 lr: 0.010000
2023-07-01 21:49:11 - train: epoch 0022, iter [00050, 00390], lr: 0.010000, loss: 2.6243
2023-07-01 21:49:13 - train: epoch 0022, iter [00100, 00390], lr: 0.010000, loss: 2.5298
2023-07-01 21:49:15 - train: epoch 0022, iter [00150, 00390], lr: 0.010000, loss: 2.6498
2023-07-01 21:49:18 - train: epoch 0022, iter [00200, 00390], lr: 0.010000, loss: 2.6414
2023-07-01 21:49:20 - train: epoch 0022, iter [00250, 00390], lr: 0.010000, loss: 2.5935
2023-07-01 21:49:22 - train: epoch 0022, iter [00300, 00390], lr: 0.010000, loss: 2.5812
2023-07-01 21:49:25 - train: epoch 0022, iter [00350, 00390], lr: 0.010000, loss: 2.5073
2023-07-01 21:49:26 - train: epoch 022, train_loss: 2.5443
2023-07-01 21:49:28 - eval: epoch: 022, acc1: 33.160%, acc5: 63.310%, test_loss: 2.6589, per_image_load_time: 0.071ms, per_image_inference_time: 0.089ms
2023-07-01 21:49:29 - until epoch: 022, best_acc1: 33.160%
2023-07-01 21:49:29 - epoch 023 lr: 0.010000
2023-07-01 21:49:32 - train: epoch 0023, iter [00050, 00390], lr: 0.010000, loss: 2.3464
2023-07-01 21:49:34 - train: epoch 0023, iter [00100, 00390], lr: 0.010000, loss: 2.4432
2023-07-01 21:49:37 - train: epoch 0023, iter [00150, 00390], lr: 0.010000, loss: 2.4106
2023-07-01 21:49:39 - train: epoch 0023, iter [00200, 00390], lr: 0.010000, loss: 2.6881
2023-07-01 21:49:41 - train: epoch 0023, iter [00250, 00390], lr: 0.010000, loss: 2.3779
2023-07-01 21:49:43 - train: epoch 0023, iter [00300, 00390], lr: 0.010000, loss: 2.5928
2023-07-01 21:49:46 - train: epoch 0023, iter [00350, 00390], lr: 0.010000, loss: 2.3417
2023-07-01 21:49:47 - train: epoch 023, train_loss: 2.5013
2023-07-01 21:49:49 - eval: epoch: 023, acc1: 34.670%, acc5: 64.570%, test_loss: 2.6174, per_image_load_time: 0.071ms, per_image_inference_time: 0.089ms
2023-07-01 21:49:50 - until epoch: 023, best_acc1: 34.670%
2023-07-01 21:49:50 - epoch 024 lr: 0.010000
2023-07-01 21:49:53 - train: epoch 0024, iter [00050, 00390], lr: 0.010000, loss: 2.3451
2023-07-01 21:49:55 - train: epoch 0024, iter [00100, 00390], lr: 0.010000, loss: 2.4349
2023-07-01 21:49:57 - train: epoch 0024, iter [00150, 00390], lr: 0.010000, loss: 2.1834
2023-07-01 21:50:00 - train: epoch 0024, iter [00200, 00390], lr: 0.010000, loss: 2.6864
2023-07-01 21:50:02 - train: epoch 0024, iter [00250, 00390], lr: 0.010000, loss: 2.6176
2023-07-01 21:50:04 - train: epoch 0024, iter [00300, 00390], lr: 0.010000, loss: 2.4161
2023-07-01 21:50:06 - train: epoch 0024, iter [00350, 00390], lr: 0.010000, loss: 2.3546
2023-07-01 21:50:08 - train: epoch 024, train_loss: 2.4748
2023-07-01 21:50:10 - eval: epoch: 024, acc1: 33.940%, acc5: 63.980%, test_loss: 2.6374, per_image_load_time: 0.071ms, per_image_inference_time: 0.088ms
2023-07-01 21:50:10 - until epoch: 024, best_acc1: 34.670%
2023-07-01 21:50:10 - epoch 025 lr: 0.010000
2023-07-01 21:50:14 - train: epoch 0025, iter [00050, 00390], lr: 0.010000, loss: 2.4150
2023-07-01 21:50:16 - train: epoch 0025, iter [00100, 00390], lr: 0.010000, loss: 2.1802
2023-07-01 21:50:18 - train: epoch 0025, iter [00150, 00390], lr: 0.010000, loss: 2.5341
2023-07-01 21:50:20 - train: epoch 0025, iter [00200, 00390], lr: 0.010000, loss: 2.4464
2023-07-01 21:50:23 - train: epoch 0025, iter [00250, 00390], lr: 0.010000, loss: 2.4704
2023-07-01 21:50:25 - train: epoch 0025, iter [00300, 00390], lr: 0.010000, loss: 2.6424
2023-07-01 21:50:27 - train: epoch 0025, iter [00350, 00390], lr: 0.010000, loss: 2.3940
2023-07-01 21:50:29 - train: epoch 025, train_loss: 2.4376
2023-07-01 21:50:31 - eval: epoch: 025, acc1: 34.680%, acc5: 64.790%, test_loss: 2.6175, per_image_load_time: 0.073ms, per_image_inference_time: 0.090ms
2023-07-01 21:50:31 - until epoch: 025, best_acc1: 34.680%
2023-07-01 21:50:31 - epoch 026 lr: 0.010000
2023-07-01 21:50:34 - train: epoch 0026, iter [00050, 00390], lr: 0.010000, loss: 2.2500
2023-07-01 21:50:37 - train: epoch 0026, iter [00100, 00390], lr: 0.010000, loss: 2.4947
2023-07-01 21:50:39 - train: epoch 0026, iter [00150, 00390], lr: 0.010000, loss: 2.4045
2023-07-01 21:50:41 - train: epoch 0026, iter [00200, 00390], lr: 0.010000, loss: 2.4321
2023-07-01 21:50:43 - train: epoch 0026, iter [00250, 00390], lr: 0.010000, loss: 2.3816
2023-07-01 21:50:46 - train: epoch 0026, iter [00300, 00390], lr: 0.010000, loss: 2.5165
2023-07-01 21:50:48 - train: epoch 0026, iter [00350, 00390], lr: 0.010000, loss: 2.4840
2023-07-01 21:50:50 - train: epoch 026, train_loss: 2.4062
2023-07-01 21:50:52 - eval: epoch: 026, acc1: 34.890%, acc5: 65.470%, test_loss: 2.5931, per_image_load_time: 0.071ms, per_image_inference_time: 0.088ms
2023-07-01 21:50:53 - until epoch: 026, best_acc1: 34.890%
2023-07-01 21:50:53 - epoch 027 lr: 0.010000
2023-07-01 21:50:56 - train: epoch 0027, iter [00050, 00390], lr: 0.010000, loss: 2.2987
2023-07-01 21:50:58 - train: epoch 0027, iter [00100, 00390], lr: 0.010000, loss: 2.3528
2023-07-01 21:51:00 - train: epoch 0027, iter [00150, 00390], lr: 0.010000, loss: 2.2609
2023-07-01 21:51:03 - train: epoch 0027, iter [00200, 00390], lr: 0.010000, loss: 2.5291
2023-07-01 21:51:05 - train: epoch 0027, iter [00250, 00390], lr: 0.010000, loss: 2.5151
2023-07-01 21:51:07 - train: epoch 0027, iter [00300, 00390], lr: 0.010000, loss: 2.5462
2023-07-01 21:51:09 - train: epoch 0027, iter [00350, 00390], lr: 0.010000, loss: 2.4678
2023-07-01 21:51:11 - train: epoch 027, train_loss: 2.3810
2023-07-01 21:51:13 - eval: epoch: 027, acc1: 35.900%, acc5: 65.990%, test_loss: 2.5539, per_image_load_time: 0.071ms, per_image_inference_time: 0.088ms
2023-07-01 21:51:14 - until epoch: 027, best_acc1: 35.900%
2023-07-01 21:51:14 - epoch 028 lr: 0.010000
2023-07-01 21:51:17 - train: epoch 0028, iter [00050, 00390], lr: 0.010000, loss: 2.4517
2023-07-01 21:51:19 - train: epoch 0028, iter [00100, 00390], lr: 0.010000, loss: 2.3333
2023-07-01 21:51:21 - train: epoch 0028, iter [00150, 00390], lr: 0.010000, loss: 2.1584
2023-07-01 21:51:24 - train: epoch 0028, iter [00200, 00390], lr: 0.010000, loss: 2.5027
2023-07-01 21:51:26 - train: epoch 0028, iter [00250, 00390], lr: 0.010000, loss: 2.3839
2023-07-01 21:51:28 - train: epoch 0028, iter [00300, 00390], lr: 0.010000, loss: 2.4255
2023-07-01 21:51:30 - train: epoch 0028, iter [00350, 00390], lr: 0.010000, loss: 2.4202
2023-07-01 21:51:32 - train: epoch 028, train_loss: 2.3362
2023-07-01 21:51:34 - eval: epoch: 028, acc1: 36.060%, acc5: 65.850%, test_loss: 2.5604, per_image_load_time: 0.073ms, per_image_inference_time: 0.088ms
2023-07-01 21:51:35 - until epoch: 028, best_acc1: 36.060%
2023-07-01 21:51:35 - epoch 029 lr: 0.010000
2023-07-01 21:51:38 - train: epoch 0029, iter [00050, 00390], lr: 0.010000, loss: 2.3117
2023-07-01 21:51:40 - train: epoch 0029, iter [00100, 00390], lr: 0.010000, loss: 2.3025
2023-07-01 21:51:42 - train: epoch 0029, iter [00150, 00390], lr: 0.010000, loss: 2.4828
2023-07-01 21:51:45 - train: epoch 0029, iter [00200, 00390], lr: 0.010000, loss: 2.2515
2023-07-01 21:51:47 - train: epoch 0029, iter [00250, 00390], lr: 0.010000, loss: 2.2498
2023-07-01 21:51:49 - train: epoch 0029, iter [00300, 00390], lr: 0.010000, loss: 2.4305
2023-07-01 21:51:51 - train: epoch 0029, iter [00350, 00390], lr: 0.010000, loss: 2.1806
2023-07-01 21:51:53 - train: epoch 029, train_loss: 2.3098
2023-07-01 21:51:55 - eval: epoch: 029, acc1: 35.610%, acc5: 65.800%, test_loss: 2.5813, per_image_load_time: 0.071ms, per_image_inference_time: 0.088ms
2023-07-01 21:51:55 - until epoch: 029, best_acc1: 36.060%
2023-07-01 21:51:55 - epoch 030 lr: 0.010000
2023-07-01 21:51:58 - train: epoch 0030, iter [00050, 00390], lr: 0.010000, loss: 2.2908
2023-07-01 21:52:01 - train: epoch 0030, iter [00100, 00390], lr: 0.010000, loss: 2.2942
2023-07-01 21:52:03 - train: epoch 0030, iter [00150, 00390], lr: 0.010000, loss: 2.0822
2023-07-01 21:52:05 - train: epoch 0030, iter [00200, 00390], lr: 0.010000, loss: 2.0730
2023-07-01 21:52:08 - train: epoch 0030, iter [00250, 00390], lr: 0.010000, loss: 2.3622
2023-07-01 21:52:10 - train: epoch 0030, iter [00300, 00390], lr: 0.010000, loss: 2.4078
2023-07-01 21:52:12 - train: epoch 0030, iter [00350, 00390], lr: 0.010000, loss: 2.2212
2023-07-01 21:52:14 - train: epoch 030, train_loss: 2.2800
2023-07-01 21:52:16 - eval: epoch: 030, acc1: 35.760%, acc5: 66.400%, test_loss: 2.5406, per_image_load_time: 0.077ms, per_image_inference_time: 0.088ms
2023-07-01 21:52:16 - until epoch: 030, best_acc1: 36.060%
2023-07-01 21:52:16 - epoch 031 lr: 0.010000
2023-07-01 21:52:19 - train: epoch 0031, iter [00050, 00390], lr: 0.010000, loss: 2.4433
2023-07-01 21:52:22 - train: epoch 0031, iter [00100, 00390], lr: 0.010000, loss: 2.5759
2023-07-01 21:52:24 - train: epoch 0031, iter [00150, 00390], lr: 0.010000, loss: 2.4053
2023-07-01 21:52:26 - train: epoch 0031, iter [00200, 00390], lr: 0.010000, loss: 2.3848
2023-07-01 21:52:28 - train: epoch 0031, iter [00250, 00390], lr: 0.010000, loss: 2.2804
2023-07-01 21:52:31 - train: epoch 0031, iter [00300, 00390], lr: 0.010000, loss: 2.2564
2023-07-01 21:52:33 - train: epoch 0031, iter [00350, 00390], lr: 0.010000, loss: 1.9752
2023-07-01 21:52:35 - train: epoch 031, train_loss: 2.2406
2023-07-01 21:52:37 - eval: epoch: 031, acc1: 36.890%, acc5: 66.460%, test_loss: 2.5316, per_image_load_time: 0.075ms, per_image_inference_time: 0.088ms
2023-07-01 21:52:37 - until epoch: 031, best_acc1: 36.890%
2023-07-01 21:52:37 - epoch 032 lr: 0.010000
2023-07-01 21:52:41 - train: epoch 0032, iter [00050, 00390], lr: 0.010000, loss: 2.3489
2023-07-01 21:52:43 - train: epoch 0032, iter [00100, 00390], lr: 0.010000, loss: 2.1700
2023-07-01 21:52:46 - train: epoch 0032, iter [00150, 00390], lr: 0.010000, loss: 2.2110
2023-07-01 21:52:49 - train: epoch 0032, iter [00200, 00390], lr: 0.010000, loss: 2.2644
2023-07-01 21:52:51 - train: epoch 0032, iter [00250, 00390], lr: 0.010000, loss: 2.3082
2023-07-01 21:52:53 - train: epoch 0032, iter [00300, 00390], lr: 0.010000, loss: 2.2957
2023-07-01 21:52:56 - train: epoch 0032, iter [00350, 00390], lr: 0.010000, loss: 2.1074
2023-07-01 21:52:58 - train: epoch 032, train_loss: 2.2131
2023-07-01 21:53:00 - eval: epoch: 032, acc1: 36.590%, acc5: 66.880%, test_loss: 2.5316, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 21:53:00 - until epoch: 032, best_acc1: 36.890%
2023-07-01 21:53:00 - epoch 033 lr: 0.010000
2023-07-01 21:53:03 - train: epoch 0033, iter [00050, 00390], lr: 0.010000, loss: 1.9748
2023-07-01 21:53:05 - train: epoch 0033, iter [00100, 00390], lr: 0.010000, loss: 2.1610
2023-07-01 21:53:08 - train: epoch 0033, iter [00150, 00390], lr: 0.010000, loss: 2.2788
2023-07-01 21:53:10 - train: epoch 0033, iter [00200, 00390], lr: 0.010000, loss: 2.1667
2023-07-01 21:53:12 - train: epoch 0033, iter [00250, 00390], lr: 0.010000, loss: 2.1924
2023-07-01 21:53:14 - train: epoch 0033, iter [00300, 00390], lr: 0.010000, loss: 2.4882
2023-07-01 21:53:17 - train: epoch 0033, iter [00350, 00390], lr: 0.010000, loss: 2.2349
2023-07-01 21:53:19 - train: epoch 033, train_loss: 2.1805
2023-07-01 21:53:20 - eval: epoch: 033, acc1: 36.960%, acc5: 67.090%, test_loss: 2.5073, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 21:53:22 - until epoch: 033, best_acc1: 36.960%
2023-07-01 21:53:22 - epoch 034 lr: 0.010000
2023-07-01 21:53:25 - train: epoch 0034, iter [00050, 00390], lr: 0.010000, loss: 2.1207
2023-07-01 21:53:27 - train: epoch 0034, iter [00100, 00390], lr: 0.010000, loss: 2.1552
2023-07-01 21:53:29 - train: epoch 0034, iter [00150, 00390], lr: 0.010000, loss: 2.1955
2023-07-01 21:53:32 - train: epoch 0034, iter [00200, 00390], lr: 0.010000, loss: 2.1323
2023-07-01 21:53:34 - train: epoch 0034, iter [00250, 00390], lr: 0.010000, loss: 2.1346
2023-07-01 21:53:36 - train: epoch 0034, iter [00300, 00390], lr: 0.010000, loss: 2.2261
2023-07-01 21:53:39 - train: epoch 0034, iter [00350, 00390], lr: 0.010000, loss: 1.9406
2023-07-01 21:53:40 - train: epoch 034, train_loss: 2.1565
2023-07-01 21:53:42 - eval: epoch: 034, acc1: 37.190%, acc5: 66.970%, test_loss: 2.5253, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 21:53:43 - until epoch: 034, best_acc1: 37.190%
2023-07-01 21:53:43 - epoch 035 lr: 0.010000
2023-07-01 21:53:46 - train: epoch 0035, iter [00050, 00390], lr: 0.010000, loss: 1.7734
2023-07-01 21:53:48 - train: epoch 0035, iter [00100, 00390], lr: 0.010000, loss: 2.0060
2023-07-01 21:53:50 - train: epoch 0035, iter [00150, 00390], lr: 0.010000, loss: 2.1966
2023-07-01 21:53:53 - train: epoch 0035, iter [00200, 00390], lr: 0.010000, loss: 1.9923
2023-07-01 21:53:55 - train: epoch 0035, iter [00250, 00390], lr: 0.010000, loss: 1.9546
2023-07-01 21:53:57 - train: epoch 0035, iter [00300, 00390], lr: 0.010000, loss: 2.0240
2023-07-01 21:54:00 - train: epoch 0035, iter [00350, 00390], lr: 0.010000, loss: 2.3270
2023-07-01 21:54:02 - train: epoch 035, train_loss: 2.1103
2023-07-01 21:54:03 - eval: epoch: 035, acc1: 37.630%, acc5: 67.460%, test_loss: 2.4945, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 21:54:04 - until epoch: 035, best_acc1: 37.630%
2023-07-01 21:54:04 - epoch 036 lr: 0.010000
2023-07-01 21:54:08 - train: epoch 0036, iter [00050, 00390], lr: 0.010000, loss: 2.0331
2023-07-01 21:54:10 - train: epoch 0036, iter [00100, 00390], lr: 0.010000, loss: 1.9347
2023-07-01 21:54:12 - train: epoch 0036, iter [00150, 00390], lr: 0.010000, loss: 2.1240
2023-07-01 21:54:15 - train: epoch 0036, iter [00200, 00390], lr: 0.010000, loss: 2.2714
2023-07-01 21:54:17 - train: epoch 0036, iter [00250, 00390], lr: 0.010000, loss: 2.0496
2023-07-01 21:54:19 - train: epoch 0036, iter [00300, 00390], lr: 0.010000, loss: 2.1258
2023-07-01 21:54:21 - train: epoch 0036, iter [00350, 00390], lr: 0.010000, loss: 1.8596
2023-07-01 21:54:23 - train: epoch 036, train_loss: 2.0919
2023-07-01 21:54:25 - eval: epoch: 036, acc1: 37.660%, acc5: 67.950%, test_loss: 2.4988, per_image_load_time: 0.077ms, per_image_inference_time: 0.089ms
2023-07-01 21:54:26 - until epoch: 036, best_acc1: 37.660%
2023-07-01 21:54:26 - epoch 037 lr: 0.010000
2023-07-01 21:54:29 - train: epoch 0037, iter [00050, 00390], lr: 0.010000, loss: 2.1354
2023-07-01 21:54:31 - train: epoch 0037, iter [00100, 00390], lr: 0.010000, loss: 2.1006
2023-07-01 21:54:34 - train: epoch 0037, iter [00150, 00390], lr: 0.010000, loss: 2.1472
2023-07-01 21:54:36 - train: epoch 0037, iter [00200, 00390], lr: 0.010000, loss: 2.2391
2023-07-01 21:54:38 - train: epoch 0037, iter [00250, 00390], lr: 0.010000, loss: 1.8452
2023-07-01 21:54:41 - train: epoch 0037, iter [00300, 00390], lr: 0.010000, loss: 2.3650
2023-07-01 21:54:43 - train: epoch 0037, iter [00350, 00390], lr: 0.010000, loss: 2.1193
2023-07-01 21:54:45 - train: epoch 037, train_loss: 2.0505
2023-07-01 21:54:47 - eval: epoch: 037, acc1: 37.950%, acc5: 67.590%, test_loss: 2.5142, per_image_load_time: 0.075ms, per_image_inference_time: 0.088ms
2023-07-01 21:54:48 - until epoch: 037, best_acc1: 37.950%
2023-07-01 21:54:48 - epoch 038 lr: 0.010000
2023-07-01 21:54:51 - train: epoch 0038, iter [00050, 00390], lr: 0.010000, loss: 1.7874
2023-07-01 21:54:53 - train: epoch 0038, iter [00100, 00390], lr: 0.010000, loss: 1.9315
2023-07-01 21:54:55 - train: epoch 0038, iter [00150, 00390], lr: 0.010000, loss: 2.1516
2023-07-01 21:54:58 - train: epoch 0038, iter [00200, 00390], lr: 0.010000, loss: 1.9247
2023-07-01 21:55:00 - train: epoch 0038, iter [00250, 00390], lr: 0.010000, loss: 2.2520
2023-07-01 21:55:02 - train: epoch 0038, iter [00300, 00390], lr: 0.010000, loss: 2.1258
2023-07-01 21:55:05 - train: epoch 0038, iter [00350, 00390], lr: 0.010000, loss: 2.2634
2023-07-01 21:55:06 - train: epoch 038, train_loss: 2.0181
2023-07-01 21:55:08 - eval: epoch: 038, acc1: 37.750%, acc5: 67.920%, test_loss: 2.5109, per_image_load_time: 0.071ms, per_image_inference_time: 0.089ms
2023-07-01 21:55:09 - until epoch: 038, best_acc1: 37.950%
2023-07-01 21:55:09 - epoch 039 lr: 0.010000
2023-07-01 21:55:12 - train: epoch 0039, iter [00050, 00390], lr: 0.010000, loss: 1.8772
2023-07-01 21:55:14 - train: epoch 0039, iter [00100, 00390], lr: 0.010000, loss: 1.9142
2023-07-01 21:55:16 - train: epoch 0039, iter [00150, 00390], lr: 0.010000, loss: 1.7786
2023-07-01 21:55:19 - train: epoch 0039, iter [00200, 00390], lr: 0.010000, loss: 1.9419
2023-07-01 21:55:21 - train: epoch 0039, iter [00250, 00390], lr: 0.010000, loss: 2.0648
2023-07-01 21:55:23 - train: epoch 0039, iter [00300, 00390], lr: 0.010000, loss: 1.9120
2023-07-01 21:55:26 - train: epoch 0039, iter [00350, 00390], lr: 0.010000, loss: 2.0760
2023-07-01 21:55:27 - train: epoch 039, train_loss: 2.0011
2023-07-01 21:55:29 - eval: epoch: 039, acc1: 38.770%, acc5: 67.920%, test_loss: 2.4880, per_image_load_time: 0.071ms, per_image_inference_time: 0.087ms
2023-07-01 21:55:30 - until epoch: 039, best_acc1: 38.770%
2023-07-01 21:55:30 - epoch 040 lr: 0.010000
2023-07-01 21:55:33 - train: epoch 0040, iter [00050, 00390], lr: 0.010000, loss: 2.0933
2023-07-01 21:55:35 - train: epoch 0040, iter [00100, 00390], lr: 0.010000, loss: 1.7292
2023-07-01 21:55:37 - train: epoch 0040, iter [00150, 00390], lr: 0.010000, loss: 1.8735
2023-07-01 21:55:40 - train: epoch 0040, iter [00200, 00390], lr: 0.010000, loss: 2.2198
2023-07-01 21:55:42 - train: epoch 0040, iter [00250, 00390], lr: 0.010000, loss: 2.2120
2023-07-01 21:55:44 - train: epoch 0040, iter [00300, 00390], lr: 0.010000, loss: 1.7787
2023-07-01 21:55:46 - train: epoch 0040, iter [00350, 00390], lr: 0.010000, loss: 2.2068
2023-07-01 21:55:48 - train: epoch 040, train_loss: 1.9654
2023-07-01 21:55:50 - eval: epoch: 040, acc1: 37.780%, acc5: 68.310%, test_loss: 2.5206, per_image_load_time: 0.073ms, per_image_inference_time: 0.089ms
2023-07-01 21:55:52 - until epoch: 040, best_acc1: 38.770%
2023-07-01 21:55:52 - epoch 041 lr: 0.010000
2023-07-01 21:55:55 - train: epoch 0041, iter [00050, 00390], lr: 0.010000, loss: 1.9172
2023-07-01 21:55:58 - train: epoch 0041, iter [00100, 00390], lr: 0.010000, loss: 1.6734
2023-07-01 21:56:00 - train: epoch 0041, iter [00150, 00390], lr: 0.010000, loss: 2.0230
2023-07-01 21:56:02 - train: epoch 0041, iter [00200, 00390], lr: 0.010000, loss: 1.9969
2023-07-01 21:56:04 - train: epoch 0041, iter [00250, 00390], lr: 0.010000, loss: 2.1946
2023-07-01 21:56:07 - train: epoch 0041, iter [00300, 00390], lr: 0.010000, loss: 1.9171
2023-07-01 21:56:09 - train: epoch 0041, iter [00350, 00390], lr: 0.010000, loss: 1.9862
2023-07-01 21:56:11 - train: epoch 041, train_loss: 1.9308
2023-07-01 21:56:13 - eval: epoch: 041, acc1: 38.680%, acc5: 68.710%, test_loss: 2.4681, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 21:56:13 - until epoch: 041, best_acc1: 38.770%
2023-07-01 21:56:13 - epoch 042 lr: 0.010000
2023-07-01 21:56:17 - train: epoch 0042, iter [00050, 00390], lr: 0.010000, loss: 1.5765
2023-07-01 21:56:19 - train: epoch 0042, iter [00100, 00390], lr: 0.010000, loss: 1.7645
2023-07-01 21:56:22 - train: epoch 0042, iter [00150, 00390], lr: 0.010000, loss: 1.7572
2023-07-01 21:56:24 - train: epoch 0042, iter [00200, 00390], lr: 0.010000, loss: 1.6694
2023-07-01 21:56:26 - train: epoch 0042, iter [00250, 00390], lr: 0.010000, loss: 1.9593
2023-07-01 21:56:29 - train: epoch 0042, iter [00300, 00390], lr: 0.010000, loss: 1.6880
2023-07-01 21:56:31 - train: epoch 0042, iter [00350, 00390], lr: 0.010000, loss: 1.6943
2023-07-01 21:56:33 - train: epoch 042, train_loss: 1.9006
2023-07-01 21:56:35 - eval: epoch: 042, acc1: 38.220%, acc5: 68.280%, test_loss: 2.5241, per_image_load_time: 0.073ms, per_image_inference_time: 0.093ms
2023-07-01 21:56:35 - until epoch: 042, best_acc1: 38.770%
2023-07-01 21:56:35 - epoch 043 lr: 0.010000
2023-07-01 21:56:39 - train: epoch 0043, iter [00050, 00390], lr: 0.010000, loss: 1.9691
2023-07-01 21:56:41 - train: epoch 0043, iter [00100, 00390], lr: 0.010000, loss: 1.5984
2023-07-01 21:56:43 - train: epoch 0043, iter [00150, 00390], lr: 0.010000, loss: 1.7282
2023-07-01 21:56:46 - train: epoch 0043, iter [00200, 00390], lr: 0.010000, loss: 2.0584
2023-07-01 21:56:48 - train: epoch 0043, iter [00250, 00390], lr: 0.010000, loss: 1.9639
2023-07-01 21:56:51 - train: epoch 0043, iter [00300, 00390], lr: 0.010000, loss: 1.9492
2023-07-01 21:56:53 - train: epoch 0043, iter [00350, 00390], lr: 0.010000, loss: 1.7977
2023-07-01 21:56:55 - train: epoch 043, train_loss: 1.8723
2023-07-01 21:56:57 - eval: epoch: 043, acc1: 38.640%, acc5: 68.400%, test_loss: 2.5137, per_image_load_time: 0.073ms, per_image_inference_time: 0.090ms
2023-07-01 21:56:57 - until epoch: 043, best_acc1: 38.770%
2023-07-01 21:56:57 - epoch 044 lr: 0.010000
2023-07-01 21:57:00 - train: epoch 0044, iter [00050, 00390], lr: 0.010000, loss: 2.0014
2023-07-01 21:57:03 - train: epoch 0044, iter [00100, 00390], lr: 0.010000, loss: 1.9035
2023-07-01 21:57:05 - train: epoch 0044, iter [00150, 00390], lr: 0.010000, loss: 1.7490
2023-07-01 21:57:08 - train: epoch 0044, iter [00200, 00390], lr: 0.010000, loss: 1.7788
2023-07-01 21:57:10 - train: epoch 0044, iter [00250, 00390], lr: 0.010000, loss: 2.1842
2023-07-01 21:57:13 - train: epoch 0044, iter [00300, 00390], lr: 0.010000, loss: 1.6131
2023-07-01 21:57:15 - train: epoch 0044, iter [00350, 00390], lr: 0.010000, loss: 1.8523
2023-07-01 21:57:17 - train: epoch 044, train_loss: 1.8475
2023-07-01 21:57:19 - eval: epoch: 044, acc1: 38.690%, acc5: 68.640%, test_loss: 2.5103, per_image_load_time: 0.076ms, per_image_inference_time: 0.088ms
2023-07-01 21:57:20 - until epoch: 044, best_acc1: 38.770%
2023-07-01 21:57:20 - epoch 045 lr: 0.010000
2023-07-01 21:57:24 - train: epoch 0045, iter [00050, 00390], lr: 0.010000, loss: 1.7614
2023-07-01 21:57:26 - train: epoch 0045, iter [00100, 00390], lr: 0.010000, loss: 1.8388
2023-07-01 21:57:29 - train: epoch 0045, iter [00150, 00390], lr: 0.010000, loss: 1.9123
2023-07-01 21:57:31 - train: epoch 0045, iter [00200, 00390], lr: 0.010000, loss: 1.8935
2023-07-01 21:57:33 - train: epoch 0045, iter [00250, 00390], lr: 0.010000, loss: 1.8721
2023-07-01 21:57:36 - train: epoch 0045, iter [00300, 00390], lr: 0.010000, loss: 1.8315
2023-07-01 21:57:38 - train: epoch 0045, iter [00350, 00390], lr: 0.010000, loss: 2.0445
2023-07-01 21:57:40 - train: epoch 045, train_loss: 1.8033
2023-07-01 21:57:42 - eval: epoch: 045, acc1: 38.670%, acc5: 68.580%, test_loss: 2.5402, per_image_load_time: 0.074ms, per_image_inference_time: 0.088ms
2023-07-01 21:57:42 - until epoch: 045, best_acc1: 38.770%
2023-07-01 21:57:43 - epoch 046 lr: 0.010000
2023-07-01 21:57:46 - train: epoch 0046, iter [00050, 00390], lr: 0.010000, loss: 1.9509
2023-07-01 21:57:48 - train: epoch 0046, iter [00100, 00390], lr: 0.010000, loss: 1.5635
2023-07-01 21:57:51 - train: epoch 0046, iter [00150, 00390], lr: 0.010000, loss: 1.5336
2023-07-01 21:57:53 - train: epoch 0046, iter [00200, 00390], lr: 0.010000, loss: 1.6502
2023-07-01 21:57:55 - train: epoch 0046, iter [00250, 00390], lr: 0.010000, loss: 1.8162
2023-07-01 21:57:58 - train: epoch 0046, iter [00300, 00390], lr: 0.010000, loss: 1.8446
2023-07-01 21:58:01 - train: epoch 0046, iter [00350, 00390], lr: 0.010000, loss: 1.7096
2023-07-01 21:58:03 - train: epoch 046, train_loss: 1.7825
2023-07-01 21:58:05 - eval: epoch: 046, acc1: 38.540%, acc5: 68.020%, test_loss: 2.5217, per_image_load_time: 0.071ms, per_image_inference_time: 0.090ms
2023-07-01 21:58:05 - until epoch: 046, best_acc1: 38.770%
2023-07-01 21:58:05 - epoch 047 lr: 0.010000
2023-07-01 21:58:09 - train: epoch 0047, iter [00050, 00390], lr: 0.010000, loss: 1.7244
2023-07-01 21:58:11 - train: epoch 0047, iter [00100, 00390], lr: 0.010000, loss: 1.5768
2023-07-01 21:58:14 - train: epoch 0047, iter [00150, 00390], lr: 0.010000, loss: 1.6009
2023-07-01 21:58:16 - train: epoch 0047, iter [00200, 00390], lr: 0.010000, loss: 1.7215
2023-07-01 21:58:18 - train: epoch 0047, iter [00250, 00390], lr: 0.010000, loss: 1.6849
2023-07-01 21:58:21 - train: epoch 0047, iter [00300, 00390], lr: 0.010000, loss: 1.6862
2023-07-01 21:58:23 - train: epoch 0047, iter [00350, 00390], lr: 0.010000, loss: 1.7441
2023-07-01 21:58:25 - train: epoch 047, train_loss: 1.7466
2023-07-01 21:58:27 - eval: epoch: 047, acc1: 38.770%, acc5: 68.250%, test_loss: 2.5430, per_image_load_time: 0.074ms, per_image_inference_time: 0.088ms
2023-07-01 21:58:27 - until epoch: 047, best_acc1: 38.770%
2023-07-01 21:58:27 - epoch 048 lr: 0.010000
2023-07-01 21:58:31 - train: epoch 0048, iter [00050, 00390], lr: 0.010000, loss: 1.6952
2023-07-01 21:58:33 - train: epoch 0048, iter [00100, 00390], lr: 0.010000, loss: 1.5167
2023-07-01 21:58:35 - train: epoch 0048, iter [00150, 00390], lr: 0.010000, loss: 1.6795
2023-07-01 21:58:38 - train: epoch 0048, iter [00200, 00390], lr: 0.010000, loss: 1.7390
2023-07-01 21:58:40 - train: epoch 0048, iter [00250, 00390], lr: 0.010000, loss: 1.5354
2023-07-01 21:58:43 - train: epoch 0048, iter [00300, 00390], lr: 0.010000, loss: 1.6920
2023-07-01 21:58:45 - train: epoch 0048, iter [00350, 00390], lr: 0.010000, loss: 1.7931
2023-07-01 21:58:47 - train: epoch 048, train_loss: 1.7139
2023-07-01 21:58:49 - eval: epoch: 048, acc1: 38.120%, acc5: 68.130%, test_loss: 2.5566, per_image_load_time: 0.070ms, per_image_inference_time: 0.088ms
2023-07-01 21:58:49 - until epoch: 048, best_acc1: 38.770%
2023-07-01 21:58:49 - epoch 049 lr: 0.010000
2023-07-01 21:58:52 - train: epoch 0049, iter [00050, 00390], lr: 0.010000, loss: 1.9719
2023-07-01 21:58:55 - train: epoch 0049, iter [00100, 00390], lr: 0.010000, loss: 1.5730
2023-07-01 21:58:57 - train: epoch 0049, iter [00150, 00390], lr: 0.010000, loss: 1.5923
2023-07-01 21:59:00 - train: epoch 0049, iter [00200, 00390], lr: 0.010000, loss: 1.5400
2023-07-01 21:59:02 - train: epoch 0049, iter [00250, 00390], lr: 0.010000, loss: 1.7123
2023-07-01 21:59:04 - train: epoch 0049, iter [00300, 00390], lr: 0.010000, loss: 1.6042
2023-07-01 21:59:07 - train: epoch 0049, iter [00350, 00390], lr: 0.010000, loss: 1.7593
2023-07-01 21:59:09 - train: epoch 049, train_loss: 1.6760
2023-07-01 21:59:10 - eval: epoch: 049, acc1: 39.190%, acc5: 68.100%, test_loss: 2.5734, per_image_load_time: 0.073ms, per_image_inference_time: 0.088ms
2023-07-01 21:59:12 - until epoch: 049, best_acc1: 39.190%
2023-07-01 21:59:12 - epoch 050 lr: 0.010000
2023-07-01 21:59:15 - train: epoch 0050, iter [00050, 00390], lr: 0.010000, loss: 1.7048
2023-07-01 21:59:17 - train: epoch 0050, iter [00100, 00390], lr: 0.010000, loss: 1.5005
2023-07-01 21:59:20 - train: epoch 0050, iter [00150, 00390], lr: 0.010000, loss: 1.5691
2023-07-01 21:59:22 - train: epoch 0050, iter [00200, 00390], lr: 0.010000, loss: 1.5794
2023-07-01 21:59:24 - train: epoch 0050, iter [00250, 00390], lr: 0.010000, loss: 1.6245
2023-07-01 21:59:27 - train: epoch 0050, iter [00300, 00390], lr: 0.010000, loss: 1.6749
2023-07-01 21:59:29 - train: epoch 0050, iter [00350, 00390], lr: 0.010000, loss: 2.0582
2023-07-01 21:59:31 - train: epoch 050, train_loss: 1.6462
2023-07-01 21:59:33 - eval: epoch: 050, acc1: 38.980%, acc5: 68.180%, test_loss: 2.5565, per_image_load_time: 0.073ms, per_image_inference_time: 0.088ms
2023-07-01 21:59:33 - until epoch: 050, best_acc1: 39.190%
2023-07-01 21:59:33 - epoch 051 lr: 0.010000
2023-07-01 21:59:37 - train: epoch 0051, iter [00050, 00390], lr: 0.010000, loss: 1.7675
2023-07-01 21:59:39 - train: epoch 0051, iter [00100, 00390], lr: 0.010000, loss: 1.4800
2023-07-01 21:59:42 - train: epoch 0051, iter [00150, 00390], lr: 0.010000, loss: 1.5232
2023-07-01 21:59:44 - train: epoch 0051, iter [00200, 00390], lr: 0.010000, loss: 1.7539
2023-07-01 21:59:46 - train: epoch 0051, iter [00250, 00390], lr: 0.010000, loss: 1.7660
2023-07-01 21:59:49 - train: epoch 0051, iter [00300, 00390], lr: 0.010000, loss: 1.4205
2023-07-01 21:59:51 - train: epoch 0051, iter [00350, 00390], lr: 0.010000, loss: 1.7376
2023-07-01 21:59:53 - train: epoch 051, train_loss: 1.6212
2023-07-01 21:59:55 - eval: epoch: 051, acc1: 38.580%, acc5: 68.260%, test_loss: 2.5806, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 21:59:56 - until epoch: 051, best_acc1: 39.190%
2023-07-01 21:59:56 - epoch 052 lr: 0.010000
2023-07-01 21:59:59 - train: epoch 0052, iter [00050, 00390], lr: 0.010000, loss: 1.8202
2023-07-01 22:00:01 - train: epoch 0052, iter [00100, 00390], lr: 0.010000, loss: 1.6425
2023-07-01 22:00:04 - train: epoch 0052, iter [00150, 00390], lr: 0.010000, loss: 1.6558
2023-07-01 22:00:06 - train: epoch 0052, iter [00200, 00390], lr: 0.010000, loss: 1.5805
2023-07-01 22:00:09 - train: epoch 0052, iter [00250, 00390], lr: 0.010000, loss: 1.6907
2023-07-01 22:00:11 - train: epoch 0052, iter [00300, 00390], lr: 0.010000, loss: 1.5342
2023-07-01 22:00:13 - train: epoch 0052, iter [00350, 00390], lr: 0.010000, loss: 1.7686
2023-07-01 22:00:15 - train: epoch 052, train_loss: 1.5797
2023-07-01 22:00:17 - eval: epoch: 052, acc1: 39.700%, acc5: 68.450%, test_loss: 2.5749, per_image_load_time: 0.073ms, per_image_inference_time: 0.088ms
2023-07-01 22:00:18 - until epoch: 052, best_acc1: 39.700%
2023-07-01 22:00:18 - epoch 053 lr: 0.010000
2023-07-01 22:00:22 - train: epoch 0053, iter [00050, 00390], lr: 0.010000, loss: 1.3542
2023-07-01 22:00:24 - train: epoch 0053, iter [00100, 00390], lr: 0.010000, loss: 1.4117
2023-07-01 22:00:26 - train: epoch 0053, iter [00150, 00390], lr: 0.010000, loss: 1.3664
2023-07-01 22:00:29 - train: epoch 0053, iter [00200, 00390], lr: 0.010000, loss: 1.4797
2023-07-01 22:00:31 - train: epoch 0053, iter [00250, 00390], lr: 0.010000, loss: 1.6696
2023-07-01 22:00:33 - train: epoch 0053, iter [00300, 00390], lr: 0.010000, loss: 1.2782
2023-07-01 22:00:36 - train: epoch 0053, iter [00350, 00390], lr: 0.010000, loss: 1.4716
2023-07-01 22:00:38 - train: epoch 053, train_loss: 1.5456
2023-07-01 22:00:40 - eval: epoch: 053, acc1: 39.190%, acc5: 68.360%, test_loss: 2.5988, per_image_load_time: 0.071ms, per_image_inference_time: 0.089ms
2023-07-01 22:00:40 - until epoch: 053, best_acc1: 39.700%
2023-07-01 22:00:40 - epoch 054 lr: 0.010000
2023-07-01 22:00:43 - train: epoch 0054, iter [00050, 00390], lr: 0.010000, loss: 1.4415
2023-07-01 22:00:46 - train: epoch 0054, iter [00100, 00390], lr: 0.010000, loss: 1.4811
2023-07-01 22:00:48 - train: epoch 0054, iter [00150, 00390], lr: 0.010000, loss: 1.3528
2023-07-01 22:00:51 - train: epoch 0054, iter [00200, 00390], lr: 0.010000, loss: 1.7193
2023-07-01 22:00:53 - train: epoch 0054, iter [00250, 00390], lr: 0.010000, loss: 1.4813
2023-07-01 22:00:55 - train: epoch 0054, iter [00300, 00390], lr: 0.010000, loss: 1.3961
2023-07-01 22:00:58 - train: epoch 0054, iter [00350, 00390], lr: 0.010000, loss: 1.3696
2023-07-01 22:01:00 - train: epoch 054, train_loss: 1.5119
2023-07-01 22:01:02 - eval: epoch: 054, acc1: 39.370%, acc5: 67.390%, test_loss: 2.6398, per_image_load_time: 0.073ms, per_image_inference_time: 0.090ms
2023-07-01 22:01:03 - until epoch: 054, best_acc1: 39.700%
2023-07-01 22:01:03 - epoch 055 lr: 0.010000
2023-07-01 22:01:06 - train: epoch 0055, iter [00050, 00390], lr: 0.010000, loss: 1.4002
2023-07-01 22:01:08 - train: epoch 0055, iter [00100, 00390], lr: 0.010000, loss: 1.3365
2023-07-01 22:01:11 - train: epoch 0055, iter [00150, 00390], lr: 0.010000, loss: 1.4227
2023-07-01 22:01:13 - train: epoch 0055, iter [00200, 00390], lr: 0.010000, loss: 1.6386
2023-07-01 22:01:16 - train: epoch 0055, iter [00250, 00390], lr: 0.010000, loss: 1.4618
2023-07-01 22:01:18 - train: epoch 0055, iter [00300, 00390], lr: 0.010000, loss: 1.3030
2023-07-01 22:01:20 - train: epoch 0055, iter [00350, 00390], lr: 0.010000, loss: 1.4148
2023-07-01 22:01:22 - train: epoch 055, train_loss: 1.4881
2023-07-01 22:01:24 - eval: epoch: 055, acc1: 39.120%, acc5: 68.210%, test_loss: 2.6182, per_image_load_time: 0.073ms, per_image_inference_time: 0.088ms
2023-07-01 22:01:25 - until epoch: 055, best_acc1: 39.700%
2023-07-01 22:01:25 - epoch 056 lr: 0.010000
2023-07-01 22:01:28 - train: epoch 0056, iter [00050, 00390], lr: 0.010000, loss: 1.4742
2023-07-01 22:01:30 - train: epoch 0056, iter [00100, 00390], lr: 0.010000, loss: 1.3341
2023-07-01 22:01:33 - train: epoch 0056, iter [00150, 00390], lr: 0.010000, loss: 1.1958
2023-07-01 22:01:35 - train: epoch 0056, iter [00200, 00390], lr: 0.010000, loss: 1.4008
2023-07-01 22:01:38 - train: epoch 0056, iter [00250, 00390], lr: 0.010000, loss: 1.4700
2023-07-01 22:01:40 - train: epoch 0056, iter [00300, 00390], lr: 0.010000, loss: 1.6042
2023-07-01 22:01:42 - train: epoch 0056, iter [00350, 00390], lr: 0.010000, loss: 1.2700
2023-07-01 22:01:44 - train: epoch 056, train_loss: 1.4340
2023-07-01 22:01:46 - eval: epoch: 056, acc1: 39.160%, acc5: 67.570%, test_loss: 2.6563, per_image_load_time: 0.075ms, per_image_inference_time: 0.088ms
2023-07-01 22:01:46 - until epoch: 056, best_acc1: 39.700%
2023-07-01 22:01:46 - epoch 057 lr: 0.010000
2023-07-01 22:01:50 - train: epoch 0057, iter [00050, 00390], lr: 0.010000, loss: 1.3358
2023-07-01 22:01:52 - train: epoch 0057, iter [00100, 00390], lr: 0.010000, loss: 1.4243
2023-07-01 22:01:55 - train: epoch 0057, iter [00150, 00390], lr: 0.010000, loss: 1.2547
2023-07-01 22:01:57 - train: epoch 0057, iter [00200, 00390], lr: 0.010000, loss: 1.4221
2023-07-01 22:01:59 - train: epoch 0057, iter [00250, 00390], lr: 0.010000, loss: 1.6185
2023-07-01 22:02:02 - train: epoch 0057, iter [00300, 00390], lr: 0.010000, loss: 1.4607
2023-07-01 22:02:04 - train: epoch 0057, iter [00350, 00390], lr: 0.010000, loss: 1.5872
2023-07-01 22:02:06 - train: epoch 057, train_loss: 1.4180
2023-07-01 22:02:08 - eval: epoch: 057, acc1: 38.770%, acc5: 67.850%, test_loss: 2.6655, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 22:02:08 - until epoch: 057, best_acc1: 39.700%
2023-07-01 22:02:08 - epoch 058 lr: 0.010000
2023-07-01 22:02:12 - train: epoch 0058, iter [00050, 00390], lr: 0.010000, loss: 1.3491
2023-07-01 22:02:14 - train: epoch 0058, iter [00100, 00390], lr: 0.010000, loss: 1.4432
2023-07-01 22:02:16 - train: epoch 0058, iter [00150, 00390], lr: 0.010000, loss: 1.2972
2023-07-01 22:02:19 - train: epoch 0058, iter [00200, 00390], lr: 0.010000, loss: 1.5275
2023-07-01 22:02:21 - train: epoch 0058, iter [00250, 00390], lr: 0.010000, loss: 1.6307
2023-07-01 22:02:24 - train: epoch 0058, iter [00300, 00390], lr: 0.010000, loss: 1.6111
2023-07-01 22:02:26 - train: epoch 0058, iter [00350, 00390], lr: 0.010000, loss: 1.5707
2023-07-01 22:02:28 - train: epoch 058, train_loss: 1.3800
2023-07-01 22:02:30 - eval: epoch: 058, acc1: 38.960%, acc5: 67.670%, test_loss: 2.7004, per_image_load_time: 0.075ms, per_image_inference_time: 0.089ms
2023-07-01 22:02:30 - until epoch: 058, best_acc1: 39.700%
2023-07-01 22:02:30 - epoch 059 lr: 0.010000
2023-07-01 22:02:33 - train: epoch 0059, iter [00050, 00390], lr: 0.010000, loss: 1.4066
2023-07-01 22:02:36 - train: epoch 0059, iter [00100, 00390], lr: 0.010000, loss: 1.2501
2023-07-01 22:02:38 - train: epoch 0059, iter [00150, 00390], lr: 0.010000, loss: 1.3860
2023-07-01 22:02:41 - train: epoch 0059, iter [00200, 00390], lr: 0.010000, loss: 1.3672
2023-07-01 22:02:43 - train: epoch 0059, iter [00250, 00390], lr: 0.010000, loss: 1.5785
2023-07-01 22:02:45 - train: epoch 0059, iter [00300, 00390], lr: 0.010000, loss: 1.4248
2023-07-01 22:02:48 - train: epoch 0059, iter [00350, 00390], lr: 0.010000, loss: 1.5802
2023-07-01 22:02:50 - train: epoch 059, train_loss: 1.3464
2023-07-01 22:02:52 - eval: epoch: 059, acc1: 38.760%, acc5: 67.120%, test_loss: 2.7138, per_image_load_time: 0.073ms, per_image_inference_time: 0.088ms
2023-07-01 22:02:52 - until epoch: 059, best_acc1: 39.700%
2023-07-01 22:02:52 - epoch 060 lr: 0.010000
2023-07-01 22:02:55 - train: epoch 0060, iter [00050, 00390], lr: 0.010000, loss: 1.2584
2023-07-01 22:02:58 - train: epoch 0060, iter [00100, 00390], lr: 0.010000, loss: 1.1413
2023-07-01 22:03:00 - train: epoch 0060, iter [00150, 00390], lr: 0.010000, loss: 1.1314
2023-07-01 22:03:02 - train: epoch 0060, iter [00200, 00390], lr: 0.010000, loss: 1.1272
2023-07-01 22:03:05 - train: epoch 0060, iter [00250, 00390], lr: 0.010000, loss: 1.2350
2023-07-01 22:03:08 - train: epoch 0060, iter [00300, 00390], lr: 0.010000, loss: 1.1416
2023-07-01 22:03:10 - train: epoch 0060, iter [00350, 00390], lr: 0.010000, loss: 1.3038
2023-07-01 22:03:12 - train: epoch 060, train_loss: 1.3067
2023-07-01 22:03:14 - eval: epoch: 060, acc1: 38.130%, acc5: 67.440%, test_loss: 2.7495, per_image_load_time: 0.073ms, per_image_inference_time: 0.091ms
2023-07-01 22:03:15 - until epoch: 060, best_acc1: 39.700%
2023-07-01 22:03:15 - epoch 061 lr: 0.002000
2023-07-01 22:03:18 - train: epoch 0061, iter [00050, 00390], lr: 0.002000, loss: 0.9559
2023-07-01 22:03:20 - train: epoch 0061, iter [00100, 00390], lr: 0.002000, loss: 1.0333
2023-07-01 22:03:23 - train: epoch 0061, iter [00150, 00390], lr: 0.002000, loss: 0.7931
2023-07-01 22:03:25 - train: epoch 0061, iter [00200, 00390], lr: 0.002000, loss: 1.0414
2023-07-01 22:03:27 - train: epoch 0061, iter [00250, 00390], lr: 0.002000, loss: 0.8028
2023-07-01 22:03:30 - train: epoch 0061, iter [00300, 00390], lr: 0.002000, loss: 0.7700
2023-07-01 22:03:32 - train: epoch 0061, iter [00350, 00390], lr: 0.002000, loss: 0.8357
2023-07-01 22:03:34 - train: epoch 061, train_loss: 0.8749
2023-07-01 22:03:36 - eval: epoch: 061, acc1: 42.550%, acc5: 70.220%, test_loss: 2.5948, per_image_load_time: 0.075ms, per_image_inference_time: 0.090ms
2023-07-01 22:03:37 - until epoch: 061, best_acc1: 42.550%
2023-07-01 22:03:37 - epoch 062 lr: 0.002000
2023-07-01 22:03:40 - train: epoch 0062, iter [00050, 00390], lr: 0.002000, loss: 0.7141
2023-07-01 22:03:43 - train: epoch 0062, iter [00100, 00390], lr: 0.002000, loss: 0.6489
2023-07-01 22:03:45 - train: epoch 0062, iter [00150, 00390], lr: 0.002000, loss: 0.9438
2023-07-01 22:03:48 - train: epoch 0062, iter [00200, 00390], lr: 0.002000, loss: 0.6915
2023-07-01 22:03:50 - train: epoch 0062, iter [00250, 00390], lr: 0.002000, loss: 0.7524
2023-07-01 22:03:53 - train: epoch 0062, iter [00300, 00390], lr: 0.002000, loss: 0.5647
2023-07-01 22:03:55 - train: epoch 0062, iter [00350, 00390], lr: 0.002000, loss: 0.7412
2023-07-01 22:03:57 - train: epoch 062, train_loss: 0.7244
2023-07-01 22:03:59 - eval: epoch: 062, acc1: 42.590%, acc5: 69.790%, test_loss: 2.6458, per_image_load_time: 0.071ms, per_image_inference_time: 0.089ms
2023-07-01 22:03:59 - until epoch: 062, best_acc1: 42.590%
2023-07-01 22:03:59 - epoch 063 lr: 0.002000
2023-07-01 22:04:03 - train: epoch 0063, iter [00050, 00390], lr: 0.002000, loss: 0.7215
2023-07-01 22:04:05 - train: epoch 0063, iter [00100, 00390], lr: 0.002000, loss: 0.6191
2023-07-01 22:04:08 - train: epoch 0063, iter [00150, 00390], lr: 0.002000, loss: 0.5811
2023-07-01 22:04:10 - train: epoch 0063, iter [00200, 00390], lr: 0.002000, loss: 0.6280
2023-07-01 22:04:12 - train: epoch 0063, iter [00250, 00390], lr: 0.002000, loss: 0.6254
2023-07-01 22:04:15 - train: epoch 0063, iter [00300, 00390], lr: 0.002000, loss: 0.6241
2023-07-01 22:04:17 - train: epoch 0063, iter [00350, 00390], lr: 0.002000, loss: 0.6589
2023-07-01 22:04:19 - train: epoch 063, train_loss: 0.6501
2023-07-01 22:04:21 - eval: epoch: 063, acc1: 42.550%, acc5: 69.820%, test_loss: 2.6865, per_image_load_time: 0.071ms, per_image_inference_time: 0.089ms
2023-07-01 22:04:21 - until epoch: 063, best_acc1: 42.590%
2023-07-01 22:04:21 - epoch 064 lr: 0.002000
2023-07-01 22:04:25 - train: epoch 0064, iter [00050, 00390], lr: 0.002000, loss: 0.4786
2023-07-01 22:04:27 - train: epoch 0064, iter [00100, 00390], lr: 0.002000, loss: 0.6587
2023-07-01 22:04:29 - train: epoch 0064, iter [00150, 00390], lr: 0.002000, loss: 0.5591
2023-07-01 22:04:32 - train: epoch 0064, iter [00200, 00390], lr: 0.002000, loss: 0.6498
2023-07-01 22:04:34 - train: epoch 0064, iter [00250, 00390], lr: 0.002000, loss: 0.7808
2023-07-01 22:04:37 - train: epoch 0064, iter [00300, 00390], lr: 0.002000, loss: 0.5580
2023-07-01 22:04:39 - train: epoch 0064, iter [00350, 00390], lr: 0.002000, loss: 0.6435
2023-07-01 22:04:41 - train: epoch 064, train_loss: 0.6157
2023-07-01 22:04:43 - eval: epoch: 064, acc1: 42.850%, acc5: 69.830%, test_loss: 2.7246, per_image_load_time: 0.071ms, per_image_inference_time: 0.089ms
2023-07-01 22:04:44 - until epoch: 064, best_acc1: 42.850%
2023-07-01 22:04:44 - epoch 065 lr: 0.002000
2023-07-01 22:04:47 - train: epoch 0065, iter [00050, 00390], lr: 0.002000, loss: 0.5331
2023-07-01 22:04:49 - train: epoch 0065, iter [00100, 00390], lr: 0.002000, loss: 0.6401
2023-07-01 22:04:52 - train: epoch 0065, iter [00150, 00390], lr: 0.002000, loss: 0.6780
2023-07-01 22:04:54 - train: epoch 0065, iter [00200, 00390], lr: 0.002000, loss: 0.6517
2023-07-01 22:04:56 - train: epoch 0065, iter [00250, 00390], lr: 0.002000, loss: 0.5191
2023-07-01 22:04:59 - train: epoch 0065, iter [00300, 00390], lr: 0.002000, loss: 0.6407
2023-07-01 22:05:01 - train: epoch 0065, iter [00350, 00390], lr: 0.002000, loss: 0.6224
2023-07-01 22:05:03 - train: epoch 065, train_loss: 0.5758
2023-07-01 22:05:05 - eval: epoch: 065, acc1: 42.960%, acc5: 69.700%, test_loss: 2.7570, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 22:05:06 - until epoch: 065, best_acc1: 42.960%
2023-07-01 22:05:06 - epoch 066 lr: 0.002000
2023-07-01 22:05:09 - train: epoch 0066, iter [00050, 00390], lr: 0.002000, loss: 0.4915
2023-07-01 22:05:11 - train: epoch 0066, iter [00100, 00390], lr: 0.002000, loss: 0.5526
2023-07-01 22:05:14 - train: epoch 0066, iter [00150, 00390], lr: 0.002000, loss: 0.5646
2023-07-01 22:05:16 - train: epoch 0066, iter [00200, 00390], lr: 0.002000, loss: 0.6488
2023-07-01 22:05:19 - train: epoch 0066, iter [00250, 00390], lr: 0.002000, loss: 0.6829
2023-07-01 22:05:21 - train: epoch 0066, iter [00300, 00390], lr: 0.002000, loss: 0.5997
2023-07-01 22:05:23 - train: epoch 0066, iter [00350, 00390], lr: 0.002000, loss: 0.6060
2023-07-01 22:05:25 - train: epoch 066, train_loss: 0.5443
2023-07-01 22:05:27 - eval: epoch: 066, acc1: 42.860%, acc5: 69.600%, test_loss: 2.8094, per_image_load_time: 0.072ms, per_image_inference_time: 0.090ms
2023-07-01 22:05:29 - until epoch: 066, best_acc1: 42.960%
2023-07-01 22:05:29 - epoch 067 lr: 0.002000
2023-07-01 22:05:32 - train: epoch 0067, iter [00050, 00390], lr: 0.002000, loss: 0.5531
2023-07-01 22:05:35 - train: epoch 0067, iter [00100, 00390], lr: 0.002000, loss: 0.5476
2023-07-01 22:05:37 - train: epoch 0067, iter [00150, 00390], lr: 0.002000, loss: 0.4558
2023-07-01 22:05:39 - train: epoch 0067, iter [00200, 00390], lr: 0.002000, loss: 0.4442
2023-07-01 22:05:42 - train: epoch 0067, iter [00250, 00390], lr: 0.002000, loss: 0.4585
2023-07-01 22:05:44 - train: epoch 0067, iter [00300, 00390], lr: 0.002000, loss: 0.4233
2023-07-01 22:05:47 - train: epoch 0067, iter [00350, 00390], lr: 0.002000, loss: 0.3572
2023-07-01 22:05:49 - train: epoch 067, train_loss: 0.5210
2023-07-01 22:05:51 - eval: epoch: 067, acc1: 42.900%, acc5: 69.480%, test_loss: 2.8495, per_image_load_time: 0.071ms, per_image_inference_time: 0.089ms
2023-07-01 22:05:51 - until epoch: 067, best_acc1: 42.960%
2023-07-01 22:05:51 - epoch 068 lr: 0.002000
2023-07-01 22:05:54 - train: epoch 0068, iter [00050, 00390], lr: 0.002000, loss: 0.3769
2023-07-01 22:05:57 - train: epoch 0068, iter [00100, 00390], lr: 0.002000, loss: 0.4375
2023-07-01 22:05:59 - train: epoch 0068, iter [00150, 00390], lr: 0.002000, loss: 0.5640
2023-07-01 22:06:02 - train: epoch 0068, iter [00200, 00390], lr: 0.002000, loss: 0.5215
2023-07-01 22:06:04 - train: epoch 0068, iter [00250, 00390], lr: 0.002000, loss: 0.4781
2023-07-01 22:06:07 - train: epoch 0068, iter [00300, 00390], lr: 0.002000, loss: 0.4995
2023-07-01 22:06:09 - train: epoch 0068, iter [00350, 00390], lr: 0.002000, loss: 0.4444
2023-07-01 22:06:11 - train: epoch 068, train_loss: 0.4978
2023-07-01 22:06:13 - eval: epoch: 068, acc1: 42.200%, acc5: 68.890%, test_loss: 2.8865, per_image_load_time: 0.071ms, per_image_inference_time: 0.089ms
2023-07-01 22:06:13 - until epoch: 068, best_acc1: 42.960%
2023-07-01 22:06:13 - epoch 069 lr: 0.002000
2023-07-01 22:06:16 - train: epoch 0069, iter [00050, 00390], lr: 0.002000, loss: 0.4491
2023-07-01 22:06:19 - train: epoch 0069, iter [00100, 00390], lr: 0.002000, loss: 0.3246
2023-07-01 22:06:21 - train: epoch 0069, iter [00150, 00390], lr: 0.002000, loss: 0.5916
2023-07-01 22:06:23 - train: epoch 0069, iter [00200, 00390], lr: 0.002000, loss: 0.5305
2023-07-01 22:06:26 - train: epoch 0069, iter [00250, 00390], lr: 0.002000, loss: 0.7268
2023-07-01 22:06:28 - train: epoch 0069, iter [00300, 00390], lr: 0.002000, loss: 0.6022
2023-07-01 22:06:31 - train: epoch 0069, iter [00350, 00390], lr: 0.002000, loss: 0.5332
2023-07-01 22:06:33 - train: epoch 069, train_loss: 0.4725
2023-07-01 22:06:35 - eval: epoch: 069, acc1: 42.420%, acc5: 69.420%, test_loss: 2.9083, per_image_load_time: 0.070ms, per_image_inference_time: 0.095ms
2023-07-01 22:06:35 - until epoch: 069, best_acc1: 42.960%
2023-07-01 22:06:35 - epoch 070 lr: 0.002000
2023-07-01 22:06:38 - train: epoch 0070, iter [00050, 00390], lr: 0.002000, loss: 0.4347
2023-07-01 22:06:41 - train: epoch 0070, iter [00100, 00390], lr: 0.002000, loss: 0.4582
2023-07-01 22:06:43 - train: epoch 0070, iter [00150, 00390], lr: 0.002000, loss: 0.4749
2023-07-01 22:06:45 - train: epoch 0070, iter [00200, 00390], lr: 0.002000, loss: 0.4627
2023-07-01 22:06:48 - train: epoch 0070, iter [00250, 00390], lr: 0.002000, loss: 0.3676
2023-07-01 22:06:50 - train: epoch 0070, iter [00300, 00390], lr: 0.002000, loss: 0.5006
2023-07-01 22:06:53 - train: epoch 0070, iter [00350, 00390], lr: 0.002000, loss: 0.4310
2023-07-01 22:06:54 - train: epoch 070, train_loss: 0.4458
2023-07-01 22:06:56 - eval: epoch: 070, acc1: 42.580%, acc5: 69.100%, test_loss: 2.9433, per_image_load_time: 0.071ms, per_image_inference_time: 0.090ms
2023-07-01 22:06:57 - until epoch: 070, best_acc1: 42.960%
2023-07-01 22:06:57 - epoch 071 lr: 0.002000
2023-07-01 22:07:00 - train: epoch 0071, iter [00050, 00390], lr: 0.002000, loss: 0.4799
2023-07-01 22:07:02 - train: epoch 0071, iter [00100, 00390], lr: 0.002000, loss: 0.4086
2023-07-01 22:07:05 - train: epoch 0071, iter [00150, 00390], lr: 0.002000, loss: 0.4951
2023-07-01 22:07:07 - train: epoch 0071, iter [00200, 00390], lr: 0.002000, loss: 0.3157
2023-07-01 22:07:10 - train: epoch 0071, iter [00250, 00390], lr: 0.002000, loss: 0.6050
2023-07-01 22:07:12 - train: epoch 0071, iter [00300, 00390], lr: 0.002000, loss: 0.4408
2023-07-01 22:07:15 - train: epoch 0071, iter [00350, 00390], lr: 0.002000, loss: 0.3675
2023-07-01 22:07:17 - train: epoch 071, train_loss: 0.4349
2023-07-01 22:07:19 - eval: epoch: 071, acc1: 42.200%, acc5: 68.970%, test_loss: 2.9929, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 22:07:19 - until epoch: 071, best_acc1: 42.960%
2023-07-01 22:07:19 - epoch 072 lr: 0.002000
2023-07-01 22:07:22 - train: epoch 0072, iter [00050, 00390], lr: 0.002000, loss: 0.2638
2023-07-01 22:07:24 - train: epoch 0072, iter [00100, 00390], lr: 0.002000, loss: 0.3346
2023-07-01 22:07:27 - train: epoch 0072, iter [00150, 00390], lr: 0.002000, loss: 0.4351
2023-07-01 22:07:29 - train: epoch 0072, iter [00200, 00390], lr: 0.002000, loss: 0.3115
2023-07-01 22:07:32 - train: epoch 0072, iter [00250, 00390], lr: 0.002000, loss: 0.3180
2023-07-01 22:07:34 - train: epoch 0072, iter [00300, 00390], lr: 0.002000, loss: 0.4435
2023-07-01 22:07:36 - train: epoch 0072, iter [00350, 00390], lr: 0.002000, loss: 0.4774
2023-07-01 22:07:38 - train: epoch 072, train_loss: 0.4144
2023-07-01 22:07:40 - eval: epoch: 072, acc1: 41.940%, acc5: 68.960%, test_loss: 3.0134, per_image_load_time: 0.072ms, per_image_inference_time: 0.090ms
2023-07-01 22:07:41 - until epoch: 072, best_acc1: 42.960%
2023-07-01 22:07:41 - epoch 073 lr: 0.002000
2023-07-01 22:07:44 - train: epoch 0073, iter [00050, 00390], lr: 0.002000, loss: 0.3702
2023-07-01 22:07:46 - train: epoch 0073, iter [00100, 00390], lr: 0.002000, loss: 0.3577
2023-07-01 22:07:49 - train: epoch 0073, iter [00150, 00390], lr: 0.002000, loss: 0.3294
2023-07-01 22:07:51 - train: epoch 0073, iter [00200, 00390], lr: 0.002000, loss: 0.4252
2023-07-01 22:07:53 - train: epoch 0073, iter [00250, 00390], lr: 0.002000, loss: 0.4770
2023-07-01 22:07:56 - train: epoch 0073, iter [00300, 00390], lr: 0.002000, loss: 0.3740
2023-07-01 22:07:58 - train: epoch 0073, iter [00350, 00390], lr: 0.002000, loss: 0.3051
2023-07-01 22:08:00 - train: epoch 073, train_loss: 0.3947
2023-07-01 22:08:02 - eval: epoch: 073, acc1: 42.040%, acc5: 69.330%, test_loss: 3.0365, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 22:08:02 - until epoch: 073, best_acc1: 42.960%
2023-07-01 22:08:02 - epoch 074 lr: 0.002000
2023-07-01 22:08:06 - train: epoch 0074, iter [00050, 00390], lr: 0.002000, loss: 0.4053
2023-07-01 22:08:08 - train: epoch 0074, iter [00100, 00390], lr: 0.002000, loss: 0.3427
2023-07-01 22:08:10 - train: epoch 0074, iter [00150, 00390], lr: 0.002000, loss: 0.3414
2023-07-01 22:08:13 - train: epoch 0074, iter [00200, 00390], lr: 0.002000, loss: 0.4150
2023-07-01 22:08:15 - train: epoch 0074, iter [00250, 00390], lr: 0.002000, loss: 0.3630
2023-07-01 22:08:18 - train: epoch 0074, iter [00300, 00390], lr: 0.002000, loss: 0.4334
2023-07-01 22:08:20 - train: epoch 0074, iter [00350, 00390], lr: 0.002000, loss: 0.4319
2023-07-01 22:08:22 - train: epoch 074, train_loss: 0.3814
2023-07-01 22:08:24 - eval: epoch: 074, acc1: 41.960%, acc5: 68.790%, test_loss: 3.0644, per_image_load_time: 0.073ms, per_image_inference_time: 0.089ms
2023-07-01 22:08:24 - until epoch: 074, best_acc1: 42.960%
2023-07-01 22:08:24 - epoch 075 lr: 0.002000
2023-07-01 22:08:28 - train: epoch 0075, iter [00050, 00390], lr: 0.002000, loss: 0.4393
2023-07-01 22:08:30 - train: epoch 0075, iter [00100, 00390], lr: 0.002000, loss: 0.3433
2023-07-01 22:08:32 - train: epoch 0075, iter [00150, 00390], lr: 0.002000, loss: 0.4464
2023-07-01 22:08:35 - train: epoch 0075, iter [00200, 00390], lr: 0.002000, loss: 0.4269
2023-07-01 22:08:37 - train: epoch 0075, iter [00250, 00390], lr: 0.002000, loss: 0.4670
2023-07-01 22:08:40 - train: epoch 0075, iter [00300, 00390], lr: 0.002000, loss: 0.3461
2023-07-01 22:08:42 - train: epoch 0075, iter [00350, 00390], lr: 0.002000, loss: 0.4408
2023-07-01 22:08:44 - train: epoch 075, train_loss: 0.3721
2023-07-01 22:08:46 - eval: epoch: 075, acc1: 41.690%, acc5: 68.950%, test_loss: 3.0966, per_image_load_time: 0.073ms, per_image_inference_time: 0.087ms
2023-07-01 22:08:46 - until epoch: 075, best_acc1: 42.960%
2023-07-01 22:08:46 - epoch 076 lr: 0.002000
2023-07-01 22:08:49 - train: epoch 0076, iter [00050, 00390], lr: 0.002000, loss: 0.2667
2023-07-01 22:08:52 - train: epoch 0076, iter [00100, 00390], lr: 0.002000, loss: 0.4133
2023-07-01 22:08:54 - train: epoch 0076, iter [00150, 00390], lr: 0.002000, loss: 0.2843
2023-07-01 22:08:57 - train: epoch 0076, iter [00200, 00390], lr: 0.002000, loss: 0.4044
2023-07-01 22:08:59 - train: epoch 0076, iter [00250, 00390], lr: 0.002000, loss: 0.3205
2023-07-01 22:09:02 - train: epoch 0076, iter [00300, 00390], lr: 0.002000, loss: 0.2710
2023-07-01 22:09:04 - train: epoch 0076, iter [00350, 00390], lr: 0.002000, loss: 0.3983
2023-07-01 22:09:06 - train: epoch 076, train_loss: 0.3605
2023-07-01 22:09:08 - eval: epoch: 076, acc1: 41.820%, acc5: 68.760%, test_loss: 3.1268, per_image_load_time: 0.070ms, per_image_inference_time: 0.088ms
2023-07-01 22:09:08 - until epoch: 076, best_acc1: 42.960%
2023-07-01 22:09:08 - epoch 077 lr: 0.002000
2023-07-01 22:09:11 - train: epoch 0077, iter [00050, 00390], lr: 0.002000, loss: 0.2498
2023-07-01 22:09:14 - train: epoch 0077, iter [00100, 00390], lr: 0.002000, loss: 0.3467
2023-07-01 22:09:17 - train: epoch 0077, iter [00150, 00390], lr: 0.002000, loss: 0.3836
2023-07-01 22:09:20 - train: epoch 0077, iter [00200, 00390], lr: 0.002000, loss: 0.4142
2023-07-01 22:09:23 - train: epoch 0077, iter [00250, 00390], lr: 0.002000, loss: 0.3438
2023-07-01 22:09:25 - train: epoch 0077, iter [00300, 00390], lr: 0.002000, loss: 0.4774
2023-07-01 22:09:27 - train: epoch 0077, iter [00350, 00390], lr: 0.002000, loss: 0.4528
2023-07-01 22:09:29 - train: epoch 077, train_loss: 0.3412
2023-07-01 22:09:31 - eval: epoch: 077, acc1: 41.910%, acc5: 68.740%, test_loss: 3.1413, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 22:09:32 - until epoch: 077, best_acc1: 42.960%
2023-07-01 22:09:32 - epoch 078 lr: 0.002000
2023-07-01 22:09:35 - train: epoch 0078, iter [00050, 00390], lr: 0.002000, loss: 0.3409
2023-07-01 22:09:37 - train: epoch 0078, iter [00100, 00390], lr: 0.002000, loss: 0.3116
2023-07-01 22:09:40 - train: epoch 0078, iter [00150, 00390], lr: 0.002000, loss: 0.5107
2023-07-01 22:09:42 - train: epoch 0078, iter [00200, 00390], lr: 0.002000, loss: 0.3511
2023-07-01 22:09:44 - train: epoch 0078, iter [00250, 00390], lr: 0.002000, loss: 0.2633
2023-07-01 22:09:47 - train: epoch 0078, iter [00300, 00390], lr: 0.002000, loss: 0.4214
2023-07-01 22:09:49 - train: epoch 0078, iter [00350, 00390], lr: 0.002000, loss: 0.3176
2023-07-01 22:09:51 - train: epoch 078, train_loss: 0.3305
2023-07-01 22:09:53 - eval: epoch: 078, acc1: 41.980%, acc5: 69.160%, test_loss: 3.1853, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 22:09:53 - until epoch: 078, best_acc1: 42.960%
2023-07-01 22:09:53 - epoch 079 lr: 0.002000
2023-07-01 22:09:57 - train: epoch 0079, iter [00050, 00390], lr: 0.002000, loss: 0.2701
2023-07-01 22:09:59 - train: epoch 0079, iter [00100, 00390], lr: 0.002000, loss: 0.3158
2023-07-01 22:10:01 - train: epoch 0079, iter [00150, 00390], lr: 0.002000, loss: 0.2896
2023-07-01 22:10:04 - train: epoch 0079, iter [00200, 00390], lr: 0.002000, loss: 0.3153
2023-07-01 22:10:06 - train: epoch 0079, iter [00250, 00390], lr: 0.002000, loss: 0.4143
2023-07-01 22:10:09 - train: epoch 0079, iter [00300, 00390], lr: 0.002000, loss: 0.4571
2023-07-01 22:10:11 - train: epoch 0079, iter [00350, 00390], lr: 0.002000, loss: 0.3746
2023-07-01 22:10:13 - train: epoch 079, train_loss: 0.3247
2023-07-01 22:10:15 - eval: epoch: 079, acc1: 41.920%, acc5: 68.750%, test_loss: 3.2014, per_image_load_time: 0.070ms, per_image_inference_time: 0.088ms
2023-07-01 22:10:15 - until epoch: 079, best_acc1: 42.960%
2023-07-01 22:10:15 - epoch 080 lr: 0.002000
2023-07-01 22:10:18 - train: epoch 0080, iter [00050, 00390], lr: 0.002000, loss: 0.3664
2023-07-01 22:10:21 - train: epoch 0080, iter [00100, 00390], lr: 0.002000, loss: 0.2037
2023-07-01 22:10:23 - train: epoch 0080, iter [00150, 00390], lr: 0.002000, loss: 0.2555
2023-07-01 22:10:26 - train: epoch 0080, iter [00200, 00390], lr: 0.002000, loss: 0.3158
2023-07-01 22:10:28 - train: epoch 0080, iter [00250, 00390], lr: 0.002000, loss: 0.2476
2023-07-01 22:10:31 - train: epoch 0080, iter [00300, 00390], lr: 0.002000, loss: 0.4098
2023-07-01 22:10:33 - train: epoch 0080, iter [00350, 00390], lr: 0.002000, loss: 0.5348
2023-07-01 22:10:35 - train: epoch 080, train_loss: 0.3068
2023-07-01 22:10:37 - eval: epoch: 080, acc1: 41.530%, acc5: 68.150%, test_loss: 3.2507, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 22:10:39 - until epoch: 080, best_acc1: 42.960%
2023-07-01 22:10:39 - epoch 081 lr: 0.002000
2023-07-01 22:10:42 - train: epoch 0081, iter [00050, 00390], lr: 0.002000, loss: 0.2996
2023-07-01 22:10:44 - train: epoch 0081, iter [00100, 00390], lr: 0.002000, loss: 0.2407
2023-07-01 22:10:47 - train: epoch 0081, iter [00150, 00390], lr: 0.002000, loss: 0.3283
2023-07-01 22:10:49 - train: epoch 0081, iter [00200, 00390], lr: 0.002000, loss: 0.2711
2023-07-01 22:10:52 - train: epoch 0081, iter [00250, 00390], lr: 0.002000, loss: 0.3161
2023-07-01 22:10:54 - train: epoch 0081, iter [00300, 00390], lr: 0.002000, loss: 0.2931
2023-07-01 22:10:56 - train: epoch 0081, iter [00350, 00390], lr: 0.002000, loss: 0.3181
2023-07-01 22:10:58 - train: epoch 081, train_loss: 0.2986
2023-07-01 22:11:00 - eval: epoch: 081, acc1: 41.920%, acc5: 68.670%, test_loss: 3.2607, per_image_load_time: 0.071ms, per_image_inference_time: 0.088ms
2023-07-01 22:11:00 - until epoch: 081, best_acc1: 42.960%
2023-07-01 22:11:00 - epoch 082 lr: 0.002000
2023-07-01 22:11:04 - train: epoch 0082, iter [00050, 00390], lr: 0.002000, loss: 0.2509
2023-07-01 22:11:06 - train: epoch 0082, iter [00100, 00390], lr: 0.002000, loss: 0.3478
2023-07-01 22:11:09 - train: epoch 0082, iter [00150, 00390], lr: 0.002000, loss: 0.3416
2023-07-01 22:11:11 - train: epoch 0082, iter [00200, 00390], lr: 0.002000, loss: 0.2440
2023-07-01 22:11:14 - train: epoch 0082, iter [00250, 00390], lr: 0.002000, loss: 0.3677
2023-07-01 22:11:16 - train: epoch 0082, iter [00300, 00390], lr: 0.002000, loss: 0.3141
2023-07-01 22:11:18 - train: epoch 0082, iter [00350, 00390], lr: 0.002000, loss: 0.2793
2023-07-01 22:11:20 - train: epoch 082, train_loss: 0.2899
2023-07-01 22:11:22 - eval: epoch: 082, acc1: 41.510%, acc5: 68.520%, test_loss: 3.2762, per_image_load_time: 0.070ms, per_image_inference_time: 0.095ms
2023-07-01 22:11:22 - until epoch: 082, best_acc1: 42.960%
2023-07-01 22:11:22 - epoch 083 lr: 0.002000
2023-07-01 22:11:26 - train: epoch 0083, iter [00050, 00390], lr: 0.002000, loss: 0.2392
2023-07-01 22:11:28 - train: epoch 0083, iter [00100, 00390], lr: 0.002000, loss: 0.3163
2023-07-01 22:11:31 - train: epoch 0083, iter [00150, 00390], lr: 0.002000, loss: 0.3624
2023-07-01 22:11:33 - train: epoch 0083, iter [00200, 00390], lr: 0.002000, loss: 0.2895
2023-07-01 22:11:35 - train: epoch 0083, iter [00250, 00390], lr: 0.002000, loss: 0.2517
2023-07-01 22:11:38 - train: epoch 0083, iter [00300, 00390], lr: 0.002000, loss: 0.2921
2023-07-01 22:11:40 - train: epoch 0083, iter [00350, 00390], lr: 0.002000, loss: 0.2818
2023-07-01 22:11:42 - train: epoch 083, train_loss: 0.2784
2023-07-01 22:11:44 - eval: epoch: 083, acc1: 41.770%, acc5: 68.720%, test_loss: 3.3144, per_image_load_time: 0.073ms, per_image_inference_time: 0.089ms
2023-07-01 22:11:44 - until epoch: 083, best_acc1: 42.960%
2023-07-01 22:11:44 - epoch 084 lr: 0.002000
2023-07-01 22:11:48 - train: epoch 0084, iter [00050, 00390], lr: 0.002000, loss: 0.3373
2023-07-01 22:11:50 - train: epoch 0084, iter [00100, 00390], lr: 0.002000, loss: 0.3140
2023-07-01 22:11:52 - train: epoch 0084, iter [00150, 00390], lr: 0.002000, loss: 0.1896
2023-07-01 22:11:55 - train: epoch 0084, iter [00200, 00390], lr: 0.002000, loss: 0.2501
2023-07-01 22:11:57 - train: epoch 0084, iter [00250, 00390], lr: 0.002000, loss: 0.3259
2023-07-01 22:12:00 - train: epoch 0084, iter [00300, 00390], lr: 0.002000, loss: 0.2987
2023-07-01 22:12:02 - train: epoch 0084, iter [00350, 00390], lr: 0.002000, loss: 0.2221
2023-07-01 22:12:04 - train: epoch 084, train_loss: 0.2729
2023-07-01 22:12:06 - eval: epoch: 084, acc1: 41.000%, acc5: 68.720%, test_loss: 3.3339, per_image_load_time: 0.072ms, per_image_inference_time: 0.092ms
2023-07-01 22:12:07 - until epoch: 084, best_acc1: 42.960%
2023-07-01 22:12:07 - epoch 085 lr: 0.002000
2023-07-01 22:12:10 - train: epoch 0085, iter [00050, 00390], lr: 0.002000, loss: 0.2429
2023-07-01 22:12:12 - train: epoch 0085, iter [00100, 00390], lr: 0.002000, loss: 0.2040
2023-07-01 22:12:15 - train: epoch 0085, iter [00150, 00390], lr: 0.002000, loss: 0.2529
2023-07-01 22:12:17 - train: epoch 0085, iter [00200, 00390], lr: 0.002000, loss: 0.3290
2023-07-01 22:12:20 - train: epoch 0085, iter [00250, 00390], lr: 0.002000, loss: 0.3501
2023-07-01 22:12:22 - train: epoch 0085, iter [00300, 00390], lr: 0.002000, loss: 0.2516
2023-07-01 22:12:24 - train: epoch 0085, iter [00350, 00390], lr: 0.002000, loss: 0.2153
2023-07-01 22:12:26 - train: epoch 085, train_loss: 0.2692
2023-07-01 22:12:28 - eval: epoch: 085, acc1: 41.310%, acc5: 68.100%, test_loss: 3.3770, per_image_load_time: 0.072ms, per_image_inference_time: 0.087ms
2023-07-01 22:12:29 - until epoch: 085, best_acc1: 42.960%
2023-07-01 22:12:29 - epoch 086 lr: 0.002000
2023-07-01 22:12:32 - train: epoch 0086, iter [00050, 00390], lr: 0.002000, loss: 0.1928
2023-07-01 22:12:35 - train: epoch 0086, iter [00100, 00390], lr: 0.002000, loss: 0.1700
2023-07-01 22:12:37 - train: epoch 0086, iter [00150, 00390], lr: 0.002000, loss: 0.2458
2023-07-01 22:12:39 - train: epoch 0086, iter [00200, 00390], lr: 0.002000, loss: 0.2575
2023-07-01 22:12:42 - train: epoch 0086, iter [00250, 00390], lr: 0.002000, loss: 0.2603
2023-07-01 22:12:44 - train: epoch 0086, iter [00300, 00390], lr: 0.002000, loss: 0.3000
2023-07-01 22:12:47 - train: epoch 0086, iter [00350, 00390], lr: 0.002000, loss: 0.4064
2023-07-01 22:12:49 - train: epoch 086, train_loss: 0.2607
2023-07-01 22:12:51 - eval: epoch: 086, acc1: 41.740%, acc5: 68.230%, test_loss: 3.3666, per_image_load_time: 0.075ms, per_image_inference_time: 0.088ms
2023-07-01 22:12:51 - until epoch: 086, best_acc1: 42.960%
2023-07-01 22:12:51 - epoch 087 lr: 0.002000
2023-07-01 22:12:54 - train: epoch 0087, iter [00050, 00390], lr: 0.002000, loss: 0.1987
2023-07-01 22:12:57 - train: epoch 0087, iter [00100, 00390], lr: 0.002000, loss: 0.1961
2023-07-01 22:12:59 - train: epoch 0087, iter [00150, 00390], lr: 0.002000, loss: 0.1649
2023-07-01 22:13:01 - train: epoch 0087, iter [00200, 00390], lr: 0.002000, loss: 0.2562
2023-07-01 22:13:04 - train: epoch 0087, iter [00250, 00390], lr: 0.002000, loss: 0.2214
2023-07-01 22:13:06 - train: epoch 0087, iter [00300, 00390], lr: 0.002000, loss: 0.2724
2023-07-01 22:13:08 - train: epoch 0087, iter [00350, 00390], lr: 0.002000, loss: 0.2394
2023-07-01 22:13:11 - train: epoch 087, train_loss: 0.2539
2023-07-01 22:13:12 - eval: epoch: 087, acc1: 41.610%, acc5: 68.170%, test_loss: 3.3800, per_image_load_time: 0.074ms, per_image_inference_time: 0.087ms
2023-07-01 22:13:13 - until epoch: 087, best_acc1: 42.960%
2023-07-01 22:13:13 - epoch 088 lr: 0.002000
2023-07-01 22:13:16 - train: epoch 0088, iter [00050, 00390], lr: 0.002000, loss: 0.2485
2023-07-01 22:13:18 - train: epoch 0088, iter [00100, 00390], lr: 0.002000, loss: 0.3496
2023-07-01 22:13:21 - train: epoch 0088, iter [00150, 00390], lr: 0.002000, loss: 0.2464
2023-07-01 22:13:23 - train: epoch 0088, iter [00200, 00390], lr: 0.002000, loss: 0.1998
2023-07-01 22:13:26 - train: epoch 0088, iter [00250, 00390], lr: 0.002000, loss: 0.2905
2023-07-01 22:13:28 - train: epoch 0088, iter [00300, 00390], lr: 0.002000, loss: 0.3221
2023-07-01 22:13:30 - train: epoch 0088, iter [00350, 00390], lr: 0.002000, loss: 0.3471
2023-07-01 22:13:32 - train: epoch 088, train_loss: 0.2554
2023-07-01 22:13:34 - eval: epoch: 088, acc1: 41.240%, acc5: 68.320%, test_loss: 3.3970, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 22:13:34 - until epoch: 088, best_acc1: 42.960%
2023-07-01 22:13:34 - epoch 089 lr: 0.002000
2023-07-01 22:13:38 - train: epoch 0089, iter [00050, 00390], lr: 0.002000, loss: 0.2607
2023-07-01 22:13:40 - train: epoch 0089, iter [00100, 00390], lr: 0.002000, loss: 0.2417
2023-07-01 22:13:42 - train: epoch 0089, iter [00150, 00390], lr: 0.002000, loss: 0.2509
2023-07-01 22:13:45 - train: epoch 0089, iter [00200, 00390], lr: 0.002000, loss: 0.2101
2023-07-01 22:13:47 - train: epoch 0089, iter [00250, 00390], lr: 0.002000, loss: 0.2926
2023-07-01 22:13:49 - train: epoch 0089, iter [00300, 00390], lr: 0.002000, loss: 0.2276
2023-07-01 22:13:52 - train: epoch 0089, iter [00350, 00390], lr: 0.002000, loss: 0.3331
2023-07-01 22:13:54 - train: epoch 089, train_loss: 0.2476
2023-07-01 22:13:56 - eval: epoch: 089, acc1: 41.300%, acc5: 67.790%, test_loss: 3.4323, per_image_load_time: 0.075ms, per_image_inference_time: 0.089ms
2023-07-01 22:13:56 - until epoch: 089, best_acc1: 42.960%
2023-07-01 22:13:56 - epoch 090 lr: 0.002000
2023-07-01 22:13:59 - train: epoch 0090, iter [00050, 00390], lr: 0.002000, loss: 0.2087
2023-07-01 22:14:02 - train: epoch 0090, iter [00100, 00390], lr: 0.002000, loss: 0.2158
2023-07-01 22:14:04 - train: epoch 0090, iter [00150, 00390], lr: 0.002000, loss: 0.1877
2023-07-01 22:14:06 - train: epoch 0090, iter [00200, 00390], lr: 0.002000, loss: 0.2559
2023-07-01 22:14:09 - train: epoch 0090, iter [00250, 00390], lr: 0.002000, loss: 0.1431
2023-07-01 22:14:11 - train: epoch 0090, iter [00300, 00390], lr: 0.002000, loss: 0.2419
2023-07-01 22:14:14 - train: epoch 0090, iter [00350, 00390], lr: 0.002000, loss: 0.2073
2023-07-01 22:14:16 - train: epoch 090, train_loss: 0.2373
2023-07-01 22:14:17 - eval: epoch: 090, acc1: 41.510%, acc5: 68.100%, test_loss: 3.4395, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 22:14:18 - until epoch: 090, best_acc1: 42.960%
2023-07-01 22:14:18 - epoch 091 lr: 0.002000
2023-07-01 22:14:21 - train: epoch 0091, iter [00050, 00390], lr: 0.002000, loss: 0.1612
2023-07-01 22:14:23 - train: epoch 0091, iter [00100, 00390], lr: 0.002000, loss: 0.1792
2023-07-01 22:14:26 - train: epoch 0091, iter [00150, 00390], lr: 0.002000, loss: 0.2082
2023-07-01 22:14:28 - train: epoch 0091, iter [00200, 00390], lr: 0.002000, loss: 0.1490
2023-07-01 22:14:31 - train: epoch 0091, iter [00250, 00390], lr: 0.002000, loss: 0.2483
2023-07-01 22:14:33 - train: epoch 0091, iter [00300, 00390], lr: 0.002000, loss: 0.3080
2023-07-01 22:14:36 - train: epoch 0091, iter [00350, 00390], lr: 0.002000, loss: 0.1246
2023-07-01 22:14:38 - train: epoch 091, train_loss: 0.2257
2023-07-01 22:14:39 - eval: epoch: 091, acc1: 41.180%, acc5: 67.280%, test_loss: 3.4747, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 22:14:40 - until epoch: 091, best_acc1: 42.960%
2023-07-01 22:14:40 - epoch 092 lr: 0.002000
2023-07-01 22:14:43 - train: epoch 0092, iter [00050, 00390], lr: 0.002000, loss: 0.2665
2023-07-01 22:14:45 - train: epoch 0092, iter [00100, 00390], lr: 0.002000, loss: 0.1765
2023-07-01 22:14:48 - train: epoch 0092, iter [00150, 00390], lr: 0.002000, loss: 0.1604
2023-07-01 22:14:50 - train: epoch 0092, iter [00200, 00390], lr: 0.002000, loss: 0.1867
2023-07-01 22:14:53 - train: epoch 0092, iter [00250, 00390], lr: 0.002000, loss: 0.1656
2023-07-01 22:14:55 - train: epoch 0092, iter [00300, 00390], lr: 0.002000, loss: 0.2032
2023-07-01 22:14:57 - train: epoch 0092, iter [00350, 00390], lr: 0.002000, loss: 0.2200
2023-07-01 22:14:59 - train: epoch 092, train_loss: 0.2265
2023-07-01 22:15:01 - eval: epoch: 092, acc1: 40.880%, acc5: 67.850%, test_loss: 3.4818, per_image_load_time: 0.075ms, per_image_inference_time: 0.088ms
2023-07-01 22:15:02 - until epoch: 092, best_acc1: 42.960%
2023-07-01 22:15:02 - epoch 093 lr: 0.002000
2023-07-01 22:15:05 - train: epoch 0093, iter [00050, 00390], lr: 0.002000, loss: 0.2740
2023-07-01 22:15:07 - train: epoch 0093, iter [00100, 00390], lr: 0.002000, loss: 0.1792
2023-07-01 22:15:10 - train: epoch 0093, iter [00150, 00390], lr: 0.002000, loss: 0.2779
2023-07-01 22:15:12 - train: epoch 0093, iter [00200, 00390], lr: 0.002000, loss: 0.2037
2023-07-01 22:15:14 - train: epoch 0093, iter [00250, 00390], lr: 0.002000, loss: 0.2012
2023-07-01 22:15:17 - train: epoch 0093, iter [00300, 00390], lr: 0.002000, loss: 0.2018
2023-07-01 22:15:19 - train: epoch 0093, iter [00350, 00390], lr: 0.002000, loss: 0.2160
2023-07-01 22:15:21 - train: epoch 093, train_loss: 0.2208
2023-07-01 22:15:23 - eval: epoch: 093, acc1: 41.310%, acc5: 67.870%, test_loss: 3.4809, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 22:15:23 - until epoch: 093, best_acc1: 42.960%
2023-07-01 22:15:23 - epoch 094 lr: 0.002000
2023-07-01 22:15:27 - train: epoch 0094, iter [00050, 00390], lr: 0.002000, loss: 0.1662
2023-07-01 22:15:29 - train: epoch 0094, iter [00100, 00390], lr: 0.002000, loss: 0.1456
2023-07-01 22:15:31 - train: epoch 0094, iter [00150, 00390], lr: 0.002000, loss: 0.2228
2023-07-01 22:15:34 - train: epoch 0094, iter [00200, 00390], lr: 0.002000, loss: 0.1823
2023-07-01 22:15:36 - train: epoch 0094, iter [00250, 00390], lr: 0.002000, loss: 0.1844
2023-07-01 22:15:39 - train: epoch 0094, iter [00300, 00390], lr: 0.002000, loss: 0.1347
2023-07-01 22:15:41 - train: epoch 0094, iter [00350, 00390], lr: 0.002000, loss: 0.2527
2023-07-01 22:15:43 - train: epoch 094, train_loss: 0.2140
2023-07-01 22:15:45 - eval: epoch: 094, acc1: 41.700%, acc5: 68.040%, test_loss: 3.5140, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 22:15:45 - until epoch: 094, best_acc1: 42.960%
2023-07-01 22:15:45 - epoch 095 lr: 0.002000
2023-07-01 22:15:48 - train: epoch 0095, iter [00050, 00390], lr: 0.002000, loss: 0.1714
2023-07-01 22:15:51 - train: epoch 0095, iter [00100, 00390], lr: 0.002000, loss: 0.1992
2023-07-01 22:15:53 - train: epoch 0095, iter [00150, 00390], lr: 0.002000, loss: 0.2623
2023-07-01 22:15:56 - train: epoch 0095, iter [00200, 00390], lr: 0.002000, loss: 0.2021
2023-07-01 22:15:58 - train: epoch 0095, iter [00250, 00390], lr: 0.002000, loss: 0.2496
2023-07-01 22:16:00 - train: epoch 0095, iter [00300, 00390], lr: 0.002000, loss: 0.3063
2023-07-01 22:16:03 - train: epoch 0095, iter [00350, 00390], lr: 0.002000, loss: 0.1641
2023-07-01 22:16:05 - train: epoch 095, train_loss: 0.2141
2023-07-01 22:16:06 - eval: epoch: 095, acc1: 40.990%, acc5: 67.960%, test_loss: 3.5185, per_image_load_time: 0.073ms, per_image_inference_time: 0.094ms
2023-07-01 22:16:07 - until epoch: 095, best_acc1: 42.960%
2023-07-01 22:16:07 - epoch 096 lr: 0.002000
2023-07-01 22:16:10 - train: epoch 0096, iter [00050, 00390], lr: 0.002000, loss: 0.1847
2023-07-01 22:16:12 - train: epoch 0096, iter [00100, 00390], lr: 0.002000, loss: 0.2609
2023-07-01 22:16:15 - train: epoch 0096, iter [00150, 00390], lr: 0.002000, loss: 0.2636
2023-07-01 22:16:17 - train: epoch 0096, iter [00200, 00390], lr: 0.002000, loss: 0.2676
2023-07-01 22:16:20 - train: epoch 0096, iter [00250, 00390], lr: 0.002000, loss: 0.2352
2023-07-01 22:16:22 - train: epoch 0096, iter [00300, 00390], lr: 0.002000, loss: 0.3398
2023-07-01 22:16:25 - train: epoch 0096, iter [00350, 00390], lr: 0.002000, loss: 0.3767
2023-07-01 22:16:27 - train: epoch 096, train_loss: 0.2086
2023-07-01 22:16:28 - eval: epoch: 096, acc1: 41.560%, acc5: 68.000%, test_loss: 3.5167, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 22:16:31 - until epoch: 096, best_acc1: 42.960%
2023-07-01 22:16:31 - epoch 097 lr: 0.002000
2023-07-01 22:16:34 - train: epoch 0097, iter [00050, 00390], lr: 0.002000, loss: 0.2396
2023-07-01 22:16:37 - train: epoch 0097, iter [00100, 00390], lr: 0.002000, loss: 0.1759
2023-07-01 22:16:39 - train: epoch 0097, iter [00150, 00390], lr: 0.002000, loss: 0.1460
2023-07-01 22:16:42 - train: epoch 0097, iter [00200, 00390], lr: 0.002000, loss: 0.2409
2023-07-01 22:16:44 - train: epoch 0097, iter [00250, 00390], lr: 0.002000, loss: 0.2114
2023-07-01 22:16:46 - train: epoch 0097, iter [00300, 00390], lr: 0.002000, loss: 0.2633
2023-07-01 22:16:49 - train: epoch 0097, iter [00350, 00390], lr: 0.002000, loss: 0.1643
2023-07-01 22:16:51 - train: epoch 097, train_loss: 0.2049
2023-07-01 22:16:53 - eval: epoch: 097, acc1: 41.550%, acc5: 68.080%, test_loss: 3.5516, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 22:16:53 - until epoch: 097, best_acc1: 42.960%
2023-07-01 22:16:53 - epoch 098 lr: 0.002000
2023-07-01 22:16:56 - train: epoch 0098, iter [00050, 00390], lr: 0.002000, loss: 0.2333
2023-07-01 22:16:59 - train: epoch 0098, iter [00100, 00390], lr: 0.002000, loss: 0.2060
2023-07-01 22:17:01 - train: epoch 0098, iter [00150, 00390], lr: 0.002000, loss: 0.1960
2023-07-01 22:17:04 - train: epoch 0098, iter [00200, 00390], lr: 0.002000, loss: 0.2665
2023-07-01 22:17:06 - train: epoch 0098, iter [00250, 00390], lr: 0.002000, loss: 0.2695
2023-07-01 22:17:08 - train: epoch 0098, iter [00300, 00390], lr: 0.002000, loss: 0.2221
2023-07-01 22:17:11 - train: epoch 0098, iter [00350, 00390], lr: 0.002000, loss: 0.2099
2023-07-01 22:17:13 - train: epoch 098, train_loss: 0.2043
2023-07-01 22:17:15 - eval: epoch: 098, acc1: 41.050%, acc5: 67.660%, test_loss: 3.5732, per_image_load_time: 0.073ms, per_image_inference_time: 0.088ms
2023-07-01 22:17:15 - until epoch: 098, best_acc1: 42.960%
2023-07-01 22:17:15 - epoch 099 lr: 0.002000
2023-07-01 22:17:18 - train: epoch 0099, iter [00050, 00390], lr: 0.002000, loss: 0.2516
2023-07-01 22:17:20 - train: epoch 0099, iter [00100, 00390], lr: 0.002000, loss: 0.1419
2023-07-01 22:17:23 - train: epoch 0099, iter [00150, 00390], lr: 0.002000, loss: 0.1477
2023-07-01 22:17:25 - train: epoch 0099, iter [00200, 00390], lr: 0.002000, loss: 0.2262
2023-07-01 22:17:28 - train: epoch 0099, iter [00250, 00390], lr: 0.002000, loss: 0.1934
2023-07-01 22:17:30 - train: epoch 0099, iter [00300, 00390], lr: 0.002000, loss: 0.1732
2023-07-01 22:17:32 - train: epoch 0099, iter [00350, 00390], lr: 0.002000, loss: 0.2218
2023-07-01 22:17:34 - train: epoch 099, train_loss: 0.2002
2023-07-01 22:17:36 - eval: epoch: 099, acc1: 40.550%, acc5: 67.200%, test_loss: 3.5811, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 22:17:38 - until epoch: 099, best_acc1: 42.960%
2023-07-01 22:17:38 - epoch 100 lr: 0.002000
2023-07-01 22:17:42 - train: epoch 0100, iter [00050, 00390], lr: 0.002000, loss: 0.3220
2023-07-01 22:17:44 - train: epoch 0100, iter [00100, 00390], lr: 0.002000, loss: 0.1342
2023-07-01 22:17:47 - train: epoch 0100, iter [00150, 00390], lr: 0.002000, loss: 0.1993
2023-07-01 22:17:49 - train: epoch 0100, iter [00200, 00390], lr: 0.002000, loss: 0.2024
2023-07-01 22:17:51 - train: epoch 0100, iter [00250, 00390], lr: 0.002000, loss: 0.2515
2023-07-01 22:17:54 - train: epoch 0100, iter [00300, 00390], lr: 0.002000, loss: 0.2477
2023-07-01 22:17:56 - train: epoch 0100, iter [00350, 00390], lr: 0.002000, loss: 0.1833
2023-07-01 22:17:58 - train: epoch 100, train_loss: 0.2019
2023-07-01 22:18:00 - eval: epoch: 100, acc1: 41.190%, acc5: 67.740%, test_loss: 3.5709, per_image_load_time: 0.075ms, per_image_inference_time: 0.087ms
2023-07-01 22:18:03 - until epoch: 100, best_acc1: 42.960%
2023-07-01 22:18:03 - epoch 101 lr: 0.002000
2023-07-01 22:18:06 - train: epoch 0101, iter [00050, 00390], lr: 0.002000, loss: 0.1635
2023-07-01 22:18:08 - train: epoch 0101, iter [00100, 00390], lr: 0.002000, loss: 0.2204
2023-07-01 22:18:11 - train: epoch 0101, iter [00150, 00390], lr: 0.002000, loss: 0.1810
2023-07-01 22:18:13 - train: epoch 0101, iter [00200, 00390], lr: 0.002000, loss: 0.1797
2023-07-01 22:18:16 - train: epoch 0101, iter [00250, 00390], lr: 0.002000, loss: 0.1909
2023-07-01 22:18:18 - train: epoch 0101, iter [00300, 00390], lr: 0.002000, loss: 0.1881
2023-07-01 22:18:20 - train: epoch 0101, iter [00350, 00390], lr: 0.002000, loss: 0.1356
2023-07-01 22:18:22 - train: epoch 101, train_loss: 0.1904
2023-07-01 22:18:24 - eval: epoch: 101, acc1: 40.770%, acc5: 67.780%, test_loss: 3.6221, per_image_load_time: 0.073ms, per_image_inference_time: 0.089ms
2023-07-01 22:18:25 - until epoch: 101, best_acc1: 42.960%
2023-07-01 22:18:25 - epoch 102 lr: 0.002000
2023-07-01 22:18:28 - train: epoch 0102, iter [00050, 00390], lr: 0.002000, loss: 0.1872
2023-07-01 22:18:30 - train: epoch 0102, iter [00100, 00390], lr: 0.002000, loss: 0.1982
2023-07-01 22:18:32 - train: epoch 0102, iter [00150, 00390], lr: 0.002000, loss: 0.1563
2023-07-01 22:18:35 - train: epoch 0102, iter [00200, 00390], lr: 0.002000, loss: 0.2053
2023-07-01 22:18:37 - train: epoch 0102, iter [00250, 00390], lr: 0.002000, loss: 0.1235
2023-07-01 22:18:40 - train: epoch 0102, iter [00300, 00390], lr: 0.002000, loss: 0.1503
2023-07-01 22:18:42 - train: epoch 0102, iter [00350, 00390], lr: 0.002000, loss: 0.2077
2023-07-01 22:18:44 - train: epoch 102, train_loss: 0.1848
2023-07-01 22:18:46 - eval: epoch: 102, acc1: 40.850%, acc5: 67.420%, test_loss: 3.6281, per_image_load_time: 0.073ms, per_image_inference_time: 0.108ms
2023-07-01 22:18:48 - until epoch: 102, best_acc1: 42.960%
2023-07-01 22:18:48 - epoch 103 lr: 0.002000
2023-07-01 22:18:52 - train: epoch 0103, iter [00050, 00390], lr: 0.002000, loss: 0.1523
2023-07-01 22:18:54 - train: epoch 0103, iter [00100, 00390], lr: 0.002000, loss: 0.2036
2023-07-01 22:18:56 - train: epoch 0103, iter [00150, 00390], lr: 0.002000, loss: 0.1865
2023-07-01 22:18:59 - train: epoch 0103, iter [00200, 00390], lr: 0.002000, loss: 0.2238
2023-07-01 22:19:01 - train: epoch 0103, iter [00250, 00390], lr: 0.002000, loss: 0.1486
2023-07-01 22:19:04 - train: epoch 0103, iter [00300, 00390], lr: 0.002000, loss: 0.2750
2023-07-01 22:19:06 - train: epoch 0103, iter [00350, 00390], lr: 0.002000, loss: 0.1725
2023-07-01 22:19:08 - train: epoch 103, train_loss: 0.1853
2023-07-01 22:19:10 - eval: epoch: 103, acc1: 41.180%, acc5: 67.160%, test_loss: 3.6147, per_image_load_time: 0.070ms, per_image_inference_time: 0.088ms
2023-07-01 22:19:10 - until epoch: 103, best_acc1: 42.960%
2023-07-01 22:19:10 - epoch 104 lr: 0.002000
2023-07-01 22:19:13 - train: epoch 0104, iter [00050, 00390], lr: 0.002000, loss: 0.1259
2023-07-01 22:19:16 - train: epoch 0104, iter [00100, 00390], lr: 0.002000, loss: 0.2338
2023-07-01 22:19:18 - train: epoch 0104, iter [00150, 00390], lr: 0.002000, loss: 0.0789
2023-07-01 22:19:21 - train: epoch 0104, iter [00200, 00390], lr: 0.002000, loss: 0.1830
2023-07-01 22:19:23 - train: epoch 0104, iter [00250, 00390], lr: 0.002000, loss: 0.1363
2023-07-01 22:19:26 - train: epoch 0104, iter [00300, 00390], lr: 0.002000, loss: 0.1769
2023-07-01 22:19:28 - train: epoch 0104, iter [00350, 00390], lr: 0.002000, loss: 0.2286
2023-07-01 22:19:30 - train: epoch 104, train_loss: 0.1839
2023-07-01 22:19:32 - eval: epoch: 104, acc1: 40.920%, acc5: 67.580%, test_loss: 3.6510, per_image_load_time: 0.071ms, per_image_inference_time: 0.089ms
2023-07-01 22:19:32 - until epoch: 104, best_acc1: 42.960%
2023-07-01 22:19:32 - epoch 105 lr: 0.002000
2023-07-01 22:19:36 - train: epoch 0105, iter [00050, 00390], lr: 0.002000, loss: 0.1292
2023-07-01 22:19:39 - train: epoch 0105, iter [00100, 00390], lr: 0.002000, loss: 0.1237
2023-07-01 22:19:42 - train: epoch 0105, iter [00150, 00390], lr: 0.002000, loss: 0.1254
2023-07-01 22:19:44 - train: epoch 0105, iter [00200, 00390], lr: 0.002000, loss: 0.1413
2023-07-01 22:19:47 - train: epoch 0105, iter [00250, 00390], lr: 0.002000, loss: 0.2223
2023-07-01 22:19:49 - train: epoch 0105, iter [00300, 00390], lr: 0.002000, loss: 0.1106
2023-07-01 22:19:51 - train: epoch 0105, iter [00350, 00390], lr: 0.002000, loss: 0.2260
2023-07-01 22:19:53 - train: epoch 105, train_loss: 0.1802
2023-07-01 22:19:55 - eval: epoch: 105, acc1: 41.060%, acc5: 67.800%, test_loss: 3.6230, per_image_load_time: 0.074ms, per_image_inference_time: 0.087ms
2023-07-01 22:19:56 - until epoch: 105, best_acc1: 42.960%
2023-07-01 22:19:56 - epoch 106 lr: 0.002000
2023-07-01 22:19:59 - train: epoch 0106, iter [00050, 00390], lr: 0.002000, loss: 0.1489
2023-07-01 22:20:01 - train: epoch 0106, iter [00100, 00390], lr: 0.002000, loss: 0.1460
2023-07-01 22:20:04 - train: epoch 0106, iter [00150, 00390], lr: 0.002000, loss: 0.1690
2023-07-01 22:20:06 - train: epoch 0106, iter [00200, 00390], lr: 0.002000, loss: 0.1147
2023-07-01 22:20:08 - train: epoch 0106, iter [00250, 00390], lr: 0.002000, loss: 0.2720
2023-07-01 22:20:11 - train: epoch 0106, iter [00300, 00390], lr: 0.002000, loss: 0.1785
2023-07-01 22:20:13 - train: epoch 0106, iter [00350, 00390], lr: 0.002000, loss: 0.1619
2023-07-01 22:20:15 - train: epoch 106, train_loss: 0.1803
2023-07-01 22:20:17 - eval: epoch: 106, acc1: 40.860%, acc5: 67.370%, test_loss: 3.6801, per_image_load_time: 0.073ms, per_image_inference_time: 0.090ms
2023-07-01 22:20:18 - until epoch: 106, best_acc1: 42.960%
2023-07-01 22:20:18 - epoch 107 lr: 0.002000
2023-07-01 22:20:21 - train: epoch 0107, iter [00050, 00390], lr: 0.002000, loss: 0.1152
2023-07-01 22:20:23 - train: epoch 0107, iter [00100, 00390], lr: 0.002000, loss: 0.1567
2023-07-01 22:20:26 - train: epoch 0107, iter [00150, 00390], lr: 0.002000, loss: 0.1130
2023-07-01 22:20:28 - train: epoch 0107, iter [00200, 00390], lr: 0.002000, loss: 0.1738
2023-07-01 22:20:31 - train: epoch 0107, iter [00250, 00390], lr: 0.002000, loss: 0.1225
2023-07-01 22:20:33 - train: epoch 0107, iter [00300, 00390], lr: 0.002000, loss: 0.1505
2023-07-01 22:20:36 - train: epoch 0107, iter [00350, 00390], lr: 0.002000, loss: 0.2213
2023-07-01 22:20:38 - train: epoch 107, train_loss: 0.1727
2023-07-01 22:20:39 - eval: epoch: 107, acc1: 40.720%, acc5: 67.400%, test_loss: 3.7122, per_image_load_time: 0.075ms, per_image_inference_time: 0.088ms
2023-07-01 22:20:40 - until epoch: 107, best_acc1: 42.960%
2023-07-01 22:20:40 - epoch 108 lr: 0.002000
2023-07-01 22:20:43 - train: epoch 0108, iter [00050, 00390], lr: 0.002000, loss: 0.1752
2023-07-01 22:20:45 - train: epoch 0108, iter [00100, 00390], lr: 0.002000, loss: 0.1052
2023-07-01 22:20:48 - train: epoch 0108, iter [00150, 00390], lr: 0.002000, loss: 0.1761
2023-07-01 22:20:50 - train: epoch 0108, iter [00200, 00390], lr: 0.002000, loss: 0.0908
2023-07-01 22:20:53 - train: epoch 0108, iter [00250, 00390], lr: 0.002000, loss: 0.1948
2023-07-01 22:20:55 - train: epoch 0108, iter [00300, 00390], lr: 0.002000, loss: 0.1587
2023-07-01 22:20:57 - train: epoch 0108, iter [00350, 00390], lr: 0.002000, loss: 0.1912
2023-07-01 22:20:59 - train: epoch 108, train_loss: 0.1743
2023-07-01 22:21:01 - eval: epoch: 108, acc1: 41.010%, acc5: 67.310%, test_loss: 3.6928, per_image_load_time: 0.075ms, per_image_inference_time: 0.088ms
2023-07-01 22:21:02 - until epoch: 108, best_acc1: 42.960%
2023-07-01 22:21:02 - epoch 109 lr: 0.002000
2023-07-01 22:21:05 - train: epoch 0109, iter [00050, 00390], lr: 0.002000, loss: 0.1573
2023-07-01 22:21:07 - train: epoch 0109, iter [00100, 00390], lr: 0.002000, loss: 0.1488
2023-07-01 22:21:10 - train: epoch 0109, iter [00150, 00390], lr: 0.002000, loss: 0.1786
2023-07-01 22:21:12 - train: epoch 0109, iter [00200, 00390], lr: 0.002000, loss: 0.1392
2023-07-01 22:21:14 - train: epoch 0109, iter [00250, 00390], lr: 0.002000, loss: 0.1153
2023-07-01 22:21:17 - train: epoch 0109, iter [00300, 00390], lr: 0.002000, loss: 0.2546
2023-07-01 22:21:19 - train: epoch 0109, iter [00350, 00390], lr: 0.002000, loss: 0.2507
2023-07-01 22:21:21 - train: epoch 109, train_loss: 0.1735
2023-07-01 22:21:23 - eval: epoch: 109, acc1: 40.650%, acc5: 67.140%, test_loss: 3.6973, per_image_load_time: 0.073ms, per_image_inference_time: 0.088ms
2023-07-01 22:21:23 - until epoch: 109, best_acc1: 42.960%
2023-07-01 22:21:23 - epoch 110 lr: 0.002000
2023-07-01 22:21:27 - train: epoch 0110, iter [00050, 00390], lr: 0.002000, loss: 0.1516
2023-07-01 22:21:29 - train: epoch 0110, iter [00100, 00390], lr: 0.002000, loss: 0.0826
2023-07-01 22:21:31 - train: epoch 0110, iter [00150, 00390], lr: 0.002000, loss: 0.1462
2023-07-01 22:21:34 - train: epoch 0110, iter [00200, 00390], lr: 0.002000, loss: 0.2175
2023-07-01 22:21:36 - train: epoch 0110, iter [00250, 00390], lr: 0.002000, loss: 0.1775
2023-07-01 22:21:39 - train: epoch 0110, iter [00300, 00390], lr: 0.002000, loss: 0.1584
2023-07-01 22:21:41 - train: epoch 0110, iter [00350, 00390], lr: 0.002000, loss: 0.1434
2023-07-01 22:21:43 - train: epoch 110, train_loss: 0.1627
2023-07-01 22:21:45 - eval: epoch: 110, acc1: 40.860%, acc5: 67.150%, test_loss: 3.7340, per_image_load_time: 0.075ms, per_image_inference_time: 0.088ms
2023-07-01 22:21:45 - until epoch: 110, best_acc1: 42.960%
2023-07-01 22:21:45 - epoch 111 lr: 0.002000
2023-07-01 22:21:48 - train: epoch 0111, iter [00050, 00390], lr: 0.002000, loss: 0.1306
2023-07-01 22:21:51 - train: epoch 0111, iter [00100, 00390], lr: 0.002000, loss: 0.1632
2023-07-01 22:21:53 - train: epoch 0111, iter [00150, 00390], lr: 0.002000, loss: 0.2109
2023-07-01 22:21:56 - train: epoch 0111, iter [00200, 00390], lr: 0.002000, loss: 0.1847
2023-07-01 22:21:58 - train: epoch 0111, iter [00250, 00390], lr: 0.002000, loss: 0.1336
2023-07-01 22:22:00 - train: epoch 0111, iter [00300, 00390], lr: 0.002000, loss: 0.1209
2023-07-01 22:22:03 - train: epoch 0111, iter [00350, 00390], lr: 0.002000, loss: 0.1330
2023-07-01 22:22:05 - train: epoch 111, train_loss: 0.1647
2023-07-01 22:22:06 - eval: epoch: 111, acc1: 40.910%, acc5: 67.290%, test_loss: 3.7066, per_image_load_time: 0.077ms, per_image_inference_time: 0.087ms
2023-07-01 22:22:07 - until epoch: 111, best_acc1: 42.960%
2023-07-01 22:22:07 - epoch 112 lr: 0.002000
2023-07-01 22:22:10 - train: epoch 0112, iter [00050, 00390], lr: 0.002000, loss: 0.1241
2023-07-01 22:22:13 - train: epoch 0112, iter [00100, 00390], lr: 0.002000, loss: 0.1635
2023-07-01 22:22:15 - train: epoch 0112, iter [00150, 00390], lr: 0.002000, loss: 0.1955
2023-07-01 22:22:18 - train: epoch 0112, iter [00200, 00390], lr: 0.002000, loss: 0.1821
2023-07-01 22:22:20 - train: epoch 0112, iter [00250, 00390], lr: 0.002000, loss: 0.1467
2023-07-01 22:22:22 - train: epoch 0112, iter [00300, 00390], lr: 0.002000, loss: 0.1597
2023-07-01 22:22:25 - train: epoch 0112, iter [00350, 00390], lr: 0.002000, loss: 0.1994
2023-07-01 22:22:27 - train: epoch 112, train_loss: 0.1644
2023-07-01 22:22:28 - eval: epoch: 112, acc1: 40.710%, acc5: 67.570%, test_loss: 3.7367, per_image_load_time: 0.073ms, per_image_inference_time: 0.088ms
2023-07-01 22:22:29 - until epoch: 112, best_acc1: 42.960%
2023-07-01 22:22:29 - epoch 113 lr: 0.002000
2023-07-01 22:22:32 - train: epoch 0113, iter [00050, 00390], lr: 0.002000, loss: 0.0767
2023-07-01 22:22:35 - train: epoch 0113, iter [00100, 00390], lr: 0.002000, loss: 0.1562
2023-07-01 22:22:37 - train: epoch 0113, iter [00150, 00390], lr: 0.002000, loss: 0.2034
2023-07-01 22:22:39 - train: epoch 0113, iter [00200, 00390], lr: 0.002000, loss: 0.2089
2023-07-01 22:22:42 - train: epoch 0113, iter [00250, 00390], lr: 0.002000, loss: 0.2471
2023-07-01 22:22:44 - train: epoch 0113, iter [00300, 00390], lr: 0.002000, loss: 0.1085
2023-07-01 22:22:47 - train: epoch 0113, iter [00350, 00390], lr: 0.002000, loss: 0.2308
2023-07-01 22:22:48 - train: epoch 113, train_loss: 0.1609
2023-07-01 22:22:50 - eval: epoch: 113, acc1: 41.020%, acc5: 67.300%, test_loss: 3.7239, per_image_load_time: 0.073ms, per_image_inference_time: 0.087ms
2023-07-01 22:22:52 - until epoch: 113, best_acc1: 42.960%
2023-07-01 22:22:52 - epoch 114 lr: 0.002000
2023-07-01 22:22:55 - train: epoch 0114, iter [00050, 00390], lr: 0.002000, loss: 0.0892
2023-07-01 22:22:58 - train: epoch 0114, iter [00100, 00390], lr: 0.002000, loss: 0.1352
2023-07-01 22:23:00 - train: epoch 0114, iter [00150, 00390], lr: 0.002000, loss: 0.1902
2023-07-01 22:23:03 - train: epoch 0114, iter [00200, 00390], lr: 0.002000, loss: 0.1198
2023-07-01 22:23:05 - train: epoch 0114, iter [00250, 00390], lr: 0.002000, loss: 0.1410
2023-07-01 22:23:08 - train: epoch 0114, iter [00300, 00390], lr: 0.002000, loss: 0.1904
2023-07-01 22:23:10 - train: epoch 0114, iter [00350, 00390], lr: 0.002000, loss: 0.1837
2023-07-01 22:23:12 - train: epoch 114, train_loss: 0.1645
2023-07-01 22:23:14 - eval: epoch: 114, acc1: 40.790%, acc5: 67.510%, test_loss: 3.7460, per_image_load_time: 0.085ms, per_image_inference_time: 0.089ms
2023-07-01 22:23:16 - until epoch: 114, best_acc1: 42.960%
2023-07-01 22:23:16 - epoch 115 lr: 0.002000
2023-07-01 22:23:20 - train: epoch 0115, iter [00050, 00390], lr: 0.002000, loss: 0.1284
2023-07-01 22:23:22 - train: epoch 0115, iter [00100, 00390], lr: 0.002000, loss: 0.1443
2023-07-01 22:23:24 - train: epoch 0115, iter [00150, 00390], lr: 0.002000, loss: 0.1544
2023-07-01 22:23:27 - train: epoch 0115, iter [00200, 00390], lr: 0.002000, loss: 0.1358
2023-07-01 22:23:29 - train: epoch 0115, iter [00250, 00390], lr: 0.002000, loss: 0.1150
2023-07-01 22:23:32 - train: epoch 0115, iter [00300, 00390], lr: 0.002000, loss: 0.2108
2023-07-01 22:23:35 - train: epoch 0115, iter [00350, 00390], lr: 0.002000, loss: 0.1547
2023-07-01 22:23:37 - train: epoch 115, train_loss: 0.1606
2023-07-01 22:23:39 - eval: epoch: 115, acc1: 41.000%, acc5: 67.450%, test_loss: 3.7504, per_image_load_time: 0.075ms, per_image_inference_time: 0.088ms
2023-07-01 22:23:39 - until epoch: 115, best_acc1: 42.960%
2023-07-01 22:23:39 - epoch 116 lr: 0.002000
2023-07-01 22:23:42 - train: epoch 0116, iter [00050, 00390], lr: 0.002000, loss: 0.1900
2023-07-01 22:23:45 - train: epoch 0116, iter [00100, 00390], lr: 0.002000, loss: 0.1115
2023-07-01 22:23:47 - train: epoch 0116, iter [00150, 00390], lr: 0.002000, loss: 0.1645
2023-07-01 22:23:49 - train: epoch 0116, iter [00200, 00390], lr: 0.002000, loss: 0.2125
2023-07-01 22:23:52 - train: epoch 0116, iter [00250, 00390], lr: 0.002000, loss: 0.1600
2023-07-01 22:23:54 - train: epoch 0116, iter [00300, 00390], lr: 0.002000, loss: 0.1426
2023-07-01 22:23:57 - train: epoch 0116, iter [00350, 00390], lr: 0.002000, loss: 0.1380
2023-07-01 22:23:59 - train: epoch 116, train_loss: 0.1604
2023-07-01 22:24:00 - eval: epoch: 116, acc1: 40.730%, acc5: 66.970%, test_loss: 3.7867, per_image_load_time: 0.075ms, per_image_inference_time: 0.091ms
2023-07-01 22:24:01 - until epoch: 116, best_acc1: 42.960%
2023-07-01 22:24:01 - epoch 117 lr: 0.002000
2023-07-01 22:24:04 - train: epoch 0117, iter [00050, 00390], lr: 0.002000, loss: 0.1443
2023-07-01 22:24:07 - train: epoch 0117, iter [00100, 00390], lr: 0.002000, loss: 0.1394
2023-07-01 22:24:09 - train: epoch 0117, iter [00150, 00390], lr: 0.002000, loss: 0.1173
2023-07-01 22:24:12 - train: epoch 0117, iter [00200, 00390], lr: 0.002000, loss: 0.1690
2023-07-01 22:24:14 - train: epoch 0117, iter [00250, 00390], lr: 0.002000, loss: 0.1421
2023-07-01 22:24:16 - train: epoch 0117, iter [00300, 00390], lr: 0.002000, loss: 0.1818
2023-07-01 22:24:19 - train: epoch 0117, iter [00350, 00390], lr: 0.002000, loss: 0.1516
2023-07-01 22:24:21 - train: epoch 117, train_loss: 0.1516
2023-07-01 22:24:23 - eval: epoch: 117, acc1: 40.780%, acc5: 67.090%, test_loss: 3.7903, per_image_load_time: 0.097ms, per_image_inference_time: 0.092ms
2023-07-01 22:24:23 - until epoch: 117, best_acc1: 42.960%
2023-07-01 22:24:23 - epoch 118 lr: 0.002000
2023-07-01 22:24:27 - train: epoch 0118, iter [00050, 00390], lr: 0.002000, loss: 0.1626
2023-07-01 22:24:29 - train: epoch 0118, iter [00100, 00390], lr: 0.002000, loss: 0.1631
2023-07-01 22:24:32 - train: epoch 0118, iter [00150, 00390], lr: 0.002000, loss: 0.1788
2023-07-01 22:24:34 - train: epoch 0118, iter [00200, 00390], lr: 0.002000, loss: 0.1638
2023-07-01 22:24:37 - train: epoch 0118, iter [00250, 00390], lr: 0.002000, loss: 0.1628
2023-07-01 22:24:39 - train: epoch 0118, iter [00300, 00390], lr: 0.002000, loss: 0.0949
2023-07-01 22:24:42 - train: epoch 0118, iter [00350, 00390], lr: 0.002000, loss: 0.1883
2023-07-01 22:24:43 - train: epoch 118, train_loss: 0.1522
2023-07-01 22:24:45 - eval: epoch: 118, acc1: 40.450%, acc5: 67.010%, test_loss: 3.7862, per_image_load_time: 0.079ms, per_image_inference_time: 0.101ms
2023-07-01 22:24:46 - until epoch: 118, best_acc1: 42.960%
2023-07-01 22:24:46 - epoch 119 lr: 0.002000
2023-07-01 22:24:49 - train: epoch 0119, iter [00050, 00390], lr: 0.002000, loss: 0.1058
2023-07-01 22:24:52 - train: epoch 0119, iter [00100, 00390], lr: 0.002000, loss: 0.1715
2023-07-01 22:24:54 - train: epoch 0119, iter [00150, 00390], lr: 0.002000, loss: 0.0849
2023-07-01 22:24:57 - train: epoch 0119, iter [00200, 00390], lr: 0.002000, loss: 0.2013
2023-07-01 22:24:59 - train: epoch 0119, iter [00250, 00390], lr: 0.002000, loss: 0.1507
2023-07-01 22:25:01 - train: epoch 0119, iter [00300, 00390], lr: 0.002000, loss: 0.1523
2023-07-01 22:25:04 - train: epoch 0119, iter [00350, 00390], lr: 0.002000, loss: 0.1281
2023-07-01 22:25:06 - train: epoch 119, train_loss: 0.1609
2023-07-01 22:25:08 - eval: epoch: 119, acc1: 40.790%, acc5: 67.150%, test_loss: 3.8169, per_image_load_time: 0.080ms, per_image_inference_time: 0.088ms
2023-07-01 22:25:10 - until epoch: 119, best_acc1: 42.960%
2023-07-01 22:25:10 - epoch 120 lr: 0.002000
2023-07-01 22:25:13 - train: epoch 0120, iter [00050, 00390], lr: 0.002000, loss: 0.1251
2023-07-01 22:25:15 - train: epoch 0120, iter [00100, 00390], lr: 0.002000, loss: 0.1333
2023-07-01 22:25:18 - train: epoch 0120, iter [00150, 00390], lr: 0.002000, loss: 0.1638
2023-07-01 22:25:20 - train: epoch 0120, iter [00200, 00390], lr: 0.002000, loss: 0.2060
2023-07-01 22:25:23 - train: epoch 0120, iter [00250, 00390], lr: 0.002000, loss: 0.1747
2023-07-01 22:25:25 - train: epoch 0120, iter [00300, 00390], lr: 0.002000, loss: 0.1773
2023-07-01 22:25:27 - train: epoch 0120, iter [00350, 00390], lr: 0.002000, loss: 0.1223
2023-07-01 22:25:29 - train: epoch 120, train_loss: 0.1506
2023-07-01 22:25:31 - eval: epoch: 120, acc1: 40.990%, acc5: 66.940%, test_loss: 3.8057, per_image_load_time: 0.076ms, per_image_inference_time: 0.087ms
2023-07-01 22:25:32 - until epoch: 120, best_acc1: 42.960%
2023-07-01 22:25:32 - epoch 121 lr: 0.000400
2023-07-01 22:25:35 - train: epoch 0121, iter [00050, 00390], lr: 0.000400, loss: 0.1467
2023-07-01 22:25:37 - train: epoch 0121, iter [00100, 00390], lr: 0.000400, loss: 0.1324
2023-07-01 22:25:40 - train: epoch 0121, iter [00150, 00390], lr: 0.000400, loss: 0.1105
2023-07-01 22:25:42 - train: epoch 0121, iter [00200, 00390], lr: 0.000400, loss: 0.0765
2023-07-01 22:25:44 - train: epoch 0121, iter [00250, 00390], lr: 0.000400, loss: 0.0826
2023-07-01 22:25:47 - train: epoch 0121, iter [00300, 00390], lr: 0.000400, loss: 0.1092
2023-07-01 22:25:49 - train: epoch 0121, iter [00350, 00390], lr: 0.000400, loss: 0.0263
2023-07-01 22:25:51 - train: epoch 121, train_loss: 0.0891
2023-07-01 22:25:53 - eval: epoch: 121, acc1: 41.920%, acc5: 68.020%, test_loss: 3.7221, per_image_load_time: 0.073ms, per_image_inference_time: 0.088ms
2023-07-01 22:25:53 - until epoch: 121, best_acc1: 42.960%
2023-07-01 22:25:53 - epoch 122 lr: 0.000400
2023-07-01 22:25:57 - train: epoch 0122, iter [00050, 00390], lr: 0.000400, loss: 0.0611
2023-07-01 22:25:59 - train: epoch 0122, iter [00100, 00390], lr: 0.000400, loss: 0.0603
2023-07-01 22:26:02 - train: epoch 0122, iter [00150, 00390], lr: 0.000400, loss: 0.0742
2023-07-01 22:26:04 - train: epoch 0122, iter [00200, 00390], lr: 0.000400, loss: 0.0462
2023-07-01 22:26:07 - train: epoch 0122, iter [00250, 00390], lr: 0.000400, loss: 0.0818
2023-07-01 22:26:09 - train: epoch 0122, iter [00300, 00390], lr: 0.000400, loss: 0.0525
2023-07-01 22:26:11 - train: epoch 0122, iter [00350, 00390], lr: 0.000400, loss: 0.0764
2023-07-01 22:26:13 - train: epoch 122, train_loss: 0.0638
2023-07-01 22:26:16 - eval: epoch: 122, acc1: 41.840%, acc5: 67.800%, test_loss: 3.7280, per_image_load_time: 0.096ms, per_image_inference_time: 0.091ms
2023-07-01 22:26:16 - until epoch: 122, best_acc1: 42.960%
2023-07-01 22:26:16 - epoch 123 lr: 0.000400
2023-07-01 22:26:20 - train: epoch 0123, iter [00050, 00390], lr: 0.000400, loss: 0.0595
2023-07-01 22:26:22 - train: epoch 0123, iter [00100, 00390], lr: 0.000400, loss: 0.0681
2023-07-01 22:26:24 - train: epoch 0123, iter [00150, 00390], lr: 0.000400, loss: 0.0689
2023-07-01 22:26:27 - train: epoch 0123, iter [00200, 00390], lr: 0.000400, loss: 0.0672
2023-07-01 22:26:29 - train: epoch 0123, iter [00250, 00390], lr: 0.000400, loss: 0.0374
2023-07-01 22:26:32 - train: epoch 0123, iter [00300, 00390], lr: 0.000400, loss: 0.0965
2023-07-01 22:26:34 - train: epoch 0123, iter [00350, 00390], lr: 0.000400, loss: 0.0505
2023-07-01 22:26:36 - train: epoch 123, train_loss: 0.0580
2023-07-01 22:26:38 - eval: epoch: 123, acc1: 41.950%, acc5: 67.700%, test_loss: 3.7380, per_image_load_time: 0.080ms, per_image_inference_time: 0.090ms
2023-07-01 22:26:38 - until epoch: 123, best_acc1: 42.960%
2023-07-01 22:26:38 - epoch 124 lr: 0.000400
2023-07-01 22:26:42 - train: epoch 0124, iter [00050, 00390], lr: 0.000400, loss: 0.0423
2023-07-01 22:26:44 - train: epoch 0124, iter [00100, 00390], lr: 0.000400, loss: 0.0681
2023-07-01 22:26:46 - train: epoch 0124, iter [00150, 00390], lr: 0.000400, loss: 0.0719
2023-07-01 22:26:49 - train: epoch 0124, iter [00200, 00390], lr: 0.000400, loss: 0.0781
2023-07-01 22:26:51 - train: epoch 0124, iter [00250, 00390], lr: 0.000400, loss: 0.0586
2023-07-01 22:26:53 - train: epoch 0124, iter [00300, 00390], lr: 0.000400, loss: 0.0640
2023-07-01 22:26:56 - train: epoch 0124, iter [00350, 00390], lr: 0.000400, loss: 0.0288
2023-07-01 22:26:58 - train: epoch 124, train_loss: 0.0518
2023-07-01 22:27:00 - eval: epoch: 124, acc1: 41.910%, acc5: 67.700%, test_loss: 3.7459, per_image_load_time: 0.096ms, per_image_inference_time: 0.091ms
2023-07-01 22:27:02 - until epoch: 124, best_acc1: 42.960%
2023-07-01 22:27:02 - epoch 125 lr: 0.000400
2023-07-01 22:27:05 - train: epoch 0125, iter [00050, 00390], lr: 0.000400, loss: 0.0535
2023-07-01 22:27:08 - train: epoch 0125, iter [00100, 00390], lr: 0.000400, loss: 0.0365
2023-07-01 22:27:10 - train: epoch 0125, iter [00150, 00390], lr: 0.000400, loss: 0.0401
2023-07-01 22:27:13 - train: epoch 0125, iter [00200, 00390], lr: 0.000400, loss: 0.0518
2023-07-01 22:27:15 - train: epoch 0125, iter [00250, 00390], lr: 0.000400, loss: 0.0694
2023-07-01 22:27:18 - train: epoch 0125, iter [00300, 00390], lr: 0.000400, loss: 0.0446
2023-07-01 22:27:21 - train: epoch 0125, iter [00350, 00390], lr: 0.000400, loss: 0.0740
2023-07-01 22:27:23 - train: epoch 125, train_loss: 0.0479
2023-07-01 22:27:25 - eval: epoch: 125, acc1: 41.940%, acc5: 67.930%, test_loss: 3.7557, per_image_load_time: 0.091ms, per_image_inference_time: 0.090ms
2023-07-01 22:27:28 - until epoch: 125, best_acc1: 42.960%
2023-07-01 22:27:28 - epoch 126 lr: 0.000400
2023-07-01 22:27:32 - train: epoch 0126, iter [00050, 00390], lr: 0.000400, loss: 0.0485
2023-07-01 22:27:34 - train: epoch 0126, iter [00100, 00390], lr: 0.000400, loss: 0.0293
2023-07-01 22:27:36 - train: epoch 0126, iter [00150, 00390], lr: 0.000400, loss: 0.0196
2023-07-01 22:27:39 - train: epoch 0126, iter [00200, 00390], lr: 0.000400, loss: 0.0602
2023-07-01 22:27:41 - train: epoch 0126, iter [00250, 00390], lr: 0.000400, loss: 0.0335
2023-07-01 22:27:44 - train: epoch 0126, iter [00300, 00390], lr: 0.000400, loss: 0.0394
2023-07-01 22:27:46 - train: epoch 0126, iter [00350, 00390], lr: 0.000400, loss: 0.0509
2023-07-01 22:27:48 - train: epoch 126, train_loss: 0.0446
2023-07-01 22:27:50 - eval: epoch: 126, acc1: 41.980%, acc5: 67.800%, test_loss: 3.7469, per_image_load_time: 0.075ms, per_image_inference_time: 0.089ms
2023-07-01 22:27:51 - until epoch: 126, best_acc1: 42.960%
2023-07-01 22:27:51 - epoch 127 lr: 0.000400
2023-07-01 22:27:54 - train: epoch 0127, iter [00050, 00390], lr: 0.000400, loss: 0.0313
2023-07-01 22:27:56 - train: epoch 0127, iter [00100, 00390], lr: 0.000400, loss: 0.0919
2023-07-01 22:27:59 - train: epoch 0127, iter [00150, 00390], lr: 0.000400, loss: 0.0352
2023-07-01 22:28:01 - train: epoch 0127, iter [00200, 00390], lr: 0.000400, loss: 0.0355
2023-07-01 22:28:04 - train: epoch 0127, iter [00250, 00390], lr: 0.000400, loss: 0.0425
2023-07-01 22:28:06 - train: epoch 0127, iter [00300, 00390], lr: 0.000400, loss: 0.0311
2023-07-01 22:28:09 - train: epoch 0127, iter [00350, 00390], lr: 0.000400, loss: 0.0334
2023-07-01 22:28:10 - train: epoch 127, train_loss: 0.0426
2023-07-01 22:28:12 - eval: epoch: 127, acc1: 42.300%, acc5: 67.960%, test_loss: 3.7539, per_image_load_time: 0.074ms, per_image_inference_time: 0.087ms
2023-07-01 22:28:13 - until epoch: 127, best_acc1: 42.960%
2023-07-01 22:28:13 - epoch 128 lr: 0.000400
2023-07-01 22:28:16 - train: epoch 0128, iter [00050, 00390], lr: 0.000400, loss: 0.0424
2023-07-01 22:28:18 - train: epoch 0128, iter [00100, 00390], lr: 0.000400, loss: 0.0452
2023-07-01 22:28:21 - train: epoch 0128, iter [00150, 00390], lr: 0.000400, loss: 0.0239
2023-07-01 22:28:24 - train: epoch 0128, iter [00200, 00390], lr: 0.000400, loss: 0.0467
2023-07-01 22:28:27 - train: epoch 0128, iter [00250, 00390], lr: 0.000400, loss: 0.0357
2023-07-01 22:28:29 - train: epoch 0128, iter [00300, 00390], lr: 0.000400, loss: 0.0338
2023-07-01 22:28:31 - train: epoch 0128, iter [00350, 00390], lr: 0.000400, loss: 0.0214
2023-07-01 22:28:33 - train: epoch 128, train_loss: 0.0417
2023-07-01 22:28:35 - eval: epoch: 128, acc1: 42.190%, acc5: 67.940%, test_loss: 3.7661, per_image_load_time: 0.073ms, per_image_inference_time: 0.088ms
2023-07-01 22:28:37 - until epoch: 128, best_acc1: 42.960%
2023-07-01 22:28:37 - epoch 129 lr: 0.000400
2023-07-01 22:28:40 - train: epoch 0129, iter [00050, 00390], lr: 0.000400, loss: 0.0255
2023-07-01 22:28:43 - train: epoch 0129, iter [00100, 00390], lr: 0.000400, loss: 0.0536
2023-07-01 22:28:45 - train: epoch 0129, iter [00150, 00390], lr: 0.000400, loss: 0.0397
2023-07-01 22:28:48 - train: epoch 0129, iter [00200, 00390], lr: 0.000400, loss: 0.0320
2023-07-01 22:28:50 - train: epoch 0129, iter [00250, 00390], lr: 0.000400, loss: 0.0286
2023-07-01 22:28:52 - train: epoch 0129, iter [00300, 00390], lr: 0.000400, loss: 0.0206
2023-07-01 22:28:55 - train: epoch 0129, iter [00350, 00390], lr: 0.000400, loss: 0.0246
2023-07-01 22:28:57 - train: epoch 129, train_loss: 0.0390
2023-07-01 22:28:59 - eval: epoch: 129, acc1: 42.150%, acc5: 67.800%, test_loss: 3.7767, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 22:28:59 - until epoch: 129, best_acc1: 42.960%
2023-07-01 22:28:59 - epoch 130 lr: 0.000400
2023-07-01 22:29:02 - train: epoch 0130, iter [00050, 00390], lr: 0.000400, loss: 0.0378
2023-07-01 22:29:05 - train: epoch 0130, iter [00100, 00390], lr: 0.000400, loss: 0.0378
2023-07-01 22:29:07 - train: epoch 0130, iter [00150, 00390], lr: 0.000400, loss: 0.0457
2023-07-01 22:29:10 - train: epoch 0130, iter [00200, 00390], lr: 0.000400, loss: 0.0405
2023-07-01 22:29:12 - train: epoch 0130, iter [00250, 00390], lr: 0.000400, loss: 0.0511
2023-07-01 22:29:14 - train: epoch 0130, iter [00300, 00390], lr: 0.000400, loss: 0.0303
2023-07-01 22:29:17 - train: epoch 0130, iter [00350, 00390], lr: 0.000400, loss: 0.0382
2023-07-01 22:29:19 - train: epoch 130, train_loss: 0.0379
2023-07-01 22:29:21 - eval: epoch: 130, acc1: 42.320%, acc5: 67.930%, test_loss: 3.7766, per_image_load_time: 0.092ms, per_image_inference_time: 0.088ms
2023-07-01 22:29:22 - until epoch: 130, best_acc1: 42.960%
2023-07-01 22:29:22 - epoch 131 lr: 0.000400
2023-07-01 22:29:25 - train: epoch 0131, iter [00050, 00390], lr: 0.000400, loss: 0.0275
2023-07-01 22:29:27 - train: epoch 0131, iter [00100, 00390], lr: 0.000400, loss: 0.0531
2023-07-01 22:29:30 - train: epoch 0131, iter [00150, 00390], lr: 0.000400, loss: 0.0485
2023-07-01 22:29:32 - train: epoch 0131, iter [00200, 00390], lr: 0.000400, loss: 0.0306
2023-07-01 22:29:34 - train: epoch 0131, iter [00250, 00390], lr: 0.000400, loss: 0.0401
2023-07-01 22:29:37 - train: epoch 0131, iter [00300, 00390], lr: 0.000400, loss: 0.0446
2023-07-01 22:29:39 - train: epoch 0131, iter [00350, 00390], lr: 0.000400, loss: 0.0298
2023-07-01 22:29:41 - train: epoch 131, train_loss: 0.0378
2023-07-01 22:29:43 - eval: epoch: 131, acc1: 42.050%, acc5: 67.880%, test_loss: 3.7790, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 22:29:44 - until epoch: 131, best_acc1: 42.960%
2023-07-01 22:29:44 - epoch 132 lr: 0.000400
2023-07-01 22:29:48 - train: epoch 0132, iter [00050, 00390], lr: 0.000400, loss: 0.0175
2023-07-01 22:29:50 - train: epoch 0132, iter [00100, 00390], lr: 0.000400, loss: 0.0348
2023-07-01 22:29:52 - train: epoch 0132, iter [00150, 00390], lr: 0.000400, loss: 0.0314
2023-07-01 22:29:55 - train: epoch 0132, iter [00200, 00390], lr: 0.000400, loss: 0.0538
2023-07-01 22:29:57 - train: epoch 0132, iter [00250, 00390], lr: 0.000400, loss: 0.0206
2023-07-01 22:30:00 - train: epoch 0132, iter [00300, 00390], lr: 0.000400, loss: 0.0274
2023-07-01 22:30:02 - train: epoch 0132, iter [00350, 00390], lr: 0.000400, loss: 0.0584
2023-07-01 22:30:04 - train: epoch 132, train_loss: 0.0353
2023-07-01 22:30:06 - eval: epoch: 132, acc1: 42.380%, acc5: 67.980%, test_loss: 3.7851, per_image_load_time: 0.074ms, per_image_inference_time: 0.089ms
2023-07-01 22:30:06 - until epoch: 132, best_acc1: 42.960%
2023-07-01 22:30:06 - epoch 133 lr: 0.000400
2023-07-01 22:30:10 - train: epoch 0133, iter [00050, 00390], lr: 0.000400, loss: 0.0128
2023-07-01 22:30:12 - train: epoch 0133, iter [00100, 00390], lr: 0.000400, loss: 0.0206
2023-07-01 22:30:14 - train: epoch 0133, iter [00150, 00390], lr: 0.000400, loss: 0.0172
2023-07-01 22:30:17 - train: epoch 0133, iter [00200, 00390], lr: 0.000400, loss: 0.1185
2023-07-01 22:30:19 - train: epoch 0133, iter [00250, 00390], lr: 0.000400, loss: 0.0569
2023-07-01 22:30:22 - train: epoch 0133, iter [00300, 00390], lr: 0.000400, loss: 0.0252
2023-07-01 22:30:24 - train: epoch 0133, iter [00350, 00390], lr: 0.000400, loss: 0.0334
2023-07-01 22:30:26 - train: epoch 133, train_loss: 0.0347
2023-07-01 22:30:28 - eval: epoch: 133, acc1: 41.970%, acc5: 68.110%, test_loss: 3.7894, per_image_load_time: 0.072ms, per_image_inference_time: 0.087ms
2023-07-01 22:30:29 - until epoch: 133, best_acc1: 42.960%
2023-07-01 22:30:29 - epoch 134 lr: 0.000400
2023-07-01 22:30:32 - train: epoch 0134, iter [00050, 00390], lr: 0.000400, loss: 0.0755
2023-07-01 22:30:34 - train: epoch 0134, iter [00100, 00390], lr: 0.000400, loss: 0.0387
2023-07-01 22:30:37 - train: epoch 0134, iter [00150, 00390], lr: 0.000400, loss: 0.0484
2023-07-01 22:30:39 - train: epoch 0134, iter [00200, 00390], lr: 0.000400, loss: 0.0232
2023-07-01 22:30:41 - train: epoch 0134, iter [00250, 00390], lr: 0.000400, loss: 0.0232
2023-07-01 22:30:44 - train: epoch 0134, iter [00300, 00390], lr: 0.000400, loss: 0.0274
2023-07-01 22:30:46 - train: epoch 0134, iter [00350, 00390], lr: 0.000400, loss: 0.0196
2023-07-01 22:30:48 - train: epoch 134, train_loss: 0.0344
2023-07-01 22:30:50 - eval: epoch: 134, acc1: 42.220%, acc5: 68.130%, test_loss: 3.7985, per_image_load_time: 0.074ms, per_image_inference_time: 0.088ms
2023-07-01 22:30:51 - until epoch: 134, best_acc1: 42.960%
2023-07-01 22:30:51 - epoch 135 lr: 0.000400
2023-07-01 22:30:54 - train: epoch 0135, iter [00050, 00390], lr: 0.000400, loss: 0.0230
2023-07-01 22:30:57 - train: epoch 0135, iter [00100, 00390], lr: 0.000400, loss: 0.0224
2023-07-01 22:30:59 - train: epoch 0135, iter [00150, 00390], lr: 0.000400, loss: 0.0239
2023-07-01 22:31:01 - train: epoch 0135, iter [00200, 00390], lr: 0.000400, loss: 0.0610
2023-07-01 22:31:04 - train: epoch 0135, iter [00250, 00390], lr: 0.000400, loss: 0.0169
2023-07-01 22:31:06 - train: epoch 0135, iter [00300, 00390], lr: 0.000400, loss: 0.0521
2023-07-01 22:31:09 - train: epoch 0135, iter [00350, 00390], lr: 0.000400, loss: 0.0161
2023-07-01 22:31:11 - train: epoch 135, train_loss: 0.0302
2023-07-01 22:31:12 - eval: epoch: 135, acc1: 42.070%, acc5: 68.060%, test_loss: 3.8015, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 22:31:13 - until epoch: 135, best_acc1: 42.960%
2023-07-01 22:31:13 - epoch 136 lr: 0.000400
2023-07-01 22:31:16 - train: epoch 0136, iter [00050, 00390], lr: 0.000400, loss: 0.0208
2023-07-01 22:31:18 - train: epoch 0136, iter [00100, 00390], lr: 0.000400, loss: 0.0245
2023-07-01 22:31:21 - train: epoch 0136, iter [00150, 00390], lr: 0.000400, loss: 0.0300
2023-07-01 22:31:23 - train: epoch 0136, iter [00200, 00390], lr: 0.000400, loss: 0.0518
2023-07-01 22:31:26 - train: epoch 0136, iter [00250, 00390], lr: 0.000400, loss: 0.0274
2023-07-01 22:31:28 - train: epoch 0136, iter [00300, 00390], lr: 0.000400, loss: 0.0260
2023-07-01 22:31:30 - train: epoch 0136, iter [00350, 00390], lr: 0.000400, loss: 0.0125
2023-07-01 22:31:32 - train: epoch 136, train_loss: 0.0313
2023-07-01 22:31:34 - eval: epoch: 136, acc1: 41.850%, acc5: 68.010%, test_loss: 3.8054, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 22:31:35 - until epoch: 136, best_acc1: 42.960%
2023-07-01 22:31:35 - epoch 137 lr: 0.000400
2023-07-01 22:31:38 - train: epoch 0137, iter [00050, 00390], lr: 0.000400, loss: 0.0185
2023-07-01 22:31:40 - train: epoch 0137, iter [00100, 00390], lr: 0.000400, loss: 0.0245
2023-07-01 22:31:43 - train: epoch 0137, iter [00150, 00390], lr: 0.000400, loss: 0.0346
2023-07-01 22:31:45 - train: epoch 0137, iter [00200, 00390], lr: 0.000400, loss: 0.0195
2023-07-01 22:31:48 - train: epoch 0137, iter [00250, 00390], lr: 0.000400, loss: 0.0249
2023-07-01 22:31:50 - train: epoch 0137, iter [00300, 00390], lr: 0.000400, loss: 0.0150
2023-07-01 22:31:52 - train: epoch 0137, iter [00350, 00390], lr: 0.000400, loss: 0.0333
2023-07-01 22:31:54 - train: epoch 137, train_loss: 0.0305
2023-07-01 22:31:56 - eval: epoch: 137, acc1: 42.180%, acc5: 67.940%, test_loss: 3.8133, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 22:31:57 - until epoch: 137, best_acc1: 42.960%
2023-07-01 22:31:57 - epoch 138 lr: 0.000400
2023-07-01 22:32:00 - train: epoch 0138, iter [00050, 00390], lr: 0.000400, loss: 0.0182
2023-07-01 22:32:02 - train: epoch 0138, iter [00100, 00390], lr: 0.000400, loss: 0.0273
2023-07-01 22:32:05 - train: epoch 0138, iter [00150, 00390], lr: 0.000400, loss: 0.0248
2023-07-01 22:32:07 - train: epoch 0138, iter [00200, 00390], lr: 0.000400, loss: 0.0249
2023-07-01 22:32:10 - train: epoch 0138, iter [00250, 00390], lr: 0.000400, loss: 0.0164
2023-07-01 22:32:12 - train: epoch 0138, iter [00300, 00390], lr: 0.000400, loss: 0.0267
2023-07-01 22:32:14 - train: epoch 0138, iter [00350, 00390], lr: 0.000400, loss: 0.0292
2023-07-01 22:32:16 - train: epoch 138, train_loss: 0.0290
2023-07-01 22:32:18 - eval: epoch: 138, acc1: 42.040%, acc5: 68.040%, test_loss: 3.8222, per_image_load_time: 0.074ms, per_image_inference_time: 0.087ms
2023-07-01 22:32:20 - until epoch: 138, best_acc1: 42.960%
2023-07-01 22:32:20 - epoch 139 lr: 0.000400
2023-07-01 22:32:23 - train: epoch 0139, iter [00050, 00390], lr: 0.000400, loss: 0.0195
2023-07-01 22:32:25 - train: epoch 0139, iter [00100, 00390], lr: 0.000400, loss: 0.0358
2023-07-01 22:32:28 - train: epoch 0139, iter [00150, 00390], lr: 0.000400, loss: 0.0216
2023-07-01 22:32:30 - train: epoch 0139, iter [00200, 00390], lr: 0.000400, loss: 0.0286
2023-07-01 22:32:32 - train: epoch 0139, iter [00250, 00390], lr: 0.000400, loss: 0.0230
2023-07-01 22:32:35 - train: epoch 0139, iter [00300, 00390], lr: 0.000400, loss: 0.0361
2023-07-01 22:32:37 - train: epoch 0139, iter [00350, 00390], lr: 0.000400, loss: 0.0366
2023-07-01 22:32:39 - train: epoch 139, train_loss: 0.0295
2023-07-01 22:32:41 - eval: epoch: 139, acc1: 41.920%, acc5: 68.100%, test_loss: 3.8241, per_image_load_time: 0.071ms, per_image_inference_time: 0.088ms
2023-07-01 22:32:41 - until epoch: 139, best_acc1: 42.960%
2023-07-01 22:32:41 - epoch 140 lr: 0.000400
2023-07-01 22:32:45 - train: epoch 0140, iter [00050, 00390], lr: 0.000400, loss: 0.0352
2023-07-01 22:32:47 - train: epoch 0140, iter [00100, 00390], lr: 0.000400, loss: 0.0336
2023-07-01 22:32:49 - train: epoch 0140, iter [00150, 00390], lr: 0.000400, loss: 0.0351
2023-07-01 22:32:52 - train: epoch 0140, iter [00200, 00390], lr: 0.000400, loss: 0.0234
2023-07-01 22:32:54 - train: epoch 0140, iter [00250, 00390], lr: 0.000400, loss: 0.0290
2023-07-01 22:32:57 - train: epoch 0140, iter [00300, 00390], lr: 0.000400, loss: 0.0203
2023-07-01 22:32:59 - train: epoch 0140, iter [00350, 00390], lr: 0.000400, loss: 0.0262
2023-07-01 22:33:01 - train: epoch 140, train_loss: 0.0278
2023-07-01 22:33:03 - eval: epoch: 140, acc1: 42.020%, acc5: 67.820%, test_loss: 3.8304, per_image_load_time: 0.071ms, per_image_inference_time: 0.088ms
2023-07-01 22:33:03 - until epoch: 140, best_acc1: 42.960%
2023-07-01 22:33:03 - epoch 141 lr: 0.000400
2023-07-01 22:33:07 - train: epoch 0141, iter [00050, 00390], lr: 0.000400, loss: 0.0351
2023-07-01 22:33:09 - train: epoch 0141, iter [00100, 00390], lr: 0.000400, loss: 0.0230
2023-07-01 22:33:11 - train: epoch 0141, iter [00150, 00390], lr: 0.000400, loss: 0.0353
2023-07-01 22:33:14 - train: epoch 0141, iter [00200, 00390], lr: 0.000400, loss: 0.0258
2023-07-01 22:33:16 - train: epoch 0141, iter [00250, 00390], lr: 0.000400, loss: 0.0199
2023-07-01 22:33:19 - train: epoch 0141, iter [00300, 00390], lr: 0.000400, loss: 0.0229
2023-07-01 22:33:21 - train: epoch 0141, iter [00350, 00390], lr: 0.000400, loss: 0.0404
2023-07-01 22:33:23 - train: epoch 141, train_loss: 0.0283
2023-07-01 22:33:25 - eval: epoch: 141, acc1: 41.780%, acc5: 67.760%, test_loss: 3.8392, per_image_load_time: 0.071ms, per_image_inference_time: 0.089ms
2023-07-01 22:33:27 - until epoch: 141, best_acc1: 42.960%
2023-07-01 22:33:27 - epoch 142 lr: 0.000400
2023-07-01 22:33:30 - train: epoch 0142, iter [00050, 00390], lr: 0.000400, loss: 0.0318
2023-07-01 22:33:33 - train: epoch 0142, iter [00100, 00390], lr: 0.000400, loss: 0.0219
2023-07-01 22:33:35 - train: epoch 0142, iter [00150, 00390], lr: 0.000400, loss: 0.0247
2023-07-01 22:33:38 - train: epoch 0142, iter [00200, 00390], lr: 0.000400, loss: 0.0299
2023-07-01 22:33:40 - train: epoch 0142, iter [00250, 00390], lr: 0.000400, loss: 0.0212
2023-07-01 22:33:43 - train: epoch 0142, iter [00300, 00390], lr: 0.000400, loss: 0.0294
2023-07-01 22:33:45 - train: epoch 0142, iter [00350, 00390], lr: 0.000400, loss: 0.0159
2023-07-01 22:33:47 - train: epoch 142, train_loss: 0.0274
2023-07-01 22:33:49 - eval: epoch: 142, acc1: 42.090%, acc5: 67.730%, test_loss: 3.8438, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 22:33:51 - until epoch: 142, best_acc1: 42.960%
2023-07-01 22:33:51 - epoch 143 lr: 0.000400
2023-07-01 22:33:54 - train: epoch 0143, iter [00050, 00390], lr: 0.000400, loss: 0.0192
2023-07-01 22:33:57 - train: epoch 0143, iter [00100, 00390], lr: 0.000400, loss: 0.0103
2023-07-01 22:33:59 - train: epoch 0143, iter [00150, 00390], lr: 0.000400, loss: 0.0238
2023-07-01 22:34:02 - train: epoch 0143, iter [00200, 00390], lr: 0.000400, loss: 0.0143
2023-07-01 22:34:04 - train: epoch 0143, iter [00250, 00390], lr: 0.000400, loss: 0.0251
2023-07-01 22:34:06 - train: epoch 0143, iter [00300, 00390], lr: 0.000400, loss: 0.0218
2023-07-01 22:34:09 - train: epoch 0143, iter [00350, 00390], lr: 0.000400, loss: 0.0397
2023-07-01 22:34:11 - train: epoch 143, train_loss: 0.0277
2023-07-01 22:34:13 - eval: epoch: 143, acc1: 42.130%, acc5: 67.710%, test_loss: 3.8434, per_image_load_time: 0.073ms, per_image_inference_time: 0.087ms
2023-07-01 22:34:13 - until epoch: 143, best_acc1: 42.960%
2023-07-01 22:34:13 - epoch 144 lr: 0.000400
2023-07-01 22:34:16 - train: epoch 0144, iter [00050, 00390], lr: 0.000400, loss: 0.0169
2023-07-01 22:34:19 - train: epoch 0144, iter [00100, 00390], lr: 0.000400, loss: 0.0179
2023-07-01 22:34:21 - train: epoch 0144, iter [00150, 00390], lr: 0.000400, loss: 0.0244
2023-07-01 22:34:24 - train: epoch 0144, iter [00200, 00390], lr: 0.000400, loss: 0.0229
2023-07-01 22:34:26 - train: epoch 0144, iter [00250, 00390], lr: 0.000400, loss: 0.0369
2023-07-01 22:34:29 - train: epoch 0144, iter [00300, 00390], lr: 0.000400, loss: 0.0299
2023-07-01 22:34:31 - train: epoch 0144, iter [00350, 00390], lr: 0.000400, loss: 0.0359
2023-07-01 22:34:33 - train: epoch 144, train_loss: 0.0262
2023-07-01 22:34:35 - eval: epoch: 144, acc1: 41.960%, acc5: 67.870%, test_loss: 3.8473, per_image_load_time: 0.075ms, per_image_inference_time: 0.094ms
2023-07-01 22:34:36 - until epoch: 144, best_acc1: 42.960%
2023-07-01 22:34:36 - epoch 145 lr: 0.000400
2023-07-01 22:34:39 - train: epoch 0145, iter [00050, 00390], lr: 0.000400, loss: 0.0126
2023-07-01 22:34:42 - train: epoch 0145, iter [00100, 00390], lr: 0.000400, loss: 0.0186
2023-07-01 22:34:44 - train: epoch 0145, iter [00150, 00390], lr: 0.000400, loss: 0.0162
2023-07-01 22:34:46 - train: epoch 0145, iter [00200, 00390], lr: 0.000400, loss: 0.0160
2023-07-01 22:34:49 - train: epoch 0145, iter [00250, 00390], lr: 0.000400, loss: 0.0361
2023-07-01 22:34:51 - train: epoch 0145, iter [00300, 00390], lr: 0.000400, loss: 0.0196
2023-07-01 22:34:54 - train: epoch 0145, iter [00350, 00390], lr: 0.000400, loss: 0.0256
2023-07-01 22:34:56 - train: epoch 145, train_loss: 0.0260
2023-07-01 22:34:57 - eval: epoch: 145, acc1: 42.190%, acc5: 67.780%, test_loss: 3.8560, per_image_load_time: 0.075ms, per_image_inference_time: 0.092ms
2023-07-01 22:34:59 - until epoch: 145, best_acc1: 42.960%
2023-07-01 22:34:59 - epoch 146 lr: 0.000400
2023-07-01 22:35:03 - train: epoch 0146, iter [00050, 00390], lr: 0.000400, loss: 0.0336
2023-07-01 22:35:06 - train: epoch 0146, iter [00100, 00390], lr: 0.000400, loss: 0.0145
2023-07-01 22:35:08 - train: epoch 0146, iter [00150, 00390], lr: 0.000400, loss: 0.0207
2023-07-01 22:35:10 - train: epoch 0146, iter [00200, 00390], lr: 0.000400, loss: 0.0193
2023-07-01 22:35:13 - train: epoch 0146, iter [00250, 00390], lr: 0.000400, loss: 0.0143
2023-07-01 22:35:15 - train: epoch 0146, iter [00300, 00390], lr: 0.000400, loss: 0.0178
2023-07-01 22:35:18 - train: epoch 0146, iter [00350, 00390], lr: 0.000400, loss: 0.0140
2023-07-01 22:35:20 - train: epoch 146, train_loss: 0.0258
2023-07-01 22:35:22 - eval: epoch: 146, acc1: 42.240%, acc5: 67.800%, test_loss: 3.8553, per_image_load_time: 0.078ms, per_image_inference_time: 0.089ms
2023-07-01 22:35:22 - until epoch: 146, best_acc1: 42.960%
2023-07-01 22:35:22 - epoch 147 lr: 0.000400
2023-07-01 22:35:25 - train: epoch 0147, iter [00050, 00390], lr: 0.000400, loss: 0.0333
2023-07-01 22:35:28 - train: epoch 0147, iter [00100, 00390], lr: 0.000400, loss: 0.0127
2023-07-01 22:35:30 - train: epoch 0147, iter [00150, 00390], lr: 0.000400, loss: 0.0179
2023-07-01 22:35:33 - train: epoch 0147, iter [00200, 00390], lr: 0.000400, loss: 0.0424
2023-07-01 22:35:35 - train: epoch 0147, iter [00250, 00390], lr: 0.000400, loss: 0.0114
2023-07-01 22:35:37 - train: epoch 0147, iter [00300, 00390], lr: 0.000400, loss: 0.0145
2023-07-01 22:35:40 - train: epoch 0147, iter [00350, 00390], lr: 0.000400, loss: 0.0212
2023-07-01 22:35:42 - train: epoch 147, train_loss: 0.0244
2023-07-01 22:35:44 - eval: epoch: 147, acc1: 42.050%, acc5: 67.880%, test_loss: 3.8516, per_image_load_time: 0.075ms, per_image_inference_time: 0.087ms
2023-07-01 22:35:45 - until epoch: 147, best_acc1: 42.960%
2023-07-01 22:35:45 - epoch 148 lr: 0.000400
2023-07-01 22:35:48 - train: epoch 0148, iter [00050, 00390], lr: 0.000400, loss: 0.0241
2023-07-01 22:35:51 - train: epoch 0148, iter [00100, 00390], lr: 0.000400, loss: 0.0139
2023-07-01 22:35:53 - train: epoch 0148, iter [00150, 00390], lr: 0.000400, loss: 0.0114
2023-07-01 22:35:55 - train: epoch 0148, iter [00200, 00390], lr: 0.000400, loss: 0.0109
2023-07-01 22:35:58 - train: epoch 0148, iter [00250, 00390], lr: 0.000400, loss: 0.0246
2023-07-01 22:36:00 - train: epoch 0148, iter [00300, 00390], lr: 0.000400, loss: 0.0099
2023-07-01 22:36:03 - train: epoch 0148, iter [00350, 00390], lr: 0.000400, loss: 0.0208
2023-07-01 22:36:05 - train: epoch 148, train_loss: 0.0244
2023-07-01 22:36:06 - eval: epoch: 148, acc1: 42.200%, acc5: 67.910%, test_loss: 3.8578, per_image_load_time: 0.075ms, per_image_inference_time: 0.089ms
2023-07-01 22:36:07 - until epoch: 148, best_acc1: 42.960%
2023-07-01 22:36:07 - epoch 149 lr: 0.000400
2023-07-01 22:36:10 - train: epoch 0149, iter [00050, 00390], lr: 0.000400, loss: 0.0208
2023-07-01 22:36:13 - train: epoch 0149, iter [00100, 00390], lr: 0.000400, loss: 0.0246
2023-07-01 22:36:15 - train: epoch 0149, iter [00150, 00390], lr: 0.000400, loss: 0.0531
2023-07-01 22:36:18 - train: epoch 0149, iter [00200, 00390], lr: 0.000400, loss: 0.0113
2023-07-01 22:36:20 - train: epoch 0149, iter [00250, 00390], lr: 0.000400, loss: 0.0140
2023-07-01 22:36:22 - train: epoch 0149, iter [00300, 00390], lr: 0.000400, loss: 0.0180
2023-07-01 22:36:25 - train: epoch 0149, iter [00350, 00390], lr: 0.000400, loss: 0.0114
2023-07-01 22:36:27 - train: epoch 149, train_loss: 0.0230
2023-07-01 22:36:29 - eval: epoch: 149, acc1: 41.960%, acc5: 68.040%, test_loss: 3.8688, per_image_load_time: 0.074ms, per_image_inference_time: 0.089ms
2023-07-01 22:36:29 - until epoch: 149, best_acc1: 42.960%
2023-07-01 22:36:29 - epoch 150 lr: 0.000400
2023-07-01 22:36:32 - train: epoch 0150, iter [00050, 00390], lr: 0.000400, loss: 0.0375
2023-07-01 22:36:35 - train: epoch 0150, iter [00100, 00390], lr: 0.000400, loss: 0.0343
2023-07-01 22:36:37 - train: epoch 0150, iter [00150, 00390], lr: 0.000400, loss: 0.0333
2023-07-01 22:36:39 - train: epoch 0150, iter [00200, 00390], lr: 0.000400, loss: 0.0345
2023-07-01 22:36:42 - train: epoch 0150, iter [00250, 00390], lr: 0.000400, loss: 0.0159
2023-07-01 22:36:44 - train: epoch 0150, iter [00300, 00390], lr: 0.000400, loss: 0.0157
2023-07-01 22:36:47 - train: epoch 0150, iter [00350, 00390], lr: 0.000400, loss: 0.0143
2023-07-01 22:36:49 - train: epoch 150, train_loss: 0.0244
2023-07-01 22:36:50 - eval: epoch: 150, acc1: 41.990%, acc5: 67.910%, test_loss: 3.8733, per_image_load_time: 0.073ms, per_image_inference_time: 0.089ms
2023-07-01 22:36:51 - until epoch: 150, best_acc1: 42.960%
2023-07-01 22:36:51 - epoch 151 lr: 0.000400
2023-07-01 22:36:54 - train: epoch 0151, iter [00050, 00390], lr: 0.000400, loss: 0.0155
2023-07-01 22:36:57 - train: epoch 0151, iter [00100, 00390], lr: 0.000400, loss: 0.0169
2023-07-01 22:36:59 - train: epoch 0151, iter [00150, 00390], lr: 0.000400, loss: 0.0196
2023-07-01 22:37:01 - train: epoch 0151, iter [00200, 00390], lr: 0.000400, loss: 0.0286
2023-07-01 22:37:04 - train: epoch 0151, iter [00250, 00390], lr: 0.000400, loss: 0.0144
2023-07-01 22:37:06 - train: epoch 0151, iter [00300, 00390], lr: 0.000400, loss: 0.0246
2023-07-01 22:37:08 - train: epoch 0151, iter [00350, 00390], lr: 0.000400, loss: 0.0147
2023-07-01 22:37:10 - train: epoch 151, train_loss: 0.0232
2023-07-01 22:37:12 - eval: epoch: 151, acc1: 41.950%, acc5: 67.700%, test_loss: 3.8825, per_image_load_time: 0.075ms, per_image_inference_time: 0.088ms
2023-07-01 22:37:13 - until epoch: 151, best_acc1: 42.960%
2023-07-01 22:37:13 - epoch 152 lr: 0.000400
2023-07-01 22:37:16 - train: epoch 0152, iter [00050, 00390], lr: 0.000400, loss: 0.0142
2023-07-01 22:37:18 - train: epoch 0152, iter [00100, 00390], lr: 0.000400, loss: 0.0225
2023-07-01 22:37:21 - train: epoch 0152, iter [00150, 00390], lr: 0.000400, loss: 0.0261
2023-07-01 22:37:23 - train: epoch 0152, iter [00200, 00390], lr: 0.000400, loss: 0.0148
2023-07-01 22:37:26 - train: epoch 0152, iter [00250, 00390], lr: 0.000400, loss: 0.0450
2023-07-01 22:37:28 - train: epoch 0152, iter [00300, 00390], lr: 0.000400, loss: 0.0292
2023-07-01 22:37:30 - train: epoch 0152, iter [00350, 00390], lr: 0.000400, loss: 0.0125
2023-07-01 22:37:32 - train: epoch 152, train_loss: 0.0230
2023-07-01 22:37:34 - eval: epoch: 152, acc1: 42.130%, acc5: 67.920%, test_loss: 3.8784, per_image_load_time: 0.075ms, per_image_inference_time: 0.089ms
2023-07-01 22:37:35 - until epoch: 152, best_acc1: 42.960%
2023-07-01 22:37:35 - epoch 153 lr: 0.000400
2023-07-01 22:37:38 - train: epoch 0153, iter [00050, 00390], lr: 0.000400, loss: 0.0163
2023-07-01 22:37:41 - train: epoch 0153, iter [00100, 00390], lr: 0.000400, loss: 0.0188
2023-07-01 22:37:43 - train: epoch 0153, iter [00150, 00390], lr: 0.000400, loss: 0.0114
2023-07-01 22:37:46 - train: epoch 0153, iter [00200, 00390], lr: 0.000400, loss: 0.0134
2023-07-01 22:37:48 - train: epoch 0153, iter [00250, 00390], lr: 0.000400, loss: 0.0262
2023-07-01 22:37:50 - train: epoch 0153, iter [00300, 00390], lr: 0.000400, loss: 0.0391
2023-07-01 22:37:53 - train: epoch 0153, iter [00350, 00390], lr: 0.000400, loss: 0.0220
2023-07-01 22:37:55 - train: epoch 153, train_loss: 0.0217
2023-07-01 22:37:57 - eval: epoch: 153, acc1: 42.010%, acc5: 67.920%, test_loss: 3.8660, per_image_load_time: 0.073ms, per_image_inference_time: 0.090ms
2023-07-01 22:37:57 - until epoch: 153, best_acc1: 42.960%
2023-07-01 22:37:57 - epoch 154 lr: 0.000400
2023-07-01 22:38:00 - train: epoch 0154, iter [00050, 00390], lr: 0.000400, loss: 0.0154
2023-07-01 22:38:03 - train: epoch 0154, iter [00100, 00390], lr: 0.000400, loss: 0.0422
2023-07-01 22:38:05 - train: epoch 0154, iter [00150, 00390], lr: 0.000400, loss: 0.0434
2023-07-01 22:38:08 - train: epoch 0154, iter [00200, 00390], lr: 0.000400, loss: 0.0174
2023-07-01 22:38:10 - train: epoch 0154, iter [00250, 00390], lr: 0.000400, loss: 0.0343
2023-07-01 22:38:12 - train: epoch 0154, iter [00300, 00390], lr: 0.000400, loss: 0.0194
2023-07-01 22:38:15 - train: epoch 0154, iter [00350, 00390], lr: 0.000400, loss: 0.0184
2023-07-01 22:38:17 - train: epoch 154, train_loss: 0.0225
2023-07-01 22:38:19 - eval: epoch: 154, acc1: 41.930%, acc5: 67.870%, test_loss: 3.8887, per_image_load_time: 0.075ms, per_image_inference_time: 0.088ms
2023-07-01 22:38:19 - until epoch: 154, best_acc1: 42.960%
2023-07-01 22:38:19 - epoch 155 lr: 0.000400
2023-07-01 22:38:22 - train: epoch 0155, iter [00050, 00390], lr: 0.000400, loss: 0.0187
2023-07-01 22:38:25 - train: epoch 0155, iter [00100, 00390], lr: 0.000400, loss: 0.0496
2023-07-01 22:38:27 - train: epoch 0155, iter [00150, 00390], lr: 0.000400, loss: 0.0336
2023-07-01 22:38:30 - train: epoch 0155, iter [00200, 00390], lr: 0.000400, loss: 0.0164
2023-07-01 22:38:32 - train: epoch 0155, iter [00250, 00390], lr: 0.000400, loss: 0.0160
2023-07-01 22:38:35 - train: epoch 0155, iter [00300, 00390], lr: 0.000400, loss: 0.0171
2023-07-01 22:38:37 - train: epoch 0155, iter [00350, 00390], lr: 0.000400, loss: 0.0439
2023-07-01 22:38:39 - train: epoch 155, train_loss: 0.0222
2023-07-01 22:38:41 - eval: epoch: 155, acc1: 41.940%, acc5: 67.640%, test_loss: 3.8852, per_image_load_time: 0.076ms, per_image_inference_time: 0.087ms
2023-07-01 22:38:41 - until epoch: 155, best_acc1: 42.960%
2023-07-01 22:38:41 - epoch 156 lr: 0.000400
2023-07-01 22:38:45 - train: epoch 0156, iter [00050, 00390], lr: 0.000400, loss: 0.0179
2023-07-01 22:38:47 - train: epoch 0156, iter [00100, 00390], lr: 0.000400, loss: 0.0215
2023-07-01 22:38:50 - train: epoch 0156, iter [00150, 00390], lr: 0.000400, loss: 0.0319
2023-07-01 22:38:52 - train: epoch 0156, iter [00200, 00390], lr: 0.000400, loss: 0.0341
2023-07-01 22:38:54 - train: epoch 0156, iter [00250, 00390], lr: 0.000400, loss: 0.0480
2023-07-01 22:38:57 - train: epoch 0156, iter [00300, 00390], lr: 0.000400, loss: 0.0266
2023-07-01 22:38:59 - train: epoch 0156, iter [00350, 00390], lr: 0.000400, loss: 0.0191
2023-07-01 22:39:01 - train: epoch 156, train_loss: 0.0216
2023-07-01 22:39:03 - eval: epoch: 156, acc1: 41.920%, acc5: 67.650%, test_loss: 3.8983, per_image_load_time: 0.075ms, per_image_inference_time: 0.089ms
2023-07-01 22:39:03 - until epoch: 156, best_acc1: 42.960%
2023-07-01 22:39:03 - epoch 157 lr: 0.000400
2023-07-01 22:39:07 - train: epoch 0157, iter [00050, 00390], lr: 0.000400, loss: 0.0154
2023-07-01 22:39:09 - train: epoch 0157, iter [00100, 00390], lr: 0.000400, loss: 0.0267
2023-07-01 22:39:11 - train: epoch 0157, iter [00150, 00390], lr: 0.000400, loss: 0.0130
2023-07-01 22:39:14 - train: epoch 0157, iter [00200, 00390], lr: 0.000400, loss: 0.0143
2023-07-01 22:39:16 - train: epoch 0157, iter [00250, 00390], lr: 0.000400, loss: 0.0239
2023-07-01 22:39:19 - train: epoch 0157, iter [00300, 00390], lr: 0.000400, loss: 0.0394
2023-07-01 22:39:21 - train: epoch 0157, iter [00350, 00390], lr: 0.000400, loss: 0.0252
2023-07-01 22:39:23 - train: epoch 157, train_loss: 0.0206
2023-07-01 22:39:25 - eval: epoch: 157, acc1: 42.100%, acc5: 67.750%, test_loss: 3.8874, per_image_load_time: 0.071ms, per_image_inference_time: 0.088ms
2023-07-01 22:39:25 - until epoch: 157, best_acc1: 42.960%
2023-07-01 22:39:25 - epoch 158 lr: 0.000400
2023-07-01 22:39:28 - train: epoch 0158, iter [00050, 00390], lr: 0.000400, loss: 0.0294
2023-07-01 22:39:31 - train: epoch 0158, iter [00100, 00390], lr: 0.000400, loss: 0.0356
2023-07-01 22:39:33 - train: epoch 0158, iter [00150, 00390], lr: 0.000400, loss: 0.0316
2023-07-01 22:39:36 - train: epoch 0158, iter [00200, 00390], lr: 0.000400, loss: 0.0215
2023-07-01 22:39:38 - train: epoch 0158, iter [00250, 00390], lr: 0.000400, loss: 0.0292
2023-07-01 22:39:41 - train: epoch 0158, iter [00300, 00390], lr: 0.000400, loss: 0.0081
2023-07-01 22:39:43 - train: epoch 0158, iter [00350, 00390], lr: 0.000400, loss: 0.0097
2023-07-01 22:39:45 - train: epoch 158, train_loss: 0.0210
2023-07-01 22:39:47 - eval: epoch: 158, acc1: 41.940%, acc5: 67.580%, test_loss: 3.8983, per_image_load_time: 0.074ms, per_image_inference_time: 0.087ms
2023-07-01 22:39:48 - until epoch: 158, best_acc1: 42.960%
2023-07-01 22:39:48 - epoch 159 lr: 0.000400
2023-07-01 22:39:51 - train: epoch 0159, iter [00050, 00390], lr: 0.000400, loss: 0.0167
2023-07-01 22:39:54 - train: epoch 0159, iter [00100, 00390], lr: 0.000400, loss: 0.0270
2023-07-01 22:39:56 - train: epoch 0159, iter [00150, 00390], lr: 0.000400, loss: 0.0105
2023-07-01 22:39:59 - train: epoch 0159, iter [00200, 00390], lr: 0.000400, loss: 0.0170
2023-07-01 22:40:01 - train: epoch 0159, iter [00250, 00390], lr: 0.000400, loss: 0.0138
2023-07-01 22:40:03 - train: epoch 0159, iter [00300, 00390], lr: 0.000400, loss: 0.0098
2023-07-01 22:40:06 - train: epoch 0159, iter [00350, 00390], lr: 0.000400, loss: 0.0510
2023-07-01 22:40:08 - train: epoch 159, train_loss: 0.0210
2023-07-01 22:40:10 - eval: epoch: 159, acc1: 41.980%, acc5: 67.870%, test_loss: 3.8898, per_image_load_time: 0.074ms, per_image_inference_time: 0.089ms
2023-07-01 22:40:11 - until epoch: 159, best_acc1: 42.960%
2023-07-01 22:40:11 - epoch 160 lr: 0.000400
2023-07-01 22:40:14 - train: epoch 0160, iter [00050, 00390], lr: 0.000400, loss: 0.0098
2023-07-01 22:40:16 - train: epoch 0160, iter [00100, 00390], lr: 0.000400, loss: 0.0297
2023-07-01 22:40:19 - train: epoch 0160, iter [00150, 00390], lr: 0.000400, loss: 0.0114
2023-07-01 22:40:21 - train: epoch 0160, iter [00200, 00390], lr: 0.000400, loss: 0.0076
2023-07-01 22:40:23 - train: epoch 0160, iter [00250, 00390], lr: 0.000400, loss: 0.0350
2023-07-01 22:40:26 - train: epoch 0160, iter [00300, 00390], lr: 0.000400, loss: 0.0130
2023-07-01 22:40:28 - train: epoch 0160, iter [00350, 00390], lr: 0.000400, loss: 0.0172
2023-07-01 22:40:31 - train: epoch 160, train_loss: 0.0205
2023-07-01 22:40:32 - eval: epoch: 160, acc1: 41.990%, acc5: 67.880%, test_loss: 3.8905, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 22:40:35 - until epoch: 160, best_acc1: 42.960%
2023-07-01 22:40:35 - epoch 161 lr: 0.000080
2023-07-01 22:40:38 - train: epoch 0161, iter [00050, 00390], lr: 0.000080, loss: 0.0110
2023-07-01 22:40:40 - train: epoch 0161, iter [00100, 00390], lr: 0.000080, loss: 0.0156
2023-07-01 22:40:43 - train: epoch 0161, iter [00150, 00390], lr: 0.000080, loss: 0.0131
2023-07-01 22:40:45 - train: epoch 0161, iter [00200, 00390], lr: 0.000080, loss: 0.0278
2023-07-01 22:40:48 - train: epoch 0161, iter [00250, 00390], lr: 0.000080, loss: 0.0134
2023-07-01 22:40:50 - train: epoch 0161, iter [00300, 00390], lr: 0.000080, loss: 0.0072
2023-07-01 22:40:52 - train: epoch 0161, iter [00350, 00390], lr: 0.000080, loss: 0.0272
2023-07-01 22:40:54 - train: epoch 161, train_loss: 0.0197
2023-07-01 22:40:56 - eval: epoch: 161, acc1: 42.150%, acc5: 67.950%, test_loss: 3.8885, per_image_load_time: 0.071ms, per_image_inference_time: 0.088ms
2023-07-01 22:40:57 - until epoch: 161, best_acc1: 42.960%
2023-07-01 22:40:57 - epoch 162 lr: 0.000080
2023-07-01 22:41:00 - train: epoch 0162, iter [00050, 00390], lr: 0.000080, loss: 0.0397
2023-07-01 22:41:02 - train: epoch 0162, iter [00100, 00390], lr: 0.000080, loss: 0.0462
2023-07-01 22:41:05 - train: epoch 0162, iter [00150, 00390], lr: 0.000080, loss: 0.0213
2023-07-01 22:41:07 - train: epoch 0162, iter [00200, 00390], lr: 0.000080, loss: 0.0175
2023-07-01 22:41:10 - train: epoch 0162, iter [00250, 00390], lr: 0.000080, loss: 0.0382
2023-07-01 22:41:12 - train: epoch 0162, iter [00300, 00390], lr: 0.000080, loss: 0.0123
2023-07-01 22:41:14 - train: epoch 0162, iter [00350, 00390], lr: 0.000080, loss: 0.0109
2023-07-01 22:41:16 - train: epoch 162, train_loss: 0.0190
2023-07-01 22:41:18 - eval: epoch: 162, acc1: 42.110%, acc5: 67.910%, test_loss: 3.8851, per_image_load_time: 0.071ms, per_image_inference_time: 0.089ms
2023-07-01 22:41:18 - until epoch: 162, best_acc1: 42.960%
2023-07-01 22:41:18 - epoch 163 lr: 0.000080
2023-07-01 22:41:22 - train: epoch 0163, iter [00050, 00390], lr: 0.000080, loss: 0.0143
2023-07-01 22:41:24 - train: epoch 0163, iter [00100, 00390], lr: 0.000080, loss: 0.0112
2023-07-01 22:41:26 - train: epoch 0163, iter [00150, 00390], lr: 0.000080, loss: 0.0110
2023-07-01 22:41:29 - train: epoch 0163, iter [00200, 00390], lr: 0.000080, loss: 0.0171
2023-07-01 22:41:31 - train: epoch 0163, iter [00250, 00390], lr: 0.000080, loss: 0.0237
2023-07-01 22:41:34 - train: epoch 0163, iter [00300, 00390], lr: 0.000080, loss: 0.0222
2023-07-01 22:41:36 - train: epoch 0163, iter [00350, 00390], lr: 0.000080, loss: 0.0158
2023-07-01 22:41:38 - train: epoch 163, train_loss: 0.0182
2023-07-01 22:41:40 - eval: epoch: 163, acc1: 42.130%, acc5: 68.000%, test_loss: 3.8889, per_image_load_time: 0.072ms, per_image_inference_time: 0.087ms
2023-07-01 22:41:40 - until epoch: 163, best_acc1: 42.960%
2023-07-01 22:41:40 - epoch 164 lr: 0.000080
2023-07-01 22:41:43 - train: epoch 0164, iter [00050, 00390], lr: 0.000080, loss: 0.0116
2023-07-01 22:41:46 - train: epoch 0164, iter [00100, 00390], lr: 0.000080, loss: 0.0135
2023-07-01 22:41:48 - train: epoch 0164, iter [00150, 00390], lr: 0.000080, loss: 0.0207
2023-07-01 22:41:51 - train: epoch 0164, iter [00200, 00390], lr: 0.000080, loss: 0.0137
2023-07-01 22:41:53 - train: epoch 0164, iter [00250, 00390], lr: 0.000080, loss: 0.0173
2023-07-01 22:41:56 - train: epoch 0164, iter [00300, 00390], lr: 0.000080, loss: 0.0239
2023-07-01 22:41:58 - train: epoch 0164, iter [00350, 00390], lr: 0.000080, loss: 0.0179
2023-07-01 22:42:00 - train: epoch 164, train_loss: 0.0171
2023-07-01 22:42:02 - eval: epoch: 164, acc1: 42.120%, acc5: 67.960%, test_loss: 3.8909, per_image_load_time: 0.071ms, per_image_inference_time: 0.090ms
2023-07-01 22:42:02 - until epoch: 164, best_acc1: 42.960%
2023-07-01 22:42:02 - epoch 165 lr: 0.000080
2023-07-01 22:42:05 - train: epoch 0165, iter [00050, 00390], lr: 0.000080, loss: 0.0272
2023-07-01 22:42:08 - train: epoch 0165, iter [00100, 00390], lr: 0.000080, loss: 0.0165
2023-07-01 22:42:10 - train: epoch 0165, iter [00150, 00390], lr: 0.000080, loss: 0.0153
2023-07-01 22:42:13 - train: epoch 0165, iter [00200, 00390], lr: 0.000080, loss: 0.0164
2023-07-01 22:42:15 - train: epoch 0165, iter [00250, 00390], lr: 0.000080, loss: 0.0103
2023-07-01 22:42:17 - train: epoch 0165, iter [00300, 00390], lr: 0.000080, loss: 0.0130
2023-07-01 22:42:20 - train: epoch 0165, iter [00350, 00390], lr: 0.000080, loss: 0.0149
2023-07-01 22:42:22 - train: epoch 165, train_loss: 0.0179
2023-07-01 22:42:24 - eval: epoch: 165, acc1: 42.110%, acc5: 68.000%, test_loss: 3.8889, per_image_load_time: 0.075ms, per_image_inference_time: 0.088ms
2023-07-01 22:42:26 - until epoch: 165, best_acc1: 42.960%
2023-07-01 22:42:26 - epoch 166 lr: 0.000080
2023-07-01 22:42:29 - train: epoch 0166, iter [00050, 00390], lr: 0.000080, loss: 0.0189
2023-07-01 22:42:32 - train: epoch 0166, iter [00100, 00390], lr: 0.000080, loss: 0.0133
2023-07-01 22:42:34 - train: epoch 0166, iter [00150, 00390], lr: 0.000080, loss: 0.0244
2023-07-01 22:42:36 - train: epoch 0166, iter [00200, 00390], lr: 0.000080, loss: 0.0325
2023-07-01 22:42:39 - train: epoch 0166, iter [00250, 00390], lr: 0.000080, loss: 0.0168
2023-07-01 22:42:41 - train: epoch 0166, iter [00300, 00390], lr: 0.000080, loss: 0.0091
2023-07-01 22:42:44 - train: epoch 0166, iter [00350, 00390], lr: 0.000080, loss: 0.0215
2023-07-01 22:42:45 - train: epoch 166, train_loss: 0.0173
2023-07-01 22:42:47 - eval: epoch: 166, acc1: 42.060%, acc5: 67.920%, test_loss: 3.8910, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 22:42:49 - until epoch: 166, best_acc1: 42.960%
2023-07-01 22:42:49 - epoch 167 lr: 0.000080
2023-07-01 22:42:53 - train: epoch 0167, iter [00050, 00390], lr: 0.000080, loss: 0.0198
2023-07-01 22:42:55 - train: epoch 0167, iter [00100, 00390], lr: 0.000080, loss: 0.0159
2023-07-01 22:42:58 - train: epoch 0167, iter [00150, 00390], lr: 0.000080, loss: 0.0098
2023-07-01 22:43:00 - train: epoch 0167, iter [00200, 00390], lr: 0.000080, loss: 0.0107
2023-07-01 22:43:02 - train: epoch 0167, iter [00250, 00390], lr: 0.000080, loss: 0.0165
2023-07-01 22:43:05 - train: epoch 0167, iter [00300, 00390], lr: 0.000080, loss: 0.0222
2023-07-01 22:43:07 - train: epoch 0167, iter [00350, 00390], lr: 0.000080, loss: 0.0143
2023-07-01 22:43:09 - train: epoch 167, train_loss: 0.0177
2023-07-01 22:43:11 - eval: epoch: 167, acc1: 42.060%, acc5: 67.740%, test_loss: 3.8917, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 22:43:11 - until epoch: 167, best_acc1: 42.960%
2023-07-01 22:43:11 - epoch 168 lr: 0.000080
2023-07-01 22:43:15 - train: epoch 0168, iter [00050, 00390], lr: 0.000080, loss: 0.0175
2023-07-01 22:43:17 - train: epoch 0168, iter [00100, 00390], lr: 0.000080, loss: 0.0238
2023-07-01 22:43:20 - train: epoch 0168, iter [00150, 00390], lr: 0.000080, loss: 0.0123
2023-07-01 22:43:22 - train: epoch 0168, iter [00200, 00390], lr: 0.000080, loss: 0.0161
2023-07-01 22:43:24 - train: epoch 0168, iter [00250, 00390], lr: 0.000080, loss: 0.0160
2023-07-01 22:43:27 - train: epoch 0168, iter [00300, 00390], lr: 0.000080, loss: 0.0100
2023-07-01 22:43:29 - train: epoch 0168, iter [00350, 00390], lr: 0.000080, loss: 0.0121
2023-07-01 22:43:31 - train: epoch 168, train_loss: 0.0171
2023-07-01 22:43:33 - eval: epoch: 168, acc1: 42.120%, acc5: 67.790%, test_loss: 3.8929, per_image_load_time: 0.073ms, per_image_inference_time: 0.089ms
2023-07-01 22:43:33 - until epoch: 168, best_acc1: 42.960%
2023-07-01 22:43:33 - epoch 169 lr: 0.000080
2023-07-01 22:43:37 - train: epoch 0169, iter [00050, 00390], lr: 0.000080, loss: 0.0156
2023-07-01 22:43:39 - train: epoch 0169, iter [00100, 00390], lr: 0.000080, loss: 0.0075
2023-07-01 22:43:42 - train: epoch 0169, iter [00150, 00390], lr: 0.000080, loss: 0.0120
2023-07-01 22:43:44 - train: epoch 0169, iter [00200, 00390], lr: 0.000080, loss: 0.0150
2023-07-01 22:43:46 - train: epoch 0169, iter [00250, 00390], lr: 0.000080, loss: 0.0362
2023-07-01 22:43:49 - train: epoch 0169, iter [00300, 00390], lr: 0.000080, loss: 0.0247
2023-07-01 22:43:51 - train: epoch 0169, iter [00350, 00390], lr: 0.000080, loss: 0.0136
2023-07-01 22:43:53 - train: epoch 169, train_loss: 0.0183
2023-07-01 22:43:55 - eval: epoch: 169, acc1: 42.160%, acc5: 67.790%, test_loss: 3.8904, per_image_load_time: 0.072ms, per_image_inference_time: 0.087ms
2023-07-01 22:43:55 - until epoch: 169, best_acc1: 42.960%
2023-07-01 22:43:55 - epoch 170 lr: 0.000080
2023-07-01 22:43:58 - train: epoch 0170, iter [00050, 00390], lr: 0.000080, loss: 0.0114
2023-07-01 22:44:01 - train: epoch 0170, iter [00100, 00390], lr: 0.000080, loss: 0.0390
2023-07-01 22:44:03 - train: epoch 0170, iter [00150, 00390], lr: 0.000080, loss: 0.0344
2023-07-01 22:44:06 - train: epoch 0170, iter [00200, 00390], lr: 0.000080, loss: 0.0144
2023-07-01 22:44:08 - train: epoch 0170, iter [00250, 00390], lr: 0.000080, loss: 0.0093
2023-07-01 22:44:11 - train: epoch 0170, iter [00300, 00390], lr: 0.000080, loss: 0.0107
2023-07-01 22:44:13 - train: epoch 0170, iter [00350, 00390], lr: 0.000080, loss: 0.0229
2023-07-01 22:44:15 - train: epoch 170, train_loss: 0.0178
2023-07-01 22:44:17 - eval: epoch: 170, acc1: 41.990%, acc5: 67.850%, test_loss: 3.8917, per_image_load_time: 0.072ms, per_image_inference_time: 0.087ms
2023-07-01 22:44:17 - until epoch: 170, best_acc1: 42.960%
2023-07-01 22:44:17 - epoch 171 lr: 0.000080
2023-07-01 22:44:20 - train: epoch 0171, iter [00050, 00390], lr: 0.000080, loss: 0.0105
2023-07-01 22:44:23 - train: epoch 0171, iter [00100, 00390], lr: 0.000080, loss: 0.0206
2023-07-01 22:44:25 - train: epoch 0171, iter [00150, 00390], lr: 0.000080, loss: 0.0353
2023-07-01 22:44:28 - train: epoch 0171, iter [00200, 00390], lr: 0.000080, loss: 0.0092
2023-07-01 22:44:31 - train: epoch 0171, iter [00250, 00390], lr: 0.000080, loss: 0.0085
2023-07-01 22:44:34 - train: epoch 0171, iter [00300, 00390], lr: 0.000080, loss: 0.0196
2023-07-01 22:44:36 - train: epoch 0171, iter [00350, 00390], lr: 0.000080, loss: 0.0091
2023-07-01 22:44:38 - train: epoch 171, train_loss: 0.0175
2023-07-01 22:44:40 - eval: epoch: 171, acc1: 42.150%, acc5: 67.900%, test_loss: 3.8935, per_image_load_time: 0.072ms, per_image_inference_time: 0.087ms
2023-07-01 22:44:41 - until epoch: 171, best_acc1: 42.960%
2023-07-01 22:44:41 - epoch 172 lr: 0.000080
2023-07-01 22:44:44 - train: epoch 0172, iter [00050, 00390], lr: 0.000080, loss: 0.0129
2023-07-01 22:44:46 - train: epoch 0172, iter [00100, 00390], lr: 0.000080, loss: 0.0226
2023-07-01 22:44:49 - train: epoch 0172, iter [00150, 00390], lr: 0.000080, loss: 0.0132
2023-07-01 22:44:51 - train: epoch 0172, iter [00200, 00390], lr: 0.000080, loss: 0.0118
2023-07-01 22:44:54 - train: epoch 0172, iter [00250, 00390], lr: 0.000080, loss: 0.0184
2023-07-01 22:44:56 - train: epoch 0172, iter [00300, 00390], lr: 0.000080, loss: 0.0120
2023-07-01 22:44:59 - train: epoch 0172, iter [00350, 00390], lr: 0.000080, loss: 0.0156
2023-07-01 22:45:01 - train: epoch 172, train_loss: 0.0170
2023-07-01 22:45:03 - eval: epoch: 172, acc1: 42.190%, acc5: 67.830%, test_loss: 3.8938, per_image_load_time: 0.074ms, per_image_inference_time: 0.088ms
2023-07-01 22:45:03 - until epoch: 172, best_acc1: 42.960%
2023-07-01 22:45:03 - epoch 173 lr: 0.000080
2023-07-01 22:45:07 - train: epoch 0173, iter [00050, 00390], lr: 0.000080, loss: 0.0127
2023-07-01 22:45:09 - train: epoch 0173, iter [00100, 00390], lr: 0.000080, loss: 0.0106
2023-07-01 22:45:11 - train: epoch 0173, iter [00150, 00390], lr: 0.000080, loss: 0.0124
2023-07-01 22:45:14 - train: epoch 0173, iter [00200, 00390], lr: 0.000080, loss: 0.0331
2023-07-01 22:45:16 - train: epoch 0173, iter [00250, 00390], lr: 0.000080, loss: 0.0104
2023-07-01 22:45:19 - train: epoch 0173, iter [00300, 00390], lr: 0.000080, loss: 0.0119
2023-07-01 22:45:21 - train: epoch 0173, iter [00350, 00390], lr: 0.000080, loss: 0.0235
2023-07-01 22:45:23 - train: epoch 173, train_loss: 0.0171
2023-07-01 22:45:25 - eval: epoch: 173, acc1: 42.340%, acc5: 67.800%, test_loss: 3.8932, per_image_load_time: 0.074ms, per_image_inference_time: 0.088ms
2023-07-01 22:45:25 - until epoch: 173, best_acc1: 42.960%
2023-07-01 22:45:25 - epoch 174 lr: 0.000080
2023-07-01 22:45:29 - train: epoch 0174, iter [00050, 00390], lr: 0.000080, loss: 0.0204
2023-07-01 22:45:31 - train: epoch 0174, iter [00100, 00390], lr: 0.000080, loss: 0.0129
2023-07-01 22:45:34 - train: epoch 0174, iter [00150, 00390], lr: 0.000080, loss: 0.0224
2023-07-01 22:45:36 - train: epoch 0174, iter [00200, 00390], lr: 0.000080, loss: 0.0124
2023-07-01 22:45:39 - train: epoch 0174, iter [00250, 00390], lr: 0.000080, loss: 0.0078
2023-07-01 22:45:41 - train: epoch 0174, iter [00300, 00390], lr: 0.000080, loss: 0.0154
2023-07-01 22:45:44 - train: epoch 0174, iter [00350, 00390], lr: 0.000080, loss: 0.0217
2023-07-01 22:45:46 - train: epoch 174, train_loss: 0.0167
2023-07-01 22:45:47 - eval: epoch: 174, acc1: 42.200%, acc5: 67.780%, test_loss: 3.8966, per_image_load_time: 0.073ms, per_image_inference_time: 0.088ms
2023-07-01 22:45:48 - until epoch: 174, best_acc1: 42.960%
2023-07-01 22:45:48 - epoch 175 lr: 0.000080
2023-07-01 22:45:51 - train: epoch 0175, iter [00050, 00390], lr: 0.000080, loss: 0.0107
2023-07-01 22:45:53 - train: epoch 0175, iter [00100, 00390], lr: 0.000080, loss: 0.0164
2023-07-01 22:45:56 - train: epoch 0175, iter [00150, 00390], lr: 0.000080, loss: 0.0108
2023-07-01 22:45:58 - train: epoch 0175, iter [00200, 00390], lr: 0.000080, loss: 0.0133
2023-07-01 22:46:01 - train: epoch 0175, iter [00250, 00390], lr: 0.000080, loss: 0.0199
2023-07-01 22:46:03 - train: epoch 0175, iter [00300, 00390], lr: 0.000080, loss: 0.0244
2023-07-01 22:46:05 - train: epoch 0175, iter [00350, 00390], lr: 0.000080, loss: 0.0174
2023-07-01 22:46:07 - train: epoch 175, train_loss: 0.0171
2023-07-01 22:46:09 - eval: epoch: 175, acc1: 42.180%, acc5: 67.760%, test_loss: 3.8959, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 22:46:09 - until epoch: 175, best_acc1: 42.960%
2023-07-01 22:46:09 - epoch 176 lr: 0.000080
2023-07-01 22:46:13 - train: epoch 0176, iter [00050, 00390], lr: 0.000080, loss: 0.0489
2023-07-01 22:46:15 - train: epoch 0176, iter [00100, 00390], lr: 0.000080, loss: 0.0221
2023-07-01 22:46:17 - train: epoch 0176, iter [00150, 00390], lr: 0.000080, loss: 0.0133
2023-07-01 22:46:20 - train: epoch 0176, iter [00200, 00390], lr: 0.000080, loss: 0.0095
2023-07-01 22:46:22 - train: epoch 0176, iter [00250, 00390], lr: 0.000080, loss: 0.0107
2023-07-01 22:46:25 - train: epoch 0176, iter [00300, 00390], lr: 0.000080, loss: 0.0060
2023-07-01 22:46:27 - train: epoch 0176, iter [00350, 00390], lr: 0.000080, loss: 0.0112
2023-07-01 22:46:29 - train: epoch 176, train_loss: 0.0165
2023-07-01 22:46:31 - eval: epoch: 176, acc1: 42.310%, acc5: 67.820%, test_loss: 3.8960, per_image_load_time: 0.073ms, per_image_inference_time: 0.089ms
2023-07-01 22:46:31 - until epoch: 176, best_acc1: 42.960%
2023-07-01 22:46:31 - epoch 177 lr: 0.000080
2023-07-01 22:46:34 - train: epoch 0177, iter [00050, 00390], lr: 0.000080, loss: 0.0107
2023-07-01 22:46:37 - train: epoch 0177, iter [00100, 00390], lr: 0.000080, loss: 0.0144
2023-07-01 22:46:39 - train: epoch 0177, iter [00150, 00390], lr: 0.000080, loss: 0.0222
2023-07-01 22:46:42 - train: epoch 0177, iter [00200, 00390], lr: 0.000080, loss: 0.0138
2023-07-01 22:46:44 - train: epoch 0177, iter [00250, 00390], lr: 0.000080, loss: 0.0355
2023-07-01 22:46:46 - train: epoch 0177, iter [00300, 00390], lr: 0.000080, loss: 0.0150
2023-07-01 22:46:49 - train: epoch 0177, iter [00350, 00390], lr: 0.000080, loss: 0.0273
2023-07-01 22:46:51 - train: epoch 177, train_loss: 0.0166
2023-07-01 22:46:52 - eval: epoch: 177, acc1: 42.130%, acc5: 67.810%, test_loss: 3.8977, per_image_load_time: 0.071ms, per_image_inference_time: 0.089ms
2023-07-01 22:46:55 - until epoch: 177, best_acc1: 42.960%
2023-07-01 22:46:55 - epoch 178 lr: 0.000080
2023-07-01 22:46:59 - train: epoch 0178, iter [00050, 00390], lr: 0.000080, loss: 0.0155
2023-07-01 22:47:01 - train: epoch 0178, iter [00100, 00390], lr: 0.000080, loss: 0.0214
2023-07-01 22:47:03 - train: epoch 0178, iter [00150, 00390], lr: 0.000080, loss: 0.0149
2023-07-01 22:47:06 - train: epoch 0178, iter [00200, 00390], lr: 0.000080, loss: 0.0179
2023-07-01 22:47:08 - train: epoch 0178, iter [00250, 00390], lr: 0.000080, loss: 0.0179
2023-07-01 22:47:11 - train: epoch 0178, iter [00300, 00390], lr: 0.000080, loss: 0.0065
2023-07-01 22:47:13 - train: epoch 0178, iter [00350, 00390], lr: 0.000080, loss: 0.0118
2023-07-01 22:47:15 - train: epoch 178, train_loss: 0.0168
2023-07-01 22:47:17 - eval: epoch: 178, acc1: 42.330%, acc5: 67.870%, test_loss: 3.8986, per_image_load_time: 0.075ms, per_image_inference_time: 0.088ms
2023-07-01 22:47:17 - until epoch: 178, best_acc1: 42.960%
2023-07-01 22:47:17 - epoch 179 lr: 0.000080
2023-07-01 22:47:20 - train: epoch 0179, iter [00050, 00390], lr: 0.000080, loss: 0.0167
2023-07-01 22:47:23 - train: epoch 0179, iter [00100, 00390], lr: 0.000080, loss: 0.0141
2023-07-01 22:47:25 - train: epoch 0179, iter [00150, 00390], lr: 0.000080, loss: 0.0125
2023-07-01 22:47:28 - train: epoch 0179, iter [00200, 00390], lr: 0.000080, loss: 0.0250
2023-07-01 22:47:30 - train: epoch 0179, iter [00250, 00390], lr: 0.000080, loss: 0.0123
2023-07-01 22:47:32 - train: epoch 0179, iter [00300, 00390], lr: 0.000080, loss: 0.0139
2023-07-01 22:47:35 - train: epoch 0179, iter [00350, 00390], lr: 0.000080, loss: 0.0126
2023-07-01 22:47:37 - train: epoch 179, train_loss: 0.0169
2023-07-01 22:47:39 - eval: epoch: 179, acc1: 42.210%, acc5: 67.820%, test_loss: 3.8980, per_image_load_time: 0.074ms, per_image_inference_time: 0.090ms
2023-07-01 22:47:39 - until epoch: 179, best_acc1: 42.960%
2023-07-01 22:47:39 - epoch 180 lr: 0.000080
2023-07-01 22:47:42 - train: epoch 0180, iter [00050, 00390], lr: 0.000080, loss: 0.0112
2023-07-01 22:47:45 - train: epoch 0180, iter [00100, 00390], lr: 0.000080, loss: 0.0130
2023-07-01 22:47:47 - train: epoch 0180, iter [00150, 00390], lr: 0.000080, loss: 0.0149
2023-07-01 22:47:49 - train: epoch 0180, iter [00200, 00390], lr: 0.000080, loss: 0.0185
2023-07-01 22:47:52 - train: epoch 0180, iter [00250, 00390], lr: 0.000080, loss: 0.0212
2023-07-01 22:47:54 - train: epoch 0180, iter [00300, 00390], lr: 0.000080, loss: 0.0212
2023-07-01 22:47:57 - train: epoch 0180, iter [00350, 00390], lr: 0.000080, loss: 0.0171
2023-07-01 22:47:59 - train: epoch 180, train_loss: 0.0164
2023-07-01 22:48:01 - eval: epoch: 180, acc1: 42.320%, acc5: 67.880%, test_loss: 3.9003, per_image_load_time: 0.093ms, per_image_inference_time: 0.087ms
2023-07-01 22:48:01 - until epoch: 180, best_acc1: 42.960%
2023-07-01 22:48:01 - epoch 181 lr: 0.000080
2023-07-01 22:48:05 - train: epoch 0181, iter [00050, 00390], lr: 0.000080, loss: 0.0296
2023-07-01 22:48:07 - train: epoch 0181, iter [00100, 00390], lr: 0.000080, loss: 0.0110
2023-07-01 22:48:09 - train: epoch 0181, iter [00150, 00390], lr: 0.000080, loss: 0.0149
2023-07-01 22:48:12 - train: epoch 0181, iter [00200, 00390], lr: 0.000080, loss: 0.0073
2023-07-01 22:48:14 - train: epoch 0181, iter [00250, 00390], lr: 0.000080, loss: 0.0126
2023-07-01 22:48:17 - train: epoch 0181, iter [00300, 00390], lr: 0.000080, loss: 0.0334
2023-07-01 22:48:19 - train: epoch 0181, iter [00350, 00390], lr: 0.000080, loss: 0.0168
2023-07-01 22:48:21 - train: epoch 181, train_loss: 0.0171
2023-07-01 22:48:23 - eval: epoch: 181, acc1: 42.200%, acc5: 67.940%, test_loss: 3.8997, per_image_load_time: 0.074ms, per_image_inference_time: 0.089ms
2023-07-01 22:48:23 - until epoch: 181, best_acc1: 42.960%
2023-07-01 22:48:23 - epoch 182 lr: 0.000080
2023-07-01 22:48:27 - train: epoch 0182, iter [00050, 00390], lr: 0.000080, loss: 0.0183
2023-07-01 22:48:29 - train: epoch 0182, iter [00100, 00390], lr: 0.000080, loss: 0.0127
2023-07-01 22:48:31 - train: epoch 0182, iter [00150, 00390], lr: 0.000080, loss: 0.0117
2023-07-01 22:48:34 - train: epoch 0182, iter [00200, 00390], lr: 0.000080, loss: 0.0118
2023-07-01 22:48:36 - train: epoch 0182, iter [00250, 00390], lr: 0.000080, loss: 0.0114
2023-07-01 22:48:39 - train: epoch 0182, iter [00300, 00390], lr: 0.000080, loss: 0.0246
2023-07-01 22:48:41 - train: epoch 0182, iter [00350, 00390], lr: 0.000080, loss: 0.0124
2023-07-01 22:48:43 - train: epoch 182, train_loss: 0.0161
2023-07-01 22:48:45 - eval: epoch: 182, acc1: 42.100%, acc5: 67.950%, test_loss: 3.8974, per_image_load_time: 0.075ms, per_image_inference_time: 0.089ms
2023-07-01 22:48:45 - until epoch: 182, best_acc1: 42.960%
2023-07-01 22:48:45 - epoch 183 lr: 0.000080
2023-07-01 22:48:49 - train: epoch 0183, iter [00050, 00390], lr: 0.000080, loss: 0.0161
2023-07-01 22:48:51 - train: epoch 0183, iter [00100, 00390], lr: 0.000080, loss: 0.0164
2023-07-01 22:48:54 - train: epoch 0183, iter [00150, 00390], lr: 0.000080, loss: 0.0111
2023-07-01 22:48:56 - train: epoch 0183, iter [00200, 00390], lr: 0.000080, loss: 0.0105
2023-07-01 22:48:59 - train: epoch 0183, iter [00250, 00390], lr: 0.000080, loss: 0.0159
2023-07-01 22:49:01 - train: epoch 0183, iter [00300, 00390], lr: 0.000080, loss: 0.0096
2023-07-01 22:49:03 - train: epoch 0183, iter [00350, 00390], lr: 0.000080, loss: 0.0125
2023-07-01 22:49:05 - train: epoch 183, train_loss: 0.0171
2023-07-01 22:49:07 - eval: epoch: 183, acc1: 42.070%, acc5: 67.870%, test_loss: 3.8990, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 22:49:08 - until epoch: 183, best_acc1: 42.960%
2023-07-01 22:49:08 - epoch 184 lr: 0.000080
2023-07-01 22:49:11 - train: epoch 0184, iter [00050, 00390], lr: 0.000080, loss: 0.0126
2023-07-01 22:49:13 - train: epoch 0184, iter [00100, 00390], lr: 0.000080, loss: 0.0128
2023-07-01 22:49:16 - train: epoch 0184, iter [00150, 00390], lr: 0.000080, loss: 0.0137
2023-07-01 22:49:18 - train: epoch 0184, iter [00200, 00390], lr: 0.000080, loss: 0.0085
2023-07-01 22:49:21 - train: epoch 0184, iter [00250, 00390], lr: 0.000080, loss: 0.0101
2023-07-01 22:49:23 - train: epoch 0184, iter [00300, 00390], lr: 0.000080, loss: 0.0062
2023-07-01 22:49:26 - train: epoch 0184, iter [00350, 00390], lr: 0.000080, loss: 0.0083
2023-07-01 22:49:28 - train: epoch 184, train_loss: 0.0161
2023-07-01 22:49:30 - eval: epoch: 184, acc1: 42.280%, acc5: 67.970%, test_loss: 3.8971, per_image_load_time: 0.099ms, per_image_inference_time: 0.091ms
2023-07-01 22:49:30 - until epoch: 184, best_acc1: 42.960%
2023-07-01 22:49:30 - epoch 185 lr: 0.000080
2023-07-01 22:49:34 - train: epoch 0185, iter [00050, 00390], lr: 0.000080, loss: 0.0266
2023-07-01 22:49:36 - train: epoch 0185, iter [00100, 00390], lr: 0.000080, loss: 0.0236
2023-07-01 22:49:38 - train: epoch 0185, iter [00150, 00390], lr: 0.000080, loss: 0.0214
2023-07-01 22:49:41 - train: epoch 0185, iter [00200, 00390], lr: 0.000080, loss: 0.0231
2023-07-01 22:49:43 - train: epoch 0185, iter [00250, 00390], lr: 0.000080, loss: 0.0113
2023-07-01 22:49:46 - train: epoch 0185, iter [00300, 00390], lr: 0.000080, loss: 0.0094
2023-07-01 22:49:48 - train: epoch 0185, iter [00350, 00390], lr: 0.000080, loss: 0.0194
2023-07-01 22:49:50 - train: epoch 185, train_loss: 0.0168
2023-07-01 22:49:52 - eval: epoch: 185, acc1: 42.250%, acc5: 67.850%, test_loss: 3.8996, per_image_load_time: 0.079ms, per_image_inference_time: 0.089ms
2023-07-01 22:49:52 - until epoch: 185, best_acc1: 42.960%
2023-07-01 22:49:52 - epoch 186 lr: 0.000080
2023-07-01 22:49:56 - train: epoch 0186, iter [00050, 00390], lr: 0.000080, loss: 0.0122
2023-07-01 22:49:58 - train: epoch 0186, iter [00100, 00390], lr: 0.000080, loss: 0.0124
2023-07-01 22:50:00 - train: epoch 0186, iter [00150, 00390], lr: 0.000080, loss: 0.0142
2023-07-01 22:50:03 - train: epoch 0186, iter [00200, 00390], lr: 0.000080, loss: 0.0087
2023-07-01 22:50:05 - train: epoch 0186, iter [00250, 00390], lr: 0.000080, loss: 0.0111
2023-07-01 22:50:08 - train: epoch 0186, iter [00300, 00390], lr: 0.000080, loss: 0.0085
2023-07-01 22:50:10 - train: epoch 0186, iter [00350, 00390], lr: 0.000080, loss: 0.0453
2023-07-01 22:50:12 - train: epoch 186, train_loss: 0.0160
2023-07-01 22:50:14 - eval: epoch: 186, acc1: 42.250%, acc5: 67.970%, test_loss: 3.9028, per_image_load_time: 0.095ms, per_image_inference_time: 0.091ms
2023-07-01 22:50:15 - until epoch: 186, best_acc1: 42.960%
2023-07-01 22:50:15 - epoch 187 lr: 0.000080
2023-07-01 22:50:18 - train: epoch 0187, iter [00050, 00390], lr: 0.000080, loss: 0.0062
2023-07-01 22:50:20 - train: epoch 0187, iter [00100, 00390], lr: 0.000080, loss: 0.0207
2023-07-01 22:50:23 - train: epoch 0187, iter [00150, 00390], lr: 0.000080, loss: 0.0076
2023-07-01 22:50:25 - train: epoch 0187, iter [00200, 00390], lr: 0.000080, loss: 0.0244
2023-07-01 22:50:27 - train: epoch 0187, iter [00250, 00390], lr: 0.000080, loss: 0.0195
2023-07-01 22:50:30 - train: epoch 0187, iter [00300, 00390], lr: 0.000080, loss: 0.0124
2023-07-01 22:50:32 - train: epoch 0187, iter [00350, 00390], lr: 0.000080, loss: 0.0251
2023-07-01 22:50:34 - train: epoch 187, train_loss: 0.0167
2023-07-01 22:50:36 - eval: epoch: 187, acc1: 42.200%, acc5: 67.970%, test_loss: 3.8996, per_image_load_time: 0.082ms, per_image_inference_time: 0.088ms
2023-07-01 22:50:37 - until epoch: 187, best_acc1: 42.960%
2023-07-01 22:50:37 - epoch 188 lr: 0.000080
2023-07-01 22:50:40 - train: epoch 0188, iter [00050, 00390], lr: 0.000080, loss: 0.0134
2023-07-01 22:50:42 - train: epoch 0188, iter [00100, 00390], lr: 0.000080, loss: 0.0073
2023-07-01 22:50:44 - train: epoch 0188, iter [00150, 00390], lr: 0.000080, loss: 0.0116
2023-07-01 22:50:47 - train: epoch 0188, iter [00200, 00390], lr: 0.000080, loss: 0.0122
2023-07-01 22:50:49 - train: epoch 0188, iter [00250, 00390], lr: 0.000080, loss: 0.0117
2023-07-01 22:50:52 - train: epoch 0188, iter [00300, 00390], lr: 0.000080, loss: 0.0099
2023-07-01 22:50:54 - train: epoch 0188, iter [00350, 00390], lr: 0.000080, loss: 0.0123
2023-07-01 22:50:56 - train: epoch 188, train_loss: 0.0162
2023-07-01 22:50:58 - eval: epoch: 188, acc1: 42.270%, acc5: 67.950%, test_loss: 3.9000, per_image_load_time: 0.076ms, per_image_inference_time: 0.095ms
2023-07-01 22:51:00 - until epoch: 188, best_acc1: 42.960%
2023-07-01 22:51:00 - epoch 189 lr: 0.000080
2023-07-01 22:51:03 - train: epoch 0189, iter [00050, 00390], lr: 0.000080, loss: 0.0136
2023-07-01 22:51:05 - train: epoch 0189, iter [00100, 00390], lr: 0.000080, loss: 0.0262
2023-07-01 22:51:08 - train: epoch 0189, iter [00150, 00390], lr: 0.000080, loss: 0.0124
2023-07-01 22:51:10 - train: epoch 0189, iter [00200, 00390], lr: 0.000080, loss: 0.0101
2023-07-01 22:51:12 - train: epoch 0189, iter [00250, 00390], lr: 0.000080, loss: 0.0201
2023-07-01 22:51:15 - train: epoch 0189, iter [00300, 00390], lr: 0.000080, loss: 0.0151
2023-07-01 22:51:17 - train: epoch 0189, iter [00350, 00390], lr: 0.000080, loss: 0.0100
2023-07-01 22:51:19 - train: epoch 189, train_loss: 0.0158
2023-07-01 22:51:21 - eval: epoch: 189, acc1: 42.200%, acc5: 67.860%, test_loss: 3.9042, per_image_load_time: 0.074ms, per_image_inference_time: 0.088ms
2023-07-01 22:51:22 - until epoch: 189, best_acc1: 42.960%
2023-07-01 22:51:22 - epoch 190 lr: 0.000080
2023-07-01 22:51:25 - train: epoch 0190, iter [00050, 00390], lr: 0.000080, loss: 0.0139
2023-07-01 22:51:27 - train: epoch 0190, iter [00100, 00390], lr: 0.000080, loss: 0.0131
2023-07-01 22:51:30 - train: epoch 0190, iter [00150, 00390], lr: 0.000080, loss: 0.0383
2023-07-01 22:51:32 - train: epoch 0190, iter [00200, 00390], lr: 0.000080, loss: 0.0208
2023-07-01 22:51:34 - train: epoch 0190, iter [00250, 00390], lr: 0.000080, loss: 0.0188
2023-07-01 22:51:37 - train: epoch 0190, iter [00300, 00390], lr: 0.000080, loss: 0.0178
2023-07-01 22:51:39 - train: epoch 0190, iter [00350, 00390], lr: 0.000080, loss: 0.0255
2023-07-01 22:51:41 - train: epoch 190, train_loss: 0.0161
2023-07-01 22:51:43 - eval: epoch: 190, acc1: 42.220%, acc5: 67.810%, test_loss: 3.9046, per_image_load_time: 0.074ms, per_image_inference_time: 0.087ms
2023-07-01 22:51:44 - until epoch: 190, best_acc1: 42.960%
2023-07-01 22:51:44 - epoch 191 lr: 0.000080
2023-07-01 22:51:47 - train: epoch 0191, iter [00050, 00390], lr: 0.000080, loss: 0.0195
2023-07-01 22:51:49 - train: epoch 0191, iter [00100, 00390], lr: 0.000080, loss: 0.0147
2023-07-01 22:51:52 - train: epoch 0191, iter [00150, 00390], lr: 0.000080, loss: 0.0078
2023-07-01 22:51:54 - train: epoch 0191, iter [00200, 00390], lr: 0.000080, loss: 0.0148
2023-07-01 22:51:56 - train: epoch 0191, iter [00250, 00390], lr: 0.000080, loss: 0.0179
2023-07-01 22:51:59 - train: epoch 0191, iter [00300, 00390], lr: 0.000080, loss: 0.0234
2023-07-01 22:52:01 - train: epoch 0191, iter [00350, 00390], lr: 0.000080, loss: 0.0074
2023-07-01 22:52:03 - train: epoch 191, train_loss: 0.0157
2023-07-01 22:52:05 - eval: epoch: 191, acc1: 42.190%, acc5: 67.770%, test_loss: 3.9029, per_image_load_time: 0.073ms, per_image_inference_time: 0.095ms
2023-07-01 22:52:05 - until epoch: 191, best_acc1: 42.960%
2023-07-01 22:52:05 - epoch 192 lr: 0.000080
2023-07-01 22:52:09 - train: epoch 0192, iter [00050, 00390], lr: 0.000080, loss: 0.0093
2023-07-01 22:52:11 - train: epoch 0192, iter [00100, 00390], lr: 0.000080, loss: 0.0097
2023-07-01 22:52:13 - train: epoch 0192, iter [00150, 00390], lr: 0.000080, loss: 0.0190
2023-07-01 22:52:16 - train: epoch 0192, iter [00200, 00390], lr: 0.000080, loss: 0.0151
2023-07-01 22:52:18 - train: epoch 0192, iter [00250, 00390], lr: 0.000080, loss: 0.0125
2023-07-01 22:52:20 - train: epoch 0192, iter [00300, 00390], lr: 0.000080, loss: 0.0098
2023-07-01 22:52:23 - train: epoch 0192, iter [00350, 00390], lr: 0.000080, loss: 0.0084
2023-07-01 22:52:25 - train: epoch 192, train_loss: 0.0155
2023-07-01 22:52:27 - eval: epoch: 192, acc1: 42.250%, acc5: 67.890%, test_loss: 3.9058, per_image_load_time: 0.073ms, per_image_inference_time: 0.089ms
2023-07-01 22:52:28 - until epoch: 192, best_acc1: 42.960%
2023-07-01 22:52:28 - epoch 193 lr: 0.000080
2023-07-01 22:52:32 - train: epoch 0193, iter [00050, 00390], lr: 0.000080, loss: 0.0142
2023-07-01 22:52:34 - train: epoch 0193, iter [00100, 00390], lr: 0.000080, loss: 0.0129
2023-07-01 22:52:37 - train: epoch 0193, iter [00150, 00390], lr: 0.000080, loss: 0.0109
2023-07-01 22:52:39 - train: epoch 0193, iter [00200, 00390], lr: 0.000080, loss: 0.0056
2023-07-01 22:52:42 - train: epoch 0193, iter [00250, 00390], lr: 0.000080, loss: 0.0105
2023-07-01 22:52:44 - train: epoch 0193, iter [00300, 00390], lr: 0.000080, loss: 0.0134
2023-07-01 22:52:47 - train: epoch 0193, iter [00350, 00390], lr: 0.000080, loss: 0.0241
2023-07-01 22:52:49 - train: epoch 193, train_loss: 0.0152
2023-07-01 22:52:50 - eval: epoch: 193, acc1: 42.210%, acc5: 67.890%, test_loss: 3.9073, per_image_load_time: 0.073ms, per_image_inference_time: 0.104ms
2023-07-01 22:52:51 - until epoch: 193, best_acc1: 42.960%
2023-07-01 22:52:51 - epoch 194 lr: 0.000080
2023-07-01 22:52:54 - train: epoch 0194, iter [00050, 00390], lr: 0.000080, loss: 0.0103
2023-07-01 22:52:57 - train: epoch 0194, iter [00100, 00390], lr: 0.000080, loss: 0.0071
2023-07-01 22:52:59 - train: epoch 0194, iter [00150, 00390], lr: 0.000080, loss: 0.0170
2023-07-01 22:53:02 - train: epoch 0194, iter [00200, 00390], lr: 0.000080, loss: 0.0086
2023-07-01 22:53:05 - train: epoch 0194, iter [00250, 00390], lr: 0.000080, loss: 0.0179
2023-07-01 22:53:07 - train: epoch 0194, iter [00300, 00390], lr: 0.000080, loss: 0.0190
2023-07-01 22:53:09 - train: epoch 0194, iter [00350, 00390], lr: 0.000080, loss: 0.0092
2023-07-01 22:53:11 - train: epoch 194, train_loss: 0.0155
2023-07-01 22:53:13 - eval: epoch: 194, acc1: 42.280%, acc5: 67.760%, test_loss: 3.9097, per_image_load_time: 0.074ms, per_image_inference_time: 0.089ms
2023-07-01 22:53:13 - until epoch: 194, best_acc1: 42.960%
2023-07-01 22:53:13 - epoch 195 lr: 0.000080
2023-07-01 22:53:17 - train: epoch 0195, iter [00050, 00390], lr: 0.000080, loss: 0.0108
2023-07-01 22:53:19 - train: epoch 0195, iter [00100, 00390], lr: 0.000080, loss: 0.0118
2023-07-01 22:53:22 - train: epoch 0195, iter [00150, 00390], lr: 0.000080, loss: 0.0196
2023-07-01 22:53:24 - train: epoch 0195, iter [00200, 00390], lr: 0.000080, loss: 0.0088
2023-07-01 22:53:27 - train: epoch 0195, iter [00250, 00390], lr: 0.000080, loss: 0.0089
2023-07-01 22:53:29 - train: epoch 0195, iter [00300, 00390], lr: 0.000080, loss: 0.0110
2023-07-01 22:53:32 - train: epoch 0195, iter [00350, 00390], lr: 0.000080, loss: 0.0153
2023-07-01 22:53:33 - train: epoch 195, train_loss: 0.0152
2023-07-01 22:53:35 - eval: epoch: 195, acc1: 42.220%, acc5: 67.890%, test_loss: 3.9089, per_image_load_time: 0.072ms, per_image_inference_time: 0.088ms
2023-07-01 22:53:36 - until epoch: 195, best_acc1: 42.960%
2023-07-01 22:53:36 - epoch 196 lr: 0.000080
2023-07-01 22:53:39 - train: epoch 0196, iter [00050, 00390], lr: 0.000080, loss: 0.0324
2023-07-01 22:53:41 - train: epoch 0196, iter [00100, 00390], lr: 0.000080, loss: 0.0194
2023-07-01 22:53:44 - train: epoch 0196, iter [00150, 00390], lr: 0.000080, loss: 0.0263
2023-07-01 22:53:46 - train: epoch 0196, iter [00200, 00390], lr: 0.000080, loss: 0.0146
2023-07-01 22:53:48 - train: epoch 0196, iter [00250, 00390], lr: 0.000080, loss: 0.0175
2023-07-01 22:53:51 - train: epoch 0196, iter [00300, 00390], lr: 0.000080, loss: 0.0149
2023-07-01 22:53:53 - train: epoch 0196, iter [00350, 00390], lr: 0.000080, loss: 0.0123
2023-07-01 22:53:55 - train: epoch 196, train_loss: 0.0155
2023-07-01 22:53:57 - eval: epoch: 196, acc1: 42.310%, acc5: 67.940%, test_loss: 3.9093, per_image_load_time: 0.073ms, per_image_inference_time: 0.089ms
2023-07-01 22:53:57 - until epoch: 196, best_acc1: 42.960%
2023-07-01 22:53:57 - epoch 197 lr: 0.000080
2023-07-01 22:54:01 - train: epoch 0197, iter [00050, 00390], lr: 0.000080, loss: 0.0074
2023-07-01 22:54:03 - train: epoch 0197, iter [00100, 00390], lr: 0.000080, loss: 0.0363
2023-07-01 22:54:06 - train: epoch 0197, iter [00150, 00390], lr: 0.000080, loss: 0.0166
2023-07-01 22:54:08 - train: epoch 0197, iter [00200, 00390], lr: 0.000080, loss: 0.0109
2023-07-01 22:54:11 - train: epoch 0197, iter [00250, 00390], lr: 0.000080, loss: 0.0280
2023-07-01 22:54:13 - train: epoch 0197, iter [00300, 00390], lr: 0.000080, loss: 0.0081
2023-07-01 22:54:15 - train: epoch 0197, iter [00350, 00390], lr: 0.000080, loss: 0.0068
2023-07-01 22:54:17 - train: epoch 197, train_loss: 0.0157
2023-07-01 22:54:19 - eval: epoch: 197, acc1: 42.370%, acc5: 67.920%, test_loss: 3.9102, per_image_load_time: 0.074ms, per_image_inference_time: 0.086ms
2023-07-01 22:54:21 - until epoch: 197, best_acc1: 42.960%
2023-07-01 22:54:21 - epoch 198 lr: 0.000080
2023-07-01 22:54:25 - train: epoch 0198, iter [00050, 00390], lr: 0.000080, loss: 0.0184
2023-07-01 22:54:27 - train: epoch 0198, iter [00100, 00390], lr: 0.000080, loss: 0.0102
2023-07-01 22:54:30 - train: epoch 0198, iter [00150, 00390], lr: 0.000080, loss: 0.0185
2023-07-01 22:54:32 - train: epoch 0198, iter [00200, 00390], lr: 0.000080, loss: 0.0178
2023-07-01 22:54:34 - train: epoch 0198, iter [00250, 00390], lr: 0.000080, loss: 0.0274
2023-07-01 22:54:37 - train: epoch 0198, iter [00300, 00390], lr: 0.000080, loss: 0.0090
2023-07-01 22:54:39 - train: epoch 0198, iter [00350, 00390], lr: 0.000080, loss: 0.0269
2023-07-01 22:54:41 - train: epoch 198, train_loss: 0.0154
2023-07-01 22:54:43 - eval: epoch: 198, acc1: 42.300%, acc5: 67.860%, test_loss: 3.9107, per_image_load_time: 0.072ms, per_image_inference_time: 0.089ms
2023-07-01 22:54:44 - until epoch: 198, best_acc1: 42.960%
2023-07-01 22:54:44 - epoch 199 lr: 0.000080
2023-07-01 22:54:47 - train: epoch 0199, iter [00050, 00390], lr: 0.000080, loss: 0.0227
2023-07-01 22:54:49 - train: epoch 0199, iter [00100, 00390], lr: 0.000080, loss: 0.0109
2023-07-01 22:54:52 - train: epoch 0199, iter [00150, 00390], lr: 0.000080, loss: 0.0115
2023-07-01 22:54:54 - train: epoch 0199, iter [00200, 00390], lr: 0.000080, loss: 0.0209
2023-07-01 22:54:56 - train: epoch 0199, iter [00250, 00390], lr: 0.000080, loss: 0.0205
2023-07-01 22:54:59 - train: epoch 0199, iter [00300, 00390], lr: 0.000080, loss: 0.0119
2023-07-01 22:55:01 - train: epoch 0199, iter [00350, 00390], lr: 0.000080, loss: 0.0156
2023-07-01 22:55:03 - train: epoch 199, train_loss: 0.0155
2023-07-01 22:55:05 - eval: epoch: 199, acc1: 42.230%, acc5: 67.790%, test_loss: 3.9108, per_image_load_time: 0.073ms, per_image_inference_time: 0.096ms
2023-07-01 22:55:06 - until epoch: 199, best_acc1: 42.960%
2023-07-01 22:55:06 - epoch 200 lr: 0.000080
2023-07-01 22:55:09 - train: epoch 0200, iter [00050, 00390], lr: 0.000080, loss: 0.0250
2023-07-01 22:55:11 - train: epoch 0200, iter [00100, 00390], lr: 0.000080, loss: 0.0133
2023-07-01 22:55:14 - train: epoch 0200, iter [00150, 00390], lr: 0.000080, loss: 0.0173
2023-07-01 22:55:16 - train: epoch 0200, iter [00200, 00390], lr: 0.000080, loss: 0.0111
2023-07-01 22:55:18 - train: epoch 0200, iter [00250, 00390], lr: 0.000080, loss: 0.0069
2023-07-01 22:55:21 - train: epoch 0200, iter [00300, 00390], lr: 0.000080, loss: 0.0088
2023-07-01 22:55:23 - train: epoch 0200, iter [00350, 00390], lr: 0.000080, loss: 0.0247
2023-07-01 22:55:25 - train: epoch 200, train_loss: 0.0151
2023-07-01 22:55:27 - eval: epoch: 200, acc1: 42.230%, acc5: 67.850%, test_loss: 3.9109, per_image_load_time: 0.073ms, per_image_inference_time: 0.089ms
2023-07-01 22:55:28 - until epoch: 200, best_acc1: 42.960%
2023-07-01 22:55:28 - train done. model: vit_small_patch16, train time: 1.190 hours, best_acc1: 42.960%
2023-07-01 23:03:00 - network: vit_mid_small_patch16
2023-07-01 23:03:00 - num_classes: 100
2023-07-01 23:03:00 - input_image_size: 32
2023-07-01 23:03:00 - num_params: 12831844
2023-07-01 23:03:00 - trained_model_path: 
2023-07-01 23:03:00 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 23:03:00 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 23:03:00 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f90cf10cd00>
2023-07-01 23:03:00 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f90cf10ca30>
2023-07-01 23:03:00 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f90cf10c910>
2023-07-01 23:03:00 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f90cf10ca60>
2023-07-01 23:03:00 - seed: 0
2023-07-01 23:03:00 - batch_size: 128
2023-07-01 23:03:00 - num_workers: 16
2023-07-01 23:03:00 - accumulation_steps: 1
2023-07-01 23:03:00 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-01 23:03:00 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-07-01 23:03:00 - epochs: 200
2023-07-01 23:03:00 - print_interval: 50
2023-07-01 23:03:00 - sync_bn: False
2023-07-01 23:03:00 - apex: True
2023-07-01 23:03:00 - use_ema_model: False
2023-07-01 23:03:00 - ema_model_decay: 0.9999
2023-07-01 23:03:00 - AUG: none
2023-07-01 23:03:00 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-01 23:03:00 - gpus_num: 1
2023-07-01 23:03:00 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f90cf1353f0>
2023-07-01 23:03:00 - --------------------parameters--------------------
2023-07-01 23:03:00 - name: cls_token, grad: True
2023-07-01 23:03:00 - name: position_encoding, grad: True
2023-07-01 23:03:00 - name: patch_embedding.conv.weight, grad: True
2023-07-01 23:03:00 - name: patch_embedding.conv.bias, grad: True
2023-07-01 23:03:00 - name: blocks.0.norm1.weight, grad: True
2023-07-01 23:03:00 - name: blocks.0.norm1.bias, grad: True
2023-07-01 23:03:00 - name: blocks.0.attention.qkv_linear.weight, grad: True
2023-07-01 23:03:00 - name: blocks.0.attention.qkv_linear.bias, grad: True
2023-07-01 23:03:00 - name: blocks.0.attention.out_linear.weight, grad: True
2023-07-01 23:03:00 - name: blocks.0.attention.out_linear.bias, grad: True
2023-07-01 23:03:00 - name: blocks.0.norm2.weight, grad: True
2023-07-01 23:03:00 - name: blocks.0.norm2.bias, grad: True
2023-07-01 23:03:00 - name: blocks.0.feed_forward.fc1.weight, grad: True
2023-07-01 23:03:00 - name: blocks.0.feed_forward.fc1.bias, grad: True
2023-07-01 23:03:00 - name: blocks.0.feed_forward.fc2.weight, grad: True
2023-07-01 23:03:00 - name: blocks.0.feed_forward.fc2.bias, grad: True
2023-07-01 23:03:00 - name: blocks.1.norm1.weight, grad: True
2023-07-01 23:03:00 - name: blocks.1.norm1.bias, grad: True
2023-07-01 23:03:00 - name: blocks.1.attention.qkv_linear.weight, grad: True
2023-07-01 23:03:00 - name: blocks.1.attention.qkv_linear.bias, grad: True
2023-07-01 23:03:00 - name: blocks.1.attention.out_linear.weight, grad: True
2023-07-01 23:03:00 - name: blocks.1.attention.out_linear.bias, grad: True
2023-07-01 23:03:00 - name: blocks.1.norm2.weight, grad: True
2023-07-01 23:03:00 - name: blocks.1.norm2.bias, grad: True
2023-07-01 23:03:00 - name: blocks.1.feed_forward.fc1.weight, grad: True
2023-07-01 23:03:00 - name: blocks.1.feed_forward.fc1.bias, grad: True
2023-07-01 23:03:00 - name: blocks.1.feed_forward.fc2.weight, grad: True
2023-07-01 23:03:00 - name: blocks.1.feed_forward.fc2.bias, grad: True
2023-07-01 23:03:00 - name: blocks.2.norm1.weight, grad: True
2023-07-01 23:03:00 - name: blocks.2.norm1.bias, grad: True
2023-07-01 23:03:00 - name: blocks.2.attention.qkv_linear.weight, grad: True
2023-07-01 23:03:00 - name: blocks.2.attention.qkv_linear.bias, grad: True
2023-07-01 23:03:00 - name: blocks.2.attention.out_linear.weight, grad: True
2023-07-01 23:03:00 - name: blocks.2.attention.out_linear.bias, grad: True
2023-07-01 23:03:00 - name: blocks.2.norm2.weight, grad: True
2023-07-01 23:03:00 - name: blocks.2.norm2.bias, grad: True
2023-07-01 23:03:00 - name: blocks.2.feed_forward.fc1.weight, grad: True
2023-07-01 23:03:00 - name: blocks.2.feed_forward.fc1.bias, grad: True
2023-07-01 23:03:00 - name: blocks.2.feed_forward.fc2.weight, grad: True
2023-07-01 23:03:00 - name: blocks.2.feed_forward.fc2.bias, grad: True
2023-07-01 23:03:00 - name: blocks.3.norm1.weight, grad: True
2023-07-01 23:03:00 - name: blocks.3.norm1.bias, grad: True
2023-07-01 23:03:00 - name: blocks.3.attention.qkv_linear.weight, grad: True
2023-07-01 23:03:00 - name: blocks.3.attention.qkv_linear.bias, grad: True
2023-07-01 23:03:00 - name: blocks.3.attention.out_linear.weight, grad: True
2023-07-01 23:03:00 - name: blocks.3.attention.out_linear.bias, grad: True
2023-07-01 23:03:00 - name: blocks.3.norm2.weight, grad: True
2023-07-01 23:03:00 - name: blocks.3.norm2.bias, grad: True
2023-07-01 23:03:00 - name: blocks.3.feed_forward.fc1.weight, grad: True
2023-07-01 23:03:00 - name: blocks.3.feed_forward.fc1.bias, grad: True
2023-07-01 23:03:00 - name: blocks.3.feed_forward.fc2.weight, grad: True
2023-07-01 23:03:00 - name: blocks.3.feed_forward.fc2.bias, grad: True
2023-07-01 23:03:00 - name: blocks.4.norm1.weight, grad: True
2023-07-01 23:03:00 - name: blocks.4.norm1.bias, grad: True
2023-07-01 23:03:00 - name: blocks.4.attention.qkv_linear.weight, grad: True
2023-07-01 23:03:00 - name: blocks.4.attention.qkv_linear.bias, grad: True
2023-07-01 23:03:00 - name: blocks.4.attention.out_linear.weight, grad: True
2023-07-01 23:03:00 - name: blocks.4.attention.out_linear.bias, grad: True
2023-07-01 23:03:00 - name: blocks.4.norm2.weight, grad: True
2023-07-01 23:03:00 - name: blocks.4.norm2.bias, grad: True
2023-07-01 23:03:00 - name: blocks.4.feed_forward.fc1.weight, grad: True
2023-07-01 23:03:00 - name: blocks.4.feed_forward.fc1.bias, grad: True
2023-07-01 23:03:00 - name: blocks.4.feed_forward.fc2.weight, grad: True
2023-07-01 23:03:00 - name: blocks.4.feed_forward.fc2.bias, grad: True
2023-07-01 23:03:00 - name: blocks.5.norm1.weight, grad: True
2023-07-01 23:03:00 - name: blocks.5.norm1.bias, grad: True
2023-07-01 23:03:00 - name: blocks.5.attention.qkv_linear.weight, grad: True
2023-07-01 23:03:00 - name: blocks.5.attention.qkv_linear.bias, grad: True
2023-07-01 23:03:00 - name: blocks.5.attention.out_linear.weight, grad: True
2023-07-01 23:03:00 - name: blocks.5.attention.out_linear.bias, grad: True
2023-07-01 23:03:00 - name: blocks.5.norm2.weight, grad: True
2023-07-01 23:03:00 - name: blocks.5.norm2.bias, grad: True
2023-07-01 23:03:00 - name: blocks.5.feed_forward.fc1.weight, grad: True
2023-07-01 23:03:00 - name: blocks.5.feed_forward.fc1.bias, grad: True
2023-07-01 23:03:00 - name: blocks.5.feed_forward.fc2.weight, grad: True
2023-07-01 23:03:00 - name: blocks.5.feed_forward.fc2.bias, grad: True
2023-07-01 23:03:00 - name: blocks.6.norm1.weight, grad: True
2023-07-01 23:03:00 - name: blocks.6.norm1.bias, grad: True
2023-07-01 23:03:00 - name: blocks.6.attention.qkv_linear.weight, grad: True
2023-07-01 23:03:00 - name: blocks.6.attention.qkv_linear.bias, grad: True
2023-07-01 23:03:00 - name: blocks.6.attention.out_linear.weight, grad: True
2023-07-01 23:03:00 - name: blocks.6.attention.out_linear.bias, grad: True
2023-07-01 23:03:00 - name: blocks.6.norm2.weight, grad: True
2023-07-01 23:03:00 - name: blocks.6.norm2.bias, grad: True
2023-07-01 23:03:00 - name: blocks.6.feed_forward.fc1.weight, grad: True
2023-07-01 23:03:00 - name: blocks.6.feed_forward.fc1.bias, grad: True
2023-07-01 23:03:00 - name: blocks.6.feed_forward.fc2.weight, grad: True
2023-07-01 23:03:00 - name: blocks.6.feed_forward.fc2.bias, grad: True
2023-07-01 23:03:00 - name: norm.weight, grad: True
2023-07-01 23:03:00 - name: norm.bias, grad: True
2023-07-01 23:03:00 - name: fc.weight, grad: True
2023-07-01 23:03:00 - name: fc.bias, grad: True
2023-07-01 23:03:00 - --------------------buffers--------------------
2023-07-01 23:03:00 - -----------no weight decay layers--------------
2023-07-01 23:03:00 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: norm.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: norm.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:00 - -------------weight decay layers---------------
2023-07-01 23:03:00 - name: cls_token, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: position_encoding, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: patch_embedding.conv.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:00 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:55 - network: vit_mid_small_patch16
2023-07-01 23:03:55 - num_classes: 100
2023-07-01 23:03:55 - input_image_size: 32
2023-07-01 23:03:55 - num_params: 12831844
2023-07-01 23:03:55 - trained_model_path: 
2023-07-01 23:03:55 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 23:03:55 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 23:03:55 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f28bf65b790>
2023-07-01 23:03:55 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f28bf65b3a0>
2023-07-01 23:03:55 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f28bf65b2b0>
2023-07-01 23:03:55 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f28bf65b340>
2023-07-01 23:03:55 - seed: 0
2023-07-01 23:03:55 - batch_size: 128
2023-07-01 23:03:55 - num_workers: 16
2023-07-01 23:03:55 - accumulation_steps: 1
2023-07-01 23:03:55 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-01 23:03:55 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-07-01 23:03:55 - epochs: 200
2023-07-01 23:03:55 - print_interval: 50
2023-07-01 23:03:55 - sync_bn: False
2023-07-01 23:03:55 - apex: True
2023-07-01 23:03:55 - use_ema_model: False
2023-07-01 23:03:55 - ema_model_decay: 0.9999
2023-07-01 23:03:55 - AUG: none
2023-07-01 23:03:55 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-01 23:03:55 - gpus_num: 1
2023-07-01 23:03:55 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f28bf6212f0>
2023-07-01 23:03:55 - --------------------parameters--------------------
2023-07-01 23:03:55 - name: cls_token, grad: True
2023-07-01 23:03:55 - name: position_encoding, grad: True
2023-07-01 23:03:55 - name: patch_embedding.conv.weight, grad: True
2023-07-01 23:03:55 - name: patch_embedding.conv.bias, grad: True
2023-07-01 23:03:55 - name: blocks.0.norm1.weight, grad: True
2023-07-01 23:03:55 - name: blocks.0.norm1.bias, grad: True
2023-07-01 23:03:55 - name: blocks.0.attention.qkv_linear.weight, grad: True
2023-07-01 23:03:55 - name: blocks.0.attention.qkv_linear.bias, grad: True
2023-07-01 23:03:55 - name: blocks.0.attention.out_linear.weight, grad: True
2023-07-01 23:03:55 - name: blocks.0.attention.out_linear.bias, grad: True
2023-07-01 23:03:55 - name: blocks.0.norm2.weight, grad: True
2023-07-01 23:03:55 - name: blocks.0.norm2.bias, grad: True
2023-07-01 23:03:55 - name: blocks.0.feed_forward.fc1.weight, grad: True
2023-07-01 23:03:55 - name: blocks.0.feed_forward.fc1.bias, grad: True
2023-07-01 23:03:55 - name: blocks.0.feed_forward.fc2.weight, grad: True
2023-07-01 23:03:55 - name: blocks.0.feed_forward.fc2.bias, grad: True
2023-07-01 23:03:55 - name: blocks.1.norm1.weight, grad: True
2023-07-01 23:03:55 - name: blocks.1.norm1.bias, grad: True
2023-07-01 23:03:55 - name: blocks.1.attention.qkv_linear.weight, grad: True
2023-07-01 23:03:55 - name: blocks.1.attention.qkv_linear.bias, grad: True
2023-07-01 23:03:55 - name: blocks.1.attention.out_linear.weight, grad: True
2023-07-01 23:03:55 - name: blocks.1.attention.out_linear.bias, grad: True
2023-07-01 23:03:55 - name: blocks.1.norm2.weight, grad: True
2023-07-01 23:03:55 - name: blocks.1.norm2.bias, grad: True
2023-07-01 23:03:55 - name: blocks.1.feed_forward.fc1.weight, grad: True
2023-07-01 23:03:55 - name: blocks.1.feed_forward.fc1.bias, grad: True
2023-07-01 23:03:55 - name: blocks.1.feed_forward.fc2.weight, grad: True
2023-07-01 23:03:55 - name: blocks.1.feed_forward.fc2.bias, grad: True
2023-07-01 23:03:55 - name: blocks.2.norm1.weight, grad: True
2023-07-01 23:03:55 - name: blocks.2.norm1.bias, grad: True
2023-07-01 23:03:55 - name: blocks.2.attention.qkv_linear.weight, grad: True
2023-07-01 23:03:55 - name: blocks.2.attention.qkv_linear.bias, grad: True
2023-07-01 23:03:55 - name: blocks.2.attention.out_linear.weight, grad: True
2023-07-01 23:03:55 - name: blocks.2.attention.out_linear.bias, grad: True
2023-07-01 23:03:55 - name: blocks.2.norm2.weight, grad: True
2023-07-01 23:03:55 - name: blocks.2.norm2.bias, grad: True
2023-07-01 23:03:55 - name: blocks.2.feed_forward.fc1.weight, grad: True
2023-07-01 23:03:55 - name: blocks.2.feed_forward.fc1.bias, grad: True
2023-07-01 23:03:55 - name: blocks.2.feed_forward.fc2.weight, grad: True
2023-07-01 23:03:55 - name: blocks.2.feed_forward.fc2.bias, grad: True
2023-07-01 23:03:55 - name: blocks.3.norm1.weight, grad: True
2023-07-01 23:03:55 - name: blocks.3.norm1.bias, grad: True
2023-07-01 23:03:55 - name: blocks.3.attention.qkv_linear.weight, grad: True
2023-07-01 23:03:55 - name: blocks.3.attention.qkv_linear.bias, grad: True
2023-07-01 23:03:55 - name: blocks.3.attention.out_linear.weight, grad: True
2023-07-01 23:03:55 - name: blocks.3.attention.out_linear.bias, grad: True
2023-07-01 23:03:55 - name: blocks.3.norm2.weight, grad: True
2023-07-01 23:03:55 - name: blocks.3.norm2.bias, grad: True
2023-07-01 23:03:55 - name: blocks.3.feed_forward.fc1.weight, grad: True
2023-07-01 23:03:55 - name: blocks.3.feed_forward.fc1.bias, grad: True
2023-07-01 23:03:55 - name: blocks.3.feed_forward.fc2.weight, grad: True
2023-07-01 23:03:55 - name: blocks.3.feed_forward.fc2.bias, grad: True
2023-07-01 23:03:55 - name: blocks.4.norm1.weight, grad: True
2023-07-01 23:03:55 - name: blocks.4.norm1.bias, grad: True
2023-07-01 23:03:55 - name: blocks.4.attention.qkv_linear.weight, grad: True
2023-07-01 23:03:55 - name: blocks.4.attention.qkv_linear.bias, grad: True
2023-07-01 23:03:55 - name: blocks.4.attention.out_linear.weight, grad: True
2023-07-01 23:03:55 - name: blocks.4.attention.out_linear.bias, grad: True
2023-07-01 23:03:55 - name: blocks.4.norm2.weight, grad: True
2023-07-01 23:03:55 - name: blocks.4.norm2.bias, grad: True
2023-07-01 23:03:55 - name: blocks.4.feed_forward.fc1.weight, grad: True
2023-07-01 23:03:55 - name: blocks.4.feed_forward.fc1.bias, grad: True
2023-07-01 23:03:55 - name: blocks.4.feed_forward.fc2.weight, grad: True
2023-07-01 23:03:55 - name: blocks.4.feed_forward.fc2.bias, grad: True
2023-07-01 23:03:55 - name: blocks.5.norm1.weight, grad: True
2023-07-01 23:03:55 - name: blocks.5.norm1.bias, grad: True
2023-07-01 23:03:55 - name: blocks.5.attention.qkv_linear.weight, grad: True
2023-07-01 23:03:55 - name: blocks.5.attention.qkv_linear.bias, grad: True
2023-07-01 23:03:55 - name: blocks.5.attention.out_linear.weight, grad: True
2023-07-01 23:03:55 - name: blocks.5.attention.out_linear.bias, grad: True
2023-07-01 23:03:55 - name: blocks.5.norm2.weight, grad: True
2023-07-01 23:03:55 - name: blocks.5.norm2.bias, grad: True
2023-07-01 23:03:55 - name: blocks.5.feed_forward.fc1.weight, grad: True
2023-07-01 23:03:55 - name: blocks.5.feed_forward.fc1.bias, grad: True
2023-07-01 23:03:55 - name: blocks.5.feed_forward.fc2.weight, grad: True
2023-07-01 23:03:55 - name: blocks.5.feed_forward.fc2.bias, grad: True
2023-07-01 23:03:55 - name: blocks.6.norm1.weight, grad: True
2023-07-01 23:03:55 - name: blocks.6.norm1.bias, grad: True
2023-07-01 23:03:55 - name: blocks.6.attention.qkv_linear.weight, grad: True
2023-07-01 23:03:55 - name: blocks.6.attention.qkv_linear.bias, grad: True
2023-07-01 23:03:55 - name: blocks.6.attention.out_linear.weight, grad: True
2023-07-01 23:03:55 - name: blocks.6.attention.out_linear.bias, grad: True
2023-07-01 23:03:55 - name: blocks.6.norm2.weight, grad: True
2023-07-01 23:03:55 - name: blocks.6.norm2.bias, grad: True
2023-07-01 23:03:55 - name: blocks.6.feed_forward.fc1.weight, grad: True
2023-07-01 23:03:55 - name: blocks.6.feed_forward.fc1.bias, grad: True
2023-07-01 23:03:55 - name: blocks.6.feed_forward.fc2.weight, grad: True
2023-07-01 23:03:55 - name: blocks.6.feed_forward.fc2.bias, grad: True
2023-07-01 23:03:55 - name: norm.weight, grad: True
2023-07-01 23:03:55 - name: norm.bias, grad: True
2023-07-01 23:03:55 - name: fc.weight, grad: True
2023-07-01 23:03:55 - name: fc.bias, grad: True
2023-07-01 23:03:55 - --------------------buffers--------------------
2023-07-01 23:03:55 - -----------no weight decay layers--------------
2023-07-01 23:03:55 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:55 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:55 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:55 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: norm.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: norm.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:03:56 - -------------weight decay layers---------------
2023-07-01 23:03:56 - name: cls_token, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: position_encoding, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: patch_embedding.conv.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:03:56 - epoch 001 lr: 0.100000
2023-07-01 23:04:58 - network: vit_mid_small_patch16
2023-07-01 23:04:58 - num_classes: 100
2023-07-01 23:04:58 - input_image_size: 32
2023-07-01 23:04:58 - num_params: 12758116
2023-07-01 23:04:58 - trained_model_path: 
2023-07-01 23:04:58 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 23:04:58 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-01 23:04:58 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f20813397c0>
2023-07-01 23:04:58 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f20813393d0>
2023-07-01 23:04:58 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f20813392e0>
2023-07-01 23:04:58 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f2081339370>
2023-07-01 23:04:58 - seed: 0
2023-07-01 23:04:58 - batch_size: 128
2023-07-01 23:04:58 - num_workers: 16
2023-07-01 23:04:58 - accumulation_steps: 1
2023-07-01 23:04:58 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-01 23:04:58 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-07-01 23:04:58 - epochs: 200
2023-07-01 23:04:58 - print_interval: 50
2023-07-01 23:04:58 - sync_bn: False
2023-07-01 23:04:58 - apex: True
2023-07-01 23:04:58 - use_ema_model: False
2023-07-01 23:04:58 - ema_model_decay: 0.9999
2023-07-01 23:04:58 - AUG: none
2023-07-01 23:04:58 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-01 23:04:58 - gpus_num: 1
2023-07-01 23:04:58 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f20813352f0>
2023-07-01 23:04:58 - --------------------parameters--------------------
2023-07-01 23:04:58 - name: cls_token, grad: True
2023-07-01 23:04:58 - name: position_encoding, grad: True
2023-07-01 23:04:58 - name: patch_embedding.conv.weight, grad: True
2023-07-01 23:04:58 - name: patch_embedding.conv.bias, grad: True
2023-07-01 23:04:58 - name: blocks.0.norm1.weight, grad: True
2023-07-01 23:04:58 - name: blocks.0.norm1.bias, grad: True
2023-07-01 23:04:58 - name: blocks.0.attention.qkv_linear.weight, grad: True
2023-07-01 23:04:58 - name: blocks.0.attention.qkv_linear.bias, grad: True
2023-07-01 23:04:58 - name: blocks.0.attention.out_linear.weight, grad: True
2023-07-01 23:04:58 - name: blocks.0.attention.out_linear.bias, grad: True
2023-07-01 23:04:58 - name: blocks.0.norm2.weight, grad: True
2023-07-01 23:04:58 - name: blocks.0.norm2.bias, grad: True
2023-07-01 23:04:58 - name: blocks.0.feed_forward.fc1.weight, grad: True
2023-07-01 23:04:58 - name: blocks.0.feed_forward.fc1.bias, grad: True
2023-07-01 23:04:58 - name: blocks.0.feed_forward.fc2.weight, grad: True
2023-07-01 23:04:58 - name: blocks.0.feed_forward.fc2.bias, grad: True
2023-07-01 23:04:58 - name: blocks.1.norm1.weight, grad: True
2023-07-01 23:04:58 - name: blocks.1.norm1.bias, grad: True
2023-07-01 23:04:58 - name: blocks.1.attention.qkv_linear.weight, grad: True
2023-07-01 23:04:58 - name: blocks.1.attention.qkv_linear.bias, grad: True
2023-07-01 23:04:58 - name: blocks.1.attention.out_linear.weight, grad: True
2023-07-01 23:04:58 - name: blocks.1.attention.out_linear.bias, grad: True
2023-07-01 23:04:58 - name: blocks.1.norm2.weight, grad: True
2023-07-01 23:04:58 - name: blocks.1.norm2.bias, grad: True
2023-07-01 23:04:58 - name: blocks.1.feed_forward.fc1.weight, grad: True
2023-07-01 23:04:58 - name: blocks.1.feed_forward.fc1.bias, grad: True
2023-07-01 23:04:58 - name: blocks.1.feed_forward.fc2.weight, grad: True
2023-07-01 23:04:58 - name: blocks.1.feed_forward.fc2.bias, grad: True
2023-07-01 23:04:58 - name: blocks.2.norm1.weight, grad: True
2023-07-01 23:04:58 - name: blocks.2.norm1.bias, grad: True
2023-07-01 23:04:58 - name: blocks.2.attention.qkv_linear.weight, grad: True
2023-07-01 23:04:58 - name: blocks.2.attention.qkv_linear.bias, grad: True
2023-07-01 23:04:58 - name: blocks.2.attention.out_linear.weight, grad: True
2023-07-01 23:04:58 - name: blocks.2.attention.out_linear.bias, grad: True
2023-07-01 23:04:58 - name: blocks.2.norm2.weight, grad: True
2023-07-01 23:04:58 - name: blocks.2.norm2.bias, grad: True
2023-07-01 23:04:58 - name: blocks.2.feed_forward.fc1.weight, grad: True
2023-07-01 23:04:58 - name: blocks.2.feed_forward.fc1.bias, grad: True
2023-07-01 23:04:58 - name: blocks.2.feed_forward.fc2.weight, grad: True
2023-07-01 23:04:58 - name: blocks.2.feed_forward.fc2.bias, grad: True
2023-07-01 23:04:58 - name: blocks.3.norm1.weight, grad: True
2023-07-01 23:04:58 - name: blocks.3.norm1.bias, grad: True
2023-07-01 23:04:58 - name: blocks.3.attention.qkv_linear.weight, grad: True
2023-07-01 23:04:58 - name: blocks.3.attention.qkv_linear.bias, grad: True
2023-07-01 23:04:58 - name: blocks.3.attention.out_linear.weight, grad: True
2023-07-01 23:04:58 - name: blocks.3.attention.out_linear.bias, grad: True
2023-07-01 23:04:58 - name: blocks.3.norm2.weight, grad: True
2023-07-01 23:04:58 - name: blocks.3.norm2.bias, grad: True
2023-07-01 23:04:58 - name: blocks.3.feed_forward.fc1.weight, grad: True
2023-07-01 23:04:58 - name: blocks.3.feed_forward.fc1.bias, grad: True
2023-07-01 23:04:58 - name: blocks.3.feed_forward.fc2.weight, grad: True
2023-07-01 23:04:58 - name: blocks.3.feed_forward.fc2.bias, grad: True
2023-07-01 23:04:58 - name: blocks.4.norm1.weight, grad: True
2023-07-01 23:04:58 - name: blocks.4.norm1.bias, grad: True
2023-07-01 23:04:58 - name: blocks.4.attention.qkv_linear.weight, grad: True
2023-07-01 23:04:58 - name: blocks.4.attention.qkv_linear.bias, grad: True
2023-07-01 23:04:58 - name: blocks.4.attention.out_linear.weight, grad: True
2023-07-01 23:04:58 - name: blocks.4.attention.out_linear.bias, grad: True
2023-07-01 23:04:58 - name: blocks.4.norm2.weight, grad: True
2023-07-01 23:04:58 - name: blocks.4.norm2.bias, grad: True
2023-07-01 23:04:58 - name: blocks.4.feed_forward.fc1.weight, grad: True
2023-07-01 23:04:58 - name: blocks.4.feed_forward.fc1.bias, grad: True
2023-07-01 23:04:58 - name: blocks.4.feed_forward.fc2.weight, grad: True
2023-07-01 23:04:58 - name: blocks.4.feed_forward.fc2.bias, grad: True
2023-07-01 23:04:58 - name: blocks.5.norm1.weight, grad: True
2023-07-01 23:04:58 - name: blocks.5.norm1.bias, grad: True
2023-07-01 23:04:58 - name: blocks.5.attention.qkv_linear.weight, grad: True
2023-07-01 23:04:58 - name: blocks.5.attention.qkv_linear.bias, grad: True
2023-07-01 23:04:58 - name: blocks.5.attention.out_linear.weight, grad: True
2023-07-01 23:04:58 - name: blocks.5.attention.out_linear.bias, grad: True
2023-07-01 23:04:58 - name: blocks.5.norm2.weight, grad: True
2023-07-01 23:04:58 - name: blocks.5.norm2.bias, grad: True
2023-07-01 23:04:58 - name: blocks.5.feed_forward.fc1.weight, grad: True
2023-07-01 23:04:58 - name: blocks.5.feed_forward.fc1.bias, grad: True
2023-07-01 23:04:58 - name: blocks.5.feed_forward.fc2.weight, grad: True
2023-07-01 23:04:58 - name: blocks.5.feed_forward.fc2.bias, grad: True
2023-07-01 23:04:58 - name: blocks.6.norm1.weight, grad: True
2023-07-01 23:04:58 - name: blocks.6.norm1.bias, grad: True
2023-07-01 23:04:58 - name: blocks.6.attention.qkv_linear.weight, grad: True
2023-07-01 23:04:58 - name: blocks.6.attention.qkv_linear.bias, grad: True
2023-07-01 23:04:58 - name: blocks.6.attention.out_linear.weight, grad: True
2023-07-01 23:04:58 - name: blocks.6.attention.out_linear.bias, grad: True
2023-07-01 23:04:58 - name: blocks.6.norm2.weight, grad: True
2023-07-01 23:04:58 - name: blocks.6.norm2.bias, grad: True
2023-07-01 23:04:58 - name: blocks.6.feed_forward.fc1.weight, grad: True
2023-07-01 23:04:58 - name: blocks.6.feed_forward.fc1.bias, grad: True
2023-07-01 23:04:58 - name: blocks.6.feed_forward.fc2.weight, grad: True
2023-07-01 23:04:58 - name: blocks.6.feed_forward.fc2.bias, grad: True
2023-07-01 23:04:58 - name: norm.weight, grad: True
2023-07-01 23:04:58 - name: norm.bias, grad: True
2023-07-01 23:04:58 - name: fc.weight, grad: True
2023-07-01 23:04:58 - name: fc.bias, grad: True
2023-07-01 23:04:58 - --------------------buffers--------------------
2023-07-01 23:04:58 - -----------no weight decay layers--------------
2023-07-01 23:04:58 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:58 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:58 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:58 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:58 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:58 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:58 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:58 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:58 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:58 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:58 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:58 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:58 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: norm.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: norm.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-01 23:04:59 - -------------weight decay layers---------------
2023-07-01 23:04:59 - name: cls_token, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: position_encoding, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: patch_embedding.conv.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-01 23:04:59 - epoch 001 lr: 0.100000
2023-07-01 23:05:05 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.6904
2023-07-01 23:05:07 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.2054
2023-07-01 23:05:08 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 4.1904
2023-07-01 23:05:10 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 3.8852
2023-07-01 23:05:11 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 4.1057
2023-07-01 23:05:13 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 3.9640
2023-07-01 23:05:14 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 3.8703
2023-07-01 23:05:15 - train: epoch 001, train_loss: 4.1499
2023-07-01 23:05:17 - eval: epoch: 001, acc1: 10.470%, acc5: 31.020%, test_loss: 3.8521, per_image_load_time: 0.104ms, per_image_inference_time: 0.054ms
2023-07-01 23:05:18 - until epoch: 001, best_acc1: 10.470%
2023-07-01 23:05:18 - epoch 002 lr: 0.100000
2023-07-01 23:05:20 - train: epoch 0002, iter [00050, 00390], lr: 0.100000, loss: 3.8697
2023-07-01 23:05:22 - train: epoch 0002, iter [00100, 00390], lr: 0.100000, loss: 3.8779
2023-07-01 23:05:23 - train: epoch 0002, iter [00150, 00390], lr: 0.100000, loss: 3.8237
2023-07-01 23:05:24 - train: epoch 0002, iter [00200, 00390], lr: 0.100000, loss: 3.9064
2023-07-01 23:05:26 - train: epoch 0002, iter [00250, 00390], lr: 0.100000, loss: 3.7383
2023-07-01 23:05:27 - train: epoch 0002, iter [00300, 00390], lr: 0.100000, loss: 3.9228
2023-07-01 23:05:29 - train: epoch 0002, iter [00350, 00390], lr: 0.100000, loss: 3.6940
2023-07-01 23:05:30 - train: epoch 002, train_loss: 3.8102
2023-07-01 23:05:31 - eval: epoch: 002, acc1: 12.950%, acc5: 35.670%, test_loss: 3.7002, per_image_load_time: 0.092ms, per_image_inference_time: 0.054ms
2023-07-01 23:05:32 - until epoch: 002, best_acc1: 12.950%
2023-07-01 23:05:32 - epoch 003 lr: 0.100000
2023-07-01 23:05:34 - train: epoch 0003, iter [00050, 00390], lr: 0.100000, loss: 3.6149
2023-07-01 23:05:36 - train: epoch 0003, iter [00100, 00390], lr: 0.100000, loss: 3.6276
2023-07-01 23:05:37 - train: epoch 0003, iter [00150, 00390], lr: 0.100000, loss: 3.8852
2023-07-01 23:05:39 - train: epoch 0003, iter [00200, 00390], lr: 0.100000, loss: 3.5092
2023-07-01 23:05:40 - train: epoch 0003, iter [00250, 00390], lr: 0.100000, loss: 3.8606
2023-07-01 23:05:41 - train: epoch 0003, iter [00300, 00390], lr: 0.100000, loss: 3.7687
2023-07-01 23:05:43 - train: epoch 0003, iter [00350, 00390], lr: 0.100000, loss: 3.6749
2023-07-01 23:05:44 - train: epoch 003, train_loss: 3.6777
2023-07-01 23:05:46 - eval: epoch: 003, acc1: 15.560%, acc5: 39.050%, test_loss: 3.5726, per_image_load_time: 0.095ms, per_image_inference_time: 0.061ms
2023-07-01 23:05:46 - until epoch: 003, best_acc1: 15.560%
2023-07-01 23:05:46 - epoch 004 lr: 0.100000
2023-07-01 23:05:49 - train: epoch 0004, iter [00050, 00390], lr: 0.100000, loss: 3.6270
2023-07-01 23:05:50 - train: epoch 0004, iter [00100, 00390], lr: 0.100000, loss: 3.7749
2023-07-01 23:05:52 - train: epoch 0004, iter [00150, 00390], lr: 0.100000, loss: 3.6389
2023-07-01 23:05:53 - train: epoch 0004, iter [00200, 00390], lr: 0.100000, loss: 3.6895
2023-07-01 23:05:54 - train: epoch 0004, iter [00250, 00390], lr: 0.100000, loss: 3.4010
2023-07-01 23:05:56 - train: epoch 0004, iter [00300, 00390], lr: 0.100000, loss: 3.6788
2023-07-01 23:05:57 - train: epoch 0004, iter [00350, 00390], lr: 0.100000, loss: 3.3266
2023-07-01 23:05:58 - train: epoch 004, train_loss: 3.5861
2023-07-01 23:06:00 - eval: epoch: 004, acc1: 17.120%, acc5: 42.300%, test_loss: 3.4841, per_image_load_time: 0.094ms, per_image_inference_time: 0.055ms
2023-07-01 23:06:00 - until epoch: 004, best_acc1: 17.120%
2023-07-01 23:06:00 - epoch 005 lr: 0.100000
2023-07-01 23:06:03 - train: epoch 0005, iter [00050, 00390], lr: 0.100000, loss: 3.4891
2023-07-01 23:06:04 - train: epoch 0005, iter [00100, 00390], lr: 0.100000, loss: 3.3901
2023-07-01 23:06:06 - train: epoch 0005, iter [00150, 00390], lr: 0.100000, loss: 3.3424
2023-07-01 23:06:07 - train: epoch 0005, iter [00200, 00390], lr: 0.100000, loss: 3.6415
2023-07-01 23:06:08 - train: epoch 0005, iter [00250, 00390], lr: 0.100000, loss: 3.3857
2023-07-01 23:06:10 - train: epoch 0005, iter [00300, 00390], lr: 0.100000, loss: 3.3730
2023-07-01 23:06:11 - train: epoch 0005, iter [00350, 00390], lr: 0.100000, loss: 3.3654
2023-07-01 23:06:12 - train: epoch 005, train_loss: 3.5092
2023-07-01 23:06:14 - eval: epoch: 005, acc1: 18.190%, acc5: 44.800%, test_loss: 3.4094, per_image_load_time: 0.093ms, per_image_inference_time: 0.053ms
2023-07-01 23:06:15 - until epoch: 005, best_acc1: 18.190%
2023-07-01 23:06:15 - epoch 006 lr: 0.100000
2023-07-01 23:06:17 - train: epoch 0006, iter [00050, 00390], lr: 0.100000, loss: 3.5343
2023-07-01 23:06:18 - train: epoch 0006, iter [00100, 00390], lr: 0.100000, loss: 3.2742
2023-07-01 23:06:20 - train: epoch 0006, iter [00150, 00390], lr: 0.100000, loss: 3.4966
2023-07-01 23:06:21 - train: epoch 0006, iter [00200, 00390], lr: 0.100000, loss: 3.2784
2023-07-01 23:06:23 - train: epoch 0006, iter [00250, 00390], lr: 0.100000, loss: 3.4072
2023-07-01 23:06:24 - train: epoch 0006, iter [00300, 00390], lr: 0.100000, loss: 3.3046
2023-07-01 23:06:25 - train: epoch 0006, iter [00350, 00390], lr: 0.100000, loss: 3.4821
2023-07-01 23:06:27 - train: epoch 006, train_loss: 3.4444
2023-07-01 23:06:28 - eval: epoch: 006, acc1: 19.220%, acc5: 45.950%, test_loss: 3.3680, per_image_load_time: 0.095ms, per_image_inference_time: 0.053ms
2023-07-01 23:06:29 - until epoch: 006, best_acc1: 19.220%
2023-07-01 23:06:29 - epoch 007 lr: 0.100000
2023-07-01 23:06:31 - train: epoch 0007, iter [00050, 00390], lr: 0.100000, loss: 3.4338
2023-07-01 23:06:33 - train: epoch 0007, iter [00100, 00390], lr: 0.100000, loss: 3.4238
2023-07-01 23:06:34 - train: epoch 0007, iter [00150, 00390], lr: 0.100000, loss: 3.3152
2023-07-01 23:06:35 - train: epoch 0007, iter [00200, 00390], lr: 0.100000, loss: 3.2580
2023-07-01 23:06:37 - train: epoch 0007, iter [00250, 00390], lr: 0.100000, loss: 3.2258
2023-07-01 23:06:38 - train: epoch 0007, iter [00300, 00390], lr: 0.100000, loss: 3.1843
2023-07-01 23:06:39 - train: epoch 0007, iter [00350, 00390], lr: 0.100000, loss: 3.2937
2023-07-01 23:06:41 - train: epoch 007, train_loss: 3.4023
2023-07-01 23:06:42 - eval: epoch: 007, acc1: 20.730%, acc5: 47.100%, test_loss: 3.3105, per_image_load_time: 0.095ms, per_image_inference_time: 0.053ms
2023-07-01 23:06:43 - until epoch: 007, best_acc1: 20.730%
2023-07-01 23:06:43 - epoch 008 lr: 0.100000
2023-07-01 23:06:45 - train: epoch 0008, iter [00050, 00390], lr: 0.100000, loss: 3.4247
2023-07-01 23:06:46 - train: epoch 0008, iter [00100, 00390], lr: 0.100000, loss: 3.4971
2023-07-01 23:06:48 - train: epoch 0008, iter [00150, 00390], lr: 0.100000, loss: 3.3140
2023-07-01 23:06:49 - train: epoch 0008, iter [00200, 00390], lr: 0.100000, loss: 3.2266
2023-07-01 23:06:51 - train: epoch 0008, iter [00250, 00390], lr: 0.100000, loss: 3.1959
2023-07-01 23:06:52 - train: epoch 0008, iter [00300, 00390], lr: 0.100000, loss: 3.3481
2023-07-01 23:06:53 - train: epoch 0008, iter [00350, 00390], lr: 0.100000, loss: 3.2980
2023-07-01 23:06:55 - train: epoch 008, train_loss: 3.3497
2023-07-01 23:06:56 - eval: epoch: 008, acc1: 20.620%, acc5: 48.220%, test_loss: 3.2923, per_image_load_time: 0.093ms, per_image_inference_time: 0.055ms
2023-07-01 23:06:57 - until epoch: 008, best_acc1: 20.730%
2023-07-01 23:06:57 - epoch 009 lr: 0.100000
2023-07-01 23:06:59 - train: epoch 0009, iter [00050, 00390], lr: 0.100000, loss: 3.1717
2023-07-01 23:07:01 - train: epoch 0009, iter [00100, 00390], lr: 0.100000, loss: 3.4347
2023-07-01 23:07:03 - train: epoch 0009, iter [00150, 00390], lr: 0.100000, loss: 3.1364
2023-07-01 23:07:04 - train: epoch 0009, iter [00200, 00390], lr: 0.100000, loss: 3.3561
2023-07-01 23:07:06 - train: epoch 0009, iter [00250, 00390], lr: 0.100000, loss: 3.3882
2023-07-01 23:07:07 - train: epoch 0009, iter [00300, 00390], lr: 0.100000, loss: 3.3761
2023-07-01 23:07:09 - train: epoch 0009, iter [00350, 00390], lr: 0.100000, loss: 3.4548
2023-07-01 23:07:10 - train: epoch 009, train_loss: 3.3125
2023-07-01 23:07:11 - eval: epoch: 009, acc1: 22.310%, acc5: 49.400%, test_loss: 3.2260, per_image_load_time: 0.093ms, per_image_inference_time: 0.054ms
2023-07-01 23:07:12 - until epoch: 009, best_acc1: 22.310%
2023-07-01 23:07:12 - epoch 010 lr: 0.100000
2023-07-01 23:07:15 - train: epoch 0010, iter [00050, 00390], lr: 0.100000, loss: 3.5234
2023-07-01 23:07:16 - train: epoch 0010, iter [00100, 00390], lr: 0.100000, loss: 3.3912
2023-07-01 23:07:18 - train: epoch 0010, iter [00150, 00390], lr: 0.100000, loss: 3.2281
2023-07-01 23:07:19 - train: epoch 0010, iter [00200, 00390], lr: 0.100000, loss: 3.3307
2023-07-01 23:07:21 - train: epoch 0010, iter [00250, 00390], lr: 0.100000, loss: 3.2845
2023-07-01 23:07:22 - train: epoch 0010, iter [00300, 00390], lr: 0.100000, loss: 2.9961
2023-07-01 23:07:24 - train: epoch 0010, iter [00350, 00390], lr: 0.100000, loss: 3.2501
2023-07-01 23:07:25 - train: epoch 010, train_loss: 3.2889
2023-07-01 23:07:27 - eval: epoch: 010, acc1: 21.890%, acc5: 48.720%, test_loss: 3.2377, per_image_load_time: 0.097ms, per_image_inference_time: 0.054ms
2023-07-01 23:07:27 - until epoch: 010, best_acc1: 22.310%
2023-07-01 23:07:27 - epoch 011 lr: 0.100000
2023-07-01 23:07:29 - train: epoch 0011, iter [00050, 00390], lr: 0.100000, loss: 3.4187
2023-07-01 23:07:31 - train: epoch 0011, iter [00100, 00390], lr: 0.100000, loss: 3.1130
2023-07-01 23:07:32 - train: epoch 0011, iter [00150, 00390], lr: 0.100000, loss: 3.3100
2023-07-01 23:07:34 - train: epoch 0011, iter [00200, 00390], lr: 0.100000, loss: 3.3334
2023-07-01 23:07:35 - train: epoch 0011, iter [00250, 00390], lr: 0.100000, loss: 3.2243
2023-07-01 23:07:36 - train: epoch 0011, iter [00300, 00390], lr: 0.100000, loss: 3.0935
2023-07-01 23:07:38 - train: epoch 0011, iter [00350, 00390], lr: 0.100000, loss: 3.1444
2023-07-01 23:07:39 - train: epoch 011, train_loss: 3.2680
2023-07-01 23:07:40 - eval: epoch: 011, acc1: 21.770%, acc5: 49.360%, test_loss: 3.2465, per_image_load_time: 0.093ms, per_image_inference_time: 0.053ms
2023-07-01 23:07:41 - until epoch: 011, best_acc1: 22.310%
2023-07-01 23:07:41 - epoch 012 lr: 0.100000
2023-07-01 23:07:43 - train: epoch 0012, iter [00050, 00390], lr: 0.100000, loss: 3.1886
2023-07-01 23:07:45 - train: epoch 0012, iter [00100, 00390], lr: 0.100000, loss: 3.2596
2023-07-01 23:07:46 - train: epoch 0012, iter [00150, 00390], lr: 0.100000, loss: 3.3833
2023-07-01 23:07:47 - train: epoch 0012, iter [00200, 00390], lr: 0.100000, loss: 3.3553
2023-07-01 23:07:49 - train: epoch 0012, iter [00250, 00390], lr: 0.100000, loss: 3.2839
2023-07-01 23:07:50 - train: epoch 0012, iter [00300, 00390], lr: 0.100000, loss: 3.2169
2023-07-01 23:07:52 - train: epoch 0012, iter [00350, 00390], lr: 0.100000, loss: 3.3499
2023-07-01 23:07:53 - train: epoch 012, train_loss: 3.2471
2023-07-01 23:07:54 - eval: epoch: 012, acc1: 22.450%, acc5: 50.990%, test_loss: 3.1858, per_image_load_time: 0.093ms, per_image_inference_time: 0.053ms
2023-07-01 23:07:55 - until epoch: 012, best_acc1: 22.450%
2023-07-01 23:07:55 - epoch 013 lr: 0.100000
2023-07-01 23:07:57 - train: epoch 0013, iter [00050, 00390], lr: 0.100000, loss: 3.1512
2023-07-01 23:07:59 - train: epoch 0013, iter [00100, 00390], lr: 0.100000, loss: 3.3219
2023-07-01 23:08:00 - train: epoch 0013, iter [00150, 00390], lr: 0.100000, loss: 3.2612
2023-07-01 23:08:01 - train: epoch 0013, iter [00200, 00390], lr: 0.100000, loss: 3.2327
2023-07-01 23:08:03 - train: epoch 0013, iter [00250, 00390], lr: 0.100000, loss: 3.2080
2023-07-01 23:08:04 - train: epoch 0013, iter [00300, 00390], lr: 0.100000, loss: 3.3055
2023-07-01 23:08:05 - train: epoch 0013, iter [00350, 00390], lr: 0.100000, loss: 2.9605
2023-07-01 23:08:07 - train: epoch 013, train_loss: 3.2246
2023-07-01 23:08:08 - eval: epoch: 013, acc1: 23.030%, acc5: 51.220%, test_loss: 3.1643, per_image_load_time: 0.093ms, per_image_inference_time: 0.054ms
2023-07-01 23:08:09 - until epoch: 013, best_acc1: 23.030%
2023-07-01 23:08:09 - epoch 014 lr: 0.100000
2023-07-01 23:08:11 - train: epoch 0014, iter [00050, 00390], lr: 0.100000, loss: 3.2557
2023-07-01 23:08:13 - train: epoch 0014, iter [00100, 00390], lr: 0.100000, loss: 3.0071
2023-07-01 23:08:14 - train: epoch 0014, iter [00150, 00390], lr: 0.100000, loss: 3.0778
2023-07-01 23:08:16 - train: epoch 0014, iter [00200, 00390], lr: 0.100000, loss: 3.1437
2023-07-01 23:08:17 - train: epoch 0014, iter [00250, 00390], lr: 0.100000, loss: 3.1755
2023-07-01 23:08:18 - train: epoch 0014, iter [00300, 00390], lr: 0.100000, loss: 3.2462
2023-07-01 23:08:20 - train: epoch 0014, iter [00350, 00390], lr: 0.100000, loss: 3.1852
2023-07-01 23:08:21 - train: epoch 014, train_loss: 3.2017
2023-07-01 23:08:22 - eval: epoch: 014, acc1: 22.730%, acc5: 50.890%, test_loss: 3.1817, per_image_load_time: 0.092ms, per_image_inference_time: 0.054ms
2023-07-01 23:08:23 - until epoch: 014, best_acc1: 23.030%
2023-07-01 23:08:23 - epoch 015 lr: 0.100000
2023-07-01 23:08:25 - train: epoch 0015, iter [00050, 00390], lr: 0.100000, loss: 2.9147
2023-07-01 23:08:27 - train: epoch 0015, iter [00100, 00390], lr: 0.100000, loss: 3.2831
2023-07-01 23:08:28 - train: epoch 0015, iter [00150, 00390], lr: 0.100000, loss: 3.4800
2023-07-01 23:08:30 - train: epoch 0015, iter [00200, 00390], lr: 0.100000, loss: 3.2107
2023-07-01 23:08:31 - train: epoch 0015, iter [00250, 00390], lr: 0.100000, loss: 3.0163
2023-07-01 23:08:33 - train: epoch 0015, iter [00300, 00390], lr: 0.100000, loss: 3.0571
2023-07-01 23:08:34 - train: epoch 0015, iter [00350, 00390], lr: 0.100000, loss: 3.0290
2023-07-01 23:08:35 - train: epoch 015, train_loss: 3.1932
2023-07-01 23:08:37 - eval: epoch: 015, acc1: 22.470%, acc5: 50.590%, test_loss: 3.1987, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:08:37 - until epoch: 015, best_acc1: 23.030%
2023-07-01 23:08:37 - epoch 016 lr: 0.100000
2023-07-01 23:08:40 - train: epoch 0016, iter [00050, 00390], lr: 0.100000, loss: 3.2800
2023-07-01 23:08:41 - train: epoch 0016, iter [00100, 00390], lr: 0.100000, loss: 3.1613
2023-07-01 23:08:42 - train: epoch 0016, iter [00150, 00390], lr: 0.100000, loss: 3.2577
2023-07-01 23:08:44 - train: epoch 0016, iter [00200, 00390], lr: 0.100000, loss: 3.2771
2023-07-01 23:08:45 - train: epoch 0016, iter [00250, 00390], lr: 0.100000, loss: 3.1156
2023-07-01 23:08:47 - train: epoch 0016, iter [00300, 00390], lr: 0.100000, loss: 3.1368
2023-07-01 23:08:48 - train: epoch 0016, iter [00350, 00390], lr: 0.100000, loss: 2.9205
2023-07-01 23:08:49 - train: epoch 016, train_loss: 3.1788
2023-07-01 23:08:51 - eval: epoch: 016, acc1: 23.450%, acc5: 51.830%, test_loss: 3.1421, per_image_load_time: 0.094ms, per_image_inference_time: 0.058ms
2023-07-01 23:08:52 - until epoch: 016, best_acc1: 23.450%
2023-07-01 23:08:52 - epoch 017 lr: 0.100000
2023-07-01 23:08:54 - train: epoch 0017, iter [00050, 00390], lr: 0.100000, loss: 3.2524
2023-07-01 23:08:55 - train: epoch 0017, iter [00100, 00390], lr: 0.100000, loss: 3.1926
2023-07-01 23:08:57 - train: epoch 0017, iter [00150, 00390], lr: 0.100000, loss: 2.8539
2023-07-01 23:08:58 - train: epoch 0017, iter [00200, 00390], lr: 0.100000, loss: 3.1627
2023-07-01 23:09:00 - train: epoch 0017, iter [00250, 00390], lr: 0.100000, loss: 3.0856
2023-07-01 23:09:01 - train: epoch 0017, iter [00300, 00390], lr: 0.100000, loss: 3.3205
2023-07-01 23:09:03 - train: epoch 0017, iter [00350, 00390], lr: 0.100000, loss: 2.9835
2023-07-01 23:09:04 - train: epoch 017, train_loss: 3.1680
2023-07-01 23:09:05 - eval: epoch: 017, acc1: 23.780%, acc5: 52.290%, test_loss: 3.1357, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:09:06 - until epoch: 017, best_acc1: 23.780%
2023-07-01 23:09:06 - epoch 018 lr: 0.100000
2023-07-01 23:09:08 - train: epoch 0018, iter [00050, 00390], lr: 0.100000, loss: 3.3192
2023-07-01 23:09:10 - train: epoch 0018, iter [00100, 00390], lr: 0.100000, loss: 3.3709
2023-07-01 23:09:11 - train: epoch 0018, iter [00150, 00390], lr: 0.100000, loss: 3.3199
2023-07-01 23:09:12 - train: epoch 0018, iter [00200, 00390], lr: 0.100000, loss: 3.1602
2023-07-01 23:09:14 - train: epoch 0018, iter [00250, 00390], lr: 0.100000, loss: 3.1526
2023-07-01 23:09:15 - train: epoch 0018, iter [00300, 00390], lr: 0.100000, loss: 3.1023
2023-07-01 23:09:17 - train: epoch 0018, iter [00350, 00390], lr: 0.100000, loss: 3.0939
2023-07-01 23:09:18 - train: epoch 018, train_loss: 3.1526
2023-07-01 23:09:19 - eval: epoch: 018, acc1: 24.770%, acc5: 52.990%, test_loss: 3.0949, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:09:20 - until epoch: 018, best_acc1: 24.770%
2023-07-01 23:09:20 - epoch 019 lr: 0.100000
2023-07-01 23:09:22 - train: epoch 0019, iter [00050, 00390], lr: 0.100000, loss: 2.9370
2023-07-01 23:09:24 - train: epoch 0019, iter [00100, 00390], lr: 0.100000, loss: 3.1683
2023-07-01 23:09:25 - train: epoch 0019, iter [00150, 00390], lr: 0.100000, loss: 3.2965
2023-07-01 23:09:27 - train: epoch 0019, iter [00200, 00390], lr: 0.100000, loss: 3.2837
2023-07-01 23:09:28 - train: epoch 0019, iter [00250, 00390], lr: 0.100000, loss: 3.3613
2023-07-01 23:09:29 - train: epoch 0019, iter [00300, 00390], lr: 0.100000, loss: 3.3252
2023-07-01 23:09:31 - train: epoch 0019, iter [00350, 00390], lr: 0.100000, loss: 3.1036
2023-07-01 23:09:32 - train: epoch 019, train_loss: 3.1350
2023-07-01 23:09:34 - eval: epoch: 019, acc1: 23.920%, acc5: 52.550%, test_loss: 3.1106, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:09:34 - until epoch: 019, best_acc1: 24.770%
2023-07-01 23:09:34 - epoch 020 lr: 0.100000
2023-07-01 23:09:37 - train: epoch 0020, iter [00050, 00390], lr: 0.100000, loss: 3.1698
2023-07-01 23:09:38 - train: epoch 0020, iter [00100, 00390], lr: 0.100000, loss: 3.2932
2023-07-01 23:09:40 - train: epoch 0020, iter [00150, 00390], lr: 0.100000, loss: 3.2923
2023-07-01 23:09:41 - train: epoch 0020, iter [00200, 00390], lr: 0.100000, loss: 3.2501
2023-07-01 23:09:43 - train: epoch 0020, iter [00250, 00390], lr: 0.100000, loss: 3.1144
2023-07-01 23:09:44 - train: epoch 0020, iter [00300, 00390], lr: 0.100000, loss: 3.3784
2023-07-01 23:09:46 - train: epoch 0020, iter [00350, 00390], lr: 0.100000, loss: 3.1845
2023-07-01 23:09:47 - train: epoch 020, train_loss: 3.1316
2023-07-01 23:09:49 - eval: epoch: 020, acc1: 25.150%, acc5: 53.330%, test_loss: 3.0781, per_image_load_time: 0.098ms, per_image_inference_time: 0.054ms
2023-07-01 23:09:50 - until epoch: 020, best_acc1: 25.150%
2023-07-01 23:09:50 - epoch 021 lr: 0.100000
2023-07-01 23:09:53 - train: epoch 0021, iter [00050, 00390], lr: 0.100000, loss: 3.0447
2023-07-01 23:09:54 - train: epoch 0021, iter [00100, 00390], lr: 0.100000, loss: 3.2829
2023-07-01 23:09:56 - train: epoch 0021, iter [00150, 00390], lr: 0.100000, loss: 3.2672
2023-07-01 23:09:57 - train: epoch 0021, iter [00200, 00390], lr: 0.100000, loss: 3.4645
2023-07-01 23:09:58 - train: epoch 0021, iter [00250, 00390], lr: 0.100000, loss: 3.2388
2023-07-01 23:10:00 - train: epoch 0021, iter [00300, 00390], lr: 0.100000, loss: 3.2043
2023-07-01 23:10:01 - train: epoch 0021, iter [00350, 00390], lr: 0.100000, loss: 3.0333
2023-07-01 23:10:02 - train: epoch 021, train_loss: 3.1094
2023-07-01 23:10:04 - eval: epoch: 021, acc1: 25.050%, acc5: 54.360%, test_loss: 3.0455, per_image_load_time: 0.097ms, per_image_inference_time: 0.053ms
2023-07-01 23:10:04 - until epoch: 021, best_acc1: 25.150%
2023-07-01 23:10:04 - epoch 022 lr: 0.100000
2023-07-01 23:10:07 - train: epoch 0022, iter [00050, 00390], lr: 0.100000, loss: 3.1688
2023-07-01 23:10:08 - train: epoch 0022, iter [00100, 00390], lr: 0.100000, loss: 3.0025
2023-07-01 23:10:09 - train: epoch 0022, iter [00150, 00390], lr: 0.100000, loss: 3.1252
2023-07-01 23:10:11 - train: epoch 0022, iter [00200, 00390], lr: 0.100000, loss: 3.1777
2023-07-01 23:10:12 - train: epoch 0022, iter [00250, 00390], lr: 0.100000, loss: 3.1552
2023-07-01 23:10:13 - train: epoch 0022, iter [00300, 00390], lr: 0.100000, loss: 3.1659
2023-07-01 23:10:15 - train: epoch 0022, iter [00350, 00390], lr: 0.100000, loss: 3.0036
2023-07-01 23:10:16 - train: epoch 022, train_loss: 3.0989
2023-07-01 23:10:18 - eval: epoch: 022, acc1: 25.210%, acc5: 53.390%, test_loss: 3.0616, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:10:18 - until epoch: 022, best_acc1: 25.210%
2023-07-01 23:10:18 - epoch 023 lr: 0.100000
2023-07-01 23:10:21 - train: epoch 0023, iter [00050, 00390], lr: 0.100000, loss: 3.1825
2023-07-01 23:10:22 - train: epoch 0023, iter [00100, 00390], lr: 0.100000, loss: 3.0562
2023-07-01 23:10:24 - train: epoch 0023, iter [00150, 00390], lr: 0.100000, loss: 3.1564
2023-07-01 23:10:25 - train: epoch 0023, iter [00200, 00390], lr: 0.100000, loss: 3.2473
2023-07-01 23:10:26 - train: epoch 0023, iter [00250, 00390], lr: 0.100000, loss: 3.0548
2023-07-01 23:10:28 - train: epoch 0023, iter [00300, 00390], lr: 0.100000, loss: 3.1422
2023-07-01 23:10:29 - train: epoch 0023, iter [00350, 00390], lr: 0.100000, loss: 2.9385
2023-07-01 23:10:30 - train: epoch 023, train_loss: 3.0820
2023-07-01 23:10:32 - eval: epoch: 023, acc1: 25.430%, acc5: 54.460%, test_loss: 3.0423, per_image_load_time: 0.093ms, per_image_inference_time: 0.054ms
2023-07-01 23:10:33 - until epoch: 023, best_acc1: 25.430%
2023-07-01 23:10:33 - epoch 024 lr: 0.100000
2023-07-01 23:10:35 - train: epoch 0024, iter [00050, 00390], lr: 0.100000, loss: 3.0400
2023-07-01 23:10:37 - train: epoch 0024, iter [00100, 00390], lr: 0.100000, loss: 2.9718
2023-07-01 23:10:38 - train: epoch 0024, iter [00150, 00390], lr: 0.100000, loss: 2.8138
2023-07-01 23:10:39 - train: epoch 0024, iter [00200, 00390], lr: 0.100000, loss: 3.1753
2023-07-01 23:10:41 - train: epoch 0024, iter [00250, 00390], lr: 0.100000, loss: 3.2017
2023-07-01 23:10:42 - train: epoch 0024, iter [00300, 00390], lr: 0.100000, loss: 2.9583
2023-07-01 23:10:44 - train: epoch 0024, iter [00350, 00390], lr: 0.100000, loss: 3.0517
2023-07-01 23:10:45 - train: epoch 024, train_loss: 3.0764
2023-07-01 23:10:47 - eval: epoch: 024, acc1: 24.860%, acc5: 53.790%, test_loss: 3.0488, per_image_load_time: 0.094ms, per_image_inference_time: 0.055ms
2023-07-01 23:10:47 - until epoch: 024, best_acc1: 25.430%
2023-07-01 23:10:47 - epoch 025 lr: 0.100000
2023-07-01 23:10:49 - train: epoch 0025, iter [00050, 00390], lr: 0.100000, loss: 3.0575
2023-07-01 23:10:51 - train: epoch 0025, iter [00100, 00390], lr: 0.100000, loss: 2.9175
2023-07-01 23:10:52 - train: epoch 0025, iter [00150, 00390], lr: 0.100000, loss: 3.1910
2023-07-01 23:10:53 - train: epoch 0025, iter [00200, 00390], lr: 0.100000, loss: 3.1051
2023-07-01 23:10:55 - train: epoch 0025, iter [00250, 00390], lr: 0.100000, loss: 3.0577
2023-07-01 23:10:56 - train: epoch 0025, iter [00300, 00390], lr: 0.100000, loss: 3.1050
2023-07-01 23:10:58 - train: epoch 0025, iter [00350, 00390], lr: 0.100000, loss: 3.0295
2023-07-01 23:10:59 - train: epoch 025, train_loss: 3.0617
2023-07-01 23:11:00 - eval: epoch: 025, acc1: 25.580%, acc5: 54.170%, test_loss: 3.0462, per_image_load_time: 0.097ms, per_image_inference_time: 0.053ms
2023-07-01 23:11:01 - until epoch: 025, best_acc1: 25.580%
2023-07-01 23:11:01 - epoch 026 lr: 0.100000
2023-07-01 23:11:04 - train: epoch 0026, iter [00050, 00390], lr: 0.100000, loss: 2.9101
2023-07-01 23:11:05 - train: epoch 0026, iter [00100, 00390], lr: 0.100000, loss: 3.3101
2023-07-01 23:11:06 - train: epoch 0026, iter [00150, 00390], lr: 0.100000, loss: 3.0038
2023-07-01 23:11:08 - train: epoch 0026, iter [00200, 00390], lr: 0.100000, loss: 3.2589
2023-07-01 23:11:09 - train: epoch 0026, iter [00250, 00390], lr: 0.100000, loss: 3.1119
2023-07-01 23:11:11 - train: epoch 0026, iter [00300, 00390], lr: 0.100000, loss: 2.9740
2023-07-01 23:11:12 - train: epoch 0026, iter [00350, 00390], lr: 0.100000, loss: 3.0591
2023-07-01 23:11:13 - train: epoch 026, train_loss: 3.0457
2023-07-01 23:11:15 - eval: epoch: 026, acc1: 25.570%, acc5: 54.790%, test_loss: 3.0129, per_image_load_time: 0.092ms, per_image_inference_time: 0.055ms
2023-07-01 23:11:15 - until epoch: 026, best_acc1: 25.580%
2023-07-01 23:11:15 - epoch 027 lr: 0.100000
2023-07-01 23:11:18 - train: epoch 0027, iter [00050, 00390], lr: 0.100000, loss: 3.0138
2023-07-01 23:11:19 - train: epoch 0027, iter [00100, 00390], lr: 0.100000, loss: 3.0213
2023-07-01 23:11:21 - train: epoch 0027, iter [00150, 00390], lr: 0.100000, loss: 3.1685
2023-07-01 23:11:22 - train: epoch 0027, iter [00200, 00390], lr: 0.100000, loss: 3.1223
2023-07-01 23:11:24 - train: epoch 0027, iter [00250, 00390], lr: 0.100000, loss: 3.1865
2023-07-01 23:11:25 - train: epoch 0027, iter [00300, 00390], lr: 0.100000, loss: 3.3001
2023-07-01 23:11:26 - train: epoch 0027, iter [00350, 00390], lr: 0.100000, loss: 3.2187
2023-07-01 23:11:27 - train: epoch 027, train_loss: 3.0441
2023-07-01 23:11:29 - eval: epoch: 027, acc1: 26.080%, acc5: 55.210%, test_loss: 3.0136, per_image_load_time: 0.091ms, per_image_inference_time: 0.054ms
2023-07-01 23:11:30 - until epoch: 027, best_acc1: 26.080%
2023-07-01 23:11:30 - epoch 028 lr: 0.100000
2023-07-01 23:11:32 - train: epoch 0028, iter [00050, 00390], lr: 0.100000, loss: 3.1350
2023-07-01 23:11:34 - train: epoch 0028, iter [00100, 00390], lr: 0.100000, loss: 2.9064
2023-07-01 23:11:35 - train: epoch 0028, iter [00150, 00390], lr: 0.100000, loss: 2.7884
2023-07-01 23:11:37 - train: epoch 0028, iter [00200, 00390], lr: 0.100000, loss: 3.3081
2023-07-01 23:11:38 - train: epoch 0028, iter [00250, 00390], lr: 0.100000, loss: 3.0882
2023-07-01 23:11:40 - train: epoch 0028, iter [00300, 00390], lr: 0.100000, loss: 3.1083
2023-07-01 23:11:41 - train: epoch 0028, iter [00350, 00390], lr: 0.100000, loss: 3.0635
2023-07-01 23:11:42 - train: epoch 028, train_loss: 3.0273
2023-07-01 23:11:44 - eval: epoch: 028, acc1: 25.390%, acc5: 53.700%, test_loss: 3.0644, per_image_load_time: 0.100ms, per_image_inference_time: 0.055ms
2023-07-01 23:11:44 - until epoch: 028, best_acc1: 26.080%
2023-07-01 23:11:44 - epoch 029 lr: 0.100000
2023-07-01 23:11:47 - train: epoch 0029, iter [00050, 00390], lr: 0.100000, loss: 2.9771
2023-07-01 23:11:48 - train: epoch 0029, iter [00100, 00390], lr: 0.100000, loss: 3.0578
2023-07-01 23:11:50 - train: epoch 0029, iter [00150, 00390], lr: 0.100000, loss: 3.1310
2023-07-01 23:11:51 - train: epoch 0029, iter [00200, 00390], lr: 0.100000, loss: 2.9881
2023-07-01 23:11:52 - train: epoch 0029, iter [00250, 00390], lr: 0.100000, loss: 2.8942
2023-07-01 23:11:54 - train: epoch 0029, iter [00300, 00390], lr: 0.100000, loss: 3.0302
2023-07-01 23:11:55 - train: epoch 0029, iter [00350, 00390], lr: 0.100000, loss: 3.0879
2023-07-01 23:11:56 - train: epoch 029, train_loss: 3.0127
2023-07-01 23:11:58 - eval: epoch: 029, acc1: 25.480%, acc5: 54.690%, test_loss: 3.0042, per_image_load_time: 0.098ms, per_image_inference_time: 0.057ms
2023-07-01 23:11:58 - until epoch: 029, best_acc1: 26.080%
2023-07-01 23:11:58 - epoch 030 lr: 0.100000
2023-07-01 23:12:01 - train: epoch 0030, iter [00050, 00390], lr: 0.100000, loss: 2.9762
2023-07-01 23:12:02 - train: epoch 0030, iter [00100, 00390], lr: 0.100000, loss: 3.0155
2023-07-01 23:12:04 - train: epoch 0030, iter [00150, 00390], lr: 0.100000, loss: 2.9006
2023-07-01 23:12:05 - train: epoch 0030, iter [00200, 00390], lr: 0.100000, loss: 3.1119
2023-07-01 23:12:06 - train: epoch 0030, iter [00250, 00390], lr: 0.100000, loss: 2.9702
2023-07-01 23:12:08 - train: epoch 0030, iter [00300, 00390], lr: 0.100000, loss: 3.0993
2023-07-01 23:12:09 - train: epoch 0030, iter [00350, 00390], lr: 0.100000, loss: 2.9076
2023-07-01 23:12:11 - train: epoch 030, train_loss: 3.0103
2023-07-01 23:12:12 - eval: epoch: 030, acc1: 26.610%, acc5: 56.000%, test_loss: 2.9748, per_image_load_time: 0.099ms, per_image_inference_time: 0.056ms
2023-07-01 23:12:13 - until epoch: 030, best_acc1: 26.610%
2023-07-01 23:12:13 - epoch 031 lr: 0.100000
2023-07-01 23:12:15 - train: epoch 0031, iter [00050, 00390], lr: 0.100000, loss: 3.1727
2023-07-01 23:12:17 - train: epoch 0031, iter [00100, 00390], lr: 0.100000, loss: 3.1793
2023-07-01 23:12:18 - train: epoch 0031, iter [00150, 00390], lr: 0.100000, loss: 3.0046
2023-07-01 23:12:20 - train: epoch 0031, iter [00200, 00390], lr: 0.100000, loss: 3.1494
2023-07-01 23:12:21 - train: epoch 0031, iter [00250, 00390], lr: 0.100000, loss: 3.0112
2023-07-01 23:12:23 - train: epoch 0031, iter [00300, 00390], lr: 0.100000, loss: 2.9557
2023-07-01 23:12:24 - train: epoch 0031, iter [00350, 00390], lr: 0.100000, loss: 2.6852
2023-07-01 23:12:26 - train: epoch 031, train_loss: 2.9964
2023-07-01 23:12:28 - eval: epoch: 031, acc1: 26.750%, acc5: 56.320%, test_loss: 2.9696, per_image_load_time: 0.100ms, per_image_inference_time: 0.054ms
2023-07-01 23:12:29 - until epoch: 031, best_acc1: 26.750%
2023-07-01 23:12:29 - epoch 032 lr: 0.100000
2023-07-01 23:12:31 - train: epoch 0032, iter [00050, 00390], lr: 0.100000, loss: 3.0344
2023-07-01 23:12:32 - train: epoch 0032, iter [00100, 00390], lr: 0.100000, loss: 2.8512
2023-07-01 23:12:34 - train: epoch 0032, iter [00150, 00390], lr: 0.100000, loss: 3.0476
2023-07-01 23:12:35 - train: epoch 0032, iter [00200, 00390], lr: 0.100000, loss: 3.1595
2023-07-01 23:12:37 - train: epoch 0032, iter [00250, 00390], lr: 0.100000, loss: 3.1235
2023-07-01 23:12:38 - train: epoch 0032, iter [00300, 00390], lr: 0.100000, loss: 3.0545
2023-07-01 23:12:40 - train: epoch 0032, iter [00350, 00390], lr: 0.100000, loss: 2.8037
2023-07-01 23:12:41 - train: epoch 032, train_loss: 2.9850
2023-07-01 23:12:43 - eval: epoch: 032, acc1: 27.000%, acc5: 55.530%, test_loss: 2.9723, per_image_load_time: 0.099ms, per_image_inference_time: 0.060ms
2023-07-01 23:12:43 - until epoch: 032, best_acc1: 27.000%
2023-07-01 23:12:43 - epoch 033 lr: 0.100000
2023-07-01 23:12:45 - train: epoch 0033, iter [00050, 00390], lr: 0.100000, loss: 2.8557
2023-07-01 23:12:47 - train: epoch 0033, iter [00100, 00390], lr: 0.100000, loss: 3.0908
2023-07-01 23:12:48 - train: epoch 0033, iter [00150, 00390], lr: 0.100000, loss: 3.0229
2023-07-01 23:12:50 - train: epoch 0033, iter [00200, 00390], lr: 0.100000, loss: 3.0511
2023-07-01 23:12:51 - train: epoch 0033, iter [00250, 00390], lr: 0.100000, loss: 3.0687
2023-07-01 23:12:53 - train: epoch 0033, iter [00300, 00390], lr: 0.100000, loss: 3.1235
2023-07-01 23:12:54 - train: epoch 0033, iter [00350, 00390], lr: 0.100000, loss: 2.9780
2023-07-01 23:12:55 - train: epoch 033, train_loss: 2.9778
2023-07-01 23:12:57 - eval: epoch: 033, acc1: 27.310%, acc5: 57.270%, test_loss: 2.9312, per_image_load_time: 0.096ms, per_image_inference_time: 0.055ms
2023-07-01 23:12:57 - until epoch: 033, best_acc1: 27.310%
2023-07-01 23:12:57 - epoch 034 lr: 0.100000
2023-07-01 23:13:00 - train: epoch 0034, iter [00050, 00390], lr: 0.100000, loss: 3.0613
2023-07-01 23:13:01 - train: epoch 0034, iter [00100, 00390], lr: 0.100000, loss: 3.0702
2023-07-01 23:13:03 - train: epoch 0034, iter [00150, 00390], lr: 0.100000, loss: 2.8454
2023-07-01 23:13:04 - train: epoch 0034, iter [00200, 00390], lr: 0.100000, loss: 2.9050
2023-07-01 23:13:05 - train: epoch 0034, iter [00250, 00390], lr: 0.100000, loss: 2.9609
2023-07-01 23:13:07 - train: epoch 0034, iter [00300, 00390], lr: 0.100000, loss: 3.0652
2023-07-01 23:13:08 - train: epoch 0034, iter [00350, 00390], lr: 0.100000, loss: 2.6859
2023-07-01 23:13:09 - train: epoch 034, train_loss: 2.9709
2023-07-01 23:13:11 - eval: epoch: 034, acc1: 26.650%, acc5: 56.520%, test_loss: 2.9475, per_image_load_time: 0.094ms, per_image_inference_time: 0.060ms
2023-07-01 23:13:11 - until epoch: 034, best_acc1: 27.310%
2023-07-01 23:13:11 - epoch 035 lr: 0.100000
2023-07-01 23:13:14 - train: epoch 0035, iter [00050, 00390], lr: 0.100000, loss: 2.9338
2023-07-01 23:13:15 - train: epoch 0035, iter [00100, 00390], lr: 0.100000, loss: 2.9546
2023-07-01 23:13:17 - train: epoch 0035, iter [00150, 00390], lr: 0.100000, loss: 2.9202
2023-07-01 23:13:18 - train: epoch 0035, iter [00200, 00390], lr: 0.100000, loss: 2.8802
2023-07-01 23:13:19 - train: epoch 0035, iter [00250, 00390], lr: 0.100000, loss: 2.9015
2023-07-01 23:13:21 - train: epoch 0035, iter [00300, 00390], lr: 0.100000, loss: 2.7828
2023-07-01 23:13:22 - train: epoch 0035, iter [00350, 00390], lr: 0.100000, loss: 3.2206
2023-07-01 23:13:23 - train: epoch 035, train_loss: 2.9528
2023-07-01 23:13:25 - eval: epoch: 035, acc1: 27.430%, acc5: 56.200%, test_loss: 2.9426, per_image_load_time: 0.096ms, per_image_inference_time: 0.060ms
2023-07-01 23:13:25 - until epoch: 035, best_acc1: 27.430%
2023-07-01 23:13:25 - epoch 036 lr: 0.100000
2023-07-01 23:13:28 - train: epoch 0036, iter [00050, 00390], lr: 0.100000, loss: 3.0244
2023-07-01 23:13:29 - train: epoch 0036, iter [00100, 00390], lr: 0.100000, loss: 2.9612
2023-07-01 23:13:31 - train: epoch 0036, iter [00150, 00390], lr: 0.100000, loss: 2.9633
2023-07-01 23:13:32 - train: epoch 0036, iter [00200, 00390], lr: 0.100000, loss: 3.1344
2023-07-01 23:13:33 - train: epoch 0036, iter [00250, 00390], lr: 0.100000, loss: 2.8059
2023-07-01 23:13:35 - train: epoch 0036, iter [00300, 00390], lr: 0.100000, loss: 2.9161
2023-07-01 23:13:36 - train: epoch 0036, iter [00350, 00390], lr: 0.100000, loss: 2.7056
2023-07-01 23:13:37 - train: epoch 036, train_loss: 2.9527
2023-07-01 23:13:39 - eval: epoch: 036, acc1: 27.590%, acc5: 57.200%, test_loss: 2.9113, per_image_load_time: 0.093ms, per_image_inference_time: 0.053ms
2023-07-01 23:13:39 - until epoch: 036, best_acc1: 27.590%
2023-07-01 23:13:39 - epoch 037 lr: 0.100000
2023-07-01 23:13:42 - train: epoch 0037, iter [00050, 00390], lr: 0.100000, loss: 2.9921
2023-07-01 23:13:43 - train: epoch 0037, iter [00100, 00390], lr: 0.100000, loss: 2.8444
2023-07-01 23:13:45 - train: epoch 0037, iter [00150, 00390], lr: 0.100000, loss: 2.9234
2023-07-01 23:13:46 - train: epoch 0037, iter [00200, 00390], lr: 0.100000, loss: 2.9783
2023-07-01 23:13:47 - train: epoch 0037, iter [00250, 00390], lr: 0.100000, loss: 2.7631
2023-07-01 23:13:49 - train: epoch 0037, iter [00300, 00390], lr: 0.100000, loss: 2.9241
2023-07-01 23:13:50 - train: epoch 0037, iter [00350, 00390], lr: 0.100000, loss: 3.0267
2023-07-01 23:13:51 - train: epoch 037, train_loss: 2.9301
2023-07-01 23:13:53 - eval: epoch: 037, acc1: 27.240%, acc5: 57.180%, test_loss: 2.9289, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:13:53 - until epoch: 037, best_acc1: 27.590%
2023-07-01 23:13:53 - epoch 038 lr: 0.100000
2023-07-01 23:13:56 - train: epoch 0038, iter [00050, 00390], lr: 0.100000, loss: 2.8726
2023-07-01 23:13:57 - train: epoch 0038, iter [00100, 00390], lr: 0.100000, loss: 3.0778
2023-07-01 23:13:59 - train: epoch 0038, iter [00150, 00390], lr: 0.100000, loss: 3.0739
2023-07-01 23:14:00 - train: epoch 0038, iter [00200, 00390], lr: 0.100000, loss: 2.7690
2023-07-01 23:14:01 - train: epoch 0038, iter [00250, 00390], lr: 0.100000, loss: 3.0308
2023-07-01 23:14:03 - train: epoch 0038, iter [00300, 00390], lr: 0.100000, loss: 2.9763
2023-07-01 23:14:04 - train: epoch 0038, iter [00350, 00390], lr: 0.100000, loss: 3.2144
2023-07-01 23:14:05 - train: epoch 038, train_loss: 2.9263
2023-07-01 23:14:07 - eval: epoch: 038, acc1: 27.740%, acc5: 56.720%, test_loss: 2.9340, per_image_load_time: 0.092ms, per_image_inference_time: 0.060ms
2023-07-01 23:14:08 - until epoch: 038, best_acc1: 27.740%
2023-07-01 23:14:08 - epoch 039 lr: 0.100000
2023-07-01 23:14:10 - train: epoch 0039, iter [00050, 00390], lr: 0.100000, loss: 2.8547
2023-07-01 23:14:12 - train: epoch 0039, iter [00100, 00390], lr: 0.100000, loss: 2.9672
2023-07-01 23:14:13 - train: epoch 0039, iter [00150, 00390], lr: 0.100000, loss: 2.8881
2023-07-01 23:14:14 - train: epoch 0039, iter [00200, 00390], lr: 0.100000, loss: 2.8471
2023-07-01 23:14:16 - train: epoch 0039, iter [00250, 00390], lr: 0.100000, loss: 2.9807
2023-07-01 23:14:17 - train: epoch 0039, iter [00300, 00390], lr: 0.100000, loss: 2.6491
2023-07-01 23:14:18 - train: epoch 0039, iter [00350, 00390], lr: 0.100000, loss: 3.1166
2023-07-01 23:14:20 - train: epoch 039, train_loss: 2.9253
2023-07-01 23:14:21 - eval: epoch: 039, acc1: 26.980%, acc5: 57.420%, test_loss: 2.9108, per_image_load_time: 0.097ms, per_image_inference_time: 0.053ms
2023-07-01 23:14:22 - until epoch: 039, best_acc1: 27.740%
2023-07-01 23:14:22 - epoch 040 lr: 0.100000
2023-07-01 23:14:24 - train: epoch 0040, iter [00050, 00390], lr: 0.100000, loss: 2.9802
2023-07-01 23:14:25 - train: epoch 0040, iter [00100, 00390], lr: 0.100000, loss: 2.6707
2023-07-01 23:14:27 - train: epoch 0040, iter [00150, 00390], lr: 0.100000, loss: 2.7667
2023-07-01 23:14:28 - train: epoch 0040, iter [00200, 00390], lr: 0.100000, loss: 3.0104
2023-07-01 23:14:29 - train: epoch 0040, iter [00250, 00390], lr: 0.100000, loss: 3.0948
2023-07-01 23:14:31 - train: epoch 0040, iter [00300, 00390], lr: 0.100000, loss: 2.6309
2023-07-01 23:14:32 - train: epoch 0040, iter [00350, 00390], lr: 0.100000, loss: 2.8068
2023-07-01 23:14:33 - train: epoch 040, train_loss: 2.9067
2023-07-01 23:14:35 - eval: epoch: 040, acc1: 29.230%, acc5: 58.490%, test_loss: 2.8726, per_image_load_time: 0.093ms, per_image_inference_time: 0.055ms
2023-07-01 23:14:36 - until epoch: 040, best_acc1: 29.230%
2023-07-01 23:14:36 - epoch 041 lr: 0.100000
2023-07-01 23:14:38 - train: epoch 0041, iter [00050, 00390], lr: 0.100000, loss: 2.8021
2023-07-01 23:14:40 - train: epoch 0041, iter [00100, 00390], lr: 0.100000, loss: 2.6815
2023-07-01 23:14:41 - train: epoch 0041, iter [00150, 00390], lr: 0.100000, loss: 3.0728
2023-07-01 23:14:43 - train: epoch 0041, iter [00200, 00390], lr: 0.100000, loss: 3.1380
2023-07-01 23:14:44 - train: epoch 0041, iter [00250, 00390], lr: 0.100000, loss: 2.9750
2023-07-01 23:14:45 - train: epoch 0041, iter [00300, 00390], lr: 0.100000, loss: 2.9616
2023-07-01 23:14:47 - train: epoch 0041, iter [00350, 00390], lr: 0.100000, loss: 3.1125
2023-07-01 23:14:48 - train: epoch 041, train_loss: 2.9052
2023-07-01 23:14:50 - eval: epoch: 041, acc1: 29.020%, acc5: 58.540%, test_loss: 2.8667, per_image_load_time: 0.094ms, per_image_inference_time: 0.055ms
2023-07-01 23:14:50 - until epoch: 041, best_acc1: 29.230%
2023-07-01 23:14:50 - epoch 042 lr: 0.100000
2023-07-01 23:14:52 - train: epoch 0042, iter [00050, 00390], lr: 0.100000, loss: 2.6790
2023-07-01 23:14:54 - train: epoch 0042, iter [00100, 00390], lr: 0.100000, loss: 2.9347
2023-07-01 23:14:55 - train: epoch 0042, iter [00150, 00390], lr: 0.100000, loss: 2.6541
2023-07-01 23:14:56 - train: epoch 0042, iter [00200, 00390], lr: 0.100000, loss: 2.6505
2023-07-01 23:14:58 - train: epoch 0042, iter [00250, 00390], lr: 0.100000, loss: 2.7246
2023-07-01 23:14:59 - train: epoch 0042, iter [00300, 00390], lr: 0.100000, loss: 2.7333
2023-07-01 23:15:01 - train: epoch 0042, iter [00350, 00390], lr: 0.100000, loss: 2.6513
2023-07-01 23:15:02 - train: epoch 042, train_loss: 2.8870
2023-07-01 23:15:03 - eval: epoch: 042, acc1: 27.860%, acc5: 58.150%, test_loss: 2.9011, per_image_load_time: 0.094ms, per_image_inference_time: 0.053ms
2023-07-01 23:15:04 - until epoch: 042, best_acc1: 29.230%
2023-07-01 23:15:04 - epoch 043 lr: 0.100000
2023-07-01 23:15:06 - train: epoch 0043, iter [00050, 00390], lr: 0.100000, loss: 3.0786
2023-07-01 23:15:08 - train: epoch 0043, iter [00100, 00390], lr: 0.100000, loss: 2.6473
2023-07-01 23:15:09 - train: epoch 0043, iter [00150, 00390], lr: 0.100000, loss: 2.7095
2023-07-01 23:15:11 - train: epoch 0043, iter [00200, 00390], lr: 0.100000, loss: 3.0542
2023-07-01 23:15:12 - train: epoch 0043, iter [00250, 00390], lr: 0.100000, loss: 2.9204
2023-07-01 23:15:13 - train: epoch 0043, iter [00300, 00390], lr: 0.100000, loss: 2.9385
2023-07-01 23:15:15 - train: epoch 0043, iter [00350, 00390], lr: 0.100000, loss: 2.8418
2023-07-01 23:15:16 - train: epoch 043, train_loss: 2.8883
2023-07-01 23:15:17 - eval: epoch: 043, acc1: 29.080%, acc5: 59.050%, test_loss: 2.8492, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:15:18 - until epoch: 043, best_acc1: 29.230%
2023-07-01 23:15:18 - epoch 044 lr: 0.100000
2023-07-01 23:15:21 - train: epoch 0044, iter [00050, 00390], lr: 0.100000, loss: 3.1649
2023-07-01 23:15:22 - train: epoch 0044, iter [00100, 00390], lr: 0.100000, loss: 2.9872
2023-07-01 23:15:24 - train: epoch 0044, iter [00150, 00390], lr: 0.100000, loss: 2.7187
2023-07-01 23:15:25 - train: epoch 0044, iter [00200, 00390], lr: 0.100000, loss: 2.8179
2023-07-01 23:15:26 - train: epoch 0044, iter [00250, 00390], lr: 0.100000, loss: 3.1217
2023-07-01 23:15:28 - train: epoch 0044, iter [00300, 00390], lr: 0.100000, loss: 2.7657
2023-07-01 23:15:29 - train: epoch 0044, iter [00350, 00390], lr: 0.100000, loss: 2.6955
2023-07-01 23:15:30 - train: epoch 044, train_loss: 2.8852
2023-07-01 23:15:32 - eval: epoch: 044, acc1: 28.330%, acc5: 57.320%, test_loss: 2.9005, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:15:34 - until epoch: 044, best_acc1: 29.230%
2023-07-01 23:15:34 - epoch 045 lr: 0.100000
2023-07-01 23:15:36 - train: epoch 0045, iter [00050, 00390], lr: 0.100000, loss: 2.8482
2023-07-01 23:15:37 - train: epoch 0045, iter [00100, 00390], lr: 0.100000, loss: 3.0681
2023-07-01 23:15:39 - train: epoch 0045, iter [00150, 00390], lr: 0.100000, loss: 2.8369
2023-07-01 23:15:40 - train: epoch 0045, iter [00200, 00390], lr: 0.100000, loss: 2.9151
2023-07-01 23:15:42 - train: epoch 0045, iter [00250, 00390], lr: 0.100000, loss: 2.8555
2023-07-01 23:15:43 - train: epoch 0045, iter [00300, 00390], lr: 0.100000, loss: 2.8280
2023-07-01 23:15:45 - train: epoch 0045, iter [00350, 00390], lr: 0.100000, loss: 3.0571
2023-07-01 23:15:46 - train: epoch 045, train_loss: 2.8766
2023-07-01 23:15:47 - eval: epoch: 045, acc1: 28.330%, acc5: 59.060%, test_loss: 2.8480, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:15:48 - until epoch: 045, best_acc1: 29.230%
2023-07-01 23:15:48 - epoch 046 lr: 0.100000
2023-07-01 23:15:50 - train: epoch 0046, iter [00050, 00390], lr: 0.100000, loss: 3.1522
2023-07-01 23:15:51 - train: epoch 0046, iter [00100, 00390], lr: 0.100000, loss: 2.8698
2023-07-01 23:15:53 - train: epoch 0046, iter [00150, 00390], lr: 0.100000, loss: 2.6419
2023-07-01 23:15:54 - train: epoch 0046, iter [00200, 00390], lr: 0.100000, loss: 2.6186
2023-07-01 23:15:56 - train: epoch 0046, iter [00250, 00390], lr: 0.100000, loss: 2.8404
2023-07-01 23:15:57 - train: epoch 0046, iter [00300, 00390], lr: 0.100000, loss: 2.7723
2023-07-01 23:15:58 - train: epoch 0046, iter [00350, 00390], lr: 0.100000, loss: 2.7285
2023-07-01 23:15:59 - train: epoch 046, train_loss: 2.8649
2023-07-01 23:16:01 - eval: epoch: 046, acc1: 28.830%, acc5: 58.190%, test_loss: 2.8755, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:16:01 - until epoch: 046, best_acc1: 29.230%
2023-07-01 23:16:01 - epoch 047 lr: 0.100000
2023-07-01 23:16:04 - train: epoch 0047, iter [00050, 00390], lr: 0.100000, loss: 2.9204
2023-07-01 23:16:05 - train: epoch 0047, iter [00100, 00390], lr: 0.100000, loss: 2.8770
2023-07-01 23:16:07 - train: epoch 0047, iter [00150, 00390], lr: 0.100000, loss: 2.6640
2023-07-01 23:16:08 - train: epoch 0047, iter [00200, 00390], lr: 0.100000, loss: 2.8859
2023-07-01 23:16:10 - train: epoch 0047, iter [00250, 00390], lr: 0.100000, loss: 2.8662
2023-07-01 23:16:11 - train: epoch 0047, iter [00300, 00390], lr: 0.100000, loss: 2.4412
2023-07-01 23:16:13 - train: epoch 0047, iter [00350, 00390], lr: 0.100000, loss: 2.8695
2023-07-01 23:16:14 - train: epoch 047, train_loss: 2.8580
2023-07-01 23:16:16 - eval: epoch: 047, acc1: 29.370%, acc5: 59.750%, test_loss: 2.8302, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:16:16 - until epoch: 047, best_acc1: 29.370%
2023-07-01 23:16:16 - epoch 048 lr: 0.100000
2023-07-01 23:16:19 - train: epoch 0048, iter [00050, 00390], lr: 0.100000, loss: 2.7800
2023-07-01 23:16:20 - train: epoch 0048, iter [00100, 00390], lr: 0.100000, loss: 2.6364
2023-07-01 23:16:22 - train: epoch 0048, iter [00150, 00390], lr: 0.100000, loss: 2.7601
2023-07-01 23:16:23 - train: epoch 0048, iter [00200, 00390], lr: 0.100000, loss: 3.0347
2023-07-01 23:16:24 - train: epoch 0048, iter [00250, 00390], lr: 0.100000, loss: 2.9277
2023-07-01 23:16:26 - train: epoch 0048, iter [00300, 00390], lr: 0.100000, loss: 2.7126
2023-07-01 23:16:27 - train: epoch 0048, iter [00350, 00390], lr: 0.100000, loss: 3.0589
2023-07-01 23:16:28 - train: epoch 048, train_loss: 2.8523
2023-07-01 23:16:30 - eval: epoch: 048, acc1: 28.430%, acc5: 58.190%, test_loss: 2.8767, per_image_load_time: 0.095ms, per_image_inference_time: 0.055ms
2023-07-01 23:16:30 - until epoch: 048, best_acc1: 29.370%
2023-07-01 23:16:30 - epoch 049 lr: 0.100000
2023-07-01 23:16:33 - train: epoch 0049, iter [00050, 00390], lr: 0.100000, loss: 3.0822
2023-07-01 23:16:34 - train: epoch 0049, iter [00100, 00390], lr: 0.100000, loss: 2.7087
2023-07-01 23:16:35 - train: epoch 0049, iter [00150, 00390], lr: 0.100000, loss: 2.8487
2023-07-01 23:16:37 - train: epoch 0049, iter [00200, 00390], lr: 0.100000, loss: 2.6321
2023-07-01 23:16:38 - train: epoch 0049, iter [00250, 00390], lr: 0.100000, loss: 2.7899
2023-07-01 23:16:39 - train: epoch 0049, iter [00300, 00390], lr: 0.100000, loss: 2.7312
2023-07-01 23:16:41 - train: epoch 0049, iter [00350, 00390], lr: 0.100000, loss: 2.8928
2023-07-01 23:16:42 - train: epoch 049, train_loss: 2.8541
2023-07-01 23:16:44 - eval: epoch: 049, acc1: 28.840%, acc5: 58.250%, test_loss: 2.8772, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:16:44 - until epoch: 049, best_acc1: 29.370%
2023-07-01 23:16:44 - epoch 050 lr: 0.100000
2023-07-01 23:16:46 - train: epoch 0050, iter [00050, 00390], lr: 0.100000, loss: 2.9120
2023-07-01 23:16:48 - train: epoch 0050, iter [00100, 00390], lr: 0.100000, loss: 2.7004
2023-07-01 23:16:49 - train: epoch 0050, iter [00150, 00390], lr: 0.100000, loss: 2.6764
2023-07-01 23:16:51 - train: epoch 0050, iter [00200, 00390], lr: 0.100000, loss: 2.7887
2023-07-01 23:16:52 - train: epoch 0050, iter [00250, 00390], lr: 0.100000, loss: 2.8005
2023-07-01 23:16:54 - train: epoch 0050, iter [00300, 00390], lr: 0.100000, loss: 3.0398
2023-07-01 23:16:55 - train: epoch 0050, iter [00350, 00390], lr: 0.100000, loss: 2.9286
2023-07-01 23:16:56 - train: epoch 050, train_loss: 2.8414
2023-07-01 23:16:58 - eval: epoch: 050, acc1: 29.420%, acc5: 59.230%, test_loss: 2.8395, per_image_load_time: 0.094ms, per_image_inference_time: 0.080ms
2023-07-01 23:16:59 - until epoch: 050, best_acc1: 29.420%
2023-07-01 23:16:59 - epoch 051 lr: 0.100000
2023-07-01 23:17:02 - train: epoch 0051, iter [00050, 00390], lr: 0.100000, loss: 3.1215
2023-07-01 23:17:03 - train: epoch 0051, iter [00100, 00390], lr: 0.100000, loss: 2.9247
2023-07-01 23:17:05 - train: epoch 0051, iter [00150, 00390], lr: 0.100000, loss: 2.5405
2023-07-01 23:17:06 - train: epoch 0051, iter [00200, 00390], lr: 0.100000, loss: 2.7934
2023-07-01 23:17:07 - train: epoch 0051, iter [00250, 00390], lr: 0.100000, loss: 2.8067
2023-07-01 23:17:09 - train: epoch 0051, iter [00300, 00390], lr: 0.100000, loss: 2.5522
2023-07-01 23:17:10 - train: epoch 0051, iter [00350, 00390], lr: 0.100000, loss: 2.8907
2023-07-01 23:17:11 - train: epoch 051, train_loss: 2.8332
2023-07-01 23:17:13 - eval: epoch: 051, acc1: 29.840%, acc5: 59.680%, test_loss: 2.7997, per_image_load_time: 0.094ms, per_image_inference_time: 0.056ms
2023-07-01 23:17:15 - until epoch: 051, best_acc1: 29.840%
2023-07-01 23:17:15 - epoch 052 lr: 0.100000
2023-07-01 23:17:17 - train: epoch 0052, iter [00050, 00390], lr: 0.100000, loss: 3.0010
2023-07-01 23:17:18 - train: epoch 0052, iter [00100, 00390], lr: 0.100000, loss: 3.0021
2023-07-01 23:17:20 - train: epoch 0052, iter [00150, 00390], lr: 0.100000, loss: 3.2141
2023-07-01 23:17:21 - train: epoch 0052, iter [00200, 00390], lr: 0.100000, loss: 2.8144
2023-07-01 23:17:23 - train: epoch 0052, iter [00250, 00390], lr: 0.100000, loss: 2.7510
2023-07-01 23:17:24 - train: epoch 0052, iter [00300, 00390], lr: 0.100000, loss: 2.8403
2023-07-01 23:17:25 - train: epoch 0052, iter [00350, 00390], lr: 0.100000, loss: 2.9783
2023-07-01 23:17:26 - train: epoch 052, train_loss: 2.8374
2023-07-01 23:17:28 - eval: epoch: 052, acc1: 29.060%, acc5: 59.430%, test_loss: 2.8390, per_image_load_time: 0.093ms, per_image_inference_time: 0.054ms
2023-07-01 23:17:29 - until epoch: 052, best_acc1: 29.840%
2023-07-01 23:17:29 - epoch 053 lr: 0.100000
2023-07-01 23:17:31 - train: epoch 0053, iter [00050, 00390], lr: 0.100000, loss: 2.6352
2023-07-01 23:17:33 - train: epoch 0053, iter [00100, 00390], lr: 0.100000, loss: 2.5794
2023-07-01 23:17:34 - train: epoch 0053, iter [00150, 00390], lr: 0.100000, loss: 2.7620
2023-07-01 23:17:35 - train: epoch 0053, iter [00200, 00390], lr: 0.100000, loss: 2.7886
2023-07-01 23:17:37 - train: epoch 0053, iter [00250, 00390], lr: 0.100000, loss: 2.7050
2023-07-01 23:17:38 - train: epoch 0053, iter [00300, 00390], lr: 0.100000, loss: 2.6054
2023-07-01 23:17:40 - train: epoch 0053, iter [00350, 00390], lr: 0.100000, loss: 2.6421
2023-07-01 23:17:41 - train: epoch 053, train_loss: 2.8214
2023-07-01 23:17:42 - eval: epoch: 053, acc1: 29.440%, acc5: 59.570%, test_loss: 2.8314, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:17:43 - until epoch: 053, best_acc1: 29.840%
2023-07-01 23:17:43 - epoch 054 lr: 0.100000
2023-07-01 23:17:45 - train: epoch 0054, iter [00050, 00390], lr: 0.100000, loss: 3.0703
2023-07-01 23:17:47 - train: epoch 0054, iter [00100, 00390], lr: 0.100000, loss: 2.7908
2023-07-01 23:17:48 - train: epoch 0054, iter [00150, 00390], lr: 0.100000, loss: 2.6799
2023-07-01 23:17:49 - train: epoch 0054, iter [00200, 00390], lr: 0.100000, loss: 3.1638
2023-07-01 23:17:51 - train: epoch 0054, iter [00250, 00390], lr: 0.100000, loss: 2.8987
2023-07-01 23:17:52 - train: epoch 0054, iter [00300, 00390], lr: 0.100000, loss: 2.9079
2023-07-01 23:17:53 - train: epoch 0054, iter [00350, 00390], lr: 0.100000, loss: 2.5329
2023-07-01 23:17:55 - train: epoch 054, train_loss: 2.8132
2023-07-01 23:17:56 - eval: epoch: 054, acc1: 29.500%, acc5: 59.610%, test_loss: 2.8269, per_image_load_time: 0.094ms, per_image_inference_time: 0.055ms
2023-07-01 23:17:57 - until epoch: 054, best_acc1: 29.840%
2023-07-01 23:17:57 - epoch 055 lr: 0.100000
2023-07-01 23:17:59 - train: epoch 0055, iter [00050, 00390], lr: 0.100000, loss: 3.0075
2023-07-01 23:18:01 - train: epoch 0055, iter [00100, 00390], lr: 0.100000, loss: 2.9740
2023-07-01 23:18:02 - train: epoch 0055, iter [00150, 00390], lr: 0.100000, loss: 2.8426
2023-07-01 23:18:03 - train: epoch 0055, iter [00200, 00390], lr: 0.100000, loss: 2.9709
2023-07-01 23:18:05 - train: epoch 0055, iter [00250, 00390], lr: 0.100000, loss: 2.8179
2023-07-01 23:18:06 - train: epoch 0055, iter [00300, 00390], lr: 0.100000, loss: 2.5853
2023-07-01 23:18:08 - train: epoch 0055, iter [00350, 00390], lr: 0.100000, loss: 2.7958
2023-07-01 23:18:09 - train: epoch 055, train_loss: 2.8119
2023-07-01 23:18:10 - eval: epoch: 055, acc1: 30.660%, acc5: 60.140%, test_loss: 2.7831, per_image_load_time: 0.097ms, per_image_inference_time: 0.053ms
2023-07-01 23:18:11 - until epoch: 055, best_acc1: 30.660%
2023-07-01 23:18:11 - epoch 056 lr: 0.100000
2023-07-01 23:18:14 - train: epoch 0056, iter [00050, 00390], lr: 0.100000, loss: 3.0751
2023-07-01 23:18:15 - train: epoch 0056, iter [00100, 00390], lr: 0.100000, loss: 2.6338
2023-07-01 23:18:17 - train: epoch 0056, iter [00150, 00390], lr: 0.100000, loss: 2.5851
2023-07-01 23:18:18 - train: epoch 0056, iter [00200, 00390], lr: 0.100000, loss: 2.6207
2023-07-01 23:18:19 - train: epoch 0056, iter [00250, 00390], lr: 0.100000, loss: 2.6337
2023-07-01 23:18:21 - train: epoch 0056, iter [00300, 00390], lr: 0.100000, loss: 3.1323
2023-07-01 23:18:22 - train: epoch 0056, iter [00350, 00390], lr: 0.100000, loss: 2.4980
2023-07-01 23:18:23 - train: epoch 056, train_loss: 2.8009
2023-07-01 23:18:25 - eval: epoch: 056, acc1: 30.280%, acc5: 60.380%, test_loss: 2.7917, per_image_load_time: 0.092ms, per_image_inference_time: 0.054ms
2023-07-01 23:18:25 - until epoch: 056, best_acc1: 30.660%
2023-07-01 23:18:25 - epoch 057 lr: 0.100000
2023-07-01 23:18:28 - train: epoch 0057, iter [00050, 00390], lr: 0.100000, loss: 3.0528
2023-07-01 23:18:29 - train: epoch 0057, iter [00100, 00390], lr: 0.100000, loss: 2.9125
2023-07-01 23:18:31 - train: epoch 0057, iter [00150, 00390], lr: 0.100000, loss: 2.5737
2023-07-01 23:18:32 - train: epoch 0057, iter [00200, 00390], lr: 0.100000, loss: 2.9440
2023-07-01 23:18:34 - train: epoch 0057, iter [00250, 00390], lr: 0.100000, loss: 2.8786
2023-07-01 23:18:35 - train: epoch 0057, iter [00300, 00390], lr: 0.100000, loss: 2.8592
2023-07-01 23:18:37 - train: epoch 0057, iter [00350, 00390], lr: 0.100000, loss: 2.7845
2023-07-01 23:18:38 - train: epoch 057, train_loss: 2.7958
2023-07-01 23:18:39 - eval: epoch: 057, acc1: 29.530%, acc5: 60.310%, test_loss: 2.8214, per_image_load_time: 0.093ms, per_image_inference_time: 0.054ms
2023-07-01 23:18:40 - until epoch: 057, best_acc1: 30.660%
2023-07-01 23:18:40 - epoch 058 lr: 0.100000
2023-07-01 23:18:42 - train: epoch 0058, iter [00050, 00390], lr: 0.100000, loss: 2.7771
2023-07-01 23:18:44 - train: epoch 0058, iter [00100, 00390], lr: 0.100000, loss: 2.9410
2023-07-01 23:18:45 - train: epoch 0058, iter [00150, 00390], lr: 0.100000, loss: 2.6062
2023-07-01 23:18:46 - train: epoch 0058, iter [00200, 00390], lr: 0.100000, loss: 2.9805
2023-07-01 23:18:48 - train: epoch 0058, iter [00250, 00390], lr: 0.100000, loss: 2.9593
2023-07-01 23:18:49 - train: epoch 0058, iter [00300, 00390], lr: 0.100000, loss: 2.9289
2023-07-01 23:18:50 - train: epoch 0058, iter [00350, 00390], lr: 0.100000, loss: 2.8674
2023-07-01 23:18:52 - train: epoch 058, train_loss: 2.7892
2023-07-01 23:18:53 - eval: epoch: 058, acc1: 29.700%, acc5: 59.440%, test_loss: 2.8448, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:18:54 - until epoch: 058, best_acc1: 30.660%
2023-07-01 23:18:54 - epoch 059 lr: 0.100000
2023-07-01 23:18:56 - train: epoch 0059, iter [00050, 00390], lr: 0.100000, loss: 2.7297
2023-07-01 23:18:58 - train: epoch 0059, iter [00100, 00390], lr: 0.100000, loss: 2.7751
2023-07-01 23:18:59 - train: epoch 0059, iter [00150, 00390], lr: 0.100000, loss: 2.8491
2023-07-01 23:19:01 - train: epoch 0059, iter [00200, 00390], lr: 0.100000, loss: 2.8730
2023-07-01 23:19:02 - train: epoch 0059, iter [00250, 00390], lr: 0.100000, loss: 3.0205
2023-07-01 23:19:04 - train: epoch 0059, iter [00300, 00390], lr: 0.100000, loss: 2.7380
2023-07-01 23:19:05 - train: epoch 0059, iter [00350, 00390], lr: 0.100000, loss: 2.9799
2023-07-01 23:19:06 - train: epoch 059, train_loss: 2.7790
2023-07-01 23:19:08 - eval: epoch: 059, acc1: 29.740%, acc5: 59.670%, test_loss: 2.8248, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:19:08 - until epoch: 059, best_acc1: 30.660%
2023-07-01 23:19:08 - epoch 060 lr: 0.100000
2023-07-01 23:19:11 - train: epoch 0060, iter [00050, 00390], lr: 0.100000, loss: 3.0077
2023-07-01 23:19:12 - train: epoch 0060, iter [00100, 00390], lr: 0.100000, loss: 2.6834
2023-07-01 23:19:14 - train: epoch 0060, iter [00150, 00390], lr: 0.100000, loss: 2.5622
2023-07-01 23:19:15 - train: epoch 0060, iter [00200, 00390], lr: 0.100000, loss: 2.5586
2023-07-01 23:19:16 - train: epoch 0060, iter [00250, 00390], lr: 0.100000, loss: 2.7091
2023-07-01 23:19:18 - train: epoch 0060, iter [00300, 00390], lr: 0.100000, loss: 2.5236
2023-07-01 23:19:19 - train: epoch 0060, iter [00350, 00390], lr: 0.100000, loss: 2.6514
2023-07-01 23:19:20 - train: epoch 060, train_loss: 2.7781
2023-07-01 23:19:22 - eval: epoch: 060, acc1: 30.660%, acc5: 61.230%, test_loss: 2.7695, per_image_load_time: 0.092ms, per_image_inference_time: 0.054ms
2023-07-01 23:19:22 - until epoch: 060, best_acc1: 30.660%
2023-07-01 23:19:22 - epoch 061 lr: 0.020000
2023-07-01 23:19:25 - train: epoch 0061, iter [00050, 00390], lr: 0.020000, loss: 2.3284
2023-07-01 23:19:26 - train: epoch 0061, iter [00100, 00390], lr: 0.020000, loss: 2.4134
2023-07-01 23:19:28 - train: epoch 0061, iter [00150, 00390], lr: 0.020000, loss: 2.4860
2023-07-01 23:19:29 - train: epoch 0061, iter [00200, 00390], lr: 0.020000, loss: 2.5137
2023-07-01 23:19:30 - train: epoch 0061, iter [00250, 00390], lr: 0.020000, loss: 2.1629
2023-07-01 23:19:32 - train: epoch 0061, iter [00300, 00390], lr: 0.020000, loss: 2.2238
2023-07-01 23:19:33 - train: epoch 0061, iter [00350, 00390], lr: 0.020000, loss: 2.3259
2023-07-01 23:19:34 - train: epoch 061, train_loss: 2.4370
2023-07-01 23:19:36 - eval: epoch: 061, acc1: 37.280%, acc5: 66.830%, test_loss: 2.4935, per_image_load_time: 0.098ms, per_image_inference_time: 0.063ms
2023-07-01 23:19:37 - until epoch: 061, best_acc1: 37.280%
2023-07-01 23:19:37 - epoch 062 lr: 0.020000
2023-07-01 23:19:39 - train: epoch 0062, iter [00050, 00390], lr: 0.020000, loss: 1.9584
2023-07-01 23:19:41 - train: epoch 0062, iter [00100, 00390], lr: 0.020000, loss: 2.2409
2023-07-01 23:19:42 - train: epoch 0062, iter [00150, 00390], lr: 0.020000, loss: 2.6222
2023-07-01 23:19:43 - train: epoch 0062, iter [00200, 00390], lr: 0.020000, loss: 2.0417
2023-07-01 23:19:45 - train: epoch 0062, iter [00250, 00390], lr: 0.020000, loss: 2.5398
2023-07-01 23:19:46 - train: epoch 0062, iter [00300, 00390], lr: 0.020000, loss: 2.1897
2023-07-01 23:19:47 - train: epoch 0062, iter [00350, 00390], lr: 0.020000, loss: 2.5032
2023-07-01 23:19:49 - train: epoch 062, train_loss: 2.3226
2023-07-01 23:19:50 - eval: epoch: 062, acc1: 37.910%, acc5: 67.270%, test_loss: 2.4743, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:19:51 - until epoch: 062, best_acc1: 37.910%
2023-07-01 23:19:51 - epoch 063 lr: 0.020000
2023-07-01 23:19:53 - train: epoch 0063, iter [00050, 00390], lr: 0.020000, loss: 2.2489
2023-07-01 23:19:55 - train: epoch 0063, iter [00100, 00390], lr: 0.020000, loss: 2.3639
2023-07-01 23:19:56 - train: epoch 0063, iter [00150, 00390], lr: 0.020000, loss: 2.2071
2023-07-01 23:19:57 - train: epoch 0063, iter [00200, 00390], lr: 0.020000, loss: 2.2269
2023-07-01 23:19:59 - train: epoch 0063, iter [00250, 00390], lr: 0.020000, loss: 2.4735
2023-07-01 23:20:00 - train: epoch 0063, iter [00300, 00390], lr: 0.020000, loss: 2.3236
2023-07-01 23:20:02 - train: epoch 0063, iter [00350, 00390], lr: 0.020000, loss: 2.0978
2023-07-01 23:20:03 - train: epoch 063, train_loss: 2.2767
2023-07-01 23:20:04 - eval: epoch: 063, acc1: 38.140%, acc5: 67.390%, test_loss: 2.4730, per_image_load_time: 0.094ms, per_image_inference_time: 0.055ms
2023-07-01 23:20:05 - until epoch: 063, best_acc1: 38.140%
2023-07-01 23:20:05 - epoch 064 lr: 0.020000
2023-07-01 23:20:08 - train: epoch 0064, iter [00050, 00390], lr: 0.020000, loss: 2.1990
2023-07-01 23:20:09 - train: epoch 0064, iter [00100, 00390], lr: 0.020000, loss: 2.1983
2023-07-01 23:20:10 - train: epoch 0064, iter [00150, 00390], lr: 0.020000, loss: 2.4067
2023-07-01 23:20:12 - train: epoch 0064, iter [00200, 00390], lr: 0.020000, loss: 2.0194
2023-07-01 23:20:13 - train: epoch 0064, iter [00250, 00390], lr: 0.020000, loss: 2.4632
2023-07-01 23:20:15 - train: epoch 0064, iter [00300, 00390], lr: 0.020000, loss: 2.0446
2023-07-01 23:20:16 - train: epoch 0064, iter [00350, 00390], lr: 0.020000, loss: 2.1234
2023-07-01 23:20:17 - train: epoch 064, train_loss: 2.2575
2023-07-01 23:20:19 - eval: epoch: 064, acc1: 37.980%, acc5: 67.990%, test_loss: 2.4599, per_image_load_time: 0.093ms, per_image_inference_time: 0.054ms
2023-07-01 23:20:19 - until epoch: 064, best_acc1: 38.140%
2023-07-01 23:20:19 - epoch 065 lr: 0.020000
2023-07-01 23:20:22 - train: epoch 0065, iter [00050, 00390], lr: 0.020000, loss: 2.1556
2023-07-01 23:20:23 - train: epoch 0065, iter [00100, 00390], lr: 0.020000, loss: 2.1634
2023-07-01 23:20:25 - train: epoch 0065, iter [00150, 00390], lr: 0.020000, loss: 2.3647
2023-07-01 23:20:26 - train: epoch 0065, iter [00200, 00390], lr: 0.020000, loss: 2.4031
2023-07-01 23:20:27 - train: epoch 0065, iter [00250, 00390], lr: 0.020000, loss: 2.1792
2023-07-01 23:20:29 - train: epoch 0065, iter [00300, 00390], lr: 0.020000, loss: 2.2887
2023-07-01 23:20:30 - train: epoch 0065, iter [00350, 00390], lr: 0.020000, loss: 2.3710
2023-07-01 23:20:31 - train: epoch 065, train_loss: 2.2267
2023-07-01 23:20:33 - eval: epoch: 065, acc1: 37.190%, acc5: 67.860%, test_loss: 2.4719, per_image_load_time: 0.094ms, per_image_inference_time: 0.055ms
2023-07-01 23:20:34 - until epoch: 065, best_acc1: 38.140%
2023-07-01 23:20:34 - epoch 066 lr: 0.020000
2023-07-01 23:20:36 - train: epoch 0066, iter [00050, 00390], lr: 0.020000, loss: 1.8578
2023-07-01 23:20:38 - train: epoch 0066, iter [00100, 00390], lr: 0.020000, loss: 2.0844
2023-07-01 23:20:39 - train: epoch 0066, iter [00150, 00390], lr: 0.020000, loss: 2.0370
2023-07-01 23:20:40 - train: epoch 0066, iter [00200, 00390], lr: 0.020000, loss: 2.3777
2023-07-01 23:20:42 - train: epoch 0066, iter [00250, 00390], lr: 0.020000, loss: 2.3638
2023-07-01 23:20:43 - train: epoch 0066, iter [00300, 00390], lr: 0.020000, loss: 1.9754
2023-07-01 23:20:44 - train: epoch 0066, iter [00350, 00390], lr: 0.020000, loss: 2.2861
2023-07-01 23:20:46 - train: epoch 066, train_loss: 2.2155
2023-07-01 23:20:47 - eval: epoch: 066, acc1: 37.600%, acc5: 68.070%, test_loss: 2.4655, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:20:48 - until epoch: 066, best_acc1: 38.140%
2023-07-01 23:20:48 - epoch 067 lr: 0.020000
2023-07-01 23:20:50 - train: epoch 0067, iter [00050, 00390], lr: 0.020000, loss: 2.1913
2023-07-01 23:20:52 - train: epoch 0067, iter [00100, 00390], lr: 0.020000, loss: 1.9990
2023-07-01 23:20:53 - train: epoch 0067, iter [00150, 00390], lr: 0.020000, loss: 2.0106
2023-07-01 23:20:54 - train: epoch 0067, iter [00200, 00390], lr: 0.020000, loss: 2.2838
2023-07-01 23:20:56 - train: epoch 0067, iter [00250, 00390], lr: 0.020000, loss: 2.0917
2023-07-01 23:20:57 - train: epoch 0067, iter [00300, 00390], lr: 0.020000, loss: 2.0673
2023-07-01 23:20:59 - train: epoch 0067, iter [00350, 00390], lr: 0.020000, loss: 2.0264
2023-07-01 23:21:00 - train: epoch 067, train_loss: 2.2053
2023-07-01 23:21:01 - eval: epoch: 067, acc1: 37.550%, acc5: 67.890%, test_loss: 2.4787, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:21:02 - until epoch: 067, best_acc1: 38.140%
2023-07-01 23:21:02 - epoch 068 lr: 0.020000
2023-07-01 23:21:04 - train: epoch 0068, iter [00050, 00390], lr: 0.020000, loss: 1.9545
2023-07-01 23:21:06 - train: epoch 0068, iter [00100, 00390], lr: 0.020000, loss: 1.9942
2023-07-01 23:21:07 - train: epoch 0068, iter [00150, 00390], lr: 0.020000, loss: 2.2064
2023-07-01 23:21:08 - train: epoch 0068, iter [00200, 00390], lr: 0.020000, loss: 2.2633
2023-07-01 23:21:10 - train: epoch 0068, iter [00250, 00390], lr: 0.020000, loss: 2.1850
2023-07-01 23:21:11 - train: epoch 0068, iter [00300, 00390], lr: 0.020000, loss: 2.1789
2023-07-01 23:21:12 - train: epoch 0068, iter [00350, 00390], lr: 0.020000, loss: 2.2556
2023-07-01 23:21:14 - train: epoch 068, train_loss: 2.1894
2023-07-01 23:21:15 - eval: epoch: 068, acc1: 37.650%, acc5: 67.490%, test_loss: 2.4879, per_image_load_time: 0.093ms, per_image_inference_time: 0.054ms
2023-07-01 23:21:16 - until epoch: 068, best_acc1: 38.140%
2023-07-01 23:21:16 - epoch 069 lr: 0.020000
2023-07-01 23:21:18 - train: epoch 0069, iter [00050, 00390], lr: 0.020000, loss: 2.3457
2023-07-01 23:21:20 - train: epoch 0069, iter [00100, 00390], lr: 0.020000, loss: 2.0484
2023-07-01 23:21:21 - train: epoch 0069, iter [00150, 00390], lr: 0.020000, loss: 2.3579
2023-07-01 23:21:22 - train: epoch 0069, iter [00200, 00390], lr: 0.020000, loss: 2.3501
2023-07-01 23:21:24 - train: epoch 0069, iter [00250, 00390], lr: 0.020000, loss: 2.4868
2023-07-01 23:21:25 - train: epoch 0069, iter [00300, 00390], lr: 0.020000, loss: 2.2714
2023-07-01 23:21:26 - train: epoch 0069, iter [00350, 00390], lr: 0.020000, loss: 2.1158
2023-07-01 23:21:28 - train: epoch 069, train_loss: 2.1836
2023-07-01 23:21:29 - eval: epoch: 069, acc1: 36.940%, acc5: 67.080%, test_loss: 2.5040, per_image_load_time: 0.095ms, per_image_inference_time: 0.053ms
2023-07-01 23:21:30 - until epoch: 069, best_acc1: 38.140%
2023-07-01 23:21:30 - epoch 070 lr: 0.020000
2023-07-01 23:21:32 - train: epoch 0070, iter [00050, 00390], lr: 0.020000, loss: 2.0439
2023-07-01 23:21:33 - train: epoch 0070, iter [00100, 00390], lr: 0.020000, loss: 1.9278
2023-07-01 23:21:35 - train: epoch 0070, iter [00150, 00390], lr: 0.020000, loss: 2.4816
2023-07-01 23:21:36 - train: epoch 0070, iter [00200, 00390], lr: 0.020000, loss: 2.0270
2023-07-01 23:21:38 - train: epoch 0070, iter [00250, 00390], lr: 0.020000, loss: 1.7487
2023-07-01 23:21:39 - train: epoch 0070, iter [00300, 00390], lr: 0.020000, loss: 2.0649
2023-07-01 23:21:40 - train: epoch 0070, iter [00350, 00390], lr: 0.020000, loss: 2.3028
2023-07-01 23:21:41 - train: epoch 070, train_loss: 2.1656
2023-07-01 23:21:43 - eval: epoch: 070, acc1: 37.440%, acc5: 67.850%, test_loss: 2.4881, per_image_load_time: 0.093ms, per_image_inference_time: 0.054ms
2023-07-01 23:21:43 - until epoch: 070, best_acc1: 38.140%
2023-07-01 23:21:43 - epoch 071 lr: 0.020000
2023-07-01 23:21:46 - train: epoch 0071, iter [00050, 00390], lr: 0.020000, loss: 2.0347
2023-07-01 23:21:47 - train: epoch 0071, iter [00100, 00390], lr: 0.020000, loss: 1.9416
2023-07-01 23:21:48 - train: epoch 0071, iter [00150, 00390], lr: 0.020000, loss: 2.0235
2023-07-01 23:21:50 - train: epoch 0071, iter [00200, 00390], lr: 0.020000, loss: 2.2199
2023-07-01 23:21:51 - train: epoch 0071, iter [00250, 00390], lr: 0.020000, loss: 2.2734
2023-07-01 23:21:53 - train: epoch 0071, iter [00300, 00390], lr: 0.020000, loss: 2.5577
2023-07-01 23:21:54 - train: epoch 0071, iter [00350, 00390], lr: 0.020000, loss: 2.1624
2023-07-01 23:21:55 - train: epoch 071, train_loss: 2.1593
2023-07-01 23:21:57 - eval: epoch: 071, acc1: 36.230%, acc5: 66.450%, test_loss: 2.5432, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:21:57 - until epoch: 071, best_acc1: 38.140%
2023-07-01 23:21:57 - epoch 072 lr: 0.020000
2023-07-01 23:22:00 - train: epoch 0072, iter [00050, 00390], lr: 0.020000, loss: 1.9013
2023-07-01 23:22:01 - train: epoch 0072, iter [00100, 00390], lr: 0.020000, loss: 2.0405
2023-07-01 23:22:02 - train: epoch 0072, iter [00150, 00390], lr: 0.020000, loss: 2.1422
2023-07-01 23:22:04 - train: epoch 0072, iter [00200, 00390], lr: 0.020000, loss: 1.8762
2023-07-01 23:22:05 - train: epoch 0072, iter [00250, 00390], lr: 0.020000, loss: 1.9248
2023-07-01 23:22:06 - train: epoch 0072, iter [00300, 00390], lr: 0.020000, loss: 1.9077
2023-07-01 23:22:08 - train: epoch 0072, iter [00350, 00390], lr: 0.020000, loss: 2.2471
2023-07-01 23:22:09 - train: epoch 072, train_loss: 2.1394
2023-07-01 23:22:11 - eval: epoch: 072, acc1: 37.160%, acc5: 67.370%, test_loss: 2.5060, per_image_load_time: 0.092ms, per_image_inference_time: 0.054ms
2023-07-01 23:22:11 - until epoch: 072, best_acc1: 38.140%
2023-07-01 23:22:11 - epoch 073 lr: 0.020000
2023-07-01 23:22:13 - train: epoch 0073, iter [00050, 00390], lr: 0.020000, loss: 2.1181
2023-07-01 23:22:15 - train: epoch 0073, iter [00100, 00390], lr: 0.020000, loss: 1.9561
2023-07-01 23:22:16 - train: epoch 0073, iter [00150, 00390], lr: 0.020000, loss: 2.2404
2023-07-01 23:22:18 - train: epoch 0073, iter [00200, 00390], lr: 0.020000, loss: 2.1848
2023-07-01 23:22:19 - train: epoch 0073, iter [00250, 00390], lr: 0.020000, loss: 2.3671
2023-07-01 23:22:21 - train: epoch 0073, iter [00300, 00390], lr: 0.020000, loss: 2.0918
2023-07-01 23:22:23 - train: epoch 0073, iter [00350, 00390], lr: 0.020000, loss: 2.0534
2023-07-01 23:22:24 - train: epoch 073, train_loss: 2.1321
2023-07-01 23:22:26 - eval: epoch: 073, acc1: 37.460%, acc5: 67.380%, test_loss: 2.4955, per_image_load_time: 0.098ms, per_image_inference_time: 0.059ms
2023-07-01 23:22:26 - until epoch: 073, best_acc1: 38.140%
2023-07-01 23:22:26 - epoch 074 lr: 0.020000
2023-07-01 23:22:28 - train: epoch 0074, iter [00050, 00390], lr: 0.020000, loss: 2.3421
2023-07-01 23:22:30 - train: epoch 0074, iter [00100, 00390], lr: 0.020000, loss: 2.2020
2023-07-01 23:22:31 - train: epoch 0074, iter [00150, 00390], lr: 0.020000, loss: 2.0335
2023-07-01 23:22:33 - train: epoch 0074, iter [00200, 00390], lr: 0.020000, loss: 2.1051
2023-07-01 23:22:34 - train: epoch 0074, iter [00250, 00390], lr: 0.020000, loss: 2.0232
2023-07-01 23:22:35 - train: epoch 0074, iter [00300, 00390], lr: 0.020000, loss: 2.0566
2023-07-01 23:22:37 - train: epoch 0074, iter [00350, 00390], lr: 0.020000, loss: 2.2268
2023-07-01 23:22:38 - train: epoch 074, train_loss: 2.1220
2023-07-01 23:22:40 - eval: epoch: 074, acc1: 37.840%, acc5: 67.720%, test_loss: 2.4886, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:22:40 - until epoch: 074, best_acc1: 38.140%
2023-07-01 23:22:40 - epoch 075 lr: 0.020000
2023-07-01 23:22:43 - train: epoch 0075, iter [00050, 00390], lr: 0.020000, loss: 2.2061
2023-07-01 23:22:44 - train: epoch 0075, iter [00100, 00390], lr: 0.020000, loss: 2.3115
2023-07-01 23:22:46 - train: epoch 0075, iter [00150, 00390], lr: 0.020000, loss: 2.1556
2023-07-01 23:22:47 - train: epoch 0075, iter [00200, 00390], lr: 0.020000, loss: 2.1247
2023-07-01 23:22:48 - train: epoch 0075, iter [00250, 00390], lr: 0.020000, loss: 2.2085
2023-07-01 23:22:50 - train: epoch 0075, iter [00300, 00390], lr: 0.020000, loss: 2.0339
2023-07-01 23:22:51 - train: epoch 0075, iter [00350, 00390], lr: 0.020000, loss: 2.2676
2023-07-01 23:22:52 - train: epoch 075, train_loss: 2.1167
2023-07-01 23:22:54 - eval: epoch: 075, acc1: 37.130%, acc5: 67.220%, test_loss: 2.5172, per_image_load_time: 0.096ms, per_image_inference_time: 0.057ms
2023-07-01 23:22:54 - until epoch: 075, best_acc1: 38.140%
2023-07-01 23:22:54 - epoch 076 lr: 0.020000
2023-07-01 23:22:57 - train: epoch 0076, iter [00050, 00390], lr: 0.020000, loss: 2.0358
2023-07-01 23:22:58 - train: epoch 0076, iter [00100, 00390], lr: 0.020000, loss: 2.3316
2023-07-01 23:23:00 - train: epoch 0076, iter [00150, 00390], lr: 0.020000, loss: 2.1507
2023-07-01 23:23:01 - train: epoch 0076, iter [00200, 00390], lr: 0.020000, loss: 1.9741
2023-07-01 23:23:02 - train: epoch 0076, iter [00250, 00390], lr: 0.020000, loss: 2.0661
2023-07-01 23:23:04 - train: epoch 0076, iter [00300, 00390], lr: 0.020000, loss: 1.9027
2023-07-01 23:23:05 - train: epoch 0076, iter [00350, 00390], lr: 0.020000, loss: 2.2674
2023-07-01 23:23:06 - train: epoch 076, train_loss: 2.1014
2023-07-01 23:23:08 - eval: epoch: 076, acc1: 37.320%, acc5: 67.570%, test_loss: 2.5235, per_image_load_time: 0.097ms, per_image_inference_time: 0.054ms
2023-07-01 23:23:08 - until epoch: 076, best_acc1: 38.140%
2023-07-01 23:23:08 - epoch 077 lr: 0.020000
2023-07-01 23:23:11 - train: epoch 0077, iter [00050, 00390], lr: 0.020000, loss: 1.8960
2023-07-01 23:23:12 - train: epoch 0077, iter [00100, 00390], lr: 0.020000, loss: 1.8224
2023-07-01 23:23:14 - train: epoch 0077, iter [00150, 00390], lr: 0.020000, loss: 2.2402
2023-07-01 23:23:15 - train: epoch 0077, iter [00200, 00390], lr: 0.020000, loss: 2.1583
2023-07-01 23:23:16 - train: epoch 0077, iter [00250, 00390], lr: 0.020000, loss: 2.0759
2023-07-01 23:23:18 - train: epoch 0077, iter [00300, 00390], lr: 0.020000, loss: 2.2170
2023-07-01 23:23:19 - train: epoch 0077, iter [00350, 00390], lr: 0.020000, loss: 2.1924
2023-07-01 23:23:20 - train: epoch 077, train_loss: 2.0926
2023-07-01 23:23:22 - eval: epoch: 077, acc1: 37.440%, acc5: 67.000%, test_loss: 2.5121, per_image_load_time: 0.094ms, per_image_inference_time: 0.053ms
2023-07-01 23:23:22 - until epoch: 077, best_acc1: 38.140%
2023-07-01 23:23:22 - epoch 078 lr: 0.020000
2023-07-01 23:23:25 - train: epoch 0078, iter [00050, 00390], lr: 0.020000, loss: 1.8614
2023-07-01 23:23:26 - train: epoch 0078, iter [00100, 00390], lr: 0.020000, loss: 2.1642
2023-07-01 23:23:27 - train: epoch 0078, iter [00150, 00390], lr: 0.020000, loss: 2.2933
2023-07-01 23:23:29 - train: epoch 0078, iter [00200, 00390], lr: 0.020000, loss: 2.0408
2023-07-01 23:23:30 - train: epoch 0078, iter [00250, 00390], lr: 0.020000, loss: 2.3439
2023-07-01 23:23:31 - train: epoch 0078, iter [00300, 00390], lr: 0.020000, loss: 2.2684
2023-07-01 23:23:33 - train: epoch 0078, iter [00350, 00390], lr: 0.020000, loss: 2.0346
2023-07-01 23:23:34 - train: epoch 078, train_loss: 2.0797
2023-07-01 23:23:36 - eval: epoch: 078, acc1: 36.920%, acc5: 67.010%, test_loss: 2.5302, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:23:36 - until epoch: 078, best_acc1: 38.140%
2023-07-01 23:23:36 - epoch 079 lr: 0.020000
2023-07-01 23:23:38 - train: epoch 0079, iter [00050, 00390], lr: 0.020000, loss: 1.8071
2023-07-01 23:23:40 - train: epoch 0079, iter [00100, 00390], lr: 0.020000, loss: 1.8815
2023-07-01 23:23:41 - train: epoch 0079, iter [00150, 00390], lr: 0.020000, loss: 2.1025
2023-07-01 23:23:43 - train: epoch 0079, iter [00200, 00390], lr: 0.020000, loss: 2.1271
2023-07-01 23:23:44 - train: epoch 0079, iter [00250, 00390], lr: 0.020000, loss: 2.1644
2023-07-01 23:23:45 - train: epoch 0079, iter [00300, 00390], lr: 0.020000, loss: 2.2807
2023-07-01 23:23:47 - train: epoch 0079, iter [00350, 00390], lr: 0.020000, loss: 2.0039
2023-07-01 23:23:48 - train: epoch 079, train_loss: 2.0745
2023-07-01 23:23:50 - eval: epoch: 079, acc1: 38.050%, acc5: 67.680%, test_loss: 2.4882, per_image_load_time: 0.099ms, per_image_inference_time: 0.055ms
2023-07-01 23:23:50 - until epoch: 079, best_acc1: 38.140%
2023-07-01 23:23:50 - epoch 080 lr: 0.020000
2023-07-01 23:23:53 - train: epoch 0080, iter [00050, 00390], lr: 0.020000, loss: 1.9665
2023-07-01 23:23:54 - train: epoch 0080, iter [00100, 00390], lr: 0.020000, loss: 2.0114
2023-07-01 23:23:55 - train: epoch 0080, iter [00150, 00390], lr: 0.020000, loss: 2.2508
2023-07-01 23:23:57 - train: epoch 0080, iter [00200, 00390], lr: 0.020000, loss: 2.2418
2023-07-01 23:23:58 - train: epoch 0080, iter [00250, 00390], lr: 0.020000, loss: 1.7559
2023-07-01 23:24:00 - train: epoch 0080, iter [00300, 00390], lr: 0.020000, loss: 2.3053
2023-07-01 23:24:01 - train: epoch 0080, iter [00350, 00390], lr: 0.020000, loss: 2.3058
2023-07-01 23:24:02 - train: epoch 080, train_loss: 2.0578
2023-07-01 23:24:04 - eval: epoch: 080, acc1: 36.580%, acc5: 67.900%, test_loss: 2.5147, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:24:04 - until epoch: 080, best_acc1: 38.140%
2023-07-01 23:24:04 - epoch 081 lr: 0.020000
2023-07-01 23:24:06 - train: epoch 0081, iter [00050, 00390], lr: 0.020000, loss: 2.1239
2023-07-01 23:24:08 - train: epoch 0081, iter [00100, 00390], lr: 0.020000, loss: 2.3355
2023-07-01 23:24:09 - train: epoch 0081, iter [00150, 00390], lr: 0.020000, loss: 2.1357
2023-07-01 23:24:11 - train: epoch 0081, iter [00200, 00390], lr: 0.020000, loss: 2.0820
2023-07-01 23:24:12 - train: epoch 0081, iter [00250, 00390], lr: 0.020000, loss: 2.2143
2023-07-01 23:24:14 - train: epoch 0081, iter [00300, 00390], lr: 0.020000, loss: 2.0553
2023-07-01 23:24:15 - train: epoch 0081, iter [00350, 00390], lr: 0.020000, loss: 2.0898
2023-07-01 23:24:16 - train: epoch 081, train_loss: 2.0408
2023-07-01 23:24:18 - eval: epoch: 081, acc1: 37.840%, acc5: 67.080%, test_loss: 2.5355, per_image_load_time: 0.099ms, per_image_inference_time: 0.054ms
2023-07-01 23:24:18 - until epoch: 081, best_acc1: 38.140%
2023-07-01 23:24:18 - epoch 082 lr: 0.020000
2023-07-01 23:24:21 - train: epoch 0082, iter [00050, 00390], lr: 0.020000, loss: 2.0705
2023-07-01 23:24:22 - train: epoch 0082, iter [00100, 00390], lr: 0.020000, loss: 2.0271
2023-07-01 23:24:24 - train: epoch 0082, iter [00150, 00390], lr: 0.020000, loss: 1.8180
2023-07-01 23:24:25 - train: epoch 0082, iter [00200, 00390], lr: 0.020000, loss: 2.0560
2023-07-01 23:24:26 - train: epoch 0082, iter [00250, 00390], lr: 0.020000, loss: 2.2878
2023-07-01 23:24:28 - train: epoch 0082, iter [00300, 00390], lr: 0.020000, loss: 2.0367
2023-07-01 23:24:29 - train: epoch 0082, iter [00350, 00390], lr: 0.020000, loss: 2.0444
2023-07-01 23:24:30 - train: epoch 082, train_loss: 2.0293
2023-07-01 23:24:32 - eval: epoch: 082, acc1: 36.910%, acc5: 66.970%, test_loss: 2.5473, per_image_load_time: 0.095ms, per_image_inference_time: 0.055ms
2023-07-01 23:24:32 - until epoch: 082, best_acc1: 38.140%
2023-07-01 23:24:32 - epoch 083 lr: 0.020000
2023-07-01 23:24:35 - train: epoch 0083, iter [00050, 00390], lr: 0.020000, loss: 2.0424
2023-07-01 23:24:36 - train: epoch 0083, iter [00100, 00390], lr: 0.020000, loss: 2.0845
2023-07-01 23:24:38 - train: epoch 0083, iter [00150, 00390], lr: 0.020000, loss: 2.0643
2023-07-01 23:24:39 - train: epoch 0083, iter [00200, 00390], lr: 0.020000, loss: 1.6987
2023-07-01 23:24:40 - train: epoch 0083, iter [00250, 00390], lr: 0.020000, loss: 2.0885
2023-07-01 23:24:42 - train: epoch 0083, iter [00300, 00390], lr: 0.020000, loss: 2.1823
2023-07-01 23:24:43 - train: epoch 0083, iter [00350, 00390], lr: 0.020000, loss: 2.0979
2023-07-01 23:24:44 - train: epoch 083, train_loss: 2.0215
2023-07-01 23:24:46 - eval: epoch: 083, acc1: 37.710%, acc5: 67.150%, test_loss: 2.5430, per_image_load_time: 0.097ms, per_image_inference_time: 0.054ms
2023-07-01 23:24:47 - until epoch: 083, best_acc1: 38.140%
2023-07-01 23:24:47 - epoch 084 lr: 0.020000
2023-07-01 23:24:49 - train: epoch 0084, iter [00050, 00390], lr: 0.020000, loss: 2.0923
2023-07-01 23:24:50 - train: epoch 0084, iter [00100, 00390], lr: 0.020000, loss: 2.1085
2023-07-01 23:24:52 - train: epoch 0084, iter [00150, 00390], lr: 0.020000, loss: 1.9894
2023-07-01 23:24:53 - train: epoch 0084, iter [00200, 00390], lr: 0.020000, loss: 1.6826
2023-07-01 23:24:54 - train: epoch 0084, iter [00250, 00390], lr: 0.020000, loss: 2.1312
2023-07-01 23:24:56 - train: epoch 0084, iter [00300, 00390], lr: 0.020000, loss: 2.1211
2023-07-01 23:24:57 - train: epoch 0084, iter [00350, 00390], lr: 0.020000, loss: 2.0644
2023-07-01 23:24:58 - train: epoch 084, train_loss: 2.0127
2023-07-01 23:25:00 - eval: epoch: 084, acc1: 38.300%, acc5: 67.420%, test_loss: 2.5089, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:25:01 - until epoch: 084, best_acc1: 38.300%
2023-07-01 23:25:01 - epoch 085 lr: 0.020000
2023-07-01 23:25:03 - train: epoch 0085, iter [00050, 00390], lr: 0.020000, loss: 1.8280
2023-07-01 23:25:04 - train: epoch 0085, iter [00100, 00390], lr: 0.020000, loss: 1.8564
2023-07-01 23:25:06 - train: epoch 0085, iter [00150, 00390], lr: 0.020000, loss: 1.8266
2023-07-01 23:25:07 - train: epoch 0085, iter [00200, 00390], lr: 0.020000, loss: 1.6816
2023-07-01 23:25:09 - train: epoch 0085, iter [00250, 00390], lr: 0.020000, loss: 1.9655
2023-07-01 23:25:10 - train: epoch 0085, iter [00300, 00390], lr: 0.020000, loss: 1.9270
2023-07-01 23:25:11 - train: epoch 0085, iter [00350, 00390], lr: 0.020000, loss: 2.0469
2023-07-01 23:25:13 - train: epoch 085, train_loss: 1.9987
2023-07-01 23:25:14 - eval: epoch: 085, acc1: 37.190%, acc5: 67.650%, test_loss: 2.5339, per_image_load_time: 0.093ms, per_image_inference_time: 0.055ms
2023-07-01 23:25:15 - until epoch: 085, best_acc1: 38.300%
2023-07-01 23:25:15 - epoch 086 lr: 0.020000
2023-07-01 23:25:17 - train: epoch 0086, iter [00050, 00390], lr: 0.020000, loss: 1.7813
2023-07-01 23:25:18 - train: epoch 0086, iter [00100, 00390], lr: 0.020000, loss: 1.7169
2023-07-01 23:25:20 - train: epoch 0086, iter [00150, 00390], lr: 0.020000, loss: 1.8790
2023-07-01 23:25:21 - train: epoch 0086, iter [00200, 00390], lr: 0.020000, loss: 1.8193
2023-07-01 23:25:22 - train: epoch 0086, iter [00250, 00390], lr: 0.020000, loss: 1.9854
2023-07-01 23:25:24 - train: epoch 0086, iter [00300, 00390], lr: 0.020000, loss: 1.8715
2023-07-01 23:25:25 - train: epoch 0086, iter [00350, 00390], lr: 0.020000, loss: 1.8904
2023-07-01 23:25:26 - train: epoch 086, train_loss: 1.9848
2023-07-01 23:25:28 - eval: epoch: 086, acc1: 38.100%, acc5: 67.490%, test_loss: 2.5253, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:25:28 - until epoch: 086, best_acc1: 38.300%
2023-07-01 23:25:28 - epoch 087 lr: 0.020000
2023-07-01 23:25:31 - train: epoch 0087, iter [00050, 00390], lr: 0.020000, loss: 1.8856
2023-07-01 23:25:32 - train: epoch 0087, iter [00100, 00390], lr: 0.020000, loss: 1.8441
2023-07-01 23:25:33 - train: epoch 0087, iter [00150, 00390], lr: 0.020000, loss: 1.9729
2023-07-01 23:25:35 - train: epoch 0087, iter [00200, 00390], lr: 0.020000, loss: 1.6787
2023-07-01 23:25:36 - train: epoch 0087, iter [00250, 00390], lr: 0.020000, loss: 1.8087
2023-07-01 23:25:38 - train: epoch 0087, iter [00300, 00390], lr: 0.020000, loss: 1.9156
2023-07-01 23:25:39 - train: epoch 0087, iter [00350, 00390], lr: 0.020000, loss: 1.9523
2023-07-01 23:25:40 - train: epoch 087, train_loss: 1.9772
2023-07-01 23:25:42 - eval: epoch: 087, acc1: 37.740%, acc5: 67.910%, test_loss: 2.4955, per_image_load_time: 0.094ms, per_image_inference_time: 0.053ms
2023-07-01 23:25:42 - until epoch: 087, best_acc1: 38.300%
2023-07-01 23:25:42 - epoch 088 lr: 0.020000
2023-07-01 23:25:45 - train: epoch 0088, iter [00050, 00390], lr: 0.020000, loss: 1.8592
2023-07-01 23:25:46 - train: epoch 0088, iter [00100, 00390], lr: 0.020000, loss: 2.0824
2023-07-01 23:25:47 - train: epoch 0088, iter [00150, 00390], lr: 0.020000, loss: 1.9007
2023-07-01 23:25:49 - train: epoch 0088, iter [00200, 00390], lr: 0.020000, loss: 1.9020
2023-07-01 23:25:50 - train: epoch 0088, iter [00250, 00390], lr: 0.020000, loss: 1.9644
2023-07-01 23:25:52 - train: epoch 0088, iter [00300, 00390], lr: 0.020000, loss: 2.1417
2023-07-01 23:25:53 - train: epoch 0088, iter [00350, 00390], lr: 0.020000, loss: 1.9087
2023-07-01 23:25:54 - train: epoch 088, train_loss: 1.9645
2023-07-01 23:25:56 - eval: epoch: 088, acc1: 37.910%, acc5: 68.220%, test_loss: 2.5100, per_image_load_time: 0.093ms, per_image_inference_time: 0.054ms
2023-07-01 23:25:56 - until epoch: 088, best_acc1: 38.300%
2023-07-01 23:25:56 - epoch 089 lr: 0.020000
2023-07-01 23:25:59 - train: epoch 0089, iter [00050, 00390], lr: 0.020000, loss: 1.6898
2023-07-01 23:26:00 - train: epoch 0089, iter [00100, 00390], lr: 0.020000, loss: 1.8588
2023-07-01 23:26:01 - train: epoch 0089, iter [00150, 00390], lr: 0.020000, loss: 1.8402
2023-07-01 23:26:03 - train: epoch 0089, iter [00200, 00390], lr: 0.020000, loss: 2.0286
2023-07-01 23:26:04 - train: epoch 0089, iter [00250, 00390], lr: 0.020000, loss: 2.1615
2023-07-01 23:26:06 - train: epoch 0089, iter [00300, 00390], lr: 0.020000, loss: 1.8324
2023-07-01 23:26:07 - train: epoch 0089, iter [00350, 00390], lr: 0.020000, loss: 2.0302
2023-07-01 23:26:08 - train: epoch 089, train_loss: 1.9570
2023-07-01 23:26:10 - eval: epoch: 089, acc1: 37.840%, acc5: 67.180%, test_loss: 2.5370, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:26:10 - until epoch: 089, best_acc1: 38.300%
2023-07-01 23:26:10 - epoch 090 lr: 0.020000
2023-07-01 23:26:13 - train: epoch 0090, iter [00050, 00390], lr: 0.020000, loss: 2.0954
2023-07-01 23:26:14 - train: epoch 0090, iter [00100, 00390], lr: 0.020000, loss: 1.8642
2023-07-01 23:26:15 - train: epoch 0090, iter [00150, 00390], lr: 0.020000, loss: 2.0480
2023-07-01 23:26:17 - train: epoch 0090, iter [00200, 00390], lr: 0.020000, loss: 2.1640
2023-07-01 23:26:18 - train: epoch 0090, iter [00250, 00390], lr: 0.020000, loss: 1.9035
2023-07-01 23:26:20 - train: epoch 0090, iter [00300, 00390], lr: 0.020000, loss: 2.1009
2023-07-01 23:26:21 - train: epoch 0090, iter [00350, 00390], lr: 0.020000, loss: 1.7765
2023-07-01 23:26:22 - train: epoch 090, train_loss: 1.9413
2023-07-01 23:26:24 - eval: epoch: 090, acc1: 38.080%, acc5: 68.120%, test_loss: 2.5239, per_image_load_time: 0.093ms, per_image_inference_time: 0.053ms
2023-07-01 23:26:24 - until epoch: 090, best_acc1: 38.300%
2023-07-01 23:26:24 - epoch 091 lr: 0.020000
2023-07-01 23:26:27 - train: epoch 0091, iter [00050, 00390], lr: 0.020000, loss: 1.5942
2023-07-01 23:26:28 - train: epoch 0091, iter [00100, 00390], lr: 0.020000, loss: 1.8392
2023-07-01 23:26:30 - train: epoch 0091, iter [00150, 00390], lr: 0.020000, loss: 1.9567
2023-07-01 23:26:31 - train: epoch 0091, iter [00200, 00390], lr: 0.020000, loss: 2.0266
2023-07-01 23:26:33 - train: epoch 0091, iter [00250, 00390], lr: 0.020000, loss: 2.1172
2023-07-01 23:26:34 - train: epoch 0091, iter [00300, 00390], lr: 0.020000, loss: 1.7813
2023-07-01 23:26:36 - train: epoch 0091, iter [00350, 00390], lr: 0.020000, loss: 2.1418
2023-07-01 23:26:37 - train: epoch 091, train_loss: 1.9311
2023-07-01 23:26:38 - eval: epoch: 091, acc1: 37.910%, acc5: 67.620%, test_loss: 2.5144, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:26:39 - until epoch: 091, best_acc1: 38.300%
2023-07-01 23:26:39 - epoch 092 lr: 0.020000
2023-07-01 23:26:41 - train: epoch 0092, iter [00050, 00390], lr: 0.020000, loss: 1.9463
2023-07-01 23:26:42 - train: epoch 0092, iter [00100, 00390], lr: 0.020000, loss: 1.8866
2023-07-01 23:26:44 - train: epoch 0092, iter [00150, 00390], lr: 0.020000, loss: 1.8078
2023-07-01 23:26:45 - train: epoch 0092, iter [00200, 00390], lr: 0.020000, loss: 1.9754
2023-07-01 23:26:47 - train: epoch 0092, iter [00250, 00390], lr: 0.020000, loss: 1.9113
2023-07-01 23:26:48 - train: epoch 0092, iter [00300, 00390], lr: 0.020000, loss: 2.0610
2023-07-01 23:26:49 - train: epoch 0092, iter [00350, 00390], lr: 0.020000, loss: 1.7797
2023-07-01 23:26:51 - train: epoch 092, train_loss: 1.9247
2023-07-01 23:26:52 - eval: epoch: 092, acc1: 38.580%, acc5: 68.500%, test_loss: 2.5022, per_image_load_time: 0.093ms, per_image_inference_time: 0.054ms
2023-07-01 23:26:53 - until epoch: 092, best_acc1: 38.580%
2023-07-01 23:26:53 - epoch 093 lr: 0.020000
2023-07-01 23:26:56 - train: epoch 0093, iter [00050, 00390], lr: 0.020000, loss: 1.7685
2023-07-01 23:26:57 - train: epoch 0093, iter [00100, 00390], lr: 0.020000, loss: 1.7076
2023-07-01 23:26:58 - train: epoch 0093, iter [00150, 00390], lr: 0.020000, loss: 2.0892
2023-07-01 23:27:00 - train: epoch 0093, iter [00200, 00390], lr: 0.020000, loss: 1.9951
2023-07-01 23:27:01 - train: epoch 0093, iter [00250, 00390], lr: 0.020000, loss: 1.9901
2023-07-01 23:27:02 - train: epoch 0093, iter [00300, 00390], lr: 0.020000, loss: 1.8620
2023-07-01 23:27:04 - train: epoch 0093, iter [00350, 00390], lr: 0.020000, loss: 2.0592
2023-07-01 23:27:05 - train: epoch 093, train_loss: 1.9104
2023-07-01 23:27:07 - eval: epoch: 093, acc1: 38.580%, acc5: 68.440%, test_loss: 2.4949, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:27:07 - until epoch: 093, best_acc1: 38.580%
2023-07-01 23:27:07 - epoch 094 lr: 0.020000
2023-07-01 23:27:09 - train: epoch 0094, iter [00050, 00390], lr: 0.020000, loss: 1.6757
2023-07-01 23:27:11 - train: epoch 0094, iter [00100, 00390], lr: 0.020000, loss: 1.7307
2023-07-01 23:27:12 - train: epoch 0094, iter [00150, 00390], lr: 0.020000, loss: 1.7029
2023-07-01 23:27:14 - train: epoch 0094, iter [00200, 00390], lr: 0.020000, loss: 1.9936
2023-07-01 23:27:15 - train: epoch 0094, iter [00250, 00390], lr: 0.020000, loss: 2.0426
2023-07-01 23:27:16 - train: epoch 0094, iter [00300, 00390], lr: 0.020000, loss: 1.7973
2023-07-01 23:27:18 - train: epoch 0094, iter [00350, 00390], lr: 0.020000, loss: 1.8466
2023-07-01 23:27:19 - train: epoch 094, train_loss: 1.8973
2023-07-01 23:27:21 - eval: epoch: 094, acc1: 38.010%, acc5: 68.140%, test_loss: 2.5203, per_image_load_time: 0.111ms, per_image_inference_time: 0.054ms
2023-07-01 23:27:22 - until epoch: 094, best_acc1: 38.580%
2023-07-01 23:27:22 - epoch 095 lr: 0.020000
2023-07-01 23:27:25 - train: epoch 0095, iter [00050, 00390], lr: 0.020000, loss: 2.0233
2023-07-01 23:27:26 - train: epoch 0095, iter [00100, 00390], lr: 0.020000, loss: 1.9389
2023-07-01 23:27:28 - train: epoch 0095, iter [00150, 00390], lr: 0.020000, loss: 2.1027
2023-07-01 23:27:29 - train: epoch 0095, iter [00200, 00390], lr: 0.020000, loss: 1.7518
2023-07-01 23:27:30 - train: epoch 0095, iter [00250, 00390], lr: 0.020000, loss: 1.7101
2023-07-01 23:27:32 - train: epoch 0095, iter [00300, 00390], lr: 0.020000, loss: 1.8940
2023-07-01 23:27:33 - train: epoch 0095, iter [00350, 00390], lr: 0.020000, loss: 1.8502
2023-07-01 23:27:34 - train: epoch 095, train_loss: 1.8895
2023-07-01 23:27:36 - eval: epoch: 095, acc1: 37.440%, acc5: 67.580%, test_loss: 2.5561, per_image_load_time: 0.095ms, per_image_inference_time: 0.072ms
2023-07-01 23:27:37 - until epoch: 095, best_acc1: 38.580%
2023-07-01 23:27:37 - epoch 096 lr: 0.020000
2023-07-01 23:27:39 - train: epoch 0096, iter [00050, 00390], lr: 0.020000, loss: 1.8967
2023-07-01 23:27:40 - train: epoch 0096, iter [00100, 00390], lr: 0.020000, loss: 1.8025
2023-07-01 23:27:42 - train: epoch 0096, iter [00150, 00390], lr: 0.020000, loss: 1.7700
2023-07-01 23:27:43 - train: epoch 0096, iter [00200, 00390], lr: 0.020000, loss: 1.8384
2023-07-01 23:27:45 - train: epoch 0096, iter [00250, 00390], lr: 0.020000, loss: 1.9392
2023-07-01 23:27:46 - train: epoch 0096, iter [00300, 00390], lr: 0.020000, loss: 2.0874
2023-07-01 23:27:47 - train: epoch 0096, iter [00350, 00390], lr: 0.020000, loss: 2.1334
2023-07-01 23:27:49 - train: epoch 096, train_loss: 1.8824
2023-07-01 23:27:50 - eval: epoch: 096, acc1: 37.090%, acc5: 67.000%, test_loss: 2.5580, per_image_load_time: 0.097ms, per_image_inference_time: 0.055ms
2023-07-01 23:27:50 - until epoch: 096, best_acc1: 38.580%
2023-07-01 23:27:50 - epoch 097 lr: 0.020000
2023-07-01 23:27:53 - train: epoch 0097, iter [00050, 00390], lr: 0.020000, loss: 1.8379
2023-07-01 23:27:55 - train: epoch 0097, iter [00100, 00390], lr: 0.020000, loss: 1.7670
2023-07-01 23:27:56 - train: epoch 0097, iter [00150, 00390], lr: 0.020000, loss: 1.5872
2023-07-01 23:27:58 - train: epoch 0097, iter [00200, 00390], lr: 0.020000, loss: 2.1246
2023-07-01 23:27:59 - train: epoch 0097, iter [00250, 00390], lr: 0.020000, loss: 1.7176
2023-07-01 23:28:01 - train: epoch 0097, iter [00300, 00390], lr: 0.020000, loss: 1.7352
2023-07-01 23:28:02 - train: epoch 0097, iter [00350, 00390], lr: 0.020000, loss: 1.9909
2023-07-01 23:28:03 - train: epoch 097, train_loss: 1.8621
2023-07-01 23:28:05 - eval: epoch: 097, acc1: 38.050%, acc5: 68.250%, test_loss: 2.5292, per_image_load_time: 0.100ms, per_image_inference_time: 0.054ms
2023-07-01 23:28:06 - until epoch: 097, best_acc1: 38.580%
2023-07-01 23:28:06 - epoch 098 lr: 0.020000
2023-07-01 23:28:08 - train: epoch 0098, iter [00050, 00390], lr: 0.020000, loss: 1.7260
2023-07-01 23:28:10 - train: epoch 0098, iter [00100, 00390], lr: 0.020000, loss: 1.9024
2023-07-01 23:28:11 - train: epoch 0098, iter [00150, 00390], lr: 0.020000, loss: 1.7867
2023-07-01 23:28:12 - train: epoch 0098, iter [00200, 00390], lr: 0.020000, loss: 1.8821
2023-07-01 23:28:14 - train: epoch 0098, iter [00250, 00390], lr: 0.020000, loss: 1.7508
2023-07-01 23:28:15 - train: epoch 0098, iter [00300, 00390], lr: 0.020000, loss: 2.3151
2023-07-01 23:28:17 - train: epoch 0098, iter [00350, 00390], lr: 0.020000, loss: 1.9847
2023-07-01 23:28:18 - train: epoch 098, train_loss: 1.8586
2023-07-01 23:28:20 - eval: epoch: 098, acc1: 37.990%, acc5: 67.830%, test_loss: 2.5395, per_image_load_time: 0.100ms, per_image_inference_time: 0.054ms
2023-07-01 23:28:20 - until epoch: 098, best_acc1: 38.580%
2023-07-01 23:28:20 - epoch 099 lr: 0.020000
2023-07-01 23:28:22 - train: epoch 0099, iter [00050, 00390], lr: 0.020000, loss: 1.7697
2023-07-01 23:28:24 - train: epoch 0099, iter [00100, 00390], lr: 0.020000, loss: 1.5728
2023-07-01 23:28:25 - train: epoch 0099, iter [00150, 00390], lr: 0.020000, loss: 1.9185
2023-07-01 23:28:27 - train: epoch 0099, iter [00200, 00390], lr: 0.020000, loss: 2.0135
2023-07-01 23:28:28 - train: epoch 0099, iter [00250, 00390], lr: 0.020000, loss: 1.9188
2023-07-01 23:28:30 - train: epoch 0099, iter [00300, 00390], lr: 0.020000, loss: 1.8174
2023-07-01 23:28:31 - train: epoch 0099, iter [00350, 00390], lr: 0.020000, loss: 1.8467
2023-07-01 23:28:33 - train: epoch 099, train_loss: 1.8485
2023-07-01 23:28:34 - eval: epoch: 099, acc1: 37.630%, acc5: 67.070%, test_loss: 2.5738, per_image_load_time: 0.095ms, per_image_inference_time: 0.056ms
2023-07-01 23:28:35 - until epoch: 099, best_acc1: 38.580%
2023-07-01 23:28:35 - epoch 100 lr: 0.020000
2023-07-01 23:28:37 - train: epoch 0100, iter [00050, 00390], lr: 0.020000, loss: 1.9407
2023-07-01 23:28:39 - train: epoch 0100, iter [00100, 00390], lr: 0.020000, loss: 1.4189
2023-07-01 23:28:40 - train: epoch 0100, iter [00150, 00390], lr: 0.020000, loss: 1.9184
2023-07-01 23:28:42 - train: epoch 0100, iter [00200, 00390], lr: 0.020000, loss: 2.1002
2023-07-01 23:28:43 - train: epoch 0100, iter [00250, 00390], lr: 0.020000, loss: 1.9352
2023-07-01 23:28:45 - train: epoch 0100, iter [00300, 00390], lr: 0.020000, loss: 1.8859
2023-07-01 23:28:46 - train: epoch 0100, iter [00350, 00390], lr: 0.020000, loss: 1.9189
2023-07-01 23:28:47 - train: epoch 100, train_loss: 1.8375
2023-07-01 23:28:49 - eval: epoch: 100, acc1: 37.770%, acc5: 67.600%, test_loss: 2.5676, per_image_load_time: 0.098ms, per_image_inference_time: 0.055ms
2023-07-01 23:28:49 - until epoch: 100, best_acc1: 38.580%
2023-07-01 23:28:49 - epoch 101 lr: 0.020000
2023-07-01 23:28:52 - train: epoch 0101, iter [00050, 00390], lr: 0.020000, loss: 1.8234
2023-07-01 23:28:53 - train: epoch 0101, iter [00100, 00390], lr: 0.020000, loss: 1.9382
2023-07-01 23:28:55 - train: epoch 0101, iter [00150, 00390], lr: 0.020000, loss: 2.1659
2023-07-01 23:28:56 - train: epoch 0101, iter [00200, 00390], lr: 0.020000, loss: 1.7559
2023-07-01 23:28:58 - train: epoch 0101, iter [00250, 00390], lr: 0.020000, loss: 2.0116
2023-07-01 23:28:59 - train: epoch 0101, iter [00300, 00390], lr: 0.020000, loss: 1.9398
2023-07-01 23:29:01 - train: epoch 0101, iter [00350, 00390], lr: 0.020000, loss: 1.6454
2023-07-01 23:29:02 - train: epoch 101, train_loss: 1.8263
2023-07-01 23:29:04 - eval: epoch: 101, acc1: 38.260%, acc5: 67.230%, test_loss: 2.5689, per_image_load_time: 0.097ms, per_image_inference_time: 0.054ms
2023-07-01 23:29:04 - until epoch: 101, best_acc1: 38.580%
2023-07-01 23:29:04 - epoch 102 lr: 0.020000
2023-07-01 23:29:07 - train: epoch 0102, iter [00050, 00390], lr: 0.020000, loss: 1.9446
2023-07-01 23:29:08 - train: epoch 0102, iter [00100, 00390], lr: 0.020000, loss: 1.7380
2023-07-01 23:29:09 - train: epoch 0102, iter [00150, 00390], lr: 0.020000, loss: 1.9427
2023-07-01 23:29:11 - train: epoch 0102, iter [00200, 00390], lr: 0.020000, loss: 1.5477
2023-07-01 23:29:12 - train: epoch 0102, iter [00250, 00390], lr: 0.020000, loss: 2.0840
2023-07-01 23:29:13 - train: epoch 0102, iter [00300, 00390], lr: 0.020000, loss: 1.7297
2023-07-01 23:29:15 - train: epoch 0102, iter [00350, 00390], lr: 0.020000, loss: 1.8318
2023-07-01 23:29:16 - train: epoch 102, train_loss: 1.8163
2023-07-01 23:29:18 - eval: epoch: 102, acc1: 38.090%, acc5: 67.400%, test_loss: 2.5810, per_image_load_time: 0.096ms, per_image_inference_time: 0.056ms
2023-07-01 23:29:18 - until epoch: 102, best_acc1: 38.580%
2023-07-01 23:29:18 - epoch 103 lr: 0.020000
2023-07-01 23:29:21 - train: epoch 0103, iter [00050, 00390], lr: 0.020000, loss: 1.5725
2023-07-01 23:29:22 - train: epoch 0103, iter [00100, 00390], lr: 0.020000, loss: 1.7707
2023-07-01 23:29:24 - train: epoch 0103, iter [00150, 00390], lr: 0.020000, loss: 1.6177
2023-07-01 23:29:26 - train: epoch 0103, iter [00200, 00390], lr: 0.020000, loss: 1.8728
2023-07-01 23:29:28 - train: epoch 0103, iter [00250, 00390], lr: 0.020000, loss: 1.8003
2023-07-01 23:29:30 - train: epoch 0103, iter [00300, 00390], lr: 0.020000, loss: 1.9750
2023-07-01 23:29:31 - train: epoch 0103, iter [00350, 00390], lr: 0.020000, loss: 1.8489
2023-07-01 23:29:33 - train: epoch 103, train_loss: 1.8092
2023-07-01 23:29:35 - eval: epoch: 103, acc1: 38.310%, acc5: 68.050%, test_loss: 2.5421, per_image_load_time: 0.129ms, per_image_inference_time: 0.055ms
2023-07-01 23:29:37 - until epoch: 103, best_acc1: 38.580%
2023-07-01 23:29:37 - epoch 104 lr: 0.020000
2023-07-01 23:29:39 - train: epoch 0104, iter [00050, 00390], lr: 0.020000, loss: 1.6084
2023-07-01 23:29:41 - train: epoch 0104, iter [00100, 00390], lr: 0.020000, loss: 1.7341
2023-07-01 23:29:42 - train: epoch 0104, iter [00150, 00390], lr: 0.020000, loss: 1.6593
2023-07-01 23:29:44 - train: epoch 0104, iter [00200, 00390], lr: 0.020000, loss: 1.7820
2023-07-01 23:29:45 - train: epoch 0104, iter [00250, 00390], lr: 0.020000, loss: 1.5626
2023-07-01 23:29:47 - train: epoch 0104, iter [00300, 00390], lr: 0.020000, loss: 1.9878
2023-07-01 23:29:49 - train: epoch 0104, iter [00350, 00390], lr: 0.020000, loss: 1.9441
2023-07-01 23:29:50 - train: epoch 104, train_loss: 1.8007
2023-07-01 23:29:52 - eval: epoch: 104, acc1: 38.990%, acc5: 67.590%, test_loss: 2.5619, per_image_load_time: 0.095ms, per_image_inference_time: 0.055ms
2023-07-01 23:29:53 - until epoch: 104, best_acc1: 38.990%
2023-07-01 23:29:53 - epoch 105 lr: 0.020000
2023-07-01 23:29:55 - train: epoch 0105, iter [00050, 00390], lr: 0.020000, loss: 1.6116
2023-07-01 23:29:57 - train: epoch 0105, iter [00100, 00390], lr: 0.020000, loss: 1.5776
2023-07-01 23:29:58 - train: epoch 0105, iter [00150, 00390], lr: 0.020000, loss: 1.5916
2023-07-01 23:29:59 - train: epoch 0105, iter [00200, 00390], lr: 0.020000, loss: 1.7646
2023-07-01 23:30:01 - train: epoch 0105, iter [00250, 00390], lr: 0.020000, loss: 1.5256
2023-07-01 23:30:02 - train: epoch 0105, iter [00300, 00390], lr: 0.020000, loss: 1.7060
2023-07-01 23:30:04 - train: epoch 0105, iter [00350, 00390], lr: 0.020000, loss: 1.8177
2023-07-01 23:30:05 - train: epoch 105, train_loss: 1.7958
2023-07-01 23:30:07 - eval: epoch: 105, acc1: 38.750%, acc5: 67.430%, test_loss: 2.5568, per_image_load_time: 0.100ms, per_image_inference_time: 0.053ms
2023-07-01 23:30:07 - until epoch: 105, best_acc1: 38.990%
2023-07-01 23:30:07 - epoch 106 lr: 0.020000
2023-07-01 23:30:09 - train: epoch 0106, iter [00050, 00390], lr: 0.020000, loss: 1.4317
2023-07-01 23:30:11 - train: epoch 0106, iter [00100, 00390], lr: 0.020000, loss: 1.6261
2023-07-01 23:30:12 - train: epoch 0106, iter [00150, 00390], lr: 0.020000, loss: 1.6760
2023-07-01 23:30:14 - train: epoch 0106, iter [00200, 00390], lr: 0.020000, loss: 1.7247
2023-07-01 23:30:15 - train: epoch 0106, iter [00250, 00390], lr: 0.020000, loss: 1.9738
2023-07-01 23:30:17 - train: epoch 0106, iter [00300, 00390], lr: 0.020000, loss: 2.0359
2023-07-01 23:30:18 - train: epoch 0106, iter [00350, 00390], lr: 0.020000, loss: 1.5863
2023-07-01 23:30:19 - train: epoch 106, train_loss: 1.7772
2023-07-01 23:30:21 - eval: epoch: 106, acc1: 37.550%, acc5: 67.580%, test_loss: 2.5783, per_image_load_time: 0.098ms, per_image_inference_time: 0.056ms
2023-07-01 23:30:22 - until epoch: 106, best_acc1: 38.990%
2023-07-01 23:30:22 - epoch 107 lr: 0.020000
2023-07-01 23:30:24 - train: epoch 0107, iter [00050, 00390], lr: 0.020000, loss: 1.6993
2023-07-01 23:30:26 - train: epoch 0107, iter [00100, 00390], lr: 0.020000, loss: 1.8298
2023-07-01 23:30:27 - train: epoch 0107, iter [00150, 00390], lr: 0.020000, loss: 1.9497
2023-07-01 23:30:29 - train: epoch 0107, iter [00200, 00390], lr: 0.020000, loss: 1.7429
2023-07-01 23:30:30 - train: epoch 0107, iter [00250, 00390], lr: 0.020000, loss: 2.0585
2023-07-01 23:30:32 - train: epoch 0107, iter [00300, 00390], lr: 0.020000, loss: 1.6907
2023-07-01 23:30:33 - train: epoch 0107, iter [00350, 00390], lr: 0.020000, loss: 2.0641
2023-07-01 23:30:35 - train: epoch 107, train_loss: 1.7759
2023-07-01 23:30:36 - eval: epoch: 107, acc1: 38.160%, acc5: 67.490%, test_loss: 2.5773, per_image_load_time: 0.100ms, per_image_inference_time: 0.056ms
2023-07-01 23:30:37 - until epoch: 107, best_acc1: 38.990%
2023-07-01 23:30:37 - epoch 108 lr: 0.020000
2023-07-01 23:30:39 - train: epoch 0108, iter [00050, 00390], lr: 0.020000, loss: 1.7396
2023-07-01 23:30:41 - train: epoch 0108, iter [00100, 00390], lr: 0.020000, loss: 1.8777
2023-07-01 23:30:42 - train: epoch 0108, iter [00150, 00390], lr: 0.020000, loss: 1.6929
2023-07-01 23:30:43 - train: epoch 0108, iter [00200, 00390], lr: 0.020000, loss: 1.6494
2023-07-01 23:30:45 - train: epoch 0108, iter [00250, 00390], lr: 0.020000, loss: 1.7408
2023-07-01 23:30:47 - train: epoch 0108, iter [00300, 00390], lr: 0.020000, loss: 1.6340
2023-07-01 23:30:48 - train: epoch 0108, iter [00350, 00390], lr: 0.020000, loss: 1.8660
2023-07-01 23:30:49 - train: epoch 108, train_loss: 1.7640
2023-07-01 23:30:51 - eval: epoch: 108, acc1: 38.210%, acc5: 67.410%, test_loss: 2.5625, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:30:51 - until epoch: 108, best_acc1: 38.990%
2023-07-01 23:30:51 - epoch 109 lr: 0.020000
2023-07-01 23:30:54 - train: epoch 0109, iter [00050, 00390], lr: 0.020000, loss: 1.6861
2023-07-01 23:30:55 - train: epoch 0109, iter [00100, 00390], lr: 0.020000, loss: 1.5365
2023-07-01 23:30:57 - train: epoch 0109, iter [00150, 00390], lr: 0.020000, loss: 1.6261
2023-07-01 23:30:58 - train: epoch 0109, iter [00200, 00390], lr: 0.020000, loss: 1.7720
2023-07-01 23:31:00 - train: epoch 0109, iter [00250, 00390], lr: 0.020000, loss: 1.8490
2023-07-01 23:31:01 - train: epoch 0109, iter [00300, 00390], lr: 0.020000, loss: 1.8238
2023-07-01 23:31:03 - train: epoch 0109, iter [00350, 00390], lr: 0.020000, loss: 2.0130
2023-07-01 23:31:04 - train: epoch 109, train_loss: 1.7553
2023-07-01 23:31:06 - eval: epoch: 109, acc1: 37.970%, acc5: 67.520%, test_loss: 2.5815, per_image_load_time: 0.098ms, per_image_inference_time: 0.056ms
2023-07-01 23:31:06 - until epoch: 109, best_acc1: 38.990%
2023-07-01 23:31:06 - epoch 110 lr: 0.020000
2023-07-01 23:31:09 - train: epoch 0110, iter [00050, 00390], lr: 0.020000, loss: 1.5600
2023-07-01 23:31:10 - train: epoch 0110, iter [00100, 00390], lr: 0.020000, loss: 1.6195
2023-07-01 23:31:11 - train: epoch 0110, iter [00150, 00390], lr: 0.020000, loss: 1.9260
2023-07-01 23:31:13 - train: epoch 0110, iter [00200, 00390], lr: 0.020000, loss: 1.9657
2023-07-01 23:31:14 - train: epoch 0110, iter [00250, 00390], lr: 0.020000, loss: 1.9447
2023-07-01 23:31:16 - train: epoch 0110, iter [00300, 00390], lr: 0.020000, loss: 1.8108
2023-07-01 23:31:17 - train: epoch 0110, iter [00350, 00390], lr: 0.020000, loss: 1.6768
2023-07-01 23:31:18 - train: epoch 110, train_loss: 1.7375
2023-07-01 23:31:20 - eval: epoch: 110, acc1: 38.720%, acc5: 67.920%, test_loss: 2.5611, per_image_load_time: 0.097ms, per_image_inference_time: 0.054ms
2023-07-01 23:31:20 - until epoch: 110, best_acc1: 38.990%
2023-07-01 23:31:20 - epoch 111 lr: 0.020000
2023-07-01 23:31:22 - train: epoch 0111, iter [00050, 00390], lr: 0.020000, loss: 1.5464
2023-07-01 23:31:24 - train: epoch 0111, iter [00100, 00390], lr: 0.020000, loss: 1.8962
2023-07-01 23:31:25 - train: epoch 0111, iter [00150, 00390], lr: 0.020000, loss: 1.9080
2023-07-01 23:31:27 - train: epoch 0111, iter [00200, 00390], lr: 0.020000, loss: 1.6950
2023-07-01 23:31:28 - train: epoch 0111, iter [00250, 00390], lr: 0.020000, loss: 1.9238
2023-07-01 23:31:29 - train: epoch 0111, iter [00300, 00390], lr: 0.020000, loss: 1.8099
2023-07-01 23:31:31 - train: epoch 0111, iter [00350, 00390], lr: 0.020000, loss: 1.7259
2023-07-01 23:31:32 - train: epoch 111, train_loss: 1.7341
2023-07-01 23:31:34 - eval: epoch: 111, acc1: 37.750%, acc5: 67.320%, test_loss: 2.5881, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:31:34 - until epoch: 111, best_acc1: 38.990%
2023-07-01 23:31:34 - epoch 112 lr: 0.020000
2023-07-01 23:31:36 - train: epoch 0112, iter [00050, 00390], lr: 0.020000, loss: 1.5411
2023-07-01 23:31:38 - train: epoch 0112, iter [00100, 00390], lr: 0.020000, loss: 1.5055
2023-07-01 23:31:39 - train: epoch 0112, iter [00150, 00390], lr: 0.020000, loss: 1.5912
2023-07-01 23:31:41 - train: epoch 0112, iter [00200, 00390], lr: 0.020000, loss: 1.7621
2023-07-01 23:31:43 - train: epoch 0112, iter [00250, 00390], lr: 0.020000, loss: 1.5990
2023-07-01 23:31:45 - train: epoch 0112, iter [00300, 00390], lr: 0.020000, loss: 1.9917
2023-07-01 23:31:46 - train: epoch 0112, iter [00350, 00390], lr: 0.020000, loss: 2.0761
2023-07-01 23:31:47 - train: epoch 112, train_loss: 1.7219
2023-07-01 23:31:49 - eval: epoch: 112, acc1: 37.800%, acc5: 67.250%, test_loss: 2.6226, per_image_load_time: 0.097ms, per_image_inference_time: 0.055ms
2023-07-01 23:31:50 - until epoch: 112, best_acc1: 38.990%
2023-07-01 23:31:50 - epoch 113 lr: 0.020000
2023-07-01 23:31:52 - train: epoch 0113, iter [00050, 00390], lr: 0.020000, loss: 1.5729
2023-07-01 23:31:54 - train: epoch 0113, iter [00100, 00390], lr: 0.020000, loss: 1.4869
2023-07-01 23:31:55 - train: epoch 0113, iter [00150, 00390], lr: 0.020000, loss: 1.7039
2023-07-01 23:31:56 - train: epoch 0113, iter [00200, 00390], lr: 0.020000, loss: 1.7255
2023-07-01 23:31:58 - train: epoch 0113, iter [00250, 00390], lr: 0.020000, loss: 1.5661
2023-07-01 23:31:59 - train: epoch 0113, iter [00300, 00390], lr: 0.020000, loss: 1.6496
2023-07-01 23:32:00 - train: epoch 0113, iter [00350, 00390], lr: 0.020000, loss: 1.6361
2023-07-01 23:32:02 - train: epoch 113, train_loss: 1.7154
2023-07-01 23:32:03 - eval: epoch: 113, acc1: 37.720%, acc5: 68.000%, test_loss: 2.5884, per_image_load_time: 0.094ms, per_image_inference_time: 0.055ms
2023-07-01 23:32:03 - until epoch: 113, best_acc1: 38.990%
2023-07-01 23:32:03 - epoch 114 lr: 0.020000
2023-07-01 23:32:06 - train: epoch 0114, iter [00050, 00390], lr: 0.020000, loss: 1.6290
2023-07-01 23:32:07 - train: epoch 0114, iter [00100, 00390], lr: 0.020000, loss: 1.5530
2023-07-01 23:32:09 - train: epoch 0114, iter [00150, 00390], lr: 0.020000, loss: 1.5430
2023-07-01 23:32:10 - train: epoch 0114, iter [00200, 00390], lr: 0.020000, loss: 1.6090
2023-07-01 23:32:12 - train: epoch 0114, iter [00250, 00390], lr: 0.020000, loss: 1.7459
2023-07-01 23:32:13 - train: epoch 0114, iter [00300, 00390], lr: 0.020000, loss: 1.6647
2023-07-01 23:32:15 - train: epoch 0114, iter [00350, 00390], lr: 0.020000, loss: 1.7466
2023-07-01 23:32:16 - train: epoch 114, train_loss: 1.7020
2023-07-01 23:32:18 - eval: epoch: 114, acc1: 37.820%, acc5: 67.130%, test_loss: 2.6095, per_image_load_time: 0.097ms, per_image_inference_time: 0.054ms
2023-07-01 23:32:18 - until epoch: 114, best_acc1: 38.990%
2023-07-01 23:32:18 - epoch 115 lr: 0.020000
2023-07-01 23:32:21 - train: epoch 0115, iter [00050, 00390], lr: 0.020000, loss: 1.3120
2023-07-01 23:32:22 - train: epoch 0115, iter [00100, 00390], lr: 0.020000, loss: 1.6388
2023-07-01 23:32:23 - train: epoch 0115, iter [00150, 00390], lr: 0.020000, loss: 1.9868
2023-07-01 23:32:25 - train: epoch 0115, iter [00200, 00390], lr: 0.020000, loss: 1.6417
2023-07-01 23:32:26 - train: epoch 0115, iter [00250, 00390], lr: 0.020000, loss: 1.6715
2023-07-01 23:32:28 - train: epoch 0115, iter [00300, 00390], lr: 0.020000, loss: 1.8036
2023-07-01 23:32:29 - train: epoch 0115, iter [00350, 00390], lr: 0.020000, loss: 1.8755
2023-07-01 23:32:30 - train: epoch 115, train_loss: 1.6978
2023-07-01 23:32:32 - eval: epoch: 115, acc1: 37.630%, acc5: 67.260%, test_loss: 2.6158, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:32:32 - until epoch: 115, best_acc1: 38.990%
2023-07-01 23:32:32 - epoch 116 lr: 0.020000
2023-07-01 23:32:35 - train: epoch 0116, iter [00050, 00390], lr: 0.020000, loss: 1.4294
2023-07-01 23:32:36 - train: epoch 0116, iter [00100, 00390], lr: 0.020000, loss: 1.4854
2023-07-01 23:32:38 - train: epoch 0116, iter [00150, 00390], lr: 0.020000, loss: 1.7096
2023-07-01 23:32:39 - train: epoch 0116, iter [00200, 00390], lr: 0.020000, loss: 1.8962
2023-07-01 23:32:40 - train: epoch 0116, iter [00250, 00390], lr: 0.020000, loss: 1.7862
2023-07-01 23:32:42 - train: epoch 0116, iter [00300, 00390], lr: 0.020000, loss: 1.8955
2023-07-01 23:32:43 - train: epoch 0116, iter [00350, 00390], lr: 0.020000, loss: 1.4801
2023-07-01 23:32:44 - train: epoch 116, train_loss: 1.6805
2023-07-01 23:32:46 - eval: epoch: 116, acc1: 38.020%, acc5: 67.010%, test_loss: 2.6418, per_image_load_time: 0.097ms, per_image_inference_time: 0.056ms
2023-07-01 23:32:47 - until epoch: 116, best_acc1: 38.990%
2023-07-01 23:32:47 - epoch 117 lr: 0.020000
2023-07-01 23:32:49 - train: epoch 0117, iter [00050, 00390], lr: 0.020000, loss: 1.6604
2023-07-01 23:32:50 - train: epoch 0117, iter [00100, 00390], lr: 0.020000, loss: 1.8945
2023-07-01 23:32:52 - train: epoch 0117, iter [00150, 00390], lr: 0.020000, loss: 1.4705
2023-07-01 23:32:53 - train: epoch 0117, iter [00200, 00390], lr: 0.020000, loss: 1.7164
2023-07-01 23:32:55 - train: epoch 0117, iter [00250, 00390], lr: 0.020000, loss: 1.8670
2023-07-01 23:32:56 - train: epoch 0117, iter [00300, 00390], lr: 0.020000, loss: 1.9450
2023-07-01 23:32:57 - train: epoch 0117, iter [00350, 00390], lr: 0.020000, loss: 1.7383
2023-07-01 23:32:59 - train: epoch 117, train_loss: 1.6799
2023-07-01 23:33:00 - eval: epoch: 117, acc1: 37.560%, acc5: 66.970%, test_loss: 2.6314, per_image_load_time: 0.099ms, per_image_inference_time: 0.053ms
2023-07-01 23:33:01 - until epoch: 117, best_acc1: 38.990%
2023-07-01 23:33:01 - epoch 118 lr: 0.020000
2023-07-01 23:33:03 - train: epoch 0118, iter [00050, 00390], lr: 0.020000, loss: 1.5547
2023-07-01 23:33:05 - train: epoch 0118, iter [00100, 00390], lr: 0.020000, loss: 1.6259
2023-07-01 23:33:06 - train: epoch 0118, iter [00150, 00390], lr: 0.020000, loss: 1.5595
2023-07-01 23:33:07 - train: epoch 0118, iter [00200, 00390], lr: 0.020000, loss: 1.7850
2023-07-01 23:33:09 - train: epoch 0118, iter [00250, 00390], lr: 0.020000, loss: 1.7086
2023-07-01 23:33:10 - train: epoch 0118, iter [00300, 00390], lr: 0.020000, loss: 1.5393
2023-07-01 23:33:12 - train: epoch 0118, iter [00350, 00390], lr: 0.020000, loss: 1.5577
2023-07-01 23:33:13 - train: epoch 118, train_loss: 1.6698
2023-07-01 23:33:14 - eval: epoch: 118, acc1: 37.590%, acc5: 67.520%, test_loss: 2.6202, per_image_load_time: 0.102ms, per_image_inference_time: 0.053ms
2023-07-01 23:33:15 - until epoch: 118, best_acc1: 38.990%
2023-07-01 23:33:15 - epoch 119 lr: 0.020000
2023-07-01 23:33:17 - train: epoch 0119, iter [00050, 00390], lr: 0.020000, loss: 1.7282
2023-07-01 23:33:19 - train: epoch 0119, iter [00100, 00390], lr: 0.020000, loss: 1.6709
2023-07-01 23:33:20 - train: epoch 0119, iter [00150, 00390], lr: 0.020000, loss: 1.6620
2023-07-01 23:33:22 - train: epoch 0119, iter [00200, 00390], lr: 0.020000, loss: 1.7378
2023-07-01 23:33:23 - train: epoch 0119, iter [00250, 00390], lr: 0.020000, loss: 1.6468
2023-07-01 23:33:25 - train: epoch 0119, iter [00300, 00390], lr: 0.020000, loss: 1.8264
2023-07-01 23:33:26 - train: epoch 0119, iter [00350, 00390], lr: 0.020000, loss: 1.7536
2023-07-01 23:33:27 - train: epoch 119, train_loss: 1.6619
2023-07-01 23:33:29 - eval: epoch: 119, acc1: 36.960%, acc5: 66.770%, test_loss: 2.6448, per_image_load_time: 0.098ms, per_image_inference_time: 0.054ms
2023-07-01 23:33:30 - until epoch: 119, best_acc1: 38.990%
2023-07-01 23:33:30 - epoch 120 lr: 0.020000
2023-07-01 23:33:32 - train: epoch 0120, iter [00050, 00390], lr: 0.020000, loss: 1.5476
2023-07-01 23:33:34 - train: epoch 0120, iter [00100, 00390], lr: 0.020000, loss: 1.7609
2023-07-01 23:33:35 - train: epoch 0120, iter [00150, 00390], lr: 0.020000, loss: 1.5838
2023-07-01 23:33:37 - train: epoch 0120, iter [00200, 00390], lr: 0.020000, loss: 1.5875
2023-07-01 23:33:38 - train: epoch 0120, iter [00250, 00390], lr: 0.020000, loss: 1.6677
2023-07-01 23:33:40 - train: epoch 0120, iter [00300, 00390], lr: 0.020000, loss: 1.5119
2023-07-01 23:33:41 - train: epoch 0120, iter [00350, 00390], lr: 0.020000, loss: 1.4636
2023-07-01 23:33:42 - train: epoch 120, train_loss: 1.6490
2023-07-01 23:33:44 - eval: epoch: 120, acc1: 37.530%, acc5: 66.640%, test_loss: 2.6728, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:33:45 - until epoch: 120, best_acc1: 38.990%
2023-07-01 23:33:45 - epoch 121 lr: 0.004000
2023-07-01 23:33:47 - train: epoch 0121, iter [00050, 00390], lr: 0.004000, loss: 1.3114
2023-07-01 23:33:48 - train: epoch 0121, iter [00100, 00390], lr: 0.004000, loss: 1.0837
2023-07-01 23:33:50 - train: epoch 0121, iter [00150, 00390], lr: 0.004000, loss: 1.1297
2023-07-01 23:33:51 - train: epoch 0121, iter [00200, 00390], lr: 0.004000, loss: 1.4425
2023-07-01 23:33:52 - train: epoch 0121, iter [00250, 00390], lr: 0.004000, loss: 1.3319
2023-07-01 23:33:54 - train: epoch 0121, iter [00300, 00390], lr: 0.004000, loss: 1.0943
2023-07-01 23:33:55 - train: epoch 0121, iter [00350, 00390], lr: 0.004000, loss: 1.1979
2023-07-01 23:33:56 - train: epoch 121, train_loss: 1.2423
2023-07-01 23:33:58 - eval: epoch: 121, acc1: 41.120%, acc5: 69.510%, test_loss: 2.5356, per_image_load_time: 0.096ms, per_image_inference_time: 0.055ms
2023-07-01 23:33:59 - until epoch: 121, best_acc1: 41.120%
2023-07-01 23:33:59 - epoch 122 lr: 0.004000
2023-07-01 23:34:01 - train: epoch 0122, iter [00050, 00390], lr: 0.004000, loss: 1.1785
2023-07-01 23:34:03 - train: epoch 0122, iter [00100, 00390], lr: 0.004000, loss: 1.2235
2023-07-01 23:34:04 - train: epoch 0122, iter [00150, 00390], lr: 0.004000, loss: 1.2894
2023-07-01 23:34:06 - train: epoch 0122, iter [00200, 00390], lr: 0.004000, loss: 0.9789
2023-07-01 23:34:07 - train: epoch 0122, iter [00250, 00390], lr: 0.004000, loss: 1.0158
2023-07-01 23:34:08 - train: epoch 0122, iter [00300, 00390], lr: 0.004000, loss: 1.0890
2023-07-01 23:34:10 - train: epoch 0122, iter [00350, 00390], lr: 0.004000, loss: 1.1199
2023-07-01 23:34:11 - train: epoch 122, train_loss: 1.0820
2023-07-01 23:34:13 - eval: epoch: 122, acc1: 41.320%, acc5: 69.590%, test_loss: 2.5807, per_image_load_time: 0.099ms, per_image_inference_time: 0.053ms
2023-07-01 23:34:14 - until epoch: 122, best_acc1: 41.320%
2023-07-01 23:34:14 - epoch 123 lr: 0.004000
2023-07-01 23:34:16 - train: epoch 0123, iter [00050, 00390], lr: 0.004000, loss: 1.1166
2023-07-01 23:34:18 - train: epoch 0123, iter [00100, 00390], lr: 0.004000, loss: 1.0616
2023-07-01 23:34:19 - train: epoch 0123, iter [00150, 00390], lr: 0.004000, loss: 0.9936
2023-07-01 23:34:20 - train: epoch 0123, iter [00200, 00390], lr: 0.004000, loss: 1.1404
2023-07-01 23:34:22 - train: epoch 0123, iter [00250, 00390], lr: 0.004000, loss: 1.2218
2023-07-01 23:34:23 - train: epoch 0123, iter [00300, 00390], lr: 0.004000, loss: 0.9564
2023-07-01 23:34:25 - train: epoch 0123, iter [00350, 00390], lr: 0.004000, loss: 0.7587
2023-07-01 23:34:26 - train: epoch 123, train_loss: 1.0160
2023-07-01 23:34:27 - eval: epoch: 123, acc1: 41.020%, acc5: 69.470%, test_loss: 2.6230, per_image_load_time: 0.098ms, per_image_inference_time: 0.054ms
2023-07-01 23:34:28 - until epoch: 123, best_acc1: 41.320%
2023-07-01 23:34:28 - epoch 124 lr: 0.004000
2023-07-01 23:34:30 - train: epoch 0124, iter [00050, 00390], lr: 0.004000, loss: 0.8794
2023-07-01 23:34:32 - train: epoch 0124, iter [00100, 00390], lr: 0.004000, loss: 1.1384
2023-07-01 23:34:33 - train: epoch 0124, iter [00150, 00390], lr: 0.004000, loss: 0.8622
2023-07-01 23:34:34 - train: epoch 0124, iter [00200, 00390], lr: 0.004000, loss: 1.2074
2023-07-01 23:34:36 - train: epoch 0124, iter [00250, 00390], lr: 0.004000, loss: 1.0942
2023-07-01 23:34:37 - train: epoch 0124, iter [00300, 00390], lr: 0.004000, loss: 0.8408
2023-07-01 23:34:38 - train: epoch 0124, iter [00350, 00390], lr: 0.004000, loss: 1.0246
2023-07-01 23:34:40 - train: epoch 124, train_loss: 0.9748
2023-07-01 23:34:41 - eval: epoch: 124, acc1: 40.870%, acc5: 69.110%, test_loss: 2.6587, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:34:42 - until epoch: 124, best_acc1: 41.320%
2023-07-01 23:34:42 - epoch 125 lr: 0.004000
2023-07-01 23:34:44 - train: epoch 0125, iter [00050, 00390], lr: 0.004000, loss: 0.9915
2023-07-01 23:34:46 - train: epoch 0125, iter [00100, 00390], lr: 0.004000, loss: 0.8877
2023-07-01 23:34:47 - train: epoch 0125, iter [00150, 00390], lr: 0.004000, loss: 1.0989
2023-07-01 23:34:48 - train: epoch 0125, iter [00200, 00390], lr: 0.004000, loss: 1.0246
2023-07-01 23:34:50 - train: epoch 0125, iter [00250, 00390], lr: 0.004000, loss: 0.8403
2023-07-01 23:34:51 - train: epoch 0125, iter [00300, 00390], lr: 0.004000, loss: 1.0876
2023-07-01 23:34:53 - train: epoch 0125, iter [00350, 00390], lr: 0.004000, loss: 1.0314
2023-07-01 23:34:54 - train: epoch 125, train_loss: 0.9378
2023-07-01 23:34:55 - eval: epoch: 125, acc1: 41.200%, acc5: 68.970%, test_loss: 2.6980, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:34:56 - until epoch: 125, best_acc1: 41.320%
2023-07-01 23:34:56 - epoch 126 lr: 0.004000
2023-07-01 23:34:58 - train: epoch 0126, iter [00050, 00390], lr: 0.004000, loss: 0.7665
2023-07-01 23:35:00 - train: epoch 0126, iter [00100, 00390], lr: 0.004000, loss: 0.8126
2023-07-01 23:35:01 - train: epoch 0126, iter [00150, 00390], lr: 0.004000, loss: 0.8908
2023-07-01 23:35:03 - train: epoch 0126, iter [00200, 00390], lr: 0.004000, loss: 1.0364
2023-07-01 23:35:04 - train: epoch 0126, iter [00250, 00390], lr: 0.004000, loss: 0.8075
2023-07-01 23:35:05 - train: epoch 0126, iter [00300, 00390], lr: 0.004000, loss: 0.8799
2023-07-01 23:35:07 - train: epoch 0126, iter [00350, 00390], lr: 0.004000, loss: 0.9689
2023-07-01 23:35:08 - train: epoch 126, train_loss: 0.9101
2023-07-01 23:35:10 - eval: epoch: 126, acc1: 40.540%, acc5: 68.970%, test_loss: 2.7458, per_image_load_time: 0.095ms, per_image_inference_time: 0.055ms
2023-07-01 23:35:10 - until epoch: 126, best_acc1: 41.320%
2023-07-01 23:35:10 - epoch 127 lr: 0.004000
2023-07-01 23:35:12 - train: epoch 0127, iter [00050, 00390], lr: 0.004000, loss: 0.8027
2023-07-01 23:35:14 - train: epoch 0127, iter [00100, 00390], lr: 0.004000, loss: 0.8868
2023-07-01 23:35:16 - train: epoch 0127, iter [00150, 00390], lr: 0.004000, loss: 0.7620
2023-07-01 23:35:17 - train: epoch 0127, iter [00200, 00390], lr: 0.004000, loss: 0.8305
2023-07-01 23:35:19 - train: epoch 0127, iter [00250, 00390], lr: 0.004000, loss: 0.8125
2023-07-01 23:35:20 - train: epoch 0127, iter [00300, 00390], lr: 0.004000, loss: 1.0780
2023-07-01 23:35:22 - train: epoch 0127, iter [00350, 00390], lr: 0.004000, loss: 1.0333
2023-07-01 23:35:23 - train: epoch 127, train_loss: 0.8896
2023-07-01 23:35:25 - eval: epoch: 127, acc1: 40.350%, acc5: 68.500%, test_loss: 2.7765, per_image_load_time: 0.101ms, per_image_inference_time: 0.056ms
2023-07-01 23:35:25 - until epoch: 127, best_acc1: 41.320%
2023-07-01 23:35:25 - epoch 128 lr: 0.004000
2023-07-01 23:35:28 - train: epoch 0128, iter [00050, 00390], lr: 0.004000, loss: 0.8157
2023-07-01 23:35:29 - train: epoch 0128, iter [00100, 00390], lr: 0.004000, loss: 0.9454
2023-07-01 23:35:31 - train: epoch 0128, iter [00150, 00390], lr: 0.004000, loss: 0.8366
2023-07-01 23:35:32 - train: epoch 0128, iter [00200, 00390], lr: 0.004000, loss: 0.8690
2023-07-01 23:35:34 - train: epoch 0128, iter [00250, 00390], lr: 0.004000, loss: 0.9486
2023-07-01 23:35:35 - train: epoch 0128, iter [00300, 00390], lr: 0.004000, loss: 0.7398
2023-07-01 23:35:37 - train: epoch 0128, iter [00350, 00390], lr: 0.004000, loss: 0.8896
2023-07-01 23:35:38 - train: epoch 128, train_loss: 0.8682
2023-07-01 23:35:40 - eval: epoch: 128, acc1: 40.500%, acc5: 68.370%, test_loss: 2.8038, per_image_load_time: 0.095ms, per_image_inference_time: 0.056ms
2023-07-01 23:35:40 - until epoch: 128, best_acc1: 41.320%
2023-07-01 23:35:40 - epoch 129 lr: 0.004000
2023-07-01 23:35:43 - train: epoch 0129, iter [00050, 00390], lr: 0.004000, loss: 0.6815
2023-07-01 23:35:44 - train: epoch 0129, iter [00100, 00390], lr: 0.004000, loss: 0.7348
2023-07-01 23:35:46 - train: epoch 0129, iter [00150, 00390], lr: 0.004000, loss: 0.7810
2023-07-01 23:35:47 - train: epoch 0129, iter [00200, 00390], lr: 0.004000, loss: 0.7154
2023-07-01 23:35:49 - train: epoch 0129, iter [00250, 00390], lr: 0.004000, loss: 0.8639
2023-07-01 23:35:50 - train: epoch 0129, iter [00300, 00390], lr: 0.004000, loss: 1.0329
2023-07-01 23:35:52 - train: epoch 0129, iter [00350, 00390], lr: 0.004000, loss: 0.8522
2023-07-01 23:35:53 - train: epoch 129, train_loss: 0.8531
2023-07-01 23:35:55 - eval: epoch: 129, acc1: 40.760%, acc5: 68.440%, test_loss: 2.8220, per_image_load_time: 0.094ms, per_image_inference_time: 0.056ms
2023-07-01 23:35:55 - until epoch: 129, best_acc1: 41.320%
2023-07-01 23:35:55 - epoch 130 lr: 0.004000
2023-07-01 23:35:58 - train: epoch 0130, iter [00050, 00390], lr: 0.004000, loss: 0.7785
2023-07-01 23:35:59 - train: epoch 0130, iter [00100, 00390], lr: 0.004000, loss: 0.8547
2023-07-01 23:36:00 - train: epoch 0130, iter [00150, 00390], lr: 0.004000, loss: 0.7525
2023-07-01 23:36:02 - train: epoch 0130, iter [00200, 00390], lr: 0.004000, loss: 0.8583
2023-07-01 23:36:03 - train: epoch 0130, iter [00250, 00390], lr: 0.004000, loss: 0.7569
2023-07-01 23:36:05 - train: epoch 0130, iter [00300, 00390], lr: 0.004000, loss: 0.8437
2023-07-01 23:36:06 - train: epoch 0130, iter [00350, 00390], lr: 0.004000, loss: 0.8282
2023-07-01 23:36:07 - train: epoch 130, train_loss: 0.8417
2023-07-01 23:36:09 - eval: epoch: 130, acc1: 40.260%, acc5: 68.060%, test_loss: 2.8667, per_image_load_time: 0.097ms, per_image_inference_time: 0.055ms
2023-07-01 23:36:09 - until epoch: 130, best_acc1: 41.320%
2023-07-01 23:36:09 - epoch 131 lr: 0.004000
2023-07-01 23:36:12 - train: epoch 0131, iter [00050, 00390], lr: 0.004000, loss: 0.7300
2023-07-01 23:36:13 - train: epoch 0131, iter [00100, 00390], lr: 0.004000, loss: 0.8247
2023-07-01 23:36:15 - train: epoch 0131, iter [00150, 00390], lr: 0.004000, loss: 0.6754
2023-07-01 23:36:16 - train: epoch 0131, iter [00200, 00390], lr: 0.004000, loss: 0.7232
2023-07-01 23:36:18 - train: epoch 0131, iter [00250, 00390], lr: 0.004000, loss: 0.7872
2023-07-01 23:36:19 - train: epoch 0131, iter [00300, 00390], lr: 0.004000, loss: 0.8067
2023-07-01 23:36:21 - train: epoch 0131, iter [00350, 00390], lr: 0.004000, loss: 0.9866
2023-07-01 23:36:22 - train: epoch 131, train_loss: 0.8241
2023-07-01 23:36:24 - eval: epoch: 131, acc1: 40.350%, acc5: 67.920%, test_loss: 2.8911, per_image_load_time: 0.100ms, per_image_inference_time: 0.053ms
2023-07-01 23:36:24 - until epoch: 131, best_acc1: 41.320%
2023-07-01 23:36:24 - epoch 132 lr: 0.004000
2023-07-01 23:36:27 - train: epoch 0132, iter [00050, 00390], lr: 0.004000, loss: 0.6938
2023-07-01 23:36:28 - train: epoch 0132, iter [00100, 00390], lr: 0.004000, loss: 0.8839
2023-07-01 23:36:29 - train: epoch 0132, iter [00150, 00390], lr: 0.004000, loss: 0.7463
2023-07-01 23:36:31 - train: epoch 0132, iter [00200, 00390], lr: 0.004000, loss: 0.7812
2023-07-01 23:36:32 - train: epoch 0132, iter [00250, 00390], lr: 0.004000, loss: 0.9678
2023-07-01 23:36:34 - train: epoch 0132, iter [00300, 00390], lr: 0.004000, loss: 0.6927
2023-07-01 23:36:35 - train: epoch 0132, iter [00350, 00390], lr: 0.004000, loss: 0.8791
2023-07-01 23:36:36 - train: epoch 132, train_loss: 0.8017
2023-07-01 23:36:38 - eval: epoch: 132, acc1: 40.290%, acc5: 68.580%, test_loss: 2.8880, per_image_load_time: 0.098ms, per_image_inference_time: 0.054ms
2023-07-01 23:36:38 - until epoch: 132, best_acc1: 41.320%
2023-07-01 23:36:38 - epoch 133 lr: 0.004000
2023-07-01 23:36:41 - train: epoch 0133, iter [00050, 00390], lr: 0.004000, loss: 0.5832
2023-07-01 23:36:42 - train: epoch 0133, iter [00100, 00390], lr: 0.004000, loss: 0.8407
2023-07-01 23:36:43 - train: epoch 0133, iter [00150, 00390], lr: 0.004000, loss: 0.7008
2023-07-01 23:36:45 - train: epoch 0133, iter [00200, 00390], lr: 0.004000, loss: 0.7410
2023-07-01 23:36:46 - train: epoch 0133, iter [00250, 00390], lr: 0.004000, loss: 0.7562
2023-07-01 23:36:48 - train: epoch 0133, iter [00300, 00390], lr: 0.004000, loss: 1.0399
2023-07-01 23:36:49 - train: epoch 0133, iter [00350, 00390], lr: 0.004000, loss: 0.9613
2023-07-01 23:36:50 - train: epoch 133, train_loss: 0.7944
2023-07-01 23:36:52 - eval: epoch: 133, acc1: 40.010%, acc5: 67.850%, test_loss: 2.9263, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:36:52 - until epoch: 133, best_acc1: 41.320%
2023-07-01 23:36:52 - epoch 134 lr: 0.004000
2023-07-01 23:36:55 - train: epoch 0134, iter [00050, 00390], lr: 0.004000, loss: 0.8872
2023-07-01 23:36:56 - train: epoch 0134, iter [00100, 00390], lr: 0.004000, loss: 0.6930
2023-07-01 23:36:58 - train: epoch 0134, iter [00150, 00390], lr: 0.004000, loss: 0.7587
2023-07-01 23:36:59 - train: epoch 0134, iter [00200, 00390], lr: 0.004000, loss: 0.7499
2023-07-01 23:37:01 - train: epoch 0134, iter [00250, 00390], lr: 0.004000, loss: 0.7058
2023-07-01 23:37:02 - train: epoch 0134, iter [00300, 00390], lr: 0.004000, loss: 0.8754
2023-07-01 23:37:03 - train: epoch 0134, iter [00350, 00390], lr: 0.004000, loss: 0.7660
2023-07-01 23:37:05 - train: epoch 134, train_loss: 0.7799
2023-07-01 23:37:06 - eval: epoch: 134, acc1: 40.440%, acc5: 68.140%, test_loss: 2.9356, per_image_load_time: 0.099ms, per_image_inference_time: 0.054ms
2023-07-01 23:37:07 - until epoch: 134, best_acc1: 41.320%
2023-07-01 23:37:07 - epoch 135 lr: 0.004000
2023-07-01 23:37:09 - train: epoch 0135, iter [00050, 00390], lr: 0.004000, loss: 0.7777
2023-07-01 23:37:11 - train: epoch 0135, iter [00100, 00390], lr: 0.004000, loss: 0.6981
2023-07-01 23:37:12 - train: epoch 0135, iter [00150, 00390], lr: 0.004000, loss: 0.7036
2023-07-01 23:37:13 - train: epoch 0135, iter [00200, 00390], lr: 0.004000, loss: 0.6940
2023-07-01 23:37:15 - train: epoch 0135, iter [00250, 00390], lr: 0.004000, loss: 0.8397
2023-07-01 23:37:16 - train: epoch 0135, iter [00300, 00390], lr: 0.004000, loss: 1.0162
2023-07-01 23:37:18 - train: epoch 0135, iter [00350, 00390], lr: 0.004000, loss: 0.6575
2023-07-01 23:37:19 - train: epoch 135, train_loss: 0.7599
2023-07-01 23:37:21 - eval: epoch: 135, acc1: 40.230%, acc5: 67.850%, test_loss: 2.9588, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:37:21 - until epoch: 135, best_acc1: 41.320%
2023-07-01 23:37:21 - epoch 136 lr: 0.004000
2023-07-01 23:37:23 - train: epoch 0136, iter [00050, 00390], lr: 0.004000, loss: 0.5294
2023-07-01 23:37:25 - train: epoch 0136, iter [00100, 00390], lr: 0.004000, loss: 0.5720
2023-07-01 23:37:26 - train: epoch 0136, iter [00150, 00390], lr: 0.004000, loss: 0.8822
2023-07-01 23:37:28 - train: epoch 0136, iter [00200, 00390], lr: 0.004000, loss: 0.7572
2023-07-01 23:37:29 - train: epoch 0136, iter [00250, 00390], lr: 0.004000, loss: 0.8075
2023-07-01 23:37:30 - train: epoch 0136, iter [00300, 00390], lr: 0.004000, loss: 0.7675
2023-07-01 23:37:32 - train: epoch 0136, iter [00350, 00390], lr: 0.004000, loss: 0.7030
2023-07-01 23:37:33 - train: epoch 136, train_loss: 0.7593
2023-07-01 23:37:35 - eval: epoch: 136, acc1: 39.950%, acc5: 67.930%, test_loss: 2.9754, per_image_load_time: 0.097ms, per_image_inference_time: 0.054ms
2023-07-01 23:37:35 - until epoch: 136, best_acc1: 41.320%
2023-07-01 23:37:35 - epoch 137 lr: 0.004000
2023-07-01 23:37:37 - train: epoch 0137, iter [00050, 00390], lr: 0.004000, loss: 0.6976
2023-07-01 23:37:39 - train: epoch 0137, iter [00100, 00390], lr: 0.004000, loss: 0.7752
2023-07-01 23:37:40 - train: epoch 0137, iter [00150, 00390], lr: 0.004000, loss: 0.6029
2023-07-01 23:37:42 - train: epoch 0137, iter [00200, 00390], lr: 0.004000, loss: 0.5692
2023-07-01 23:37:43 - train: epoch 0137, iter [00250, 00390], lr: 0.004000, loss: 0.6095
2023-07-01 23:37:45 - train: epoch 0137, iter [00300, 00390], lr: 0.004000, loss: 0.7655
2023-07-01 23:37:46 - train: epoch 0137, iter [00350, 00390], lr: 0.004000, loss: 0.8858
2023-07-01 23:37:48 - train: epoch 137, train_loss: 0.7488
2023-07-01 23:37:49 - eval: epoch: 137, acc1: 39.540%, acc5: 67.760%, test_loss: 3.0197, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:37:50 - until epoch: 137, best_acc1: 41.320%
2023-07-01 23:37:50 - epoch 138 lr: 0.004000
2023-07-01 23:37:52 - train: epoch 0138, iter [00050, 00390], lr: 0.004000, loss: 0.6727
2023-07-01 23:37:53 - train: epoch 0138, iter [00100, 00390], lr: 0.004000, loss: 0.5405
2023-07-01 23:37:55 - train: epoch 0138, iter [00150, 00390], lr: 0.004000, loss: 0.7202
2023-07-01 23:37:56 - train: epoch 0138, iter [00200, 00390], lr: 0.004000, loss: 0.9872
2023-07-01 23:37:58 - train: epoch 0138, iter [00250, 00390], lr: 0.004000, loss: 0.7439
2023-07-01 23:37:59 - train: epoch 0138, iter [00300, 00390], lr: 0.004000, loss: 0.7612
2023-07-01 23:38:00 - train: epoch 0138, iter [00350, 00390], lr: 0.004000, loss: 0.8769
2023-07-01 23:38:02 - train: epoch 138, train_loss: 0.7444
2023-07-01 23:38:03 - eval: epoch: 138, acc1: 39.630%, acc5: 67.760%, test_loss: 3.0273, per_image_load_time: 0.097ms, per_image_inference_time: 0.053ms
2023-07-01 23:38:04 - until epoch: 138, best_acc1: 41.320%
2023-07-01 23:38:04 - epoch 139 lr: 0.004000
2023-07-01 23:38:06 - train: epoch 0139, iter [00050, 00390], lr: 0.004000, loss: 0.6678
2023-07-01 23:38:08 - train: epoch 0139, iter [00100, 00390], lr: 0.004000, loss: 0.5778
2023-07-01 23:38:09 - train: epoch 0139, iter [00150, 00390], lr: 0.004000, loss: 0.7336
2023-07-01 23:38:11 - train: epoch 0139, iter [00200, 00390], lr: 0.004000, loss: 0.7869
2023-07-01 23:38:12 - train: epoch 0139, iter [00250, 00390], lr: 0.004000, loss: 0.7931
2023-07-01 23:38:14 - train: epoch 0139, iter [00300, 00390], lr: 0.004000, loss: 0.7389
2023-07-01 23:38:15 - train: epoch 0139, iter [00350, 00390], lr: 0.004000, loss: 0.7606
2023-07-01 23:38:16 - train: epoch 139, train_loss: 0.7345
2023-07-01 23:38:18 - eval: epoch: 139, acc1: 39.220%, acc5: 67.710%, test_loss: 3.0596, per_image_load_time: 0.098ms, per_image_inference_time: 0.054ms
2023-07-01 23:38:18 - until epoch: 139, best_acc1: 41.320%
2023-07-01 23:38:18 - epoch 140 lr: 0.004000
2023-07-01 23:38:21 - train: epoch 0140, iter [00050, 00390], lr: 0.004000, loss: 0.6125
2023-07-01 23:38:22 - train: epoch 0140, iter [00100, 00390], lr: 0.004000, loss: 0.5478
2023-07-01 23:38:24 - train: epoch 0140, iter [00150, 00390], lr: 0.004000, loss: 0.7472
2023-07-01 23:38:25 - train: epoch 0140, iter [00200, 00390], lr: 0.004000, loss: 0.8815
2023-07-01 23:38:27 - train: epoch 0140, iter [00250, 00390], lr: 0.004000, loss: 0.8762
2023-07-01 23:38:28 - train: epoch 0140, iter [00300, 00390], lr: 0.004000, loss: 0.7215
2023-07-01 23:38:30 - train: epoch 0140, iter [00350, 00390], lr: 0.004000, loss: 0.7942
2023-07-01 23:38:31 - train: epoch 140, train_loss: 0.7266
2023-07-01 23:38:33 - eval: epoch: 140, acc1: 39.720%, acc5: 67.530%, test_loss: 3.0818, per_image_load_time: 0.096ms, per_image_inference_time: 0.055ms
2023-07-01 23:38:33 - until epoch: 140, best_acc1: 41.320%
2023-07-01 23:38:33 - epoch 141 lr: 0.004000
2023-07-01 23:38:36 - train: epoch 0141, iter [00050, 00390], lr: 0.004000, loss: 0.6632
2023-07-01 23:38:37 - train: epoch 0141, iter [00100, 00390], lr: 0.004000, loss: 0.8717
2023-07-01 23:38:39 - train: epoch 0141, iter [00150, 00390], lr: 0.004000, loss: 0.7536
2023-07-01 23:38:40 - train: epoch 0141, iter [00200, 00390], lr: 0.004000, loss: 0.7391
2023-07-01 23:38:42 - train: epoch 0141, iter [00250, 00390], lr: 0.004000, loss: 0.7725
2023-07-01 23:38:43 - train: epoch 0141, iter [00300, 00390], lr: 0.004000, loss: 0.5927
2023-07-01 23:38:45 - train: epoch 0141, iter [00350, 00390], lr: 0.004000, loss: 0.9544
2023-07-01 23:38:46 - train: epoch 141, train_loss: 0.7228
2023-07-01 23:38:48 - eval: epoch: 141, acc1: 39.350%, acc5: 67.560%, test_loss: 3.1004, per_image_load_time: 0.097ms, per_image_inference_time: 0.057ms
2023-07-01 23:38:48 - until epoch: 141, best_acc1: 41.320%
2023-07-01 23:38:48 - epoch 142 lr: 0.004000
2023-07-01 23:38:50 - train: epoch 0142, iter [00050, 00390], lr: 0.004000, loss: 0.6234
2023-07-01 23:38:52 - train: epoch 0142, iter [00100, 00390], lr: 0.004000, loss: 0.7831
2023-07-01 23:38:53 - train: epoch 0142, iter [00150, 00390], lr: 0.004000, loss: 0.6020
2023-07-01 23:38:54 - train: epoch 0142, iter [00200, 00390], lr: 0.004000, loss: 0.8052
2023-07-01 23:38:56 - train: epoch 0142, iter [00250, 00390], lr: 0.004000, loss: 0.6678
2023-07-01 23:38:57 - train: epoch 0142, iter [00300, 00390], lr: 0.004000, loss: 0.5573
2023-07-01 23:38:59 - train: epoch 0142, iter [00350, 00390], lr: 0.004000, loss: 0.7100
2023-07-01 23:39:00 - train: epoch 142, train_loss: 0.7140
2023-07-01 23:39:02 - eval: epoch: 142, acc1: 39.130%, acc5: 67.490%, test_loss: 3.1011, per_image_load_time: 0.096ms, per_image_inference_time: 0.053ms
2023-07-01 23:39:02 - until epoch: 142, best_acc1: 41.320%
2023-07-01 23:39:02 - epoch 143 lr: 0.004000
2023-07-01 23:39:05 - train: epoch 0143, iter [00050, 00390], lr: 0.004000, loss: 0.8034
2023-07-01 23:39:06 - train: epoch 0143, iter [00100, 00390], lr: 0.004000, loss: 0.5282
2023-07-01 23:39:08 - train: epoch 0143, iter [00150, 00390], lr: 0.004000, loss: 0.6422
2023-07-01 23:39:09 - train: epoch 0143, iter [00200, 00390], lr: 0.004000, loss: 0.6246
2023-07-01 23:39:11 - train: epoch 0143, iter [00250, 00390], lr: 0.004000, loss: 0.7032
2023-07-01 23:39:12 - train: epoch 0143, iter [00300, 00390], lr: 0.004000, loss: 0.8315
2023-07-01 23:39:13 - train: epoch 0143, iter [00350, 00390], lr: 0.004000, loss: 0.6768
2023-07-01 23:39:15 - train: epoch 143, train_loss: 0.7091
2023-07-01 23:39:16 - eval: epoch: 143, acc1: 39.560%, acc5: 67.350%, test_loss: 3.1436, per_image_load_time: 0.097ms, per_image_inference_time: 0.053ms
2023-07-01 23:39:17 - until epoch: 143, best_acc1: 41.320%
2023-07-01 23:39:17 - epoch 144 lr: 0.004000
2023-07-01 23:39:19 - train: epoch 0144, iter [00050, 00390], lr: 0.004000, loss: 0.6736
2023-07-01 23:39:21 - train: epoch 0144, iter [00100, 00390], lr: 0.004000, loss: 0.6063
2023-07-01 23:39:22 - train: epoch 0144, iter [00150, 00390], lr: 0.004000, loss: 0.7846
2023-07-01 23:39:23 - train: epoch 0144, iter [00200, 00390], lr: 0.004000, loss: 0.8452
2023-07-01 23:39:25 - train: epoch 0144, iter [00250, 00390], lr: 0.004000, loss: 0.8158
2023-07-01 23:39:26 - train: epoch 0144, iter [00300, 00390], lr: 0.004000, loss: 0.8439
2023-07-01 23:39:27 - train: epoch 0144, iter [00350, 00390], lr: 0.004000, loss: 0.5370
2023-07-01 23:39:29 - train: epoch 144, train_loss: 0.7024
2023-07-01 23:39:30 - eval: epoch: 144, acc1: 38.890%, acc5: 67.380%, test_loss: 3.1317, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:39:31 - until epoch: 144, best_acc1: 41.320%
2023-07-01 23:39:31 - epoch 145 lr: 0.004000
2023-07-01 23:39:33 - train: epoch 0145, iter [00050, 00390], lr: 0.004000, loss: 0.5907
2023-07-01 23:39:34 - train: epoch 0145, iter [00100, 00390], lr: 0.004000, loss: 0.6673
2023-07-01 23:39:36 - train: epoch 0145, iter [00150, 00390], lr: 0.004000, loss: 0.7492
2023-07-01 23:39:37 - train: epoch 0145, iter [00200, 00390], lr: 0.004000, loss: 0.7358
2023-07-01 23:39:39 - train: epoch 0145, iter [00250, 00390], lr: 0.004000, loss: 0.7127
2023-07-01 23:39:40 - train: epoch 0145, iter [00300, 00390], lr: 0.004000, loss: 0.7097
2023-07-01 23:39:41 - train: epoch 0145, iter [00350, 00390], lr: 0.004000, loss: 0.7930
2023-07-01 23:39:42 - train: epoch 145, train_loss: 0.6967
2023-07-01 23:39:44 - eval: epoch: 145, acc1: 39.660%, acc5: 67.550%, test_loss: 3.1330, per_image_load_time: 0.095ms, per_image_inference_time: 0.060ms
2023-07-01 23:39:44 - until epoch: 145, best_acc1: 41.320%
2023-07-01 23:39:44 - epoch 146 lr: 0.004000
2023-07-01 23:39:47 - train: epoch 0146, iter [00050, 00390], lr: 0.004000, loss: 0.8066
2023-07-01 23:39:48 - train: epoch 0146, iter [00100, 00390], lr: 0.004000, loss: 0.6187
2023-07-01 23:39:50 - train: epoch 0146, iter [00150, 00390], lr: 0.004000, loss: 0.5598
2023-07-01 23:39:51 - train: epoch 0146, iter [00200, 00390], lr: 0.004000, loss: 0.6939
2023-07-01 23:39:52 - train: epoch 0146, iter [00250, 00390], lr: 0.004000, loss: 0.7259
2023-07-01 23:39:54 - train: epoch 0146, iter [00300, 00390], lr: 0.004000, loss: 0.6947
2023-07-01 23:39:55 - train: epoch 0146, iter [00350, 00390], lr: 0.004000, loss: 0.7364
2023-07-01 23:39:56 - train: epoch 146, train_loss: 0.6904
2023-07-01 23:39:58 - eval: epoch: 146, acc1: 39.180%, acc5: 67.500%, test_loss: 3.1500, per_image_load_time: 0.096ms, per_image_inference_time: 0.055ms
2023-07-01 23:39:58 - until epoch: 146, best_acc1: 41.320%
2023-07-01 23:39:58 - epoch 147 lr: 0.004000
2023-07-01 23:40:01 - train: epoch 0147, iter [00050, 00390], lr: 0.004000, loss: 0.4481
2023-07-01 23:40:02 - train: epoch 0147, iter [00100, 00390], lr: 0.004000, loss: 0.5655
2023-07-01 23:40:04 - train: epoch 0147, iter [00150, 00390], lr: 0.004000, loss: 0.7855
2023-07-01 23:40:05 - train: epoch 0147, iter [00200, 00390], lr: 0.004000, loss: 0.8223
2023-07-01 23:40:07 - train: epoch 0147, iter [00250, 00390], lr: 0.004000, loss: 0.7471
2023-07-01 23:40:08 - train: epoch 0147, iter [00300, 00390], lr: 0.004000, loss: 0.7428
2023-07-01 23:40:09 - train: epoch 0147, iter [00350, 00390], lr: 0.004000, loss: 0.6397
2023-07-01 23:40:10 - train: epoch 147, train_loss: 0.6826
2023-07-01 23:40:12 - eval: epoch: 147, acc1: 39.120%, acc5: 67.220%, test_loss: 3.1602, per_image_load_time: 0.093ms, per_image_inference_time: 0.053ms
2023-07-01 23:40:13 - until epoch: 147, best_acc1: 41.320%
2023-07-01 23:40:13 - epoch 148 lr: 0.004000
2023-07-01 23:40:15 - train: epoch 0148, iter [00050, 00390], lr: 0.004000, loss: 0.5959
2023-07-01 23:40:16 - train: epoch 0148, iter [00100, 00390], lr: 0.004000, loss: 0.6071
2023-07-01 23:40:18 - train: epoch 0148, iter [00150, 00390], lr: 0.004000, loss: 0.5531
2023-07-01 23:40:19 - train: epoch 0148, iter [00200, 00390], lr: 0.004000, loss: 0.5630
2023-07-01 23:40:20 - train: epoch 0148, iter [00250, 00390], lr: 0.004000, loss: 0.6754
2023-07-01 23:40:22 - train: epoch 0148, iter [00300, 00390], lr: 0.004000, loss: 0.6144
2023-07-01 23:40:23 - train: epoch 0148, iter [00350, 00390], lr: 0.004000, loss: 0.6131
2023-07-01 23:40:24 - train: epoch 148, train_loss: 0.6762
2023-07-01 23:40:26 - eval: epoch: 148, acc1: 39.020%, acc5: 67.330%, test_loss: 3.1936, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:40:26 - until epoch: 148, best_acc1: 41.320%
2023-07-01 23:40:26 - epoch 149 lr: 0.004000
2023-07-01 23:40:29 - train: epoch 0149, iter [00050, 00390], lr: 0.004000, loss: 0.6581
2023-07-01 23:40:30 - train: epoch 0149, iter [00100, 00390], lr: 0.004000, loss: 0.5680
2023-07-01 23:40:32 - train: epoch 0149, iter [00150, 00390], lr: 0.004000, loss: 0.6938
2023-07-01 23:40:33 - train: epoch 0149, iter [00200, 00390], lr: 0.004000, loss: 0.7473
2023-07-01 23:40:34 - train: epoch 0149, iter [00250, 00390], lr: 0.004000, loss: 0.8715
2023-07-01 23:40:36 - train: epoch 0149, iter [00300, 00390], lr: 0.004000, loss: 0.5937
2023-07-01 23:40:37 - train: epoch 0149, iter [00350, 00390], lr: 0.004000, loss: 0.7677
2023-07-01 23:40:38 - train: epoch 149, train_loss: 0.6665
2023-07-01 23:40:40 - eval: epoch: 149, acc1: 38.790%, acc5: 66.640%, test_loss: 3.2096, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:40:40 - until epoch: 149, best_acc1: 41.320%
2023-07-01 23:40:40 - epoch 150 lr: 0.004000
2023-07-01 23:40:43 - train: epoch 0150, iter [00050, 00390], lr: 0.004000, loss: 0.6556
2023-07-01 23:40:44 - train: epoch 0150, iter [00100, 00390], lr: 0.004000, loss: 0.5666
2023-07-01 23:40:45 - train: epoch 0150, iter [00150, 00390], lr: 0.004000, loss: 0.7664
2023-07-01 23:40:47 - train: epoch 0150, iter [00200, 00390], lr: 0.004000, loss: 0.5490
2023-07-01 23:40:48 - train: epoch 0150, iter [00250, 00390], lr: 0.004000, loss: 0.5812
2023-07-01 23:40:49 - train: epoch 0150, iter [00300, 00390], lr: 0.004000, loss: 0.7588
2023-07-01 23:40:51 - train: epoch 0150, iter [00350, 00390], lr: 0.004000, loss: 0.9277
2023-07-01 23:40:52 - train: epoch 150, train_loss: 0.6640
2023-07-01 23:40:54 - eval: epoch: 150, acc1: 38.780%, acc5: 67.220%, test_loss: 3.2319, per_image_load_time: 0.095ms, per_image_inference_time: 0.053ms
2023-07-01 23:40:54 - until epoch: 150, best_acc1: 41.320%
2023-07-01 23:40:54 - epoch 151 lr: 0.004000
2023-07-01 23:40:56 - train: epoch 0151, iter [00050, 00390], lr: 0.004000, loss: 0.5087
2023-07-01 23:40:58 - train: epoch 0151, iter [00100, 00390], lr: 0.004000, loss: 0.5358
2023-07-01 23:40:59 - train: epoch 0151, iter [00150, 00390], lr: 0.004000, loss: 0.5343
2023-07-01 23:41:00 - train: epoch 0151, iter [00200, 00390], lr: 0.004000, loss: 0.6440
2023-07-01 23:41:02 - train: epoch 0151, iter [00250, 00390], lr: 0.004000, loss: 0.7191
2023-07-01 23:41:03 - train: epoch 0151, iter [00300, 00390], lr: 0.004000, loss: 0.6757
2023-07-01 23:41:05 - train: epoch 0151, iter [00350, 00390], lr: 0.004000, loss: 0.6296
2023-07-01 23:41:06 - train: epoch 151, train_loss: 0.6582
2023-07-01 23:41:08 - eval: epoch: 151, acc1: 38.950%, acc5: 66.950%, test_loss: 3.2341, per_image_load_time: 0.094ms, per_image_inference_time: 0.053ms
2023-07-01 23:41:08 - until epoch: 151, best_acc1: 41.320%
2023-07-01 23:41:08 - epoch 152 lr: 0.004000
2023-07-01 23:41:10 - train: epoch 0152, iter [00050, 00390], lr: 0.004000, loss: 0.6968
2023-07-01 23:41:12 - train: epoch 0152, iter [00100, 00390], lr: 0.004000, loss: 0.5978
2023-07-01 23:41:13 - train: epoch 0152, iter [00150, 00390], lr: 0.004000, loss: 0.5622
2023-07-01 23:41:15 - train: epoch 0152, iter [00200, 00390], lr: 0.004000, loss: 0.5912
2023-07-01 23:41:16 - train: epoch 0152, iter [00250, 00390], lr: 0.004000, loss: 0.7165
2023-07-01 23:41:17 - train: epoch 0152, iter [00300, 00390], lr: 0.004000, loss: 0.7465
2023-07-01 23:41:19 - train: epoch 0152, iter [00350, 00390], lr: 0.004000, loss: 0.4886
2023-07-01 23:41:20 - train: epoch 152, train_loss: 0.6490
2023-07-01 23:41:21 - eval: epoch: 152, acc1: 38.530%, acc5: 67.000%, test_loss: 3.2707, per_image_load_time: 0.095ms, per_image_inference_time: 0.053ms
2023-07-01 23:41:22 - until epoch: 152, best_acc1: 41.320%
2023-07-01 23:41:22 - epoch 153 lr: 0.004000
2023-07-01 23:41:25 - train: epoch 0153, iter [00050, 00390], lr: 0.004000, loss: 0.5988
2023-07-01 23:41:26 - train: epoch 0153, iter [00100, 00390], lr: 0.004000, loss: 0.5568
2023-07-01 23:41:27 - train: epoch 0153, iter [00150, 00390], lr: 0.004000, loss: 0.6598
2023-07-01 23:41:29 - train: epoch 0153, iter [00200, 00390], lr: 0.004000, loss: 0.5578
2023-07-01 23:41:30 - train: epoch 0153, iter [00250, 00390], lr: 0.004000, loss: 0.6072
2023-07-01 23:41:31 - train: epoch 0153, iter [00300, 00390], lr: 0.004000, loss: 0.6233
2023-07-01 23:41:33 - train: epoch 0153, iter [00350, 00390], lr: 0.004000, loss: 0.7237
2023-07-01 23:41:34 - train: epoch 153, train_loss: 0.6424
2023-07-01 23:41:36 - eval: epoch: 153, acc1: 38.760%, acc5: 67.230%, test_loss: 3.2488, per_image_load_time: 0.096ms, per_image_inference_time: 0.053ms
2023-07-01 23:41:36 - until epoch: 153, best_acc1: 41.320%
2023-07-01 23:41:36 - epoch 154 lr: 0.004000
2023-07-01 23:41:38 - train: epoch 0154, iter [00050, 00390], lr: 0.004000, loss: 0.4350
2023-07-01 23:41:40 - train: epoch 0154, iter [00100, 00390], lr: 0.004000, loss: 0.4332
2023-07-01 23:41:41 - train: epoch 0154, iter [00150, 00390], lr: 0.004000, loss: 0.6103
2023-07-01 23:41:42 - train: epoch 0154, iter [00200, 00390], lr: 0.004000, loss: 0.6259
2023-07-01 23:41:44 - train: epoch 0154, iter [00250, 00390], lr: 0.004000, loss: 0.6012
2023-07-01 23:41:45 - train: epoch 0154, iter [00300, 00390], lr: 0.004000, loss: 0.7686
2023-07-01 23:41:47 - train: epoch 0154, iter [00350, 00390], lr: 0.004000, loss: 0.6598
2023-07-01 23:41:48 - train: epoch 154, train_loss: 0.6417
2023-07-01 23:41:49 - eval: epoch: 154, acc1: 38.660%, acc5: 67.160%, test_loss: 3.2870, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:41:50 - until epoch: 154, best_acc1: 41.320%
2023-07-01 23:41:50 - epoch 155 lr: 0.004000
2023-07-01 23:41:52 - train: epoch 0155, iter [00050, 00390], lr: 0.004000, loss: 0.6081
2023-07-01 23:41:54 - train: epoch 0155, iter [00100, 00390], lr: 0.004000, loss: 0.4719
2023-07-01 23:41:55 - train: epoch 0155, iter [00150, 00390], lr: 0.004000, loss: 0.4249
2023-07-01 23:41:57 - train: epoch 0155, iter [00200, 00390], lr: 0.004000, loss: 0.7300
2023-07-01 23:41:58 - train: epoch 0155, iter [00250, 00390], lr: 0.004000, loss: 0.6148
2023-07-01 23:41:59 - train: epoch 0155, iter [00300, 00390], lr: 0.004000, loss: 0.7440
2023-07-01 23:42:01 - train: epoch 0155, iter [00350, 00390], lr: 0.004000, loss: 0.7898
2023-07-01 23:42:02 - train: epoch 155, train_loss: 0.6344
2023-07-01 23:42:04 - eval: epoch: 155, acc1: 38.590%, acc5: 67.150%, test_loss: 3.2868, per_image_load_time: 0.100ms, per_image_inference_time: 0.053ms
2023-07-01 23:42:04 - until epoch: 155, best_acc1: 41.320%
2023-07-01 23:42:04 - epoch 156 lr: 0.004000
2023-07-01 23:42:06 - train: epoch 0156, iter [00050, 00390], lr: 0.004000, loss: 0.6301
2023-07-01 23:42:08 - train: epoch 0156, iter [00100, 00390], lr: 0.004000, loss: 0.5368
2023-07-01 23:42:09 - train: epoch 0156, iter [00150, 00390], lr: 0.004000, loss: 0.5654
2023-07-01 23:42:11 - train: epoch 0156, iter [00200, 00390], lr: 0.004000, loss: 0.5645
2023-07-01 23:42:12 - train: epoch 0156, iter [00250, 00390], lr: 0.004000, loss: 0.6640
2023-07-01 23:42:13 - train: epoch 0156, iter [00300, 00390], lr: 0.004000, loss: 0.6425
2023-07-01 23:42:15 - train: epoch 0156, iter [00350, 00390], lr: 0.004000, loss: 0.6147
2023-07-01 23:42:16 - train: epoch 156, train_loss: 0.6320
2023-07-01 23:42:17 - eval: epoch: 156, acc1: 39.000%, acc5: 67.330%, test_loss: 3.3273, per_image_load_time: 0.096ms, per_image_inference_time: 0.055ms
2023-07-01 23:42:18 - until epoch: 156, best_acc1: 41.320%
2023-07-01 23:42:18 - epoch 157 lr: 0.004000
2023-07-01 23:42:20 - train: epoch 0157, iter [00050, 00390], lr: 0.004000, loss: 0.3975
2023-07-01 23:42:22 - train: epoch 0157, iter [00100, 00390], lr: 0.004000, loss: 0.6392
2023-07-01 23:42:23 - train: epoch 0157, iter [00150, 00390], lr: 0.004000, loss: 0.8233
2023-07-01 23:42:25 - train: epoch 0157, iter [00200, 00390], lr: 0.004000, loss: 0.8078
2023-07-01 23:42:26 - train: epoch 0157, iter [00250, 00390], lr: 0.004000, loss: 0.5991
2023-07-01 23:42:27 - train: epoch 0157, iter [00300, 00390], lr: 0.004000, loss: 0.6992
2023-07-01 23:42:29 - train: epoch 0157, iter [00350, 00390], lr: 0.004000, loss: 0.6066
2023-07-01 23:42:30 - train: epoch 157, train_loss: 0.6272
2023-07-01 23:42:31 - eval: epoch: 157, acc1: 38.690%, acc5: 66.770%, test_loss: 3.3211, per_image_load_time: 0.094ms, per_image_inference_time: 0.053ms
2023-07-01 23:42:32 - until epoch: 157, best_acc1: 41.320%
2023-07-01 23:42:32 - epoch 158 lr: 0.004000
2023-07-01 23:42:35 - train: epoch 0158, iter [00050, 00390], lr: 0.004000, loss: 0.6397
2023-07-01 23:42:36 - train: epoch 0158, iter [00100, 00390], lr: 0.004000, loss: 0.7229
2023-07-01 23:42:38 - train: epoch 0158, iter [00150, 00390], lr: 0.004000, loss: 0.5385
2023-07-01 23:42:39 - train: epoch 0158, iter [00200, 00390], lr: 0.004000, loss: 0.5964
2023-07-01 23:42:40 - train: epoch 0158, iter [00250, 00390], lr: 0.004000, loss: 0.7541
2023-07-01 23:42:42 - train: epoch 0158, iter [00300, 00390], lr: 0.004000, loss: 0.5508
2023-07-01 23:42:43 - train: epoch 0158, iter [00350, 00390], lr: 0.004000, loss: 0.6940
2023-07-01 23:42:44 - train: epoch 158, train_loss: 0.6295
2023-07-01 23:42:46 - eval: epoch: 158, acc1: 38.390%, acc5: 67.090%, test_loss: 3.3268, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:42:47 - until epoch: 158, best_acc1: 41.320%
2023-07-01 23:42:47 - epoch 159 lr: 0.004000
2023-07-01 23:42:49 - train: epoch 0159, iter [00050, 00390], lr: 0.004000, loss: 0.5655
2023-07-01 23:42:50 - train: epoch 0159, iter [00100, 00390], lr: 0.004000, loss: 0.5977
2023-07-01 23:42:52 - train: epoch 0159, iter [00150, 00390], lr: 0.004000, loss: 0.5204
2023-07-01 23:42:53 - train: epoch 0159, iter [00200, 00390], lr: 0.004000, loss: 0.6841
2023-07-01 23:42:54 - train: epoch 0159, iter [00250, 00390], lr: 0.004000, loss: 0.6149
2023-07-01 23:42:56 - train: epoch 0159, iter [00300, 00390], lr: 0.004000, loss: 0.7326
2023-07-01 23:42:57 - train: epoch 0159, iter [00350, 00390], lr: 0.004000, loss: 0.8307
2023-07-01 23:42:58 - train: epoch 159, train_loss: 0.6153
2023-07-01 23:43:00 - eval: epoch: 159, acc1: 38.800%, acc5: 67.050%, test_loss: 3.3274, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:43:01 - until epoch: 159, best_acc1: 41.320%
2023-07-01 23:43:01 - epoch 160 lr: 0.004000
2023-07-01 23:43:03 - train: epoch 0160, iter [00050, 00390], lr: 0.004000, loss: 0.5781
2023-07-01 23:43:04 - train: epoch 0160, iter [00100, 00390], lr: 0.004000, loss: 0.5181
2023-07-01 23:43:06 - train: epoch 0160, iter [00150, 00390], lr: 0.004000, loss: 0.6335
2023-07-01 23:43:07 - train: epoch 0160, iter [00200, 00390], lr: 0.004000, loss: 0.5474
2023-07-01 23:43:09 - train: epoch 0160, iter [00250, 00390], lr: 0.004000, loss: 0.6975
2023-07-01 23:43:10 - train: epoch 0160, iter [00300, 00390], lr: 0.004000, loss: 0.7300
2023-07-01 23:43:11 - train: epoch 0160, iter [00350, 00390], lr: 0.004000, loss: 0.7445
2023-07-01 23:43:12 - train: epoch 160, train_loss: 0.6129
2023-07-01 23:43:14 - eval: epoch: 160, acc1: 38.710%, acc5: 66.850%, test_loss: 3.3343, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:43:15 - until epoch: 160, best_acc1: 41.320%
2023-07-01 23:43:15 - epoch 161 lr: 0.000800
2023-07-01 23:43:17 - train: epoch 0161, iter [00050, 00390], lr: 0.000800, loss: 0.4401
2023-07-01 23:43:19 - train: epoch 0161, iter [00100, 00390], lr: 0.000800, loss: 0.4530
2023-07-01 23:43:20 - train: epoch 0161, iter [00150, 00390], lr: 0.000800, loss: 0.3983
2023-07-01 23:43:21 - train: epoch 0161, iter [00200, 00390], lr: 0.000800, loss: 0.5318
2023-07-01 23:43:23 - train: epoch 0161, iter [00250, 00390], lr: 0.000800, loss: 0.3707
2023-07-01 23:43:24 - train: epoch 0161, iter [00300, 00390], lr: 0.000800, loss: 0.3420
2023-07-01 23:43:25 - train: epoch 0161, iter [00350, 00390], lr: 0.000800, loss: 0.3731
2023-07-01 23:43:27 - train: epoch 161, train_loss: 0.4366
2023-07-01 23:43:28 - eval: epoch: 161, acc1: 40.310%, acc5: 67.910%, test_loss: 3.2594, per_image_load_time: 0.093ms, per_image_inference_time: 0.054ms
2023-07-01 23:43:28 - until epoch: 161, best_acc1: 41.320%
2023-07-01 23:43:28 - epoch 162 lr: 0.000800
2023-07-01 23:43:31 - train: epoch 0162, iter [00050, 00390], lr: 0.000800, loss: 0.5718
2023-07-01 23:43:32 - train: epoch 0162, iter [00100, 00390], lr: 0.000800, loss: 0.4449
2023-07-01 23:43:34 - train: epoch 0162, iter [00150, 00390], lr: 0.000800, loss: 0.4490
2023-07-01 23:43:35 - train: epoch 0162, iter [00200, 00390], lr: 0.000800, loss: 0.3458
2023-07-01 23:43:36 - train: epoch 0162, iter [00250, 00390], lr: 0.000800, loss: 0.4191
2023-07-01 23:43:38 - train: epoch 0162, iter [00300, 00390], lr: 0.000800, loss: 0.3514
2023-07-01 23:43:39 - train: epoch 0162, iter [00350, 00390], lr: 0.000800, loss: 0.3920
2023-07-01 23:43:40 - train: epoch 162, train_loss: 0.3777
2023-07-01 23:43:42 - eval: epoch: 162, acc1: 39.930%, acc5: 67.720%, test_loss: 3.2762, per_image_load_time: 0.096ms, per_image_inference_time: 0.072ms
2023-07-01 23:43:43 - until epoch: 162, best_acc1: 41.320%
2023-07-01 23:43:43 - epoch 163 lr: 0.000800
2023-07-01 23:43:46 - train: epoch 0163, iter [00050, 00390], lr: 0.000800, loss: 0.3405
2023-07-01 23:43:47 - train: epoch 0163, iter [00100, 00390], lr: 0.000800, loss: 0.3635
2023-07-01 23:43:49 - train: epoch 0163, iter [00150, 00390], lr: 0.000800, loss: 0.3727
2023-07-01 23:43:50 - train: epoch 0163, iter [00200, 00390], lr: 0.000800, loss: 0.3054
2023-07-01 23:43:52 - train: epoch 0163, iter [00250, 00390], lr: 0.000800, loss: 0.3292
2023-07-01 23:43:53 - train: epoch 0163, iter [00300, 00390], lr: 0.000800, loss: 0.4366
2023-07-01 23:43:55 - train: epoch 0163, iter [00350, 00390], lr: 0.000800, loss: 0.4131
2023-07-01 23:43:56 - train: epoch 163, train_loss: 0.3525
2023-07-01 23:43:58 - eval: epoch: 163, acc1: 40.210%, acc5: 67.560%, test_loss: 3.2860, per_image_load_time: 0.095ms, per_image_inference_time: 0.055ms
2023-07-01 23:43:58 - until epoch: 163, best_acc1: 41.320%
2023-07-01 23:43:58 - epoch 164 lr: 0.000800
2023-07-01 23:44:00 - train: epoch 0164, iter [00050, 00390], lr: 0.000800, loss: 0.3975
2023-07-01 23:44:02 - train: epoch 0164, iter [00100, 00390], lr: 0.000800, loss: 0.3396
2023-07-01 23:44:03 - train: epoch 0164, iter [00150, 00390], lr: 0.000800, loss: 0.3945
2023-07-01 23:44:04 - train: epoch 0164, iter [00200, 00390], lr: 0.000800, loss: 0.2356
2023-07-01 23:44:06 - train: epoch 0164, iter [00250, 00390], lr: 0.000800, loss: 0.3174
2023-07-01 23:44:07 - train: epoch 0164, iter [00300, 00390], lr: 0.000800, loss: 0.5251
2023-07-01 23:44:09 - train: epoch 0164, iter [00350, 00390], lr: 0.000800, loss: 0.3666
2023-07-01 23:44:10 - train: epoch 164, train_loss: 0.3396
2023-07-01 23:44:11 - eval: epoch: 164, acc1: 40.060%, acc5: 67.500%, test_loss: 3.3011, per_image_load_time: 0.093ms, per_image_inference_time: 0.054ms
2023-07-01 23:44:12 - until epoch: 164, best_acc1: 41.320%
2023-07-01 23:44:12 - epoch 165 lr: 0.000800
2023-07-01 23:44:14 - train: epoch 0165, iter [00050, 00390], lr: 0.000800, loss: 0.4530
2023-07-01 23:44:16 - train: epoch 0165, iter [00100, 00390], lr: 0.000800, loss: 0.2928
2023-07-01 23:44:17 - train: epoch 0165, iter [00150, 00390], lr: 0.000800, loss: 0.3813
2023-07-01 23:44:18 - train: epoch 0165, iter [00200, 00390], lr: 0.000800, loss: 0.2926
2023-07-01 23:44:20 - train: epoch 0165, iter [00250, 00390], lr: 0.000800, loss: 0.2444
2023-07-01 23:44:21 - train: epoch 0165, iter [00300, 00390], lr: 0.000800, loss: 0.3335
2023-07-01 23:44:23 - train: epoch 0165, iter [00350, 00390], lr: 0.000800, loss: 0.3358
2023-07-01 23:44:24 - train: epoch 165, train_loss: 0.3220
2023-07-01 23:44:25 - eval: epoch: 165, acc1: 40.170%, acc5: 67.360%, test_loss: 3.3192, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:44:26 - until epoch: 165, best_acc1: 41.320%
2023-07-01 23:44:26 - epoch 166 lr: 0.000800
2023-07-01 23:44:28 - train: epoch 0166, iter [00050, 00390], lr: 0.000800, loss: 0.3111
2023-07-01 23:44:30 - train: epoch 0166, iter [00100, 00390], lr: 0.000800, loss: 0.2934
2023-07-01 23:44:31 - train: epoch 0166, iter [00150, 00390], lr: 0.000800, loss: 0.3816
2023-07-01 23:44:33 - train: epoch 0166, iter [00200, 00390], lr: 0.000800, loss: 0.3526
2023-07-01 23:44:34 - train: epoch 0166, iter [00250, 00390], lr: 0.000800, loss: 0.3161
2023-07-01 23:44:35 - train: epoch 0166, iter [00300, 00390], lr: 0.000800, loss: 0.2308
2023-07-01 23:44:37 - train: epoch 0166, iter [00350, 00390], lr: 0.000800, loss: 0.3241
2023-07-01 23:44:38 - train: epoch 166, train_loss: 0.3139
2023-07-01 23:44:40 - eval: epoch: 166, acc1: 39.940%, acc5: 67.290%, test_loss: 3.3377, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:44:40 - until epoch: 166, best_acc1: 41.320%
2023-07-01 23:44:40 - epoch 167 lr: 0.000800
2023-07-01 23:44:42 - train: epoch 0167, iter [00050, 00390], lr: 0.000800, loss: 0.2435
2023-07-01 23:44:44 - train: epoch 0167, iter [00100, 00390], lr: 0.000800, loss: 0.2001
2023-07-01 23:44:45 - train: epoch 0167, iter [00150, 00390], lr: 0.000800, loss: 0.3437
2023-07-01 23:44:46 - train: epoch 0167, iter [00200, 00390], lr: 0.000800, loss: 0.2565
2023-07-01 23:44:48 - train: epoch 0167, iter [00250, 00390], lr: 0.000800, loss: 0.2287
2023-07-01 23:44:49 - train: epoch 0167, iter [00300, 00390], lr: 0.000800, loss: 0.5181
2023-07-01 23:44:51 - train: epoch 0167, iter [00350, 00390], lr: 0.000800, loss: 0.3200
2023-07-01 23:44:52 - train: epoch 167, train_loss: 0.3094
2023-07-01 23:44:54 - eval: epoch: 167, acc1: 39.890%, acc5: 67.600%, test_loss: 3.3353, per_image_load_time: 0.098ms, per_image_inference_time: 0.054ms
2023-07-01 23:44:54 - until epoch: 167, best_acc1: 41.320%
2023-07-01 23:44:54 - epoch 168 lr: 0.000800
2023-07-01 23:44:57 - train: epoch 0168, iter [00050, 00390], lr: 0.000800, loss: 0.2656
2023-07-01 23:44:58 - train: epoch 0168, iter [00100, 00390], lr: 0.000800, loss: 0.4359
2023-07-01 23:45:00 - train: epoch 0168, iter [00150, 00390], lr: 0.000800, loss: 0.3305
2023-07-01 23:45:01 - train: epoch 0168, iter [00200, 00390], lr: 0.000800, loss: 0.3181
2023-07-01 23:45:02 - train: epoch 0168, iter [00250, 00390], lr: 0.000800, loss: 0.3339
2023-07-01 23:45:04 - train: epoch 0168, iter [00300, 00390], lr: 0.000800, loss: 0.2332
2023-07-01 23:45:05 - train: epoch 0168, iter [00350, 00390], lr: 0.000800, loss: 0.2913
2023-07-01 23:45:06 - train: epoch 168, train_loss: 0.2979
2023-07-01 23:45:08 - eval: epoch: 168, acc1: 39.940%, acc5: 67.490%, test_loss: 3.3596, per_image_load_time: 0.098ms, per_image_inference_time: 0.055ms
2023-07-01 23:45:09 - until epoch: 168, best_acc1: 41.320%
2023-07-01 23:45:09 - epoch 169 lr: 0.000800
2023-07-01 23:45:11 - train: epoch 0169, iter [00050, 00390], lr: 0.000800, loss: 0.3777
2023-07-01 23:45:12 - train: epoch 0169, iter [00100, 00390], lr: 0.000800, loss: 0.1946
2023-07-01 23:45:14 - train: epoch 0169, iter [00150, 00390], lr: 0.000800, loss: 0.3316
2023-07-01 23:45:15 - train: epoch 0169, iter [00200, 00390], lr: 0.000800, loss: 0.2423
2023-07-01 23:45:17 - train: epoch 0169, iter [00250, 00390], lr: 0.000800, loss: 0.3250
2023-07-01 23:45:18 - train: epoch 0169, iter [00300, 00390], lr: 0.000800, loss: 0.2954
2023-07-01 23:45:19 - train: epoch 0169, iter [00350, 00390], lr: 0.000800, loss: 0.2874
2023-07-01 23:45:20 - train: epoch 169, train_loss: 0.2966
2023-07-01 23:45:22 - eval: epoch: 169, acc1: 39.600%, acc5: 67.290%, test_loss: 3.3760, per_image_load_time: 0.095ms, per_image_inference_time: 0.055ms
2023-07-01 23:45:23 - until epoch: 169, best_acc1: 41.320%
2023-07-01 23:45:23 - epoch 170 lr: 0.000800
2023-07-01 23:45:25 - train: epoch 0170, iter [00050, 00390], lr: 0.000800, loss: 0.3214
2023-07-01 23:45:26 - train: epoch 0170, iter [00100, 00390], lr: 0.000800, loss: 0.2854
2023-07-01 23:45:28 - train: epoch 0170, iter [00150, 00390], lr: 0.000800, loss: 0.1855
2023-07-01 23:45:29 - train: epoch 0170, iter [00200, 00390], lr: 0.000800, loss: 0.3216
2023-07-01 23:45:31 - train: epoch 0170, iter [00250, 00390], lr: 0.000800, loss: 0.3254
2023-07-01 23:45:32 - train: epoch 0170, iter [00300, 00390], lr: 0.000800, loss: 0.2426
2023-07-01 23:45:33 - train: epoch 0170, iter [00350, 00390], lr: 0.000800, loss: 0.3363
2023-07-01 23:45:35 - train: epoch 170, train_loss: 0.2911
2023-07-01 23:45:36 - eval: epoch: 170, acc1: 39.960%, acc5: 67.320%, test_loss: 3.3856, per_image_load_time: 0.097ms, per_image_inference_time: 0.054ms
2023-07-01 23:45:37 - until epoch: 170, best_acc1: 41.320%
2023-07-01 23:45:37 - epoch 171 lr: 0.000800
2023-07-01 23:45:39 - train: epoch 0171, iter [00050, 00390], lr: 0.000800, loss: 0.3052
2023-07-01 23:45:40 - train: epoch 0171, iter [00100, 00390], lr: 0.000800, loss: 0.2581
2023-07-01 23:45:42 - train: epoch 0171, iter [00150, 00390], lr: 0.000800, loss: 0.3189
2023-07-01 23:45:43 - train: epoch 0171, iter [00200, 00390], lr: 0.000800, loss: 0.2240
2023-07-01 23:45:45 - train: epoch 0171, iter [00250, 00390], lr: 0.000800, loss: 0.2863
2023-07-01 23:45:46 - train: epoch 0171, iter [00300, 00390], lr: 0.000800, loss: 0.3995
2023-07-01 23:45:47 - train: epoch 0171, iter [00350, 00390], lr: 0.000800, loss: 0.2986
2023-07-01 23:45:48 - train: epoch 171, train_loss: 0.2811
2023-07-01 23:45:50 - eval: epoch: 171, acc1: 40.070%, acc5: 67.300%, test_loss: 3.3908, per_image_load_time: 0.095ms, per_image_inference_time: 0.055ms
2023-07-01 23:45:50 - until epoch: 171, best_acc1: 41.320%
2023-07-01 23:45:50 - epoch 172 lr: 0.000800
2023-07-01 23:45:53 - train: epoch 0172, iter [00050, 00390], lr: 0.000800, loss: 0.2706
2023-07-01 23:45:54 - train: epoch 0172, iter [00100, 00390], lr: 0.000800, loss: 0.2569
2023-07-01 23:45:56 - train: epoch 0172, iter [00150, 00390], lr: 0.000800, loss: 0.2055
2023-07-01 23:45:58 - train: epoch 0172, iter [00200, 00390], lr: 0.000800, loss: 0.3536
2023-07-01 23:46:00 - train: epoch 0172, iter [00250, 00390], lr: 0.000800, loss: 0.2602
2023-07-01 23:46:01 - train: epoch 0172, iter [00300, 00390], lr: 0.000800, loss: 0.2717
2023-07-01 23:46:03 - train: epoch 0172, iter [00350, 00390], lr: 0.000800, loss: 0.2899
2023-07-01 23:46:04 - train: epoch 172, train_loss: 0.2830
2023-07-01 23:46:06 - eval: epoch: 172, acc1: 39.840%, acc5: 67.410%, test_loss: 3.3869, per_image_load_time: 0.098ms, per_image_inference_time: 0.054ms
2023-07-01 23:46:06 - until epoch: 172, best_acc1: 41.320%
2023-07-01 23:46:06 - epoch 173 lr: 0.000800
2023-07-01 23:46:08 - train: epoch 0173, iter [00050, 00390], lr: 0.000800, loss: 0.3151
2023-07-01 23:46:10 - train: epoch 0173, iter [00100, 00390], lr: 0.000800, loss: 0.3749
2023-07-01 23:46:11 - train: epoch 0173, iter [00150, 00390], lr: 0.000800, loss: 0.3264
2023-07-01 23:46:12 - train: epoch 0173, iter [00200, 00390], lr: 0.000800, loss: 0.2758
2023-07-01 23:46:14 - train: epoch 0173, iter [00250, 00390], lr: 0.000800, loss: 0.2460
2023-07-01 23:46:15 - train: epoch 0173, iter [00300, 00390], lr: 0.000800, loss: 0.2340
2023-07-01 23:46:17 - train: epoch 0173, iter [00350, 00390], lr: 0.000800, loss: 0.2972
2023-07-01 23:46:18 - train: epoch 173, train_loss: 0.2755
2023-07-01 23:46:19 - eval: epoch: 173, acc1: 39.790%, acc5: 67.200%, test_loss: 3.4103, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:46:20 - until epoch: 173, best_acc1: 41.320%
2023-07-01 23:46:20 - epoch 174 lr: 0.000800
2023-07-01 23:46:22 - train: epoch 0174, iter [00050, 00390], lr: 0.000800, loss: 0.2108
2023-07-01 23:46:24 - train: epoch 0174, iter [00100, 00390], lr: 0.000800, loss: 0.3288
2023-07-01 23:46:25 - train: epoch 0174, iter [00150, 00390], lr: 0.000800, loss: 0.2437
2023-07-01 23:46:26 - train: epoch 0174, iter [00200, 00390], lr: 0.000800, loss: 0.1894
2023-07-01 23:46:28 - train: epoch 0174, iter [00250, 00390], lr: 0.000800, loss: 0.2333
2023-07-01 23:46:29 - train: epoch 0174, iter [00300, 00390], lr: 0.000800, loss: 0.3208
2023-07-01 23:46:31 - train: epoch 0174, iter [00350, 00390], lr: 0.000800, loss: 0.2176
2023-07-01 23:46:32 - train: epoch 174, train_loss: 0.2642
2023-07-01 23:46:33 - eval: epoch: 174, acc1: 39.720%, acc5: 67.370%, test_loss: 3.4272, per_image_load_time: 0.097ms, per_image_inference_time: 0.052ms
2023-07-01 23:46:34 - until epoch: 174, best_acc1: 41.320%
2023-07-01 23:46:34 - epoch 175 lr: 0.000800
2023-07-01 23:46:36 - train: epoch 0175, iter [00050, 00390], lr: 0.000800, loss: 0.2656
2023-07-01 23:46:38 - train: epoch 0175, iter [00100, 00390], lr: 0.000800, loss: 0.3046
2023-07-01 23:46:39 - train: epoch 0175, iter [00150, 00390], lr: 0.000800, loss: 0.2598
2023-07-01 23:46:40 - train: epoch 0175, iter [00200, 00390], lr: 0.000800, loss: 0.3027
2023-07-01 23:46:42 - train: epoch 0175, iter [00250, 00390], lr: 0.000800, loss: 0.2512
2023-07-01 23:46:43 - train: epoch 0175, iter [00300, 00390], lr: 0.000800, loss: 0.3064
2023-07-01 23:46:45 - train: epoch 0175, iter [00350, 00390], lr: 0.000800, loss: 0.3384
2023-07-01 23:46:46 - train: epoch 175, train_loss: 0.2676
2023-07-01 23:46:47 - eval: epoch: 175, acc1: 39.700%, acc5: 67.090%, test_loss: 3.4405, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:46:48 - until epoch: 175, best_acc1: 41.320%
2023-07-01 23:46:48 - epoch 176 lr: 0.000800
2023-07-01 23:46:50 - train: epoch 0176, iter [00050, 00390], lr: 0.000800, loss: 0.3670
2023-07-01 23:46:52 - train: epoch 0176, iter [00100, 00390], lr: 0.000800, loss: 0.3355
2023-07-01 23:46:53 - train: epoch 0176, iter [00150, 00390], lr: 0.000800, loss: 0.2393
2023-07-01 23:46:54 - train: epoch 0176, iter [00200, 00390], lr: 0.000800, loss: 0.2145
2023-07-01 23:46:56 - train: epoch 0176, iter [00250, 00390], lr: 0.000800, loss: 0.2396
2023-07-01 23:46:57 - train: epoch 0176, iter [00300, 00390], lr: 0.000800, loss: 0.3161
2023-07-01 23:46:59 - train: epoch 0176, iter [00350, 00390], lr: 0.000800, loss: 0.1802
2023-07-01 23:47:00 - train: epoch 176, train_loss: 0.2682
2023-07-01 23:47:02 - eval: epoch: 176, acc1: 39.740%, acc5: 67.250%, test_loss: 3.4462, per_image_load_time: 0.121ms, per_image_inference_time: 0.053ms
2023-07-01 23:47:02 - until epoch: 176, best_acc1: 41.320%
2023-07-01 23:47:02 - epoch 177 lr: 0.000800
2023-07-01 23:47:05 - train: epoch 0177, iter [00050, 00390], lr: 0.000800, loss: 0.2149
2023-07-01 23:47:06 - train: epoch 0177, iter [00100, 00390], lr: 0.000800, loss: 0.2033
2023-07-01 23:47:08 - train: epoch 0177, iter [00150, 00390], lr: 0.000800, loss: 0.2701
2023-07-01 23:47:09 - train: epoch 0177, iter [00200, 00390], lr: 0.000800, loss: 0.2823
2023-07-01 23:47:10 - train: epoch 0177, iter [00250, 00390], lr: 0.000800, loss: 0.2443
2023-07-01 23:47:12 - train: epoch 0177, iter [00300, 00390], lr: 0.000800, loss: 0.2058
2023-07-01 23:47:13 - train: epoch 0177, iter [00350, 00390], lr: 0.000800, loss: 0.2260
2023-07-01 23:47:14 - train: epoch 177, train_loss: 0.2537
2023-07-01 23:47:16 - eval: epoch: 177, acc1: 39.760%, acc5: 67.230%, test_loss: 3.4702, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:47:16 - until epoch: 177, best_acc1: 41.320%
2023-07-01 23:47:16 - epoch 178 lr: 0.000800
2023-07-01 23:47:19 - train: epoch 0178, iter [00050, 00390], lr: 0.000800, loss: 0.1989
2023-07-01 23:47:20 - train: epoch 0178, iter [00100, 00390], lr: 0.000800, loss: 0.2853
2023-07-01 23:47:22 - train: epoch 0178, iter [00150, 00390], lr: 0.000800, loss: 0.2373
2023-07-01 23:47:23 - train: epoch 0178, iter [00200, 00390], lr: 0.000800, loss: 0.2524
2023-07-01 23:47:24 - train: epoch 0178, iter [00250, 00390], lr: 0.000800, loss: 0.2820
2023-07-01 23:47:26 - train: epoch 0178, iter [00300, 00390], lr: 0.000800, loss: 0.1562
2023-07-01 23:47:27 - train: epoch 0178, iter [00350, 00390], lr: 0.000800, loss: 0.2763
2023-07-01 23:47:28 - train: epoch 178, train_loss: 0.2584
2023-07-01 23:47:30 - eval: epoch: 178, acc1: 39.740%, acc5: 67.410%, test_loss: 3.4624, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:47:30 - until epoch: 178, best_acc1: 41.320%
2023-07-01 23:47:30 - epoch 179 lr: 0.000800
2023-07-01 23:47:33 - train: epoch 0179, iter [00050, 00390], lr: 0.000800, loss: 0.1954
2023-07-01 23:47:34 - train: epoch 0179, iter [00100, 00390], lr: 0.000800, loss: 0.1953
2023-07-01 23:47:36 - train: epoch 0179, iter [00150, 00390], lr: 0.000800, loss: 0.3029
2023-07-01 23:47:37 - train: epoch 0179, iter [00200, 00390], lr: 0.000800, loss: 0.2509
2023-07-01 23:47:38 - train: epoch 0179, iter [00250, 00390], lr: 0.000800, loss: 0.1800
2023-07-01 23:47:40 - train: epoch 0179, iter [00300, 00390], lr: 0.000800, loss: 0.3150
2023-07-01 23:47:41 - train: epoch 0179, iter [00350, 00390], lr: 0.000800, loss: 0.3009
2023-07-01 23:47:42 - train: epoch 179, train_loss: 0.2561
2023-07-01 23:47:44 - eval: epoch: 179, acc1: 40.070%, acc5: 67.500%, test_loss: 3.4669, per_image_load_time: 0.093ms, per_image_inference_time: 0.054ms
2023-07-01 23:47:44 - until epoch: 179, best_acc1: 41.320%
2023-07-01 23:47:44 - epoch 180 lr: 0.000800
2023-07-01 23:47:47 - train: epoch 0180, iter [00050, 00390], lr: 0.000800, loss: 0.2302
2023-07-01 23:47:48 - train: epoch 0180, iter [00100, 00390], lr: 0.000800, loss: 0.1889
2023-07-01 23:47:50 - train: epoch 0180, iter [00150, 00390], lr: 0.000800, loss: 0.2868
2023-07-01 23:47:51 - train: epoch 0180, iter [00200, 00390], lr: 0.000800, loss: 0.2566
2023-07-01 23:47:52 - train: epoch 0180, iter [00250, 00390], lr: 0.000800, loss: 0.3267
2023-07-01 23:47:54 - train: epoch 0180, iter [00300, 00390], lr: 0.000800, loss: 0.2251
2023-07-01 23:47:55 - train: epoch 0180, iter [00350, 00390], lr: 0.000800, loss: 0.2563
2023-07-01 23:47:56 - train: epoch 180, train_loss: 0.2482
2023-07-01 23:47:58 - eval: epoch: 180, acc1: 39.750%, acc5: 67.200%, test_loss: 3.4871, per_image_load_time: 0.094ms, per_image_inference_time: 0.060ms
2023-07-01 23:47:58 - until epoch: 180, best_acc1: 41.320%
2023-07-01 23:47:58 - epoch 181 lr: 0.000800
2023-07-01 23:48:01 - train: epoch 0181, iter [00050, 00390], lr: 0.000800, loss: 0.2773
2023-07-01 23:48:02 - train: epoch 0181, iter [00100, 00390], lr: 0.000800, loss: 0.2297
2023-07-01 23:48:04 - train: epoch 0181, iter [00150, 00390], lr: 0.000800, loss: 0.1414
2023-07-01 23:48:05 - train: epoch 0181, iter [00200, 00390], lr: 0.000800, loss: 0.2171
2023-07-01 23:48:06 - train: epoch 0181, iter [00250, 00390], lr: 0.000800, loss: 0.2266
2023-07-01 23:48:08 - train: epoch 0181, iter [00300, 00390], lr: 0.000800, loss: 0.3038
2023-07-01 23:48:09 - train: epoch 0181, iter [00350, 00390], lr: 0.000800, loss: 0.2464
2023-07-01 23:48:10 - train: epoch 181, train_loss: 0.2502
2023-07-01 23:48:12 - eval: epoch: 181, acc1: 39.780%, acc5: 67.090%, test_loss: 3.4976, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:48:13 - until epoch: 181, best_acc1: 41.320%
2023-07-01 23:48:13 - epoch 182 lr: 0.000800
2023-07-01 23:48:15 - train: epoch 0182, iter [00050, 00390], lr: 0.000800, loss: 0.2749
2023-07-01 23:48:17 - train: epoch 0182, iter [00100, 00390], lr: 0.000800, loss: 0.3016
2023-07-01 23:48:18 - train: epoch 0182, iter [00150, 00390], lr: 0.000800, loss: 0.2327
2023-07-01 23:48:20 - train: epoch 0182, iter [00200, 00390], lr: 0.000800, loss: 0.2295
2023-07-01 23:48:21 - train: epoch 0182, iter [00250, 00390], lr: 0.000800, loss: 0.2612
2023-07-01 23:48:22 - train: epoch 0182, iter [00300, 00390], lr: 0.000800, loss: 0.2298
2023-07-01 23:48:24 - train: epoch 0182, iter [00350, 00390], lr: 0.000800, loss: 0.1841
2023-07-01 23:48:25 - train: epoch 182, train_loss: 0.2472
2023-07-01 23:48:26 - eval: epoch: 182, acc1: 39.790%, acc5: 67.040%, test_loss: 3.4983, per_image_load_time: 0.094ms, per_image_inference_time: 0.054ms
2023-07-01 23:48:27 - until epoch: 182, best_acc1: 41.320%
2023-07-01 23:48:27 - epoch 183 lr: 0.000800
2023-07-01 23:48:30 - train: epoch 0183, iter [00050, 00390], lr: 0.000800, loss: 0.2048
2023-07-01 23:48:31 - train: epoch 0183, iter [00100, 00390], lr: 0.000800, loss: 0.3482
2023-07-01 23:48:33 - train: epoch 0183, iter [00150, 00390], lr: 0.000800, loss: 0.2130
2023-07-01 23:48:34 - train: epoch 0183, iter [00200, 00390], lr: 0.000800, loss: 0.2171
2023-07-01 23:48:35 - train: epoch 0183, iter [00250, 00390], lr: 0.000800, loss: 0.2835
2023-07-01 23:48:37 - train: epoch 0183, iter [00300, 00390], lr: 0.000800, loss: 0.1991
2023-07-01 23:48:38 - train: epoch 0183, iter [00350, 00390], lr: 0.000800, loss: 0.2395
2023-07-01 23:48:40 - train: epoch 183, train_loss: 0.2401
2023-07-01 23:48:41 - eval: epoch: 183, acc1: 39.750%, acc5: 66.910%, test_loss: 3.5116, per_image_load_time: 0.094ms, per_image_inference_time: 0.055ms
2023-07-01 23:48:42 - until epoch: 183, best_acc1: 41.320%
2023-07-01 23:48:42 - epoch 184 lr: 0.000800
2023-07-01 23:48:44 - train: epoch 0184, iter [00050, 00390], lr: 0.000800, loss: 0.1764
2023-07-01 23:48:46 - train: epoch 0184, iter [00100, 00390], lr: 0.000800, loss: 0.1862
2023-07-01 23:48:47 - train: epoch 0184, iter [00150, 00390], lr: 0.000800, loss: 0.1941
2023-07-01 23:48:48 - train: epoch 0184, iter [00200, 00390], lr: 0.000800, loss: 0.2651
2023-07-01 23:48:50 - train: epoch 0184, iter [00250, 00390], lr: 0.000800, loss: 0.2641
2023-07-01 23:48:51 - train: epoch 0184, iter [00300, 00390], lr: 0.000800, loss: 0.2049
2023-07-01 23:48:53 - train: epoch 0184, iter [00350, 00390], lr: 0.000800, loss: 0.2477
2023-07-01 23:48:54 - train: epoch 184, train_loss: 0.2372
2023-07-01 23:48:55 - eval: epoch: 184, acc1: 39.550%, acc5: 67.170%, test_loss: 3.5235, per_image_load_time: 0.097ms, per_image_inference_time: 0.055ms
2023-07-01 23:48:56 - until epoch: 184, best_acc1: 41.320%
2023-07-01 23:48:56 - epoch 185 lr: 0.000800
2023-07-01 23:48:59 - train: epoch 0185, iter [00050, 00390], lr: 0.000800, loss: 0.2397
2023-07-01 23:49:00 - train: epoch 0185, iter [00100, 00390], lr: 0.000800, loss: 0.2453
2023-07-01 23:49:01 - train: epoch 0185, iter [00150, 00390], lr: 0.000800, loss: 0.2722
2023-07-01 23:49:03 - train: epoch 0185, iter [00200, 00390], lr: 0.000800, loss: 0.2885
2023-07-01 23:49:04 - train: epoch 0185, iter [00250, 00390], lr: 0.000800, loss: 0.3068
2023-07-01 23:49:06 - train: epoch 0185, iter [00300, 00390], lr: 0.000800, loss: 0.3202
2023-07-01 23:49:07 - train: epoch 0185, iter [00350, 00390], lr: 0.000800, loss: 0.1733
2023-07-01 23:49:08 - train: epoch 185, train_loss: 0.2366
2023-07-01 23:49:10 - eval: epoch: 185, acc1: 39.550%, acc5: 66.830%, test_loss: 3.5388, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-01 23:49:10 - until epoch: 185, best_acc1: 41.320%
2023-07-01 23:49:10 - epoch 186 lr: 0.000800
2023-07-01 23:49:13 - train: epoch 0186, iter [00050, 00390], lr: 0.000800, loss: 0.2540
2023-07-01 23:49:15 - train: epoch 0186, iter [00100, 00390], lr: 0.000800, loss: 0.1756
2023-07-01 23:49:16 - train: epoch 0186, iter [00150, 00390], lr: 0.000800, loss: 0.2426
2023-07-01 23:49:18 - train: epoch 0186, iter [00200, 00390], lr: 0.000800, loss: 0.3397
2023-07-01 23:49:19 - train: epoch 0186, iter [00250, 00390], lr: 0.000800, loss: 0.2383
2023-07-01 23:49:21 - train: epoch 0186, iter [00300, 00390], lr: 0.000800, loss: 0.1764
2023-07-01 23:49:22 - train: epoch 0186, iter [00350, 00390], lr: 0.000800, loss: 0.2276
2023-07-01 23:49:23 - train: epoch 186, train_loss: 0.2312
2023-07-01 23:49:25 - eval: epoch: 186, acc1: 39.820%, acc5: 67.150%, test_loss: 3.5364, per_image_load_time: 0.097ms, per_image_inference_time: 0.055ms
2023-07-01 23:49:26 - until epoch: 186, best_acc1: 41.320%
2023-07-01 23:49:26 - epoch 187 lr: 0.000800
2023-07-01 23:49:29 - train: epoch 0187, iter [00050, 00390], lr: 0.000800, loss: 0.1485
2023-07-01 23:49:30 - train: epoch 0187, iter [00100, 00390], lr: 0.000800, loss: 0.2195
2023-07-01 23:49:31 - train: epoch 0187, iter [00150, 00390], lr: 0.000800, loss: 0.3512
2023-07-01 23:49:33 - train: epoch 0187, iter [00200, 00390], lr: 0.000800, loss: 0.3235
2023-07-01 23:49:34 - train: epoch 0187, iter [00250, 00390], lr: 0.000800, loss: 0.1708
2023-07-01 23:49:36 - train: epoch 0187, iter [00300, 00390], lr: 0.000800, loss: 0.1965
2023-07-01 23:49:37 - train: epoch 0187, iter [00350, 00390], lr: 0.000800, loss: 0.2154
2023-07-01 23:49:39 - train: epoch 187, train_loss: 0.2342
2023-07-01 23:49:40 - eval: epoch: 187, acc1: 39.400%, acc5: 66.970%, test_loss: 3.5542, per_image_load_time: 0.101ms, per_image_inference_time: 0.054ms
2023-07-01 23:49:41 - until epoch: 187, best_acc1: 41.320%
2023-07-01 23:49:41 - epoch 188 lr: 0.000800
2023-07-01 23:49:44 - train: epoch 0188, iter [00050, 00390], lr: 0.000800, loss: 0.2594
2023-07-01 23:49:45 - train: epoch 0188, iter [00100, 00390], lr: 0.000800, loss: 0.2485
2023-07-01 23:49:47 - train: epoch 0188, iter [00150, 00390], lr: 0.000800, loss: 0.1988
2023-07-01 23:49:48 - train: epoch 0188, iter [00200, 00390], lr: 0.000800, loss: 0.2480
2023-07-01 23:49:49 - train: epoch 0188, iter [00250, 00390], lr: 0.000800, loss: 0.2142
2023-07-01 23:49:51 - train: epoch 0188, iter [00300, 00390], lr: 0.000800, loss: 0.1990
2023-07-01 23:49:52 - train: epoch 0188, iter [00350, 00390], lr: 0.000800, loss: 0.2131
2023-07-01 23:49:53 - train: epoch 188, train_loss: 0.2307
2023-07-01 23:49:55 - eval: epoch: 188, acc1: 39.460%, acc5: 66.940%, test_loss: 3.5678, per_image_load_time: 0.095ms, per_image_inference_time: 0.055ms
2023-07-01 23:49:56 - until epoch: 188, best_acc1: 41.320%
2023-07-01 23:49:56 - epoch 189 lr: 0.000800
2023-07-01 23:49:58 - train: epoch 0189, iter [00050, 00390], lr: 0.000800, loss: 0.2066
2023-07-01 23:50:00 - train: epoch 0189, iter [00100, 00390], lr: 0.000800, loss: 0.2616
2023-07-01 23:50:01 - train: epoch 0189, iter [00150, 00390], lr: 0.000800, loss: 0.1323
2023-07-01 23:50:03 - train: epoch 0189, iter [00200, 00390], lr: 0.000800, loss: 0.2190
2023-07-01 23:50:04 - train: epoch 0189, iter [00250, 00390], lr: 0.000800, loss: 0.2565
2023-07-01 23:50:06 - train: epoch 0189, iter [00300, 00390], lr: 0.000800, loss: 0.1456
2023-07-01 23:50:07 - train: epoch 0189, iter [00350, 00390], lr: 0.000800, loss: 0.2207
2023-07-01 23:50:08 - train: epoch 189, train_loss: 0.2275
2023-07-01 23:50:10 - eval: epoch: 189, acc1: 39.770%, acc5: 67.110%, test_loss: 3.5727, per_image_load_time: 0.100ms, per_image_inference_time: 0.055ms
2023-07-01 23:50:11 - until epoch: 189, best_acc1: 41.320%
2023-07-01 23:50:11 - epoch 190 lr: 0.000800
2023-07-01 23:50:14 - train: epoch 0190, iter [00050, 00390], lr: 0.000800, loss: 0.1598
2023-07-01 23:50:16 - train: epoch 0190, iter [00100, 00390], lr: 0.000800, loss: 0.2280
2023-07-01 23:50:17 - train: epoch 0190, iter [00150, 00390], lr: 0.000800, loss: 0.2909
2023-07-01 23:50:18 - train: epoch 0190, iter [00200, 00390], lr: 0.000800, loss: 0.3026
2023-07-01 23:50:20 - train: epoch 0190, iter [00250, 00390], lr: 0.000800, loss: 0.2858
2023-07-01 23:50:21 - train: epoch 0190, iter [00300, 00390], lr: 0.000800, loss: 0.1790
2023-07-01 23:50:23 - train: epoch 0190, iter [00350, 00390], lr: 0.000800, loss: 0.2057
2023-07-01 23:50:24 - train: epoch 190, train_loss: 0.2281
2023-07-01 23:50:26 - eval: epoch: 190, acc1: 39.670%, acc5: 67.000%, test_loss: 3.5770, per_image_load_time: 0.096ms, per_image_inference_time: 0.054ms
2023-07-01 23:50:26 - until epoch: 190, best_acc1: 41.320%
2023-07-01 23:50:26 - epoch 191 lr: 0.000800
2023-07-01 23:50:28 - train: epoch 0191, iter [00050, 00390], lr: 0.000800, loss: 0.2569
2023-07-01 23:50:30 - train: epoch 0191, iter [00100, 00390], lr: 0.000800, loss: 0.1870
2023-07-01 23:50:31 - train: epoch 0191, iter [00150, 00390], lr: 0.000800, loss: 0.1701
2023-07-01 23:50:33 - train: epoch 0191, iter [00200, 00390], lr: 0.000800, loss: 0.2070
2023-07-01 23:50:34 - train: epoch 0191, iter [00250, 00390], lr: 0.000800, loss: 0.2217
2023-07-01 23:50:35 - train: epoch 0191, iter [00300, 00390], lr: 0.000800, loss: 0.2313
2023-07-01 23:50:37 - train: epoch 0191, iter [00350, 00390], lr: 0.000800, loss: 0.2530
2023-07-01 23:50:38 - train: epoch 191, train_loss: 0.2178
2023-07-01 23:50:39 - eval: epoch: 191, acc1: 39.930%, acc5: 66.960%, test_loss: 3.5823, per_image_load_time: 0.094ms, per_image_inference_time: 0.053ms
2023-07-01 23:50:40 - until epoch: 191, best_acc1: 41.320%
2023-07-01 23:50:40 - epoch 192 lr: 0.000800
2023-07-01 23:50:42 - train: epoch 0192, iter [00050, 00390], lr: 0.000800, loss: 0.2020
2023-07-01 23:50:44 - train: epoch 0192, iter [00100, 00390], lr: 0.000800, loss: 0.1964
2023-07-01 23:50:45 - train: epoch 0192, iter [00150, 00390], lr: 0.000800, loss: 0.1940
2023-07-01 23:50:47 - train: epoch 0192, iter [00200, 00390], lr: 0.000800, loss: 0.1930
2023-07-01 23:50:48 - train: epoch 0192, iter [00250, 00390], lr: 0.000800, loss: 0.2522
2023-07-01 23:50:50 - train: epoch 0192, iter [00300, 00390], lr: 0.000800, loss: 0.2138
2023-07-01 23:50:51 - train: epoch 0192, iter [00350, 00390], lr: 0.000800, loss: 0.2192
2023-07-01 23:50:52 - train: epoch 192, train_loss: 0.2189
2023-07-01 23:50:54 - eval: epoch: 192, acc1: 39.800%, acc5: 66.910%, test_loss: 3.5832, per_image_load_time: 0.099ms, per_image_inference_time: 0.054ms
2023-07-01 23:50:54 - until epoch: 192, best_acc1: 41.320%
2023-07-01 23:50:54 - epoch 193 lr: 0.000800
2023-07-01 23:50:57 - train: epoch 0193, iter [00050, 00390], lr: 0.000800, loss: 0.2011
2023-07-01 23:50:58 - train: epoch 0193, iter [00100, 00390], lr: 0.000800, loss: 0.2104
2023-07-01 23:51:00 - train: epoch 0193, iter [00150, 00390], lr: 0.000800, loss: 0.2391
2023-07-01 23:51:01 - train: epoch 0193, iter [00200, 00390], lr: 0.000800, loss: 0.1390
2023-07-01 23:51:02 - train: epoch 0193, iter [00250, 00390], lr: 0.000800, loss: 0.1524
2023-07-01 23:51:04 - train: epoch 0193, iter [00300, 00390], lr: 0.000800, loss: 0.2445
2023-07-01 23:51:05 - train: epoch 0193, iter [00350, 00390], lr: 0.000800, loss: 0.2411
2023-07-01 23:51:07 - train: epoch 193, train_loss: 0.2170
2023-07-01 23:51:08 - eval: epoch: 193, acc1: 39.560%, acc5: 66.940%, test_loss: 3.6092, per_image_load_time: 0.102ms, per_image_inference_time: 0.056ms
2023-07-01 23:51:10 - until epoch: 193, best_acc1: 41.320%
2023-07-01 23:51:10 - epoch 194 lr: 0.000800
2023-07-01 23:51:12 - train: epoch 0194, iter [00050, 00390], lr: 0.000800, loss: 0.1664
2023-07-01 23:51:14 - train: epoch 0194, iter [00100, 00390], lr: 0.000800, loss: 0.1546
2023-07-01 23:51:15 - train: epoch 0194, iter [00150, 00390], lr: 0.000800, loss: 0.1505
2023-07-01 23:51:16 - train: epoch 0194, iter [00200, 00390], lr: 0.000800, loss: 0.1660
2023-07-01 23:51:18 - train: epoch 0194, iter [00250, 00390], lr: 0.000800, loss: 0.2062
2023-07-01 23:51:19 - train: epoch 0194, iter [00300, 00390], lr: 0.000800, loss: 0.1505
2023-07-01 23:51:20 - train: epoch 0194, iter [00350, 00390], lr: 0.000800, loss: 0.2161
2023-07-01 23:51:22 - train: epoch 194, train_loss: 0.2151
2023-07-01 23:51:23 - eval: epoch: 194, acc1: 39.510%, acc5: 66.710%, test_loss: 3.6115, per_image_load_time: 0.097ms, per_image_inference_time: 0.054ms
2023-07-01 23:51:24 - until epoch: 194, best_acc1: 41.320%
2023-07-01 23:51:24 - epoch 195 lr: 0.000800
2023-07-01 23:51:26 - train: epoch 0195, iter [00050, 00390], lr: 0.000800, loss: 0.2087
2023-07-01 23:51:28 - train: epoch 0195, iter [00100, 00390], lr: 0.000800, loss: 0.1535
2023-07-01 23:51:29 - train: epoch 0195, iter [00150, 00390], lr: 0.000800, loss: 0.2489
2023-07-01 23:51:30 - train: epoch 0195, iter [00200, 00390], lr: 0.000800, loss: 0.1932
2023-07-01 23:51:32 - train: epoch 0195, iter [00250, 00390], lr: 0.000800, loss: 0.2688
2023-07-01 23:51:33 - train: epoch 0195, iter [00300, 00390], lr: 0.000800, loss: 0.1227
2023-07-01 23:51:35 - train: epoch 0195, iter [00350, 00390], lr: 0.000800, loss: 0.2383
2023-07-01 23:51:36 - train: epoch 195, train_loss: 0.2145
2023-07-01 23:51:38 - eval: epoch: 195, acc1: 39.560%, acc5: 66.850%, test_loss: 3.6252, per_image_load_time: 0.100ms, per_image_inference_time: 0.055ms
2023-07-01 23:51:39 - until epoch: 195, best_acc1: 41.320%
2023-07-01 23:51:39 - epoch 196 lr: 0.000800
2023-07-01 23:51:42 - train: epoch 0196, iter [00050, 00390], lr: 0.000800, loss: 0.2607
2023-07-01 23:51:43 - train: epoch 0196, iter [00100, 00390], lr: 0.000800, loss: 0.2040
2023-07-01 23:51:45 - train: epoch 0196, iter [00150, 00390], lr: 0.000800, loss: 0.2035
2023-07-01 23:51:47 - train: epoch 0196, iter [00200, 00390], lr: 0.000800, loss: 0.2211
2023-07-01 23:51:48 - train: epoch 0196, iter [00250, 00390], lr: 0.000800, loss: 0.1810
2023-07-01 23:51:49 - train: epoch 0196, iter [00300, 00390], lr: 0.000800, loss: 0.2096
2023-07-01 23:51:51 - train: epoch 0196, iter [00350, 00390], lr: 0.000800, loss: 0.2430
2023-07-01 23:51:52 - train: epoch 196, train_loss: 0.2120
2023-07-01 23:51:54 - eval: epoch: 196, acc1: 39.840%, acc5: 66.800%, test_loss: 3.6329, per_image_load_time: 0.099ms, per_image_inference_time: 0.054ms
2023-07-01 23:51:54 - until epoch: 196, best_acc1: 41.320%
2023-07-01 23:51:54 - epoch 197 lr: 0.000800
2023-07-01 23:51:57 - train: epoch 0197, iter [00050, 00390], lr: 0.000800, loss: 0.1748
2023-07-01 23:51:58 - train: epoch 0197, iter [00100, 00390], lr: 0.000800, loss: 0.3344
2023-07-01 23:52:00 - train: epoch 0197, iter [00150, 00390], lr: 0.000800, loss: 0.2139
2023-07-01 23:52:01 - train: epoch 0197, iter [00200, 00390], lr: 0.000800, loss: 0.1578
2023-07-01 23:52:03 - train: epoch 0197, iter [00250, 00390], lr: 0.000800, loss: 0.3043
2023-07-01 23:52:04 - train: epoch 0197, iter [00300, 00390], lr: 0.000800, loss: 0.1434
2023-07-01 23:52:06 - train: epoch 0197, iter [00350, 00390], lr: 0.000800, loss: 0.1792
2023-07-01 23:52:07 - train: epoch 197, train_loss: 0.2166
2023-07-01 23:52:09 - eval: epoch: 197, acc1: 39.430%, acc5: 66.880%, test_loss: 3.6378, per_image_load_time: 0.097ms, per_image_inference_time: 0.055ms
2023-07-01 23:52:09 - until epoch: 197, best_acc1: 41.320%
2023-07-01 23:52:09 - epoch 198 lr: 0.000800
2023-07-01 23:52:11 - train: epoch 0198, iter [00050, 00390], lr: 0.000800, loss: 0.1468
2023-07-01 23:52:13 - train: epoch 0198, iter [00100, 00390], lr: 0.000800, loss: 0.1358
2023-07-01 23:52:14 - train: epoch 0198, iter [00150, 00390], lr: 0.000800, loss: 0.2365
2023-07-01 23:52:16 - train: epoch 0198, iter [00200, 00390], lr: 0.000800, loss: 0.1932
2023-07-01 23:52:17 - train: epoch 0198, iter [00250, 00390], lr: 0.000800, loss: 0.1774
2023-07-01 23:52:18 - train: epoch 0198, iter [00300, 00390], lr: 0.000800, loss: 0.1989
2023-07-01 23:52:20 - train: epoch 0198, iter [00350, 00390], lr: 0.000800, loss: 0.1739
2023-07-01 23:52:21 - train: epoch 198, train_loss: 0.2076
2023-07-01 23:52:23 - eval: epoch: 198, acc1: 39.940%, acc5: 66.910%, test_loss: 3.6324, per_image_load_time: 0.096ms, per_image_inference_time: 0.053ms
2023-07-01 23:52:24 - until epoch: 198, best_acc1: 41.320%
2023-07-01 23:52:24 - epoch 199 lr: 0.000800
2023-07-01 23:52:27 - train: epoch 0199, iter [00050, 00390], lr: 0.000800, loss: 0.1224
2023-07-01 23:52:28 - train: epoch 0199, iter [00100, 00390], lr: 0.000800, loss: 0.2330
2023-07-01 23:52:29 - train: epoch 0199, iter [00150, 00390], lr: 0.000800, loss: 0.1964
2023-07-01 23:52:31 - train: epoch 0199, iter [00200, 00390], lr: 0.000800, loss: 0.1406
2023-07-01 23:52:32 - train: epoch 0199, iter [00250, 00390], lr: 0.000800, loss: 0.1829
2023-07-01 23:52:34 - train: epoch 0199, iter [00300, 00390], lr: 0.000800, loss: 0.3209
2023-07-01 23:52:35 - train: epoch 0199, iter [00350, 00390], lr: 0.000800, loss: 0.2880
2023-07-01 23:52:36 - train: epoch 199, train_loss: 0.2067
2023-07-01 23:52:38 - eval: epoch: 199, acc1: 39.450%, acc5: 66.510%, test_loss: 3.6562, per_image_load_time: 0.095ms, per_image_inference_time: 0.055ms
2023-07-01 23:52:38 - until epoch: 199, best_acc1: 41.320%
2023-07-01 23:52:38 - epoch 200 lr: 0.000800
2023-07-01 23:52:41 - train: epoch 0200, iter [00050, 00390], lr: 0.000800, loss: 0.2440
2023-07-01 23:52:42 - train: epoch 0200, iter [00100, 00390], lr: 0.000800, loss: 0.3233
2023-07-01 23:52:44 - train: epoch 0200, iter [00150, 00390], lr: 0.000800, loss: 0.1774
2023-07-01 23:52:45 - train: epoch 0200, iter [00200, 00390], lr: 0.000800, loss: 0.1440
2023-07-01 23:52:46 - train: epoch 0200, iter [00250, 00390], lr: 0.000800, loss: 0.2238
2023-07-01 23:52:48 - train: epoch 0200, iter [00300, 00390], lr: 0.000800, loss: 0.1099
2023-07-01 23:52:49 - train: epoch 0200, iter [00350, 00390], lr: 0.000800, loss: 0.2143
2023-07-01 23:52:50 - train: epoch 200, train_loss: 0.2055
2023-07-01 23:52:52 - eval: epoch: 200, acc1: 39.520%, acc5: 66.730%, test_loss: 3.6623, per_image_load_time: 0.097ms, per_image_inference_time: 0.053ms
2023-07-01 23:52:52 - until epoch: 200, best_acc1: 41.320%
2023-07-01 23:52:52 - train done. model: vit_mid_small_patch16, train time: 0.769 hours, best_acc1: 41.320%
2023-07-02 00:00:55 - network: vit_mid_small_patch16
2023-07-02 00:00:55 - num_classes: 100
2023-07-02 00:00:55 - input_image_size: 32
2023-07-02 00:00:55 - num_params: 12758116
2023-07-02 00:00:55 - trained_model_path: 
2023-07-02 00:00:55 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-02 00:00:55 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-02 00:00:55 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7ffbae4ad790>
2023-07-02 00:00:55 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7ffbae4ad3a0>
2023-07-02 00:00:55 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7ffbae4ad2b0>
2023-07-02 00:00:55 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7ffbae4ad340>
2023-07-02 00:00:55 - seed: 0
2023-07-02 00:00:55 - batch_size: 128
2023-07-02 00:00:55 - num_workers: 16
2023-07-02 00:00:55 - accumulation_steps: 1
2023-07-02 00:00:55 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-02 00:00:55 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-07-02 00:00:55 - epochs: 200
2023-07-02 00:00:55 - print_interval: 50
2023-07-02 00:00:55 - sync_bn: False
2023-07-02 00:00:55 - apex: True
2023-07-02 00:00:55 - use_ema_model: False
2023-07-02 00:00:55 - ema_model_decay: 0.9999
2023-07-02 00:00:55 - AUG: cutmix
2023-07-02 00:00:55 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-02 00:00:55 - gpus_num: 1
2023-07-02 00:00:55 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7ffbae4ab6f0>
2023-07-02 00:00:55 - --------------------parameters--------------------
2023-07-02 00:00:55 - name: cls_token, grad: True
2023-07-02 00:00:55 - name: position_encoding, grad: True
2023-07-02 00:00:55 - name: patch_embedding.conv.weight, grad: True
2023-07-02 00:00:55 - name: patch_embedding.conv.bias, grad: True
2023-07-02 00:00:55 - name: blocks.0.norm1.weight, grad: True
2023-07-02 00:00:55 - name: blocks.0.norm1.bias, grad: True
2023-07-02 00:00:55 - name: blocks.0.attention.qkv_linear.weight, grad: True
2023-07-02 00:00:55 - name: blocks.0.attention.qkv_linear.bias, grad: True
2023-07-02 00:00:55 - name: blocks.0.attention.out_linear.weight, grad: True
2023-07-02 00:00:55 - name: blocks.0.attention.out_linear.bias, grad: True
2023-07-02 00:00:55 - name: blocks.0.norm2.weight, grad: True
2023-07-02 00:00:55 - name: blocks.0.norm2.bias, grad: True
2023-07-02 00:00:55 - name: blocks.0.feed_forward.fc1.weight, grad: True
2023-07-02 00:00:55 - name: blocks.0.feed_forward.fc1.bias, grad: True
2023-07-02 00:00:55 - name: blocks.0.feed_forward.fc2.weight, grad: True
2023-07-02 00:00:55 - name: blocks.0.feed_forward.fc2.bias, grad: True
2023-07-02 00:00:55 - name: blocks.1.norm1.weight, grad: True
2023-07-02 00:00:55 - name: blocks.1.norm1.bias, grad: True
2023-07-02 00:00:55 - name: blocks.1.attention.qkv_linear.weight, grad: True
2023-07-02 00:00:55 - name: blocks.1.attention.qkv_linear.bias, grad: True
2023-07-02 00:00:55 - name: blocks.1.attention.out_linear.weight, grad: True
2023-07-02 00:00:55 - name: blocks.1.attention.out_linear.bias, grad: True
2023-07-02 00:00:55 - name: blocks.1.norm2.weight, grad: True
2023-07-02 00:00:55 - name: blocks.1.norm2.bias, grad: True
2023-07-02 00:00:55 - name: blocks.1.feed_forward.fc1.weight, grad: True
2023-07-02 00:00:55 - name: blocks.1.feed_forward.fc1.bias, grad: True
2023-07-02 00:00:55 - name: blocks.1.feed_forward.fc2.weight, grad: True
2023-07-02 00:00:55 - name: blocks.1.feed_forward.fc2.bias, grad: True
2023-07-02 00:00:55 - name: blocks.2.norm1.weight, grad: True
2023-07-02 00:00:55 - name: blocks.2.norm1.bias, grad: True
2023-07-02 00:00:55 - name: blocks.2.attention.qkv_linear.weight, grad: True
2023-07-02 00:00:55 - name: blocks.2.attention.qkv_linear.bias, grad: True
2023-07-02 00:00:55 - name: blocks.2.attention.out_linear.weight, grad: True
2023-07-02 00:00:55 - name: blocks.2.attention.out_linear.bias, grad: True
2023-07-02 00:00:55 - name: blocks.2.norm2.weight, grad: True
2023-07-02 00:00:55 - name: blocks.2.norm2.bias, grad: True
2023-07-02 00:00:55 - name: blocks.2.feed_forward.fc1.weight, grad: True
2023-07-02 00:00:55 - name: blocks.2.feed_forward.fc1.bias, grad: True
2023-07-02 00:00:55 - name: blocks.2.feed_forward.fc2.weight, grad: True
2023-07-02 00:00:55 - name: blocks.2.feed_forward.fc2.bias, grad: True
2023-07-02 00:00:55 - name: blocks.3.norm1.weight, grad: True
2023-07-02 00:00:55 - name: blocks.3.norm1.bias, grad: True
2023-07-02 00:00:55 - name: blocks.3.attention.qkv_linear.weight, grad: True
2023-07-02 00:00:55 - name: blocks.3.attention.qkv_linear.bias, grad: True
2023-07-02 00:00:55 - name: blocks.3.attention.out_linear.weight, grad: True
2023-07-02 00:00:55 - name: blocks.3.attention.out_linear.bias, grad: True
2023-07-02 00:00:55 - name: blocks.3.norm2.weight, grad: True
2023-07-02 00:00:55 - name: blocks.3.norm2.bias, grad: True
2023-07-02 00:00:55 - name: blocks.3.feed_forward.fc1.weight, grad: True
2023-07-02 00:00:55 - name: blocks.3.feed_forward.fc1.bias, grad: True
2023-07-02 00:00:55 - name: blocks.3.feed_forward.fc2.weight, grad: True
2023-07-02 00:00:55 - name: blocks.3.feed_forward.fc2.bias, grad: True
2023-07-02 00:00:55 - name: blocks.4.norm1.weight, grad: True
2023-07-02 00:00:55 - name: blocks.4.norm1.bias, grad: True
2023-07-02 00:00:55 - name: blocks.4.attention.qkv_linear.weight, grad: True
2023-07-02 00:00:55 - name: blocks.4.attention.qkv_linear.bias, grad: True
2023-07-02 00:00:55 - name: blocks.4.attention.out_linear.weight, grad: True
2023-07-02 00:00:55 - name: blocks.4.attention.out_linear.bias, grad: True
2023-07-02 00:00:55 - name: blocks.4.norm2.weight, grad: True
2023-07-02 00:00:55 - name: blocks.4.norm2.bias, grad: True
2023-07-02 00:00:55 - name: blocks.4.feed_forward.fc1.weight, grad: True
2023-07-02 00:00:55 - name: blocks.4.feed_forward.fc1.bias, grad: True
2023-07-02 00:00:55 - name: blocks.4.feed_forward.fc2.weight, grad: True
2023-07-02 00:00:55 - name: blocks.4.feed_forward.fc2.bias, grad: True
2023-07-02 00:00:55 - name: blocks.5.norm1.weight, grad: True
2023-07-02 00:00:55 - name: blocks.5.norm1.bias, grad: True
2023-07-02 00:00:55 - name: blocks.5.attention.qkv_linear.weight, grad: True
2023-07-02 00:00:55 - name: blocks.5.attention.qkv_linear.bias, grad: True
2023-07-02 00:00:55 - name: blocks.5.attention.out_linear.weight, grad: True
2023-07-02 00:00:55 - name: blocks.5.attention.out_linear.bias, grad: True
2023-07-02 00:00:55 - name: blocks.5.norm2.weight, grad: True
2023-07-02 00:00:55 - name: blocks.5.norm2.bias, grad: True
2023-07-02 00:00:55 - name: blocks.5.feed_forward.fc1.weight, grad: True
2023-07-02 00:00:55 - name: blocks.5.feed_forward.fc1.bias, grad: True
2023-07-02 00:00:55 - name: blocks.5.feed_forward.fc2.weight, grad: True
2023-07-02 00:00:55 - name: blocks.5.feed_forward.fc2.bias, grad: True
2023-07-02 00:00:55 - name: blocks.6.norm1.weight, grad: True
2023-07-02 00:00:55 - name: blocks.6.norm1.bias, grad: True
2023-07-02 00:00:55 - name: blocks.6.attention.qkv_linear.weight, grad: True
2023-07-02 00:00:55 - name: blocks.6.attention.qkv_linear.bias, grad: True
2023-07-02 00:00:55 - name: blocks.6.attention.out_linear.weight, grad: True
2023-07-02 00:00:55 - name: blocks.6.attention.out_linear.bias, grad: True
2023-07-02 00:00:55 - name: blocks.6.norm2.weight, grad: True
2023-07-02 00:00:55 - name: blocks.6.norm2.bias, grad: True
2023-07-02 00:00:55 - name: blocks.6.feed_forward.fc1.weight, grad: True
2023-07-02 00:00:55 - name: blocks.6.feed_forward.fc1.bias, grad: True
2023-07-02 00:00:55 - name: blocks.6.feed_forward.fc2.weight, grad: True
2023-07-02 00:00:55 - name: blocks.6.feed_forward.fc2.bias, grad: True
2023-07-02 00:00:55 - name: norm.weight, grad: True
2023-07-02 00:00:55 - name: norm.bias, grad: True
2023-07-02 00:00:55 - name: fc.weight, grad: True
2023-07-02 00:00:55 - name: fc.bias, grad: True
2023-07-02 00:00:55 - --------------------buffers--------------------
2023-07-02 00:00:55 - -----------no weight decay layers--------------
2023-07-02 00:00:55 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: norm.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: norm.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:00:55 - -------------weight decay layers---------------
2023-07-02 00:00:55 - name: cls_token, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: position_encoding, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: patch_embedding.conv.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:00:55 - epoch 001 lr: 0.100000
2023-07-02 00:01:02 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.9669
2023-07-02 00:01:03 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.5147
2023-07-02 00:01:05 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 4.2605
2023-07-02 00:01:06 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 4.3560
2023-07-02 00:01:08 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 4.3983
2023-07-02 00:01:09 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 4.5574
2023-07-02 00:01:10 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 4.4720
2023-07-02 00:01:12 - train: epoch 001, train_loss: 4.4721
2023-07-02 00:01:13 - eval: epoch: 001, acc1: 5.940%, acc5: 21.690%, test_loss: 4.1879, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:01:14 - until epoch: 001, best_acc1: 5.940%
2023-07-02 00:01:14 - epoch 002 lr: 0.100000
2023-07-02 00:01:16 - train: epoch 0002, iter [00050, 00390], lr: 0.100000, loss: 4.3462
2023-07-02 00:01:17 - train: epoch 0002, iter [00100, 00390], lr: 0.100000, loss: 4.2131
2023-07-02 00:01:18 - train: epoch 0002, iter [00150, 00390], lr: 0.100000, loss: 4.0833
2023-07-02 00:01:20 - train: epoch 0002, iter [00200, 00390], lr: 0.100000, loss: 4.4029
2023-07-02 00:01:21 - train: epoch 0002, iter [00250, 00390], lr: 0.100000, loss: 4.4314
2023-07-02 00:01:23 - train: epoch 0002, iter [00300, 00390], lr: 0.100000, loss: 4.2327
2023-07-02 00:01:24 - train: epoch 0002, iter [00350, 00390], lr: 0.100000, loss: 4.1170
2023-07-02 00:01:25 - train: epoch 002, train_loss: 4.2817
2023-07-02 00:01:27 - eval: epoch: 002, acc1: 8.560%, acc5: 27.590%, test_loss: 4.0010, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:01:27 - until epoch: 002, best_acc1: 8.560%
2023-07-02 00:01:27 - epoch 003 lr: 0.100000
2023-07-02 00:01:29 - train: epoch 0003, iter [00050, 00390], lr: 0.100000, loss: 4.0748
2023-07-02 00:01:31 - train: epoch 0003, iter [00100, 00390], lr: 0.100000, loss: 4.3478
2023-07-02 00:01:32 - train: epoch 0003, iter [00150, 00390], lr: 0.100000, loss: 4.1953
2023-07-02 00:01:34 - train: epoch 0003, iter [00200, 00390], lr: 0.100000, loss: 4.3064
2023-07-02 00:01:35 - train: epoch 0003, iter [00250, 00390], lr: 0.100000, loss: 4.3999
2023-07-02 00:01:36 - train: epoch 0003, iter [00300, 00390], lr: 0.100000, loss: 4.3055
2023-07-02 00:01:38 - train: epoch 0003, iter [00350, 00390], lr: 0.100000, loss: 4.3818
2023-07-02 00:01:39 - train: epoch 003, train_loss: 4.2066
2023-07-02 00:01:40 - eval: epoch: 003, acc1: 10.260%, acc5: 31.110%, test_loss: 3.9003, per_image_load_time: 0.070ms, per_image_inference_time: 0.060ms
2023-07-02 00:01:41 - until epoch: 003, best_acc1: 10.260%
2023-07-02 00:01:41 - epoch 004 lr: 0.100000
2023-07-02 00:01:43 - train: epoch 0004, iter [00050, 00390], lr: 0.100000, loss: 3.9089
2023-07-02 00:01:45 - train: epoch 0004, iter [00100, 00390], lr: 0.100000, loss: 3.9674
2023-07-02 00:01:46 - train: epoch 0004, iter [00150, 00390], lr: 0.100000, loss: 3.9331
2023-07-02 00:01:47 - train: epoch 0004, iter [00200, 00390], lr: 0.100000, loss: 4.0834
2023-07-02 00:01:49 - train: epoch 0004, iter [00250, 00390], lr: 0.100000, loss: 4.0460
2023-07-02 00:01:50 - train: epoch 0004, iter [00300, 00390], lr: 0.100000, loss: 4.1746
2023-07-02 00:01:52 - train: epoch 0004, iter [00350, 00390], lr: 0.100000, loss: 4.2468
2023-07-02 00:01:53 - train: epoch 004, train_loss: 4.1797
2023-07-02 00:01:54 - eval: epoch: 004, acc1: 12.360%, acc5: 34.690%, test_loss: 3.8174, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-07-02 00:01:55 - until epoch: 004, best_acc1: 12.360%
2023-07-02 00:01:55 - epoch 005 lr: 0.100000
2023-07-02 00:01:57 - train: epoch 0005, iter [00050, 00390], lr: 0.100000, loss: 4.3353
2023-07-02 00:01:58 - train: epoch 0005, iter [00100, 00390], lr: 0.100000, loss: 3.9128
2023-07-02 00:02:00 - train: epoch 0005, iter [00150, 00390], lr: 0.100000, loss: 4.2056
2023-07-02 00:02:01 - train: epoch 0005, iter [00200, 00390], lr: 0.100000, loss: 4.1910
2023-07-02 00:02:03 - train: epoch 0005, iter [00250, 00390], lr: 0.100000, loss: 4.2315
2023-07-02 00:02:04 - train: epoch 0005, iter [00300, 00390], lr: 0.100000, loss: 4.2470
2023-07-02 00:02:05 - train: epoch 0005, iter [00350, 00390], lr: 0.100000, loss: 4.1977
2023-07-02 00:02:07 - train: epoch 005, train_loss: 4.1504
2023-07-02 00:02:08 - eval: epoch: 005, acc1: 13.750%, acc5: 36.880%, test_loss: 3.7400, per_image_load_time: 0.067ms, per_image_inference_time: 0.053ms
2023-07-02 00:02:08 - until epoch: 005, best_acc1: 13.750%
2023-07-02 00:02:08 - epoch 006 lr: 0.100000
2023-07-02 00:02:11 - train: epoch 0006, iter [00050, 00390], lr: 0.100000, loss: 3.8374
2023-07-02 00:02:12 - train: epoch 0006, iter [00100, 00390], lr: 0.100000, loss: 4.2106
2023-07-02 00:02:14 - train: epoch 0006, iter [00150, 00390], lr: 0.100000, loss: 4.3089
2023-07-02 00:02:15 - train: epoch 0006, iter [00200, 00390], lr: 0.100000, loss: 4.2638
2023-07-02 00:02:17 - train: epoch 0006, iter [00250, 00390], lr: 0.100000, loss: 4.2409
2023-07-02 00:02:18 - train: epoch 0006, iter [00300, 00390], lr: 0.100000, loss: 3.7497
2023-07-02 00:02:20 - train: epoch 0006, iter [00350, 00390], lr: 0.100000, loss: 4.1422
2023-07-02 00:02:21 - train: epoch 006, train_loss: 4.0910
2023-07-02 00:02:22 - eval: epoch: 006, acc1: 13.340%, acc5: 36.380%, test_loss: 3.7690, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-07-02 00:02:23 - until epoch: 006, best_acc1: 13.750%
2023-07-02 00:02:23 - epoch 007 lr: 0.100000
2023-07-02 00:02:25 - train: epoch 0007, iter [00050, 00390], lr: 0.100000, loss: 4.3112
2023-07-02 00:02:27 - train: epoch 0007, iter [00100, 00390], lr: 0.100000, loss: 4.3953
2023-07-02 00:02:28 - train: epoch 0007, iter [00150, 00390], lr: 0.100000, loss: 3.8994
2023-07-02 00:02:30 - train: epoch 0007, iter [00200, 00390], lr: 0.100000, loss: 4.2887
2023-07-02 00:02:31 - train: epoch 0007, iter [00250, 00390], lr: 0.100000, loss: 3.9491
2023-07-02 00:02:33 - train: epoch 0007, iter [00300, 00390], lr: 0.100000, loss: 4.2627
2023-07-02 00:02:34 - train: epoch 0007, iter [00350, 00390], lr: 0.100000, loss: 3.6598
2023-07-02 00:02:35 - train: epoch 007, train_loss: 4.0908
2023-07-02 00:02:36 - eval: epoch: 007, acc1: 15.420%, acc5: 40.260%, test_loss: 3.6153, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 00:02:37 - until epoch: 007, best_acc1: 15.420%
2023-07-02 00:02:37 - epoch 008 lr: 0.100000
2023-07-02 00:02:39 - train: epoch 0008, iter [00050, 00390], lr: 0.100000, loss: 4.0326
2023-07-02 00:02:40 - train: epoch 0008, iter [00100, 00390], lr: 0.100000, loss: 4.3034
2023-07-02 00:02:42 - train: epoch 0008, iter [00150, 00390], lr: 0.100000, loss: 4.2796
2023-07-02 00:02:43 - train: epoch 0008, iter [00200, 00390], lr: 0.100000, loss: 4.0044
2023-07-02 00:02:45 - train: epoch 0008, iter [00250, 00390], lr: 0.100000, loss: 4.1444
2023-07-02 00:02:46 - train: epoch 0008, iter [00300, 00390], lr: 0.100000, loss: 4.4075
2023-07-02 00:02:48 - train: epoch 0008, iter [00350, 00390], lr: 0.100000, loss: 3.9569
2023-07-02 00:02:49 - train: epoch 008, train_loss: 4.0739
2023-07-02 00:02:50 - eval: epoch: 008, acc1: 14.680%, acc5: 39.090%, test_loss: 3.6252, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-07-02 00:02:50 - until epoch: 008, best_acc1: 15.420%
2023-07-02 00:02:50 - epoch 009 lr: 0.100000
2023-07-02 00:02:53 - train: epoch 0009, iter [00050, 00390], lr: 0.100000, loss: 3.9770
2023-07-02 00:02:54 - train: epoch 0009, iter [00100, 00390], lr: 0.100000, loss: 3.7386
2023-07-02 00:02:55 - train: epoch 0009, iter [00150, 00390], lr: 0.100000, loss: 4.2303
2023-07-02 00:02:57 - train: epoch 0009, iter [00200, 00390], lr: 0.100000, loss: 3.7922
2023-07-02 00:02:58 - train: epoch 0009, iter [00250, 00390], lr: 0.100000, loss: 3.8294
2023-07-02 00:03:00 - train: epoch 0009, iter [00300, 00390], lr: 0.100000, loss: 4.1144
2023-07-02 00:03:01 - train: epoch 0009, iter [00350, 00390], lr: 0.100000, loss: 4.0546
2023-07-02 00:03:02 - train: epoch 009, train_loss: 4.0418
2023-07-02 00:03:04 - eval: epoch: 009, acc1: 16.520%, acc5: 41.520%, test_loss: 3.5595, per_image_load_time: 0.069ms, per_image_inference_time: 0.056ms
2023-07-02 00:03:04 - until epoch: 009, best_acc1: 16.520%
2023-07-02 00:03:04 - epoch 010 lr: 0.100000
2023-07-02 00:03:06 - train: epoch 0010, iter [00050, 00390], lr: 0.100000, loss: 4.3778
2023-07-02 00:03:08 - train: epoch 0010, iter [00100, 00390], lr: 0.100000, loss: 4.2322
2023-07-02 00:03:09 - train: epoch 0010, iter [00150, 00390], lr: 0.100000, loss: 4.3311
2023-07-02 00:03:11 - train: epoch 0010, iter [00200, 00390], lr: 0.100000, loss: 4.3092
2023-07-02 00:03:12 - train: epoch 0010, iter [00250, 00390], lr: 0.100000, loss: 4.0539
2023-07-02 00:03:13 - train: epoch 0010, iter [00300, 00390], lr: 0.100000, loss: 4.0107
2023-07-02 00:03:15 - train: epoch 0010, iter [00350, 00390], lr: 0.100000, loss: 4.1740
2023-07-02 00:03:16 - train: epoch 010, train_loss: 4.0246
2023-07-02 00:03:17 - eval: epoch: 010, acc1: 16.700%, acc5: 43.020%, test_loss: 3.5082, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:03:18 - until epoch: 010, best_acc1: 16.700%
2023-07-02 00:03:18 - epoch 011 lr: 0.100000
2023-07-02 00:03:20 - train: epoch 0011, iter [00050, 00390], lr: 0.100000, loss: 3.9032
2023-07-02 00:03:21 - train: epoch 0011, iter [00100, 00390], lr: 0.100000, loss: 4.1386
2023-07-02 00:03:23 - train: epoch 0011, iter [00150, 00390], lr: 0.100000, loss: 4.2053
2023-07-02 00:03:24 - train: epoch 0011, iter [00200, 00390], lr: 0.100000, loss: 3.6216
2023-07-02 00:03:26 - train: epoch 0011, iter [00250, 00390], lr: 0.100000, loss: 3.6519
2023-07-02 00:03:27 - train: epoch 0011, iter [00300, 00390], lr: 0.100000, loss: 3.4685
2023-07-02 00:03:28 - train: epoch 0011, iter [00350, 00390], lr: 0.100000, loss: 3.6353
2023-07-02 00:03:30 - train: epoch 011, train_loss: 4.0184
2023-07-02 00:03:31 - eval: epoch: 011, acc1: 17.580%, acc5: 43.780%, test_loss: 3.4883, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-07-02 00:03:32 - until epoch: 011, best_acc1: 17.580%
2023-07-02 00:03:32 - epoch 012 lr: 0.100000
2023-07-02 00:03:34 - train: epoch 0012, iter [00050, 00390], lr: 0.100000, loss: 4.0443
2023-07-02 00:03:35 - train: epoch 0012, iter [00100, 00390], lr: 0.100000, loss: 4.2977
2023-07-02 00:03:37 - train: epoch 0012, iter [00150, 00390], lr: 0.100000, loss: 4.3939
2023-07-02 00:03:38 - train: epoch 0012, iter [00200, 00390], lr: 0.100000, loss: 4.1975
2023-07-02 00:03:40 - train: epoch 0012, iter [00250, 00390], lr: 0.100000, loss: 4.2183
2023-07-02 00:03:41 - train: epoch 0012, iter [00300, 00390], lr: 0.100000, loss: 3.5608
2023-07-02 00:03:42 - train: epoch 0012, iter [00350, 00390], lr: 0.100000, loss: 3.8378
2023-07-02 00:03:44 - train: epoch 012, train_loss: 4.0113
2023-07-02 00:03:45 - eval: epoch: 012, acc1: 17.940%, acc5: 44.210%, test_loss: 3.4968, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:03:46 - until epoch: 012, best_acc1: 17.940%
2023-07-02 00:03:46 - epoch 013 lr: 0.100000
2023-07-02 00:03:48 - train: epoch 0013, iter [00050, 00390], lr: 0.100000, loss: 4.1367
2023-07-02 00:03:49 - train: epoch 0013, iter [00100, 00390], lr: 0.100000, loss: 4.2420
2023-07-02 00:03:51 - train: epoch 0013, iter [00150, 00390], lr: 0.100000, loss: 3.5825
2023-07-02 00:03:52 - train: epoch 0013, iter [00200, 00390], lr: 0.100000, loss: 4.2508
2023-07-02 00:03:53 - train: epoch 0013, iter [00250, 00390], lr: 0.100000, loss: 4.2054
2023-07-02 00:03:55 - train: epoch 0013, iter [00300, 00390], lr: 0.100000, loss: 4.1164
2023-07-02 00:03:56 - train: epoch 0013, iter [00350, 00390], lr: 0.100000, loss: 4.0752
2023-07-02 00:03:57 - train: epoch 013, train_loss: 3.9748
2023-07-02 00:03:59 - eval: epoch: 013, acc1: 17.680%, acc5: 45.090%, test_loss: 3.4647, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:03:59 - until epoch: 013, best_acc1: 17.940%
2023-07-02 00:03:59 - epoch 014 lr: 0.100000
2023-07-02 00:04:01 - train: epoch 0014, iter [00050, 00390], lr: 0.100000, loss: 4.2909
2023-07-02 00:04:03 - train: epoch 0014, iter [00100, 00390], lr: 0.100000, loss: 3.9261
2023-07-02 00:04:04 - train: epoch 0014, iter [00150, 00390], lr: 0.100000, loss: 3.9178
2023-07-02 00:04:06 - train: epoch 0014, iter [00200, 00390], lr: 0.100000, loss: 4.1422
2023-07-02 00:04:07 - train: epoch 0014, iter [00250, 00390], lr: 0.100000, loss: 4.1746
2023-07-02 00:04:08 - train: epoch 0014, iter [00300, 00390], lr: 0.100000, loss: 4.2145
2023-07-02 00:04:10 - train: epoch 0014, iter [00350, 00390], lr: 0.100000, loss: 4.2968
2023-07-02 00:04:11 - train: epoch 014, train_loss: 3.9685
2023-07-02 00:04:12 - eval: epoch: 014, acc1: 18.640%, acc5: 45.100%, test_loss: 3.4528, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:04:13 - until epoch: 014, best_acc1: 18.640%
2023-07-02 00:04:13 - epoch 015 lr: 0.100000
2023-07-02 00:04:15 - train: epoch 0015, iter [00050, 00390], lr: 0.100000, loss: 3.9990
2023-07-02 00:04:16 - train: epoch 0015, iter [00100, 00390], lr: 0.100000, loss: 4.3749
2023-07-02 00:04:18 - train: epoch 0015, iter [00150, 00390], lr: 0.100000, loss: 4.3648
2023-07-02 00:04:19 - train: epoch 0015, iter [00200, 00390], lr: 0.100000, loss: 3.6624
2023-07-02 00:04:21 - train: epoch 0015, iter [00250, 00390], lr: 0.100000, loss: 3.4776
2023-07-02 00:04:22 - train: epoch 0015, iter [00300, 00390], lr: 0.100000, loss: 3.6957
2023-07-02 00:04:23 - train: epoch 0015, iter [00350, 00390], lr: 0.100000, loss: 4.1244
2023-07-02 00:04:25 - train: epoch 015, train_loss: 3.9721
2023-07-02 00:04:26 - eval: epoch: 015, acc1: 18.910%, acc5: 45.660%, test_loss: 3.4024, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:04:27 - until epoch: 015, best_acc1: 18.910%
2023-07-02 00:04:27 - epoch 016 lr: 0.100000
2023-07-02 00:04:29 - train: epoch 0016, iter [00050, 00390], lr: 0.100000, loss: 4.1561
2023-07-02 00:04:30 - train: epoch 0016, iter [00100, 00390], lr: 0.100000, loss: 3.6663
2023-07-02 00:04:32 - train: epoch 0016, iter [00150, 00390], lr: 0.100000, loss: 3.8689
2023-07-02 00:04:33 - train: epoch 0016, iter [00200, 00390], lr: 0.100000, loss: 3.8469
2023-07-02 00:04:34 - train: epoch 0016, iter [00250, 00390], lr: 0.100000, loss: 3.8433
2023-07-02 00:04:36 - train: epoch 0016, iter [00300, 00390], lr: 0.100000, loss: 4.1865
2023-07-02 00:04:37 - train: epoch 0016, iter [00350, 00390], lr: 0.100000, loss: 4.0005
2023-07-02 00:04:38 - train: epoch 016, train_loss: 3.9674
2023-07-02 00:04:40 - eval: epoch: 016, acc1: 18.830%, acc5: 45.540%, test_loss: 3.4240, per_image_load_time: 0.067ms, per_image_inference_time: 0.053ms
2023-07-02 00:04:40 - until epoch: 016, best_acc1: 18.910%
2023-07-02 00:04:40 - epoch 017 lr: 0.100000
2023-07-02 00:04:42 - train: epoch 0017, iter [00050, 00390], lr: 0.100000, loss: 4.4452
2023-07-02 00:04:44 - train: epoch 0017, iter [00100, 00390], lr: 0.100000, loss: 4.2192
2023-07-02 00:04:45 - train: epoch 0017, iter [00150, 00390], lr: 0.100000, loss: 4.0964
2023-07-02 00:04:47 - train: epoch 0017, iter [00200, 00390], lr: 0.100000, loss: 4.1649
2023-07-02 00:04:48 - train: epoch 0017, iter [00250, 00390], lr: 0.100000, loss: 4.1273
2023-07-02 00:04:49 - train: epoch 0017, iter [00300, 00390], lr: 0.100000, loss: 4.3380
2023-07-02 00:04:51 - train: epoch 0017, iter [00350, 00390], lr: 0.100000, loss: 3.4478
2023-07-02 00:04:52 - train: epoch 017, train_loss: 3.9650
2023-07-02 00:04:53 - eval: epoch: 017, acc1: 18.800%, acc5: 46.000%, test_loss: 3.4155, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:04:54 - until epoch: 017, best_acc1: 18.910%
2023-07-02 00:04:54 - epoch 018 lr: 0.100000
2023-07-02 00:04:56 - train: epoch 0018, iter [00050, 00390], lr: 0.100000, loss: 4.2212
2023-07-02 00:04:57 - train: epoch 0018, iter [00100, 00390], lr: 0.100000, loss: 4.1724
2023-07-02 00:04:59 - train: epoch 0018, iter [00150, 00390], lr: 0.100000, loss: 3.5716
2023-07-02 00:05:00 - train: epoch 0018, iter [00200, 00390], lr: 0.100000, loss: 3.9422
2023-07-02 00:05:01 - train: epoch 0018, iter [00250, 00390], lr: 0.100000, loss: 4.1681
2023-07-02 00:05:03 - train: epoch 0018, iter [00300, 00390], lr: 0.100000, loss: 3.3747
2023-07-02 00:05:04 - train: epoch 0018, iter [00350, 00390], lr: 0.100000, loss: 4.0807
2023-07-02 00:05:05 - train: epoch 018, train_loss: 3.9593
2023-07-02 00:05:07 - eval: epoch: 018, acc1: 19.310%, acc5: 46.160%, test_loss: 3.4131, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 00:05:07 - until epoch: 018, best_acc1: 19.310%
2023-07-02 00:05:07 - epoch 019 lr: 0.100000
2023-07-02 00:05:10 - train: epoch 0019, iter [00050, 00390], lr: 0.100000, loss: 3.5513
2023-07-02 00:05:11 - train: epoch 0019, iter [00100, 00390], lr: 0.100000, loss: 3.4882
2023-07-02 00:05:12 - train: epoch 0019, iter [00150, 00390], lr: 0.100000, loss: 4.2599
2023-07-02 00:05:14 - train: epoch 0019, iter [00200, 00390], lr: 0.100000, loss: 4.2298
2023-07-02 00:05:15 - train: epoch 0019, iter [00250, 00390], lr: 0.100000, loss: 4.1992
2023-07-02 00:05:17 - train: epoch 0019, iter [00300, 00390], lr: 0.100000, loss: 4.1141
2023-07-02 00:05:18 - train: epoch 0019, iter [00350, 00390], lr: 0.100000, loss: 4.1754
2023-07-02 00:05:19 - train: epoch 019, train_loss: 3.9500
2023-07-02 00:05:21 - eval: epoch: 019, acc1: 19.440%, acc5: 47.230%, test_loss: 3.4026, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-07-02 00:05:21 - until epoch: 019, best_acc1: 19.440%
2023-07-02 00:05:21 - epoch 020 lr: 0.100000
2023-07-02 00:05:23 - train: epoch 0020, iter [00050, 00390], lr: 0.100000, loss: 4.2692
2023-07-02 00:05:25 - train: epoch 0020, iter [00100, 00390], lr: 0.100000, loss: 3.9277
2023-07-02 00:05:26 - train: epoch 0020, iter [00150, 00390], lr: 0.100000, loss: 4.2379
2023-07-02 00:05:28 - train: epoch 0020, iter [00200, 00390], lr: 0.100000, loss: 4.0696
2023-07-02 00:05:29 - train: epoch 0020, iter [00250, 00390], lr: 0.100000, loss: 3.4610
2023-07-02 00:05:30 - train: epoch 0020, iter [00300, 00390], lr: 0.100000, loss: 4.0623
2023-07-02 00:05:32 - train: epoch 0020, iter [00350, 00390], lr: 0.100000, loss: 3.9630
2023-07-02 00:05:33 - train: epoch 020, train_loss: 3.9541
2023-07-02 00:05:34 - eval: epoch: 020, acc1: 19.900%, acc5: 47.040%, test_loss: 3.3586, per_image_load_time: 0.070ms, per_image_inference_time: 0.056ms
2023-07-02 00:05:35 - until epoch: 020, best_acc1: 19.900%
2023-07-02 00:05:35 - epoch 021 lr: 0.100000
2023-07-02 00:05:37 - train: epoch 0021, iter [00050, 00390], lr: 0.100000, loss: 4.1131
2023-07-02 00:05:39 - train: epoch 0021, iter [00100, 00390], lr: 0.100000, loss: 3.6752
2023-07-02 00:05:40 - train: epoch 0021, iter [00150, 00390], lr: 0.100000, loss: 4.1691
2023-07-02 00:05:42 - train: epoch 0021, iter [00200, 00390], lr: 0.100000, loss: 3.6158
2023-07-02 00:05:43 - train: epoch 0021, iter [00250, 00390], lr: 0.100000, loss: 4.2427
2023-07-02 00:05:44 - train: epoch 0021, iter [00300, 00390], lr: 0.100000, loss: 4.1753
2023-07-02 00:05:46 - train: epoch 0021, iter [00350, 00390], lr: 0.100000, loss: 3.7730
2023-07-02 00:05:47 - train: epoch 021, train_loss: 3.9484
2023-07-02 00:05:48 - eval: epoch: 021, acc1: 20.690%, acc5: 48.200%, test_loss: 3.3882, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 00:05:49 - until epoch: 021, best_acc1: 20.690%
2023-07-02 00:05:49 - epoch 022 lr: 0.100000
2023-07-02 00:05:51 - train: epoch 0022, iter [00050, 00390], lr: 0.100000, loss: 4.1984
2023-07-02 00:05:52 - train: epoch 0022, iter [00100, 00390], lr: 0.100000, loss: 4.1754
2023-07-02 00:05:54 - train: epoch 0022, iter [00150, 00390], lr: 0.100000, loss: 4.2678
2023-07-02 00:05:55 - train: epoch 0022, iter [00200, 00390], lr: 0.100000, loss: 3.5425
2023-07-02 00:05:57 - train: epoch 0022, iter [00250, 00390], lr: 0.100000, loss: 4.1705
2023-07-02 00:05:58 - train: epoch 0022, iter [00300, 00390], lr: 0.100000, loss: 3.9276
2023-07-02 00:05:59 - train: epoch 0022, iter [00350, 00390], lr: 0.100000, loss: 3.4197
2023-07-02 00:06:01 - train: epoch 022, train_loss: 3.9189
2023-07-02 00:06:02 - eval: epoch: 022, acc1: 19.620%, acc5: 47.140%, test_loss: 3.3674, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 00:06:02 - until epoch: 022, best_acc1: 20.690%
2023-07-02 00:06:02 - epoch 023 lr: 0.100000
2023-07-02 00:06:04 - train: epoch 0023, iter [00050, 00390], lr: 0.100000, loss: 4.2502
2023-07-02 00:06:06 - train: epoch 0023, iter [00100, 00390], lr: 0.100000, loss: 3.8181
2023-07-02 00:06:07 - train: epoch 0023, iter [00150, 00390], lr: 0.100000, loss: 3.6251
2023-07-02 00:06:09 - train: epoch 0023, iter [00200, 00390], lr: 0.100000, loss: 3.5852
2023-07-02 00:06:10 - train: epoch 0023, iter [00250, 00390], lr: 0.100000, loss: 4.1998
2023-07-02 00:06:11 - train: epoch 0023, iter [00300, 00390], lr: 0.100000, loss: 3.8171
2023-07-02 00:06:13 - train: epoch 0023, iter [00350, 00390], lr: 0.100000, loss: 3.6021
2023-07-02 00:06:14 - train: epoch 023, train_loss: 3.9257
2023-07-02 00:06:15 - eval: epoch: 023, acc1: 19.800%, acc5: 48.110%, test_loss: 3.3434, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:06:16 - until epoch: 023, best_acc1: 20.690%
2023-07-02 00:06:16 - epoch 024 lr: 0.100000
2023-07-02 00:06:18 - train: epoch 0024, iter [00050, 00390], lr: 0.100000, loss: 4.1136
2023-07-02 00:06:19 - train: epoch 0024, iter [00100, 00390], lr: 0.100000, loss: 3.3691
2023-07-02 00:06:21 - train: epoch 0024, iter [00150, 00390], lr: 0.100000, loss: 4.0390
2023-07-02 00:06:22 - train: epoch 0024, iter [00200, 00390], lr: 0.100000, loss: 3.5668
2023-07-02 00:06:23 - train: epoch 0024, iter [00250, 00390], lr: 0.100000, loss: 4.0803
2023-07-02 00:06:25 - train: epoch 0024, iter [00300, 00390], lr: 0.100000, loss: 3.4715
2023-07-02 00:06:26 - train: epoch 0024, iter [00350, 00390], lr: 0.100000, loss: 4.1319
2023-07-02 00:06:27 - train: epoch 024, train_loss: 3.9174
2023-07-02 00:06:29 - eval: epoch: 024, acc1: 20.230%, acc5: 47.600%, test_loss: 3.3683, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-07-02 00:06:29 - until epoch: 024, best_acc1: 20.690%
2023-07-02 00:06:29 - epoch 025 lr: 0.100000
2023-07-02 00:06:31 - train: epoch 0025, iter [00050, 00390], lr: 0.100000, loss: 4.1458
2023-07-02 00:06:33 - train: epoch 0025, iter [00100, 00390], lr: 0.100000, loss: 4.0578
2023-07-02 00:06:34 - train: epoch 0025, iter [00150, 00390], lr: 0.100000, loss: 3.6422
2023-07-02 00:06:35 - train: epoch 0025, iter [00200, 00390], lr: 0.100000, loss: 3.8255
2023-07-02 00:06:37 - train: epoch 0025, iter [00250, 00390], lr: 0.100000, loss: 3.4471
2023-07-02 00:06:38 - train: epoch 0025, iter [00300, 00390], lr: 0.100000, loss: 3.9665
2023-07-02 00:06:40 - train: epoch 0025, iter [00350, 00390], lr: 0.100000, loss: 4.2462
2023-07-02 00:06:41 - train: epoch 025, train_loss: 3.9175
2023-07-02 00:06:42 - eval: epoch: 025, acc1: 19.190%, acc5: 47.680%, test_loss: 3.3441, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-07-02 00:06:42 - until epoch: 025, best_acc1: 20.690%
2023-07-02 00:06:42 - epoch 026 lr: 0.100000
2023-07-02 00:06:45 - train: epoch 0026, iter [00050, 00390], lr: 0.100000, loss: 3.3263
2023-07-02 00:06:46 - train: epoch 0026, iter [00100, 00390], lr: 0.100000, loss: 3.9599
2023-07-02 00:06:48 - train: epoch 0026, iter [00150, 00390], lr: 0.100000, loss: 4.2248
2023-07-02 00:06:49 - train: epoch 0026, iter [00200, 00390], lr: 0.100000, loss: 3.9848
2023-07-02 00:06:50 - train: epoch 0026, iter [00250, 00390], lr: 0.100000, loss: 4.0722
2023-07-02 00:06:52 - train: epoch 0026, iter [00300, 00390], lr: 0.100000, loss: 3.4552
2023-07-02 00:06:53 - train: epoch 0026, iter [00350, 00390], lr: 0.100000, loss: 3.5962
2023-07-02 00:06:54 - train: epoch 026, train_loss: 3.8762
2023-07-02 00:06:56 - eval: epoch: 026, acc1: 20.820%, acc5: 49.840%, test_loss: 3.3132, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:06:56 - until epoch: 026, best_acc1: 20.820%
2023-07-02 00:06:56 - epoch 027 lr: 0.100000
2023-07-02 00:06:58 - train: epoch 0027, iter [00050, 00390], lr: 0.100000, loss: 3.6007
2023-07-02 00:07:00 - train: epoch 0027, iter [00100, 00390], lr: 0.100000, loss: 3.7344
2023-07-02 00:07:01 - train: epoch 0027, iter [00150, 00390], lr: 0.100000, loss: 3.7522
2023-07-02 00:07:03 - train: epoch 0027, iter [00200, 00390], lr: 0.100000, loss: 3.5109
2023-07-02 00:07:04 - train: epoch 0027, iter [00250, 00390], lr: 0.100000, loss: 3.6298
2023-07-02 00:07:05 - train: epoch 0027, iter [00300, 00390], lr: 0.100000, loss: 4.0026
2023-07-02 00:07:07 - train: epoch 0027, iter [00350, 00390], lr: 0.100000, loss: 3.5799
2023-07-02 00:07:08 - train: epoch 027, train_loss: 3.9201
2023-07-02 00:07:09 - eval: epoch: 027, acc1: 20.820%, acc5: 48.820%, test_loss: 3.3797, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:07:10 - until epoch: 027, best_acc1: 20.820%
2023-07-02 00:07:10 - epoch 028 lr: 0.100000
2023-07-02 00:07:12 - train: epoch 0028, iter [00050, 00390], lr: 0.100000, loss: 3.6375
2023-07-02 00:07:13 - train: epoch 0028, iter [00100, 00390], lr: 0.100000, loss: 3.5649
2023-07-02 00:07:15 - train: epoch 0028, iter [00150, 00390], lr: 0.100000, loss: 3.2627
2023-07-02 00:07:16 - train: epoch 0028, iter [00200, 00390], lr: 0.100000, loss: 3.9116
2023-07-02 00:07:18 - train: epoch 0028, iter [00250, 00390], lr: 0.100000, loss: 4.0713
2023-07-02 00:07:19 - train: epoch 0028, iter [00300, 00390], lr: 0.100000, loss: 3.6081
2023-07-02 00:07:21 - train: epoch 0028, iter [00350, 00390], lr: 0.100000, loss: 4.1200
2023-07-02 00:07:22 - train: epoch 028, train_loss: 3.9052
2023-07-02 00:07:23 - eval: epoch: 028, acc1: 21.100%, acc5: 48.610%, test_loss: 3.3196, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:07:24 - until epoch: 028, best_acc1: 21.100%
2023-07-02 00:07:24 - epoch 029 lr: 0.100000
2023-07-02 00:07:27 - train: epoch 0029, iter [00050, 00390], lr: 0.100000, loss: 3.9294
2023-07-02 00:07:28 - train: epoch 0029, iter [00100, 00390], lr: 0.100000, loss: 4.2583
2023-07-02 00:07:29 - train: epoch 0029, iter [00150, 00390], lr: 0.100000, loss: 4.1792
2023-07-02 00:07:31 - train: epoch 0029, iter [00200, 00390], lr: 0.100000, loss: 3.4026
2023-07-02 00:07:32 - train: epoch 0029, iter [00250, 00390], lr: 0.100000, loss: 3.2501
2023-07-02 00:07:34 - train: epoch 0029, iter [00300, 00390], lr: 0.100000, loss: 4.2524
2023-07-02 00:07:35 - train: epoch 0029, iter [00350, 00390], lr: 0.100000, loss: 3.4551
2023-07-02 00:07:36 - train: epoch 029, train_loss: 3.9170
2023-07-02 00:07:37 - eval: epoch: 029, acc1: 21.540%, acc5: 49.250%, test_loss: 3.3006, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 00:07:38 - until epoch: 029, best_acc1: 21.540%
2023-07-02 00:07:38 - epoch 030 lr: 0.100000
2023-07-02 00:07:40 - train: epoch 0030, iter [00050, 00390], lr: 0.100000, loss: 3.8525
2023-07-02 00:07:42 - train: epoch 0030, iter [00100, 00390], lr: 0.100000, loss: 4.1943
2023-07-02 00:07:43 - train: epoch 0030, iter [00150, 00390], lr: 0.100000, loss: 3.6368
2023-07-02 00:07:44 - train: epoch 0030, iter [00200, 00390], lr: 0.100000, loss: 4.1607
2023-07-02 00:07:46 - train: epoch 0030, iter [00250, 00390], lr: 0.100000, loss: 4.0518
2023-07-02 00:07:47 - train: epoch 0030, iter [00300, 00390], lr: 0.100000, loss: 3.7471
2023-07-02 00:07:48 - train: epoch 0030, iter [00350, 00390], lr: 0.100000, loss: 3.5542
2023-07-02 00:07:50 - train: epoch 030, train_loss: 3.8850
2023-07-02 00:07:51 - eval: epoch: 030, acc1: 20.560%, acc5: 49.440%, test_loss: 3.3277, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 00:07:51 - until epoch: 030, best_acc1: 21.540%
2023-07-02 00:07:51 - epoch 031 lr: 0.100000
2023-07-02 00:07:53 - train: epoch 0031, iter [00050, 00390], lr: 0.100000, loss: 3.4784
2023-07-02 00:07:55 - train: epoch 0031, iter [00100, 00390], lr: 0.100000, loss: 4.2774
2023-07-02 00:07:56 - train: epoch 0031, iter [00150, 00390], lr: 0.100000, loss: 3.9817
2023-07-02 00:07:58 - train: epoch 0031, iter [00200, 00390], lr: 0.100000, loss: 3.5477
2023-07-02 00:07:59 - train: epoch 0031, iter [00250, 00390], lr: 0.100000, loss: 4.1077
2023-07-02 00:08:00 - train: epoch 0031, iter [00300, 00390], lr: 0.100000, loss: 4.2050
2023-07-02 00:08:02 - train: epoch 0031, iter [00350, 00390], lr: 0.100000, loss: 3.7383
2023-07-02 00:08:03 - train: epoch 031, train_loss: 3.8969
2023-07-02 00:08:04 - eval: epoch: 031, acc1: 21.740%, acc5: 49.840%, test_loss: 3.2787, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 00:08:05 - until epoch: 031, best_acc1: 21.740%
2023-07-02 00:08:05 - epoch 032 lr: 0.100000
2023-07-02 00:08:07 - train: epoch 0032, iter [00050, 00390], lr: 0.100000, loss: 4.2446
2023-07-02 00:08:08 - train: epoch 0032, iter [00100, 00390], lr: 0.100000, loss: 4.0775
2023-07-02 00:08:10 - train: epoch 0032, iter [00150, 00390], lr: 0.100000, loss: 4.1578
2023-07-02 00:08:11 - train: epoch 0032, iter [00200, 00390], lr: 0.100000, loss: 4.1035
2023-07-02 00:08:13 - train: epoch 0032, iter [00250, 00390], lr: 0.100000, loss: 3.7010
2023-07-02 00:08:14 - train: epoch 0032, iter [00300, 00390], lr: 0.100000, loss: 3.2894
2023-07-02 00:08:15 - train: epoch 0032, iter [00350, 00390], lr: 0.100000, loss: 3.9009
2023-07-02 00:08:17 - train: epoch 032, train_loss: 3.8869
2023-07-02 00:08:18 - eval: epoch: 032, acc1: 22.180%, acc5: 50.530%, test_loss: 3.2618, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-07-02 00:08:19 - until epoch: 032, best_acc1: 22.180%
2023-07-02 00:08:19 - epoch 033 lr: 0.100000
2023-07-02 00:08:21 - train: epoch 0033, iter [00050, 00390], lr: 0.100000, loss: 3.9527
2023-07-02 00:08:22 - train: epoch 0033, iter [00100, 00390], lr: 0.100000, loss: 3.4184
2023-07-02 00:08:24 - train: epoch 0033, iter [00150, 00390], lr: 0.100000, loss: 3.7238
2023-07-02 00:08:25 - train: epoch 0033, iter [00200, 00390], lr: 0.100000, loss: 4.2911
2023-07-02 00:08:27 - train: epoch 0033, iter [00250, 00390], lr: 0.100000, loss: 4.0407
2023-07-02 00:08:28 - train: epoch 0033, iter [00300, 00390], lr: 0.100000, loss: 4.2491
2023-07-02 00:08:29 - train: epoch 0033, iter [00350, 00390], lr: 0.100000, loss: 3.7599
2023-07-02 00:08:30 - train: epoch 033, train_loss: 3.8936
2023-07-02 00:08:32 - eval: epoch: 033, acc1: 22.170%, acc5: 49.790%, test_loss: 3.2449, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 00:08:32 - until epoch: 033, best_acc1: 22.180%
2023-07-02 00:08:32 - epoch 034 lr: 0.100000
2023-07-02 00:08:34 - train: epoch 0034, iter [00050, 00390], lr: 0.100000, loss: 4.1423
2023-07-02 00:08:36 - train: epoch 0034, iter [00100, 00390], lr: 0.100000, loss: 4.2244
2023-07-02 00:08:37 - train: epoch 0034, iter [00150, 00390], lr: 0.100000, loss: 3.2614
2023-07-02 00:08:39 - train: epoch 0034, iter [00200, 00390], lr: 0.100000, loss: 4.1719
2023-07-02 00:08:40 - train: epoch 0034, iter [00250, 00390], lr: 0.100000, loss: 3.4609
2023-07-02 00:08:42 - train: epoch 0034, iter [00300, 00390], lr: 0.100000, loss: 4.0297
2023-07-02 00:08:43 - train: epoch 0034, iter [00350, 00390], lr: 0.100000, loss: 4.1783
2023-07-02 00:08:44 - train: epoch 034, train_loss: 3.8854
2023-07-02 00:08:46 - eval: epoch: 034, acc1: 22.110%, acc5: 50.440%, test_loss: 3.2582, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:08:46 - until epoch: 034, best_acc1: 22.180%
2023-07-02 00:08:46 - epoch 035 lr: 0.100000
2023-07-02 00:08:48 - train: epoch 0035, iter [00050, 00390], lr: 0.100000, loss: 3.9045
2023-07-02 00:08:50 - train: epoch 0035, iter [00100, 00390], lr: 0.100000, loss: 3.8153
2023-07-02 00:08:51 - train: epoch 0035, iter [00150, 00390], lr: 0.100000, loss: 3.5743
2023-07-02 00:08:53 - train: epoch 0035, iter [00200, 00390], lr: 0.100000, loss: 3.7432
2023-07-02 00:08:54 - train: epoch 0035, iter [00250, 00390], lr: 0.100000, loss: 4.3336
2023-07-02 00:08:55 - train: epoch 0035, iter [00300, 00390], lr: 0.100000, loss: 4.0810
2023-07-02 00:08:57 - train: epoch 0035, iter [00350, 00390], lr: 0.100000, loss: 4.2065
2023-07-02 00:08:58 - train: epoch 035, train_loss: 3.8811
2023-07-02 00:08:59 - eval: epoch: 035, acc1: 22.220%, acc5: 49.650%, test_loss: 3.2806, per_image_load_time: 0.070ms, per_image_inference_time: 0.052ms
2023-07-02 00:09:00 - until epoch: 035, best_acc1: 22.220%
2023-07-02 00:09:00 - epoch 036 lr: 0.100000
2023-07-02 00:09:02 - train: epoch 0036, iter [00050, 00390], lr: 0.100000, loss: 3.9579
2023-07-02 00:09:04 - train: epoch 0036, iter [00100, 00390], lr: 0.100000, loss: 3.2935
2023-07-02 00:09:05 - train: epoch 0036, iter [00150, 00390], lr: 0.100000, loss: 3.7294
2023-07-02 00:09:06 - train: epoch 0036, iter [00200, 00390], lr: 0.100000, loss: 4.2378
2023-07-02 00:09:08 - train: epoch 0036, iter [00250, 00390], lr: 0.100000, loss: 4.0103
2023-07-02 00:09:09 - train: epoch 0036, iter [00300, 00390], lr: 0.100000, loss: 3.5779
2023-07-02 00:09:11 - train: epoch 0036, iter [00350, 00390], lr: 0.100000, loss: 3.9328
2023-07-02 00:09:12 - train: epoch 036, train_loss: 3.8903
2023-07-02 00:09:13 - eval: epoch: 036, acc1: 22.500%, acc5: 50.090%, test_loss: 3.2662, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:09:14 - until epoch: 036, best_acc1: 22.500%
2023-07-02 00:09:14 - epoch 037 lr: 0.100000
2023-07-02 00:09:16 - train: epoch 0037, iter [00050, 00390], lr: 0.100000, loss: 4.2689
2023-07-02 00:09:17 - train: epoch 0037, iter [00100, 00390], lr: 0.100000, loss: 3.1702
2023-07-02 00:09:19 - train: epoch 0037, iter [00150, 00390], lr: 0.100000, loss: 4.1580
2023-07-02 00:09:20 - train: epoch 0037, iter [00200, 00390], lr: 0.100000, loss: 3.9300
2023-07-02 00:09:21 - train: epoch 0037, iter [00250, 00390], lr: 0.100000, loss: 3.6411
2023-07-02 00:09:23 - train: epoch 0037, iter [00300, 00390], lr: 0.100000, loss: 3.2967
2023-07-02 00:09:24 - train: epoch 0037, iter [00350, 00390], lr: 0.100000, loss: 4.1764
2023-07-02 00:09:25 - train: epoch 037, train_loss: 3.8823
2023-07-02 00:09:27 - eval: epoch: 037, acc1: 21.800%, acc5: 50.420%, test_loss: 3.2866, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:09:27 - until epoch: 037, best_acc1: 22.500%
2023-07-02 00:09:27 - epoch 038 lr: 0.100000
2023-07-02 00:09:29 - train: epoch 0038, iter [00050, 00390], lr: 0.100000, loss: 3.9773
2023-07-02 00:09:31 - train: epoch 0038, iter [00100, 00390], lr: 0.100000, loss: 3.5008
2023-07-02 00:09:32 - train: epoch 0038, iter [00150, 00390], lr: 0.100000, loss: 4.2325
2023-07-02 00:09:34 - train: epoch 0038, iter [00200, 00390], lr: 0.100000, loss: 3.2228
2023-07-02 00:09:35 - train: epoch 0038, iter [00250, 00390], lr: 0.100000, loss: 3.3125
2023-07-02 00:09:37 - train: epoch 0038, iter [00300, 00390], lr: 0.100000, loss: 3.6256
2023-07-02 00:09:38 - train: epoch 0038, iter [00350, 00390], lr: 0.100000, loss: 3.9210
2023-07-02 00:09:39 - train: epoch 038, train_loss: 3.8567
2023-07-02 00:09:41 - eval: epoch: 038, acc1: 22.680%, acc5: 50.670%, test_loss: 3.2592, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:09:42 - until epoch: 038, best_acc1: 22.680%
2023-07-02 00:09:42 - epoch 039 lr: 0.100000
2023-07-02 00:09:44 - train: epoch 0039, iter [00050, 00390], lr: 0.100000, loss: 4.0894
2023-07-02 00:09:45 - train: epoch 0039, iter [00100, 00390], lr: 0.100000, loss: 3.4679
2023-07-02 00:09:46 - train: epoch 0039, iter [00150, 00390], lr: 0.100000, loss: 3.5792
2023-07-02 00:09:48 - train: epoch 0039, iter [00200, 00390], lr: 0.100000, loss: 3.9211
2023-07-02 00:09:49 - train: epoch 0039, iter [00250, 00390], lr: 0.100000, loss: 3.7624
2023-07-02 00:09:51 - train: epoch 0039, iter [00300, 00390], lr: 0.100000, loss: 3.5871
2023-07-02 00:09:52 - train: epoch 0039, iter [00350, 00390], lr: 0.100000, loss: 3.5776
2023-07-02 00:09:53 - train: epoch 039, train_loss: 3.8496
2023-07-02 00:09:55 - eval: epoch: 039, acc1: 21.870%, acc5: 50.220%, test_loss: 3.2897, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:09:55 - until epoch: 039, best_acc1: 22.680%
2023-07-02 00:09:55 - epoch 040 lr: 0.100000
2023-07-02 00:09:57 - train: epoch 0040, iter [00050, 00390], lr: 0.100000, loss: 3.3816
2023-07-02 00:09:59 - train: epoch 0040, iter [00100, 00390], lr: 0.100000, loss: 3.6191
2023-07-02 00:10:00 - train: epoch 0040, iter [00150, 00390], lr: 0.100000, loss: 4.1617
2023-07-02 00:10:02 - train: epoch 0040, iter [00200, 00390], lr: 0.100000, loss: 4.1597
2023-07-02 00:10:03 - train: epoch 0040, iter [00250, 00390], lr: 0.100000, loss: 3.7124
2023-07-02 00:10:04 - train: epoch 0040, iter [00300, 00390], lr: 0.100000, loss: 4.0019
2023-07-02 00:10:06 - train: epoch 0040, iter [00350, 00390], lr: 0.100000, loss: 3.4658
2023-07-02 00:10:07 - train: epoch 040, train_loss: 3.8657
2023-07-02 00:10:08 - eval: epoch: 040, acc1: 22.300%, acc5: 51.320%, test_loss: 3.2586, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 00:10:09 - until epoch: 040, best_acc1: 22.680%
2023-07-02 00:10:09 - epoch 041 lr: 0.100000
2023-07-02 00:10:11 - train: epoch 0041, iter [00050, 00390], lr: 0.100000, loss: 3.6230
2023-07-02 00:10:12 - train: epoch 0041, iter [00100, 00390], lr: 0.100000, loss: 3.7204
2023-07-02 00:10:14 - train: epoch 0041, iter [00150, 00390], lr: 0.100000, loss: 4.2160
2023-07-02 00:10:15 - train: epoch 0041, iter [00200, 00390], lr: 0.100000, loss: 3.6994
2023-07-02 00:10:16 - train: epoch 0041, iter [00250, 00390], lr: 0.100000, loss: 3.8183
2023-07-02 00:10:18 - train: epoch 0041, iter [00300, 00390], lr: 0.100000, loss: 3.3631
2023-07-02 00:10:19 - train: epoch 0041, iter [00350, 00390], lr: 0.100000, loss: 4.0712
2023-07-02 00:10:20 - train: epoch 041, train_loss: 3.8442
2023-07-02 00:10:22 - eval: epoch: 041, acc1: 22.940%, acc5: 51.040%, test_loss: 3.2436, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:10:22 - until epoch: 041, best_acc1: 22.940%
2023-07-02 00:10:22 - epoch 042 lr: 0.100000
2023-07-02 00:10:25 - train: epoch 0042, iter [00050, 00390], lr: 0.100000, loss: 4.0393
2023-07-02 00:10:26 - train: epoch 0042, iter [00100, 00390], lr: 0.100000, loss: 4.2632
2023-07-02 00:10:27 - train: epoch 0042, iter [00150, 00390], lr: 0.100000, loss: 4.1636
2023-07-02 00:10:29 - train: epoch 0042, iter [00200, 00390], lr: 0.100000, loss: 4.1063
2023-07-02 00:10:30 - train: epoch 0042, iter [00250, 00390], lr: 0.100000, loss: 3.4719
2023-07-02 00:10:32 - train: epoch 0042, iter [00300, 00390], lr: 0.100000, loss: 3.5351
2023-07-02 00:10:33 - train: epoch 0042, iter [00350, 00390], lr: 0.100000, loss: 3.4231
2023-07-02 00:10:34 - train: epoch 042, train_loss: 3.8685
2023-07-02 00:10:36 - eval: epoch: 042, acc1: 21.940%, acc5: 50.180%, test_loss: 3.2426, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:10:36 - until epoch: 042, best_acc1: 22.940%
2023-07-02 00:10:36 - epoch 043 lr: 0.100000
2023-07-02 00:10:38 - train: epoch 0043, iter [00050, 00390], lr: 0.100000, loss: 4.2184
2023-07-02 00:10:40 - train: epoch 0043, iter [00100, 00390], lr: 0.100000, loss: 3.9617
2023-07-02 00:10:41 - train: epoch 0043, iter [00150, 00390], lr: 0.100000, loss: 3.3322
2023-07-02 00:10:43 - train: epoch 0043, iter [00200, 00390], lr: 0.100000, loss: 4.1429
2023-07-02 00:10:44 - train: epoch 0043, iter [00250, 00390], lr: 0.100000, loss: 3.6908
2023-07-02 00:10:45 - train: epoch 0043, iter [00300, 00390], lr: 0.100000, loss: 3.5394
2023-07-02 00:10:47 - train: epoch 0043, iter [00350, 00390], lr: 0.100000, loss: 4.1503
2023-07-02 00:10:48 - train: epoch 043, train_loss: 3.8281
2023-07-02 00:10:49 - eval: epoch: 043, acc1: 22.880%, acc5: 51.660%, test_loss: 3.1996, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:10:50 - until epoch: 043, best_acc1: 22.940%
2023-07-02 00:10:50 - epoch 044 lr: 0.100000
2023-07-02 00:10:52 - train: epoch 0044, iter [00050, 00390], lr: 0.100000, loss: 3.7554
2023-07-02 00:10:54 - train: epoch 0044, iter [00100, 00390], lr: 0.100000, loss: 3.9437
2023-07-02 00:10:56 - train: epoch 0044, iter [00150, 00390], lr: 0.100000, loss: 4.2016
2023-07-02 00:10:57 - train: epoch 0044, iter [00200, 00390], lr: 0.100000, loss: 3.2294
2023-07-02 00:10:59 - train: epoch 0044, iter [00250, 00390], lr: 0.100000, loss: 3.9045
2023-07-02 00:11:00 - train: epoch 0044, iter [00300, 00390], lr: 0.100000, loss: 3.8872
2023-07-02 00:11:01 - train: epoch 0044, iter [00350, 00390], lr: 0.100000, loss: 3.2133
2023-07-02 00:11:03 - train: epoch 044, train_loss: 3.8392
2023-07-02 00:11:04 - eval: epoch: 044, acc1: 22.610%, acc5: 51.040%, test_loss: 3.2133, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 00:11:04 - until epoch: 044, best_acc1: 22.940%
2023-07-02 00:11:04 - epoch 045 lr: 0.100000
2023-07-02 00:11:06 - train: epoch 0045, iter [00050, 00390], lr: 0.100000, loss: 3.4979
2023-07-02 00:11:08 - train: epoch 0045, iter [00100, 00390], lr: 0.100000, loss: 3.8489
2023-07-02 00:11:09 - train: epoch 0045, iter [00150, 00390], lr: 0.100000, loss: 3.4598
2023-07-02 00:11:11 - train: epoch 0045, iter [00200, 00390], lr: 0.100000, loss: 3.2900
2023-07-02 00:11:12 - train: epoch 0045, iter [00250, 00390], lr: 0.100000, loss: 3.4592
2023-07-02 00:11:14 - train: epoch 0045, iter [00300, 00390], lr: 0.100000, loss: 4.0930
2023-07-02 00:11:15 - train: epoch 0045, iter [00350, 00390], lr: 0.100000, loss: 4.1612
2023-07-02 00:11:16 - train: epoch 045, train_loss: 3.8405
2023-07-02 00:11:18 - eval: epoch: 045, acc1: 22.960%, acc5: 51.960%, test_loss: 3.1801, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:11:19 - until epoch: 045, best_acc1: 22.960%
2023-07-02 00:11:19 - epoch 046 lr: 0.100000
2023-07-02 00:11:21 - train: epoch 0046, iter [00050, 00390], lr: 0.100000, loss: 3.5043
2023-07-02 00:11:22 - train: epoch 0046, iter [00100, 00390], lr: 0.100000, loss: 3.6159
2023-07-02 00:11:24 - train: epoch 0046, iter [00150, 00390], lr: 0.100000, loss: 3.8723
2023-07-02 00:11:26 - train: epoch 0046, iter [00200, 00390], lr: 0.100000, loss: 3.8944
2023-07-02 00:11:27 - train: epoch 0046, iter [00250, 00390], lr: 0.100000, loss: 3.7302
2023-07-02 00:11:29 - train: epoch 0046, iter [00300, 00390], lr: 0.100000, loss: 3.2023
2023-07-02 00:11:30 - train: epoch 0046, iter [00350, 00390], lr: 0.100000, loss: 4.1713
2023-07-02 00:11:32 - train: epoch 046, train_loss: 3.8585
2023-07-02 00:11:33 - eval: epoch: 046, acc1: 23.500%, acc5: 52.320%, test_loss: 3.1831, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-02 00:11:34 - until epoch: 046, best_acc1: 23.500%
2023-07-02 00:11:34 - epoch 047 lr: 0.100000
2023-07-02 00:11:36 - train: epoch 0047, iter [00050, 00390], lr: 0.100000, loss: 3.2998
2023-07-02 00:11:38 - train: epoch 0047, iter [00100, 00390], lr: 0.100000, loss: 3.4889
2023-07-02 00:11:39 - train: epoch 0047, iter [00150, 00390], lr: 0.100000, loss: 3.6235
2023-07-02 00:11:40 - train: epoch 0047, iter [00200, 00390], lr: 0.100000, loss: 3.9697
2023-07-02 00:11:42 - train: epoch 0047, iter [00250, 00390], lr: 0.100000, loss: 3.8825
2023-07-02 00:11:43 - train: epoch 0047, iter [00300, 00390], lr: 0.100000, loss: 3.4243
2023-07-02 00:11:45 - train: epoch 0047, iter [00350, 00390], lr: 0.100000, loss: 3.9624
2023-07-02 00:11:46 - train: epoch 047, train_loss: 3.8563
2023-07-02 00:11:47 - eval: epoch: 047, acc1: 23.490%, acc5: 51.950%, test_loss: 3.1989, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-07-02 00:11:47 - until epoch: 047, best_acc1: 23.500%
2023-07-02 00:11:47 - epoch 048 lr: 0.100000
2023-07-02 00:11:50 - train: epoch 0048, iter [00050, 00390], lr: 0.100000, loss: 3.8450
2023-07-02 00:11:51 - train: epoch 0048, iter [00100, 00390], lr: 0.100000, loss: 4.0419
2023-07-02 00:11:52 - train: epoch 0048, iter [00150, 00390], lr: 0.100000, loss: 3.3390
2023-07-02 00:11:54 - train: epoch 0048, iter [00200, 00390], lr: 0.100000, loss: 4.0868
2023-07-02 00:11:55 - train: epoch 0048, iter [00250, 00390], lr: 0.100000, loss: 3.8469
2023-07-02 00:11:57 - train: epoch 0048, iter [00300, 00390], lr: 0.100000, loss: 3.1703
2023-07-02 00:11:58 - train: epoch 0048, iter [00350, 00390], lr: 0.100000, loss: 3.4571
2023-07-02 00:12:00 - train: epoch 048, train_loss: 3.8422
2023-07-02 00:12:01 - eval: epoch: 048, acc1: 22.660%, acc5: 51.090%, test_loss: 3.2323, per_image_load_time: 0.089ms, per_image_inference_time: 0.057ms
2023-07-02 00:12:02 - until epoch: 048, best_acc1: 23.500%
2023-07-02 00:12:02 - epoch 049 lr: 0.100000
2023-07-02 00:12:04 - train: epoch 0049, iter [00050, 00390], lr: 0.100000, loss: 3.7037
2023-07-02 00:12:05 - train: epoch 0049, iter [00100, 00390], lr: 0.100000, loss: 4.0339
2023-07-02 00:12:07 - train: epoch 0049, iter [00150, 00390], lr: 0.100000, loss: 3.3121
2023-07-02 00:12:09 - train: epoch 0049, iter [00200, 00390], lr: 0.100000, loss: 3.7124
2023-07-02 00:12:11 - train: epoch 0049, iter [00250, 00390], lr: 0.100000, loss: 4.1706
2023-07-02 00:12:12 - train: epoch 0049, iter [00300, 00390], lr: 0.100000, loss: 4.1899
2023-07-02 00:12:14 - train: epoch 0049, iter [00350, 00390], lr: 0.100000, loss: 4.1357
2023-07-02 00:12:16 - train: epoch 049, train_loss: 3.8117
2023-07-02 00:12:18 - eval: epoch: 049, acc1: 22.760%, acc5: 51.080%, test_loss: 3.2240, per_image_load_time: 0.092ms, per_image_inference_time: 0.056ms
2023-07-02 00:12:19 - until epoch: 049, best_acc1: 23.500%
2023-07-02 00:12:19 - epoch 050 lr: 0.100000
2023-07-02 00:12:22 - train: epoch 0050, iter [00050, 00390], lr: 0.100000, loss: 3.9692
2023-07-02 00:12:23 - train: epoch 0050, iter [00100, 00390], lr: 0.100000, loss: 3.2604
2023-07-02 00:12:25 - train: epoch 0050, iter [00150, 00390], lr: 0.100000, loss: 4.0693
2023-07-02 00:12:26 - train: epoch 0050, iter [00200, 00390], lr: 0.100000, loss: 3.7969
2023-07-02 00:12:28 - train: epoch 0050, iter [00250, 00390], lr: 0.100000, loss: 3.5050
2023-07-02 00:12:29 - train: epoch 0050, iter [00300, 00390], lr: 0.100000, loss: 3.9790
2023-07-02 00:12:30 - train: epoch 0050, iter [00350, 00390], lr: 0.100000, loss: 4.0179
2023-07-02 00:12:32 - train: epoch 050, train_loss: 3.8675
2023-07-02 00:12:33 - eval: epoch: 050, acc1: 22.160%, acc5: 50.750%, test_loss: 3.2462, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-07-02 00:12:33 - until epoch: 050, best_acc1: 23.500%
2023-07-02 00:12:33 - epoch 051 lr: 0.100000
2023-07-02 00:12:35 - train: epoch 0051, iter [00050, 00390], lr: 0.100000, loss: 4.1146
2023-07-02 00:12:37 - train: epoch 0051, iter [00100, 00390], lr: 0.100000, loss: 4.0699
2023-07-02 00:12:38 - train: epoch 0051, iter [00150, 00390], lr: 0.100000, loss: 4.0049
2023-07-02 00:12:40 - train: epoch 0051, iter [00200, 00390], lr: 0.100000, loss: 4.1207
2023-07-02 00:12:41 - train: epoch 0051, iter [00250, 00390], lr: 0.100000, loss: 4.2245
2023-07-02 00:12:43 - train: epoch 0051, iter [00300, 00390], lr: 0.100000, loss: 3.3799
2023-07-02 00:12:44 - train: epoch 0051, iter [00350, 00390], lr: 0.100000, loss: 4.2534
2023-07-02 00:12:45 - train: epoch 051, train_loss: 3.8358
2023-07-02 00:12:47 - eval: epoch: 051, acc1: 23.130%, acc5: 51.400%, test_loss: 3.2237, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-07-02 00:12:47 - until epoch: 051, best_acc1: 23.500%
2023-07-02 00:12:47 - epoch 052 lr: 0.100000
2023-07-02 00:12:49 - train: epoch 0052, iter [00050, 00390], lr: 0.100000, loss: 3.6059
2023-07-02 00:12:51 - train: epoch 0052, iter [00100, 00390], lr: 0.100000, loss: 4.0724
2023-07-02 00:12:52 - train: epoch 0052, iter [00150, 00390], lr: 0.100000, loss: 4.1843
2023-07-02 00:12:54 - train: epoch 0052, iter [00200, 00390], lr: 0.100000, loss: 3.8412
2023-07-02 00:12:55 - train: epoch 0052, iter [00250, 00390], lr: 0.100000, loss: 4.1006
2023-07-02 00:12:57 - train: epoch 0052, iter [00300, 00390], lr: 0.100000, loss: 3.6922
2023-07-02 00:12:58 - train: epoch 0052, iter [00350, 00390], lr: 0.100000, loss: 4.1649
2023-07-02 00:12:59 - train: epoch 052, train_loss: 3.8386
2023-07-02 00:13:01 - eval: epoch: 052, acc1: 22.620%, acc5: 51.380%, test_loss: 3.2235, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-07-02 00:13:01 - until epoch: 052, best_acc1: 23.500%
2023-07-02 00:13:01 - epoch 053 lr: 0.100000
2023-07-02 00:13:04 - train: epoch 0053, iter [00050, 00390], lr: 0.100000, loss: 3.5029
2023-07-02 00:13:05 - train: epoch 0053, iter [00100, 00390], lr: 0.100000, loss: 3.1521
2023-07-02 00:13:07 - train: epoch 0053, iter [00150, 00390], lr: 0.100000, loss: 3.1768
2023-07-02 00:13:08 - train: epoch 0053, iter [00200, 00390], lr: 0.100000, loss: 4.2449
2023-07-02 00:13:09 - train: epoch 0053, iter [00250, 00390], lr: 0.100000, loss: 3.3837
2023-07-02 00:13:11 - train: epoch 0053, iter [00300, 00390], lr: 0.100000, loss: 4.0219
2023-07-02 00:13:12 - train: epoch 0053, iter [00350, 00390], lr: 0.100000, loss: 4.0431
2023-07-02 00:13:14 - train: epoch 053, train_loss: 3.8408
2023-07-02 00:13:15 - eval: epoch: 053, acc1: 23.620%, acc5: 52.680%, test_loss: 3.1575, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-07-02 00:13:15 - until epoch: 053, best_acc1: 23.620%
2023-07-02 00:13:15 - epoch 054 lr: 0.100000
2023-07-02 00:13:18 - train: epoch 0054, iter [00050, 00390], lr: 0.100000, loss: 4.1300
2023-07-02 00:13:19 - train: epoch 0054, iter [00100, 00390], lr: 0.100000, loss: 4.0817
2023-07-02 00:13:20 - train: epoch 0054, iter [00150, 00390], lr: 0.100000, loss: 3.3554
2023-07-02 00:13:22 - train: epoch 0054, iter [00200, 00390], lr: 0.100000, loss: 3.6111
2023-07-02 00:13:23 - train: epoch 0054, iter [00250, 00390], lr: 0.100000, loss: 3.9417
2023-07-02 00:13:25 - train: epoch 0054, iter [00300, 00390], lr: 0.100000, loss: 3.4102
2023-07-02 00:13:26 - train: epoch 0054, iter [00350, 00390], lr: 0.100000, loss: 3.3020
2023-07-02 00:13:27 - train: epoch 054, train_loss: 3.8452
2023-07-02 00:13:29 - eval: epoch: 054, acc1: 23.630%, acc5: 52.730%, test_loss: 3.1585, per_image_load_time: 0.074ms, per_image_inference_time: 0.054ms
2023-07-02 00:13:29 - until epoch: 054, best_acc1: 23.630%
2023-07-02 00:13:29 - epoch 055 lr: 0.100000
2023-07-02 00:13:31 - train: epoch 0055, iter [00050, 00390], lr: 0.100000, loss: 3.9185
2023-07-02 00:13:33 - train: epoch 0055, iter [00100, 00390], lr: 0.100000, loss: 3.6399
2023-07-02 00:13:34 - train: epoch 0055, iter [00150, 00390], lr: 0.100000, loss: 3.9981
2023-07-02 00:13:36 - train: epoch 0055, iter [00200, 00390], lr: 0.100000, loss: 3.8156
2023-07-02 00:13:37 - train: epoch 0055, iter [00250, 00390], lr: 0.100000, loss: 4.1116
2023-07-02 00:13:38 - train: epoch 0055, iter [00300, 00390], lr: 0.100000, loss: 4.1559
2023-07-02 00:13:40 - train: epoch 0055, iter [00350, 00390], lr: 0.100000, loss: 3.8772
2023-07-02 00:13:41 - train: epoch 055, train_loss: 3.8549
2023-07-02 00:13:43 - eval: epoch: 055, acc1: 23.980%, acc5: 52.140%, test_loss: 3.1745, per_image_load_time: 0.095ms, per_image_inference_time: 0.054ms
2023-07-02 00:13:44 - until epoch: 055, best_acc1: 23.980%
2023-07-02 00:13:44 - epoch 056 lr: 0.100000
2023-07-02 00:13:46 - train: epoch 0056, iter [00050, 00390], lr: 0.100000, loss: 3.9879
2023-07-02 00:13:48 - train: epoch 0056, iter [00100, 00390], lr: 0.100000, loss: 3.1123
2023-07-02 00:13:49 - train: epoch 0056, iter [00150, 00390], lr: 0.100000, loss: 4.2889
2023-07-02 00:13:50 - train: epoch 0056, iter [00200, 00390], lr: 0.100000, loss: 3.9751
2023-07-02 00:13:52 - train: epoch 0056, iter [00250, 00390], lr: 0.100000, loss: 3.1917
2023-07-02 00:13:53 - train: epoch 0056, iter [00300, 00390], lr: 0.100000, loss: 4.1522
2023-07-02 00:13:55 - train: epoch 0056, iter [00350, 00390], lr: 0.100000, loss: 3.5893
2023-07-02 00:13:56 - train: epoch 056, train_loss: 3.8295
2023-07-02 00:13:57 - eval: epoch: 056, acc1: 23.250%, acc5: 52.480%, test_loss: 3.2228, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-07-02 00:13:58 - until epoch: 056, best_acc1: 23.980%
2023-07-02 00:13:58 - epoch 057 lr: 0.100000
2023-07-02 00:14:00 - train: epoch 0057, iter [00050, 00390], lr: 0.100000, loss: 3.3533
2023-07-02 00:14:01 - train: epoch 0057, iter [00100, 00390], lr: 0.100000, loss: 3.5399
2023-07-02 00:14:03 - train: epoch 0057, iter [00150, 00390], lr: 0.100000, loss: 3.0734
2023-07-02 00:14:04 - train: epoch 0057, iter [00200, 00390], lr: 0.100000, loss: 4.1451
2023-07-02 00:14:05 - train: epoch 0057, iter [00250, 00390], lr: 0.100000, loss: 3.3739
2023-07-02 00:14:07 - train: epoch 0057, iter [00300, 00390], lr: 0.100000, loss: 3.9578
2023-07-02 00:14:08 - train: epoch 0057, iter [00350, 00390], lr: 0.100000, loss: 3.2773
2023-07-02 00:14:10 - train: epoch 057, train_loss: 3.8189
2023-07-02 00:14:11 - eval: epoch: 057, acc1: 23.410%, acc5: 52.570%, test_loss: 3.1962, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:14:11 - until epoch: 057, best_acc1: 23.980%
2023-07-02 00:14:11 - epoch 058 lr: 0.100000
2023-07-02 00:14:14 - train: epoch 0058, iter [00050, 00390], lr: 0.100000, loss: 4.2039
2023-07-02 00:14:15 - train: epoch 0058, iter [00100, 00390], lr: 0.100000, loss: 4.0366
2023-07-02 00:14:16 - train: epoch 0058, iter [00150, 00390], lr: 0.100000, loss: 4.0697
2023-07-02 00:14:18 - train: epoch 0058, iter [00200, 00390], lr: 0.100000, loss: 3.3966
2023-07-02 00:14:19 - train: epoch 0058, iter [00250, 00390], lr: 0.100000, loss: 4.1992
2023-07-02 00:14:21 - train: epoch 0058, iter [00300, 00390], lr: 0.100000, loss: 3.8013
2023-07-02 00:14:22 - train: epoch 0058, iter [00350, 00390], lr: 0.100000, loss: 3.5022
2023-07-02 00:14:23 - train: epoch 058, train_loss: 3.8278
2023-07-02 00:14:25 - eval: epoch: 058, acc1: 24.440%, acc5: 53.220%, test_loss: 3.1632, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:14:25 - until epoch: 058, best_acc1: 24.440%
2023-07-02 00:14:25 - epoch 059 lr: 0.100000
2023-07-02 00:14:27 - train: epoch 0059, iter [00050, 00390], lr: 0.100000, loss: 4.3530
2023-07-02 00:14:29 - train: epoch 0059, iter [00100, 00390], lr: 0.100000, loss: 4.1037
2023-07-02 00:14:30 - train: epoch 0059, iter [00150, 00390], lr: 0.100000, loss: 4.1083
2023-07-02 00:14:32 - train: epoch 0059, iter [00200, 00390], lr: 0.100000, loss: 3.3502
2023-07-02 00:14:33 - train: epoch 0059, iter [00250, 00390], lr: 0.100000, loss: 3.9816
2023-07-02 00:14:34 - train: epoch 0059, iter [00300, 00390], lr: 0.100000, loss: 4.1119
2023-07-02 00:14:36 - train: epoch 0059, iter [00350, 00390], lr: 0.100000, loss: 4.1234
2023-07-02 00:14:37 - train: epoch 059, train_loss: 3.8000
2023-07-02 00:14:38 - eval: epoch: 059, acc1: 24.420%, acc5: 53.240%, test_loss: 3.1457, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 00:14:38 - until epoch: 059, best_acc1: 24.440%
2023-07-02 00:14:38 - epoch 060 lr: 0.100000
2023-07-02 00:14:41 - train: epoch 0060, iter [00050, 00390], lr: 0.100000, loss: 3.4369
2023-07-02 00:14:42 - train: epoch 0060, iter [00100, 00390], lr: 0.100000, loss: 3.6484
2023-07-02 00:14:44 - train: epoch 0060, iter [00150, 00390], lr: 0.100000, loss: 3.8858
2023-07-02 00:14:45 - train: epoch 0060, iter [00200, 00390], lr: 0.100000, loss: 3.1706
2023-07-02 00:14:46 - train: epoch 0060, iter [00250, 00390], lr: 0.100000, loss: 4.0382
2023-07-02 00:14:48 - train: epoch 0060, iter [00300, 00390], lr: 0.100000, loss: 3.0634
2023-07-02 00:14:49 - train: epoch 0060, iter [00350, 00390], lr: 0.100000, loss: 3.2356
2023-07-02 00:14:51 - train: epoch 060, train_loss: 3.8145
2023-07-02 00:14:52 - eval: epoch: 060, acc1: 23.400%, acc5: 52.050%, test_loss: 3.1819, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:14:53 - until epoch: 060, best_acc1: 24.440%
2023-07-02 00:14:53 - epoch 061 lr: 0.020000
2023-07-02 00:14:55 - train: epoch 0061, iter [00050, 00390], lr: 0.020000, loss: 3.0359
2023-07-02 00:14:57 - train: epoch 0061, iter [00100, 00390], lr: 0.020000, loss: 3.8016
2023-07-02 00:14:58 - train: epoch 0061, iter [00150, 00390], lr: 0.020000, loss: 4.1293
2023-07-02 00:15:00 - train: epoch 0061, iter [00200, 00390], lr: 0.020000, loss: 3.3824
2023-07-02 00:15:01 - train: epoch 0061, iter [00250, 00390], lr: 0.020000, loss: 2.7395
2023-07-02 00:15:03 - train: epoch 0061, iter [00300, 00390], lr: 0.020000, loss: 3.9058
2023-07-02 00:15:04 - train: epoch 0061, iter [00350, 00390], lr: 0.020000, loss: 4.1303
2023-07-02 00:15:05 - train: epoch 061, train_loss: 3.6690
2023-07-02 00:15:07 - eval: epoch: 061, acc1: 28.730%, acc5: 58.370%, test_loss: 2.9435, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 00:15:07 - until epoch: 061, best_acc1: 28.730%
2023-07-02 00:15:07 - epoch 062 lr: 0.020000
2023-07-02 00:15:09 - train: epoch 0062, iter [00050, 00390], lr: 0.020000, loss: 3.4268
2023-07-02 00:15:11 - train: epoch 0062, iter [00100, 00390], lr: 0.020000, loss: 3.8104
2023-07-02 00:15:12 - train: epoch 0062, iter [00150, 00390], lr: 0.020000, loss: 4.2498
2023-07-02 00:15:14 - train: epoch 0062, iter [00200, 00390], lr: 0.020000, loss: 2.9684
2023-07-02 00:15:15 - train: epoch 0062, iter [00250, 00390], lr: 0.020000, loss: 3.7352
2023-07-02 00:15:16 - train: epoch 0062, iter [00300, 00390], lr: 0.020000, loss: 2.9368
2023-07-02 00:15:18 - train: epoch 0062, iter [00350, 00390], lr: 0.020000, loss: 3.8543
2023-07-02 00:15:19 - train: epoch 062, train_loss: 3.6787
2023-07-02 00:15:20 - eval: epoch: 062, acc1: 29.440%, acc5: 59.100%, test_loss: 2.9029, per_image_load_time: 0.071ms, per_image_inference_time: 0.055ms
2023-07-02 00:15:21 - until epoch: 062, best_acc1: 29.440%
2023-07-02 00:15:21 - epoch 063 lr: 0.020000
2023-07-02 00:15:23 - train: epoch 0063, iter [00050, 00390], lr: 0.020000, loss: 3.4253
2023-07-02 00:15:25 - train: epoch 0063, iter [00100, 00390], lr: 0.020000, loss: 4.1352
2023-07-02 00:15:26 - train: epoch 0063, iter [00150, 00390], lr: 0.020000, loss: 3.8337
2023-07-02 00:15:27 - train: epoch 0063, iter [00200, 00390], lr: 0.020000, loss: 2.9044
2023-07-02 00:15:29 - train: epoch 0063, iter [00250, 00390], lr: 0.020000, loss: 3.8732
2023-07-02 00:15:30 - train: epoch 0063, iter [00300, 00390], lr: 0.020000, loss: 3.8452
2023-07-02 00:15:32 - train: epoch 0063, iter [00350, 00390], lr: 0.020000, loss: 3.6259
2023-07-02 00:15:33 - train: epoch 063, train_loss: 3.6364
2023-07-02 00:15:34 - eval: epoch: 063, acc1: 30.510%, acc5: 59.850%, test_loss: 2.8697, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 00:15:35 - until epoch: 063, best_acc1: 30.510%
2023-07-02 00:15:35 - epoch 064 lr: 0.020000
2023-07-02 00:15:37 - train: epoch 0064, iter [00050, 00390], lr: 0.020000, loss: 4.0167
2023-07-02 00:15:38 - train: epoch 0064, iter [00100, 00390], lr: 0.020000, loss: 3.7777
2023-07-02 00:15:40 - train: epoch 0064, iter [00150, 00390], lr: 0.020000, loss: 3.8374
2023-07-02 00:15:41 - train: epoch 0064, iter [00200, 00390], lr: 0.020000, loss: 3.7611
2023-07-02 00:15:43 - train: epoch 0064, iter [00250, 00390], lr: 0.020000, loss: 4.2106
2023-07-02 00:15:44 - train: epoch 0064, iter [00300, 00390], lr: 0.020000, loss: 4.0717
2023-07-02 00:15:46 - train: epoch 0064, iter [00350, 00390], lr: 0.020000, loss: 4.0537
2023-07-02 00:15:47 - train: epoch 064, train_loss: 3.6063
2023-07-02 00:15:48 - eval: epoch: 064, acc1: 30.440%, acc5: 60.310%, test_loss: 2.8470, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 00:15:49 - until epoch: 064, best_acc1: 30.510%
2023-07-02 00:15:49 - epoch 065 lr: 0.020000
2023-07-02 00:15:51 - train: epoch 0065, iter [00050, 00390], lr: 0.020000, loss: 3.3009
2023-07-02 00:15:52 - train: epoch 0065, iter [00100, 00390], lr: 0.020000, loss: 3.6955
2023-07-02 00:15:54 - train: epoch 0065, iter [00150, 00390], lr: 0.020000, loss: 3.9470
2023-07-02 00:15:55 - train: epoch 0065, iter [00200, 00390], lr: 0.020000, loss: 3.2121
2023-07-02 00:15:56 - train: epoch 0065, iter [00250, 00390], lr: 0.020000, loss: 3.5747
2023-07-02 00:15:58 - train: epoch 0065, iter [00300, 00390], lr: 0.020000, loss: 3.3687
2023-07-02 00:15:59 - train: epoch 0065, iter [00350, 00390], lr: 0.020000, loss: 4.1203
2023-07-02 00:16:00 - train: epoch 065, train_loss: 3.6331
2023-07-02 00:16:02 - eval: epoch: 065, acc1: 30.170%, acc5: 60.600%, test_loss: 2.8387, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:16:02 - until epoch: 065, best_acc1: 30.510%
2023-07-02 00:16:02 - epoch 066 lr: 0.020000
2023-07-02 00:16:04 - train: epoch 0066, iter [00050, 00390], lr: 0.020000, loss: 4.0025
2023-07-02 00:16:06 - train: epoch 0066, iter [00100, 00390], lr: 0.020000, loss: 3.6049
2023-07-02 00:16:07 - train: epoch 0066, iter [00150, 00390], lr: 0.020000, loss: 3.8611
2023-07-02 00:16:09 - train: epoch 0066, iter [00200, 00390], lr: 0.020000, loss: 3.7900
2023-07-02 00:16:10 - train: epoch 0066, iter [00250, 00390], lr: 0.020000, loss: 3.1820
2023-07-02 00:16:11 - train: epoch 0066, iter [00300, 00390], lr: 0.020000, loss: 3.1151
2023-07-02 00:16:13 - train: epoch 0066, iter [00350, 00390], lr: 0.020000, loss: 3.0678
2023-07-02 00:16:14 - train: epoch 066, train_loss: 3.6216
2023-07-02 00:16:15 - eval: epoch: 066, acc1: 30.020%, acc5: 60.220%, test_loss: 2.8706, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:16:16 - until epoch: 066, best_acc1: 30.510%
2023-07-02 00:16:16 - epoch 067 lr: 0.020000
2023-07-02 00:16:18 - train: epoch 0067, iter [00050, 00390], lr: 0.020000, loss: 3.7140
2023-07-02 00:16:19 - train: epoch 0067, iter [00100, 00390], lr: 0.020000, loss: 3.4812
2023-07-02 00:16:21 - train: epoch 0067, iter [00150, 00390], lr: 0.020000, loss: 3.3402
2023-07-02 00:16:22 - train: epoch 0067, iter [00200, 00390], lr: 0.020000, loss: 3.2520
2023-07-02 00:16:24 - train: epoch 0067, iter [00250, 00390], lr: 0.020000, loss: 2.8290
2023-07-02 00:16:25 - train: epoch 0067, iter [00300, 00390], lr: 0.020000, loss: 4.0013
2023-07-02 00:16:26 - train: epoch 0067, iter [00350, 00390], lr: 0.020000, loss: 4.1251
2023-07-02 00:16:28 - train: epoch 067, train_loss: 3.6352
2023-07-02 00:16:29 - eval: epoch: 067, acc1: 30.390%, acc5: 60.360%, test_loss: 2.8588, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:16:29 - until epoch: 067, best_acc1: 30.510%
2023-07-02 00:16:29 - epoch 068 lr: 0.020000
2023-07-02 00:16:32 - train: epoch 0068, iter [00050, 00390], lr: 0.020000, loss: 3.5748
2023-07-02 00:16:33 - train: epoch 0068, iter [00100, 00390], lr: 0.020000, loss: 3.7117
2023-07-02 00:16:34 - train: epoch 0068, iter [00150, 00390], lr: 0.020000, loss: 4.3964
2023-07-02 00:16:36 - train: epoch 0068, iter [00200, 00390], lr: 0.020000, loss: 3.7732
2023-07-02 00:16:37 - train: epoch 0068, iter [00250, 00390], lr: 0.020000, loss: 4.0486
2023-07-02 00:16:38 - train: epoch 0068, iter [00300, 00390], lr: 0.020000, loss: 3.7823
2023-07-02 00:16:40 - train: epoch 0068, iter [00350, 00390], lr: 0.020000, loss: 3.8883
2023-07-02 00:16:41 - train: epoch 068, train_loss: 3.6154
2023-07-02 00:16:42 - eval: epoch: 068, acc1: 29.960%, acc5: 59.280%, test_loss: 2.8851, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:16:43 - until epoch: 068, best_acc1: 30.510%
2023-07-02 00:16:43 - epoch 069 lr: 0.020000
2023-07-02 00:16:45 - train: epoch 0069, iter [00050, 00390], lr: 0.020000, loss: 3.9967
2023-07-02 00:16:46 - train: epoch 0069, iter [00100, 00390], lr: 0.020000, loss: 2.9945
2023-07-02 00:16:48 - train: epoch 0069, iter [00150, 00390], lr: 0.020000, loss: 3.1324
2023-07-02 00:16:49 - train: epoch 0069, iter [00200, 00390], lr: 0.020000, loss: 3.9707
2023-07-02 00:16:50 - train: epoch 0069, iter [00250, 00390], lr: 0.020000, loss: 3.9784
2023-07-02 00:16:52 - train: epoch 0069, iter [00300, 00390], lr: 0.020000, loss: 3.3684
2023-07-02 00:16:53 - train: epoch 0069, iter [00350, 00390], lr: 0.020000, loss: 4.1410
2023-07-02 00:16:55 - train: epoch 069, train_loss: 3.5953
2023-07-02 00:16:56 - eval: epoch: 069, acc1: 30.470%, acc5: 60.410%, test_loss: 2.8516, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:16:57 - until epoch: 069, best_acc1: 30.510%
2023-07-02 00:16:57 - epoch 070 lr: 0.020000
2023-07-02 00:16:59 - train: epoch 0070, iter [00050, 00390], lr: 0.020000, loss: 3.9783
2023-07-02 00:17:00 - train: epoch 0070, iter [00100, 00390], lr: 0.020000, loss: 4.0517
2023-07-02 00:17:02 - train: epoch 0070, iter [00150, 00390], lr: 0.020000, loss: 3.0484
2023-07-02 00:17:03 - train: epoch 0070, iter [00200, 00390], lr: 0.020000, loss: 3.7708
2023-07-02 00:17:05 - train: epoch 0070, iter [00250, 00390], lr: 0.020000, loss: 3.4049
2023-07-02 00:17:06 - train: epoch 0070, iter [00300, 00390], lr: 0.020000, loss: 2.8627
2023-07-02 00:17:07 - train: epoch 0070, iter [00350, 00390], lr: 0.020000, loss: 4.2302
2023-07-02 00:17:09 - train: epoch 070, train_loss: 3.6044
2023-07-02 00:17:10 - eval: epoch: 070, acc1: 30.980%, acc5: 61.650%, test_loss: 2.8040, per_image_load_time: 0.073ms, per_image_inference_time: 0.054ms
2023-07-02 00:17:11 - until epoch: 070, best_acc1: 30.980%
2023-07-02 00:17:11 - epoch 071 lr: 0.020000
2023-07-02 00:17:13 - train: epoch 0071, iter [00050, 00390], lr: 0.020000, loss: 3.7594
2023-07-02 00:17:14 - train: epoch 0071, iter [00100, 00390], lr: 0.020000, loss: 3.9044
2023-07-02 00:17:16 - train: epoch 0071, iter [00150, 00390], lr: 0.020000, loss: 3.9047
2023-07-02 00:17:17 - train: epoch 0071, iter [00200, 00390], lr: 0.020000, loss: 3.9103
2023-07-02 00:17:19 - train: epoch 0071, iter [00250, 00390], lr: 0.020000, loss: 3.3908
2023-07-02 00:17:20 - train: epoch 0071, iter [00300, 00390], lr: 0.020000, loss: 4.2087
2023-07-02 00:17:21 - train: epoch 0071, iter [00350, 00390], lr: 0.020000, loss: 3.8819
2023-07-02 00:17:23 - train: epoch 071, train_loss: 3.6054
2023-07-02 00:17:24 - eval: epoch: 071, acc1: 30.790%, acc5: 60.780%, test_loss: 2.8241, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 00:17:24 - until epoch: 071, best_acc1: 30.980%
2023-07-02 00:17:24 - epoch 072 lr: 0.020000
2023-07-02 00:17:26 - train: epoch 0072, iter [00050, 00390], lr: 0.020000, loss: 3.8259
2023-07-02 00:17:28 - train: epoch 0072, iter [00100, 00390], lr: 0.020000, loss: 4.2568
2023-07-02 00:17:29 - train: epoch 0072, iter [00150, 00390], lr: 0.020000, loss: 4.0151
2023-07-02 00:17:31 - train: epoch 0072, iter [00200, 00390], lr: 0.020000, loss: 3.9278
2023-07-02 00:17:32 - train: epoch 0072, iter [00250, 00390], lr: 0.020000, loss: 2.7017
2023-07-02 00:17:33 - train: epoch 0072, iter [00300, 00390], lr: 0.020000, loss: 3.5508
2023-07-02 00:17:35 - train: epoch 0072, iter [00350, 00390], lr: 0.020000, loss: 4.0073
2023-07-02 00:17:36 - train: epoch 072, train_loss: 3.6087
2023-07-02 00:17:37 - eval: epoch: 072, acc1: 30.670%, acc5: 60.770%, test_loss: 2.8371, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 00:17:38 - until epoch: 072, best_acc1: 30.980%
2023-07-02 00:17:38 - epoch 073 lr: 0.020000
2023-07-02 00:17:40 - train: epoch 0073, iter [00050, 00390], lr: 0.020000, loss: 3.1846
2023-07-02 00:17:41 - train: epoch 0073, iter [00100, 00390], lr: 0.020000, loss: 3.6920
2023-07-02 00:17:43 - train: epoch 0073, iter [00150, 00390], lr: 0.020000, loss: 4.0150
2023-07-02 00:17:44 - train: epoch 0073, iter [00200, 00390], lr: 0.020000, loss: 3.2795
2023-07-02 00:17:46 - train: epoch 0073, iter [00250, 00390], lr: 0.020000, loss: 3.5547
2023-07-02 00:17:47 - train: epoch 0073, iter [00300, 00390], lr: 0.020000, loss: 3.8558
2023-07-02 00:17:48 - train: epoch 0073, iter [00350, 00390], lr: 0.020000, loss: 3.7994
2023-07-02 00:17:49 - train: epoch 073, train_loss: 3.5745
2023-07-02 00:17:51 - eval: epoch: 073, acc1: 31.260%, acc5: 61.900%, test_loss: 2.8060, per_image_load_time: 0.070ms, per_image_inference_time: 0.061ms
2023-07-02 00:17:52 - until epoch: 073, best_acc1: 31.260%
2023-07-02 00:17:52 - epoch 074 lr: 0.020000
2023-07-02 00:17:55 - train: epoch 0074, iter [00050, 00390], lr: 0.020000, loss: 4.0981
2023-07-02 00:17:56 - train: epoch 0074, iter [00100, 00390], lr: 0.020000, loss: 3.1290
2023-07-02 00:17:57 - train: epoch 0074, iter [00150, 00390], lr: 0.020000, loss: 3.4820
2023-07-02 00:17:59 - train: epoch 0074, iter [00200, 00390], lr: 0.020000, loss: 3.9576
2023-07-02 00:18:00 - train: epoch 0074, iter [00250, 00390], lr: 0.020000, loss: 3.8519
2023-07-02 00:18:01 - train: epoch 0074, iter [00300, 00390], lr: 0.020000, loss: 4.1189
2023-07-02 00:18:03 - train: epoch 0074, iter [00350, 00390], lr: 0.020000, loss: 3.9229
2023-07-02 00:18:04 - train: epoch 074, train_loss: 3.5993
2023-07-02 00:18:05 - eval: epoch: 074, acc1: 31.060%, acc5: 61.580%, test_loss: 2.8157, per_image_load_time: 0.070ms, per_image_inference_time: 0.056ms
2023-07-02 00:18:06 - until epoch: 074, best_acc1: 31.260%
2023-07-02 00:18:06 - epoch 075 lr: 0.020000
2023-07-02 00:18:08 - train: epoch 0075, iter [00050, 00390], lr: 0.020000, loss: 2.9816
2023-07-02 00:18:09 - train: epoch 0075, iter [00100, 00390], lr: 0.020000, loss: 4.1050
2023-07-02 00:18:11 - train: epoch 0075, iter [00150, 00390], lr: 0.020000, loss: 3.8160
2023-07-02 00:18:12 - train: epoch 0075, iter [00200, 00390], lr: 0.020000, loss: 3.4242
2023-07-02 00:18:13 - train: epoch 0075, iter [00250, 00390], lr: 0.020000, loss: 3.9442
2023-07-02 00:18:15 - train: epoch 0075, iter [00300, 00390], lr: 0.020000, loss: 3.8200
2023-07-02 00:18:16 - train: epoch 0075, iter [00350, 00390], lr: 0.020000, loss: 3.7111
2023-07-02 00:18:17 - train: epoch 075, train_loss: 3.5969
2023-07-02 00:18:19 - eval: epoch: 075, acc1: 31.620%, acc5: 61.490%, test_loss: 2.8094, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-07-02 00:18:20 - until epoch: 075, best_acc1: 31.620%
2023-07-02 00:18:20 - epoch 076 lr: 0.020000
2023-07-02 00:18:22 - train: epoch 0076, iter [00050, 00390], lr: 0.020000, loss: 3.6716
2023-07-02 00:18:24 - train: epoch 0076, iter [00100, 00390], lr: 0.020000, loss: 3.2877
2023-07-02 00:18:25 - train: epoch 0076, iter [00150, 00390], lr: 0.020000, loss: 3.8844
2023-07-02 00:18:26 - train: epoch 0076, iter [00200, 00390], lr: 0.020000, loss: 2.6529
2023-07-02 00:18:28 - train: epoch 0076, iter [00250, 00390], lr: 0.020000, loss: 3.9571
2023-07-02 00:18:29 - train: epoch 0076, iter [00300, 00390], lr: 0.020000, loss: 3.2847
2023-07-02 00:18:30 - train: epoch 0076, iter [00350, 00390], lr: 0.020000, loss: 4.0743
2023-07-02 00:18:32 - train: epoch 076, train_loss: 3.5748
2023-07-02 00:18:33 - eval: epoch: 076, acc1: 31.520%, acc5: 61.630%, test_loss: 2.8045, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:18:33 - until epoch: 076, best_acc1: 31.620%
2023-07-02 00:18:33 - epoch 077 lr: 0.020000
2023-07-02 00:18:36 - train: epoch 0077, iter [00050, 00390], lr: 0.020000, loss: 3.2686
2023-07-02 00:18:37 - train: epoch 0077, iter [00100, 00390], lr: 0.020000, loss: 3.9227
2023-07-02 00:18:38 - train: epoch 0077, iter [00150, 00390], lr: 0.020000, loss: 3.3071
2023-07-02 00:18:40 - train: epoch 0077, iter [00200, 00390], lr: 0.020000, loss: 3.7832
2023-07-02 00:18:41 - train: epoch 0077, iter [00250, 00390], lr: 0.020000, loss: 4.0849
2023-07-02 00:18:43 - train: epoch 0077, iter [00300, 00390], lr: 0.020000, loss: 3.4613
2023-07-02 00:18:44 - train: epoch 0077, iter [00350, 00390], lr: 0.020000, loss: 4.0629
2023-07-02 00:18:45 - train: epoch 077, train_loss: 3.5815
2023-07-02 00:18:47 - eval: epoch: 077, acc1: 31.530%, acc5: 61.290%, test_loss: 2.7864, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:18:47 - until epoch: 077, best_acc1: 31.620%
2023-07-02 00:18:47 - epoch 078 lr: 0.020000
2023-07-02 00:18:49 - train: epoch 0078, iter [00050, 00390], lr: 0.020000, loss: 3.6710
2023-07-02 00:18:51 - train: epoch 0078, iter [00100, 00390], lr: 0.020000, loss: 2.7404
2023-07-02 00:18:52 - train: epoch 0078, iter [00150, 00390], lr: 0.020000, loss: 3.2503
2023-07-02 00:18:53 - train: epoch 0078, iter [00200, 00390], lr: 0.020000, loss: 3.9601
2023-07-02 00:18:55 - train: epoch 0078, iter [00250, 00390], lr: 0.020000, loss: 4.1314
2023-07-02 00:18:56 - train: epoch 0078, iter [00300, 00390], lr: 0.020000, loss: 4.0783
2023-07-02 00:18:58 - train: epoch 0078, iter [00350, 00390], lr: 0.020000, loss: 2.7976
2023-07-02 00:18:59 - train: epoch 078, train_loss: 3.5579
2023-07-02 00:19:00 - eval: epoch: 078, acc1: 31.730%, acc5: 61.490%, test_loss: 2.7959, per_image_load_time: 0.072ms, per_image_inference_time: 0.058ms
2023-07-02 00:19:01 - until epoch: 078, best_acc1: 31.730%
2023-07-02 00:19:01 - epoch 079 lr: 0.020000
2023-07-02 00:19:03 - train: epoch 0079, iter [00050, 00390], lr: 0.020000, loss: 3.3683
2023-07-02 00:19:04 - train: epoch 0079, iter [00100, 00390], lr: 0.020000, loss: 2.8371
2023-07-02 00:19:06 - train: epoch 0079, iter [00150, 00390], lr: 0.020000, loss: 3.7214
2023-07-02 00:19:07 - train: epoch 0079, iter [00200, 00390], lr: 0.020000, loss: 3.8990
2023-07-02 00:19:09 - train: epoch 0079, iter [00250, 00390], lr: 0.020000, loss: 3.8988
2023-07-02 00:19:10 - train: epoch 0079, iter [00300, 00390], lr: 0.020000, loss: 3.8898
2023-07-02 00:19:11 - train: epoch 0079, iter [00350, 00390], lr: 0.020000, loss: 3.6693
2023-07-02 00:19:13 - train: epoch 079, train_loss: 3.5316
2023-07-02 00:19:14 - eval: epoch: 079, acc1: 32.070%, acc5: 62.020%, test_loss: 2.7697, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:19:15 - until epoch: 079, best_acc1: 32.070%
2023-07-02 00:19:15 - epoch 080 lr: 0.020000
2023-07-02 00:19:17 - train: epoch 0080, iter [00050, 00390], lr: 0.020000, loss: 3.6907
2023-07-02 00:19:18 - train: epoch 0080, iter [00100, 00390], lr: 0.020000, loss: 3.8860
2023-07-02 00:19:20 - train: epoch 0080, iter [00150, 00390], lr: 0.020000, loss: 3.1427
2023-07-02 00:19:21 - train: epoch 0080, iter [00200, 00390], lr: 0.020000, loss: 4.2649
2023-07-02 00:19:22 - train: epoch 0080, iter [00250, 00390], lr: 0.020000, loss: 3.3495
2023-07-02 00:19:24 - train: epoch 0080, iter [00300, 00390], lr: 0.020000, loss: 3.5039
2023-07-02 00:19:25 - train: epoch 0080, iter [00350, 00390], lr: 0.020000, loss: 4.2357
2023-07-02 00:19:26 - train: epoch 080, train_loss: 3.5737
2023-07-02 00:19:28 - eval: epoch: 080, acc1: 31.650%, acc5: 62.120%, test_loss: 2.7801, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:19:28 - until epoch: 080, best_acc1: 32.070%
2023-07-02 00:19:28 - epoch 081 lr: 0.020000
2023-07-02 00:19:30 - train: epoch 0081, iter [00050, 00390], lr: 0.020000, loss: 3.8601
2023-07-02 00:19:32 - train: epoch 0081, iter [00100, 00390], lr: 0.020000, loss: 3.5197
2023-07-02 00:19:33 - train: epoch 0081, iter [00150, 00390], lr: 0.020000, loss: 4.0240
2023-07-02 00:19:34 - train: epoch 0081, iter [00200, 00390], lr: 0.020000, loss: 2.9372
2023-07-02 00:19:36 - train: epoch 0081, iter [00250, 00390], lr: 0.020000, loss: 3.5958
2023-07-02 00:19:37 - train: epoch 0081, iter [00300, 00390], lr: 0.020000, loss: 3.8569
2023-07-02 00:19:39 - train: epoch 0081, iter [00350, 00390], lr: 0.020000, loss: 3.6181
2023-07-02 00:19:40 - train: epoch 081, train_loss: 3.5813
2023-07-02 00:19:41 - eval: epoch: 081, acc1: 31.970%, acc5: 62.830%, test_loss: 2.7563, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:19:42 - until epoch: 081, best_acc1: 32.070%
2023-07-02 00:19:42 - epoch 082 lr: 0.020000
2023-07-02 00:19:44 - train: epoch 0082, iter [00050, 00390], lr: 0.020000, loss: 3.9447
2023-07-02 00:19:45 - train: epoch 0082, iter [00100, 00390], lr: 0.020000, loss: 3.3208
2023-07-02 00:19:47 - train: epoch 0082, iter [00150, 00390], lr: 0.020000, loss: 3.9361
2023-07-02 00:19:48 - train: epoch 0082, iter [00200, 00390], lr: 0.020000, loss: 4.0509
2023-07-02 00:19:50 - train: epoch 0082, iter [00250, 00390], lr: 0.020000, loss: 4.0719
2023-07-02 00:19:51 - train: epoch 0082, iter [00300, 00390], lr: 0.020000, loss: 2.7345
2023-07-02 00:19:52 - train: epoch 0082, iter [00350, 00390], lr: 0.020000, loss: 2.8631
2023-07-02 00:19:54 - train: epoch 082, train_loss: 3.6013
2023-07-02 00:19:55 - eval: epoch: 082, acc1: 31.030%, acc5: 60.870%, test_loss: 2.8092, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:19:55 - until epoch: 082, best_acc1: 32.070%
2023-07-02 00:19:55 - epoch 083 lr: 0.020000
2023-07-02 00:19:58 - train: epoch 0083, iter [00050, 00390], lr: 0.020000, loss: 3.3070
2023-07-02 00:19:59 - train: epoch 0083, iter [00100, 00390], lr: 0.020000, loss: 3.3135
2023-07-02 00:20:01 - train: epoch 0083, iter [00150, 00390], lr: 0.020000, loss: 3.9659
2023-07-02 00:20:02 - train: epoch 0083, iter [00200, 00390], lr: 0.020000, loss: 2.7525
2023-07-02 00:20:03 - train: epoch 0083, iter [00250, 00390], lr: 0.020000, loss: 3.0176
2023-07-02 00:20:05 - train: epoch 0083, iter [00300, 00390], lr: 0.020000, loss: 3.1514
2023-07-02 00:20:06 - train: epoch 0083, iter [00350, 00390], lr: 0.020000, loss: 2.6460
2023-07-02 00:20:07 - train: epoch 083, train_loss: 3.5793
2023-07-02 00:20:09 - eval: epoch: 083, acc1: 32.300%, acc5: 62.230%, test_loss: 2.7612, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:20:09 - until epoch: 083, best_acc1: 32.300%
2023-07-02 00:20:09 - epoch 084 lr: 0.020000
2023-07-02 00:20:11 - train: epoch 0084, iter [00050, 00390], lr: 0.020000, loss: 2.9819
2023-07-02 00:20:13 - train: epoch 0084, iter [00100, 00390], lr: 0.020000, loss: 4.0242
2023-07-02 00:20:14 - train: epoch 0084, iter [00150, 00390], lr: 0.020000, loss: 3.6370
2023-07-02 00:20:16 - train: epoch 0084, iter [00200, 00390], lr: 0.020000, loss: 3.4719
2023-07-02 00:20:17 - train: epoch 0084, iter [00250, 00390], lr: 0.020000, loss: 3.9680
2023-07-02 00:20:18 - train: epoch 0084, iter [00300, 00390], lr: 0.020000, loss: 3.2328
2023-07-02 00:20:20 - train: epoch 0084, iter [00350, 00390], lr: 0.020000, loss: 4.1238
2023-07-02 00:20:21 - train: epoch 084, train_loss: 3.5635
2023-07-02 00:20:22 - eval: epoch: 084, acc1: 31.230%, acc5: 61.440%, test_loss: 2.8030, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 00:20:23 - until epoch: 084, best_acc1: 32.300%
2023-07-02 00:20:23 - epoch 085 lr: 0.020000
2023-07-02 00:20:25 - train: epoch 0085, iter [00050, 00390], lr: 0.020000, loss: 3.4669
2023-07-02 00:20:26 - train: epoch 0085, iter [00100, 00390], lr: 0.020000, loss: 3.8281
2023-07-02 00:20:28 - train: epoch 0085, iter [00150, 00390], lr: 0.020000, loss: 3.5318
2023-07-02 00:20:29 - train: epoch 0085, iter [00200, 00390], lr: 0.020000, loss: 3.1280
2023-07-02 00:20:31 - train: epoch 0085, iter [00250, 00390], lr: 0.020000, loss: 3.5792
2023-07-02 00:20:32 - train: epoch 0085, iter [00300, 00390], lr: 0.020000, loss: 2.8797
2023-07-02 00:20:33 - train: epoch 0085, iter [00350, 00390], lr: 0.020000, loss: 4.1430
2023-07-02 00:20:34 - train: epoch 085, train_loss: 3.5597
2023-07-02 00:20:36 - eval: epoch: 085, acc1: 32.610%, acc5: 62.430%, test_loss: 2.7356, per_image_load_time: 0.075ms, per_image_inference_time: 0.053ms
2023-07-02 00:20:36 - until epoch: 085, best_acc1: 32.610%
2023-07-02 00:20:36 - epoch 086 lr: 0.020000
2023-07-02 00:20:39 - train: epoch 0086, iter [00050, 00390], lr: 0.020000, loss: 2.5575
2023-07-02 00:20:40 - train: epoch 0086, iter [00100, 00390], lr: 0.020000, loss: 2.6560
2023-07-02 00:20:41 - train: epoch 0086, iter [00150, 00390], lr: 0.020000, loss: 3.3344
2023-07-02 00:20:43 - train: epoch 0086, iter [00200, 00390], lr: 0.020000, loss: 3.0674
2023-07-02 00:20:44 - train: epoch 0086, iter [00250, 00390], lr: 0.020000, loss: 2.7171
2023-07-02 00:20:46 - train: epoch 0086, iter [00300, 00390], lr: 0.020000, loss: 3.8685
2023-07-02 00:20:47 - train: epoch 0086, iter [00350, 00390], lr: 0.020000, loss: 3.4908
2023-07-02 00:20:48 - train: epoch 086, train_loss: 3.5767
2023-07-02 00:20:49 - eval: epoch: 086, acc1: 33.040%, acc5: 62.150%, test_loss: 2.7512, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:20:50 - until epoch: 086, best_acc1: 33.040%
2023-07-02 00:20:50 - epoch 087 lr: 0.020000
2023-07-02 00:20:52 - train: epoch 0087, iter [00050, 00390], lr: 0.020000, loss: 3.5633
2023-07-02 00:20:54 - train: epoch 0087, iter [00100, 00390], lr: 0.020000, loss: 2.8074
2023-07-02 00:20:55 - train: epoch 0087, iter [00150, 00390], lr: 0.020000, loss: 3.8591
2023-07-02 00:20:56 - train: epoch 0087, iter [00200, 00390], lr: 0.020000, loss: 3.7010
2023-07-02 00:20:58 - train: epoch 0087, iter [00250, 00390], lr: 0.020000, loss: 3.1052
2023-07-02 00:20:59 - train: epoch 0087, iter [00300, 00390], lr: 0.020000, loss: 3.7921
2023-07-02 00:21:01 - train: epoch 0087, iter [00350, 00390], lr: 0.020000, loss: 3.4099
2023-07-02 00:21:02 - train: epoch 087, train_loss: 3.5675
2023-07-02 00:21:03 - eval: epoch: 087, acc1: 32.510%, acc5: 62.790%, test_loss: 2.7470, per_image_load_time: 0.069ms, per_image_inference_time: 0.060ms
2023-07-02 00:21:04 - until epoch: 087, best_acc1: 33.040%
2023-07-02 00:21:04 - epoch 088 lr: 0.020000
2023-07-02 00:21:06 - train: epoch 0088, iter [00050, 00390], lr: 0.020000, loss: 3.3236
2023-07-02 00:21:07 - train: epoch 0088, iter [00100, 00390], lr: 0.020000, loss: 3.2337
2023-07-02 00:21:09 - train: epoch 0088, iter [00150, 00390], lr: 0.020000, loss: 3.8014
2023-07-02 00:21:10 - train: epoch 0088, iter [00200, 00390], lr: 0.020000, loss: 2.6640
2023-07-02 00:21:12 - train: epoch 0088, iter [00250, 00390], lr: 0.020000, loss: 3.9537
2023-07-02 00:21:13 - train: epoch 0088, iter [00300, 00390], lr: 0.020000, loss: 4.1390
2023-07-02 00:21:14 - train: epoch 0088, iter [00350, 00390], lr: 0.020000, loss: 3.9360
2023-07-02 00:21:16 - train: epoch 088, train_loss: 3.5763
2023-07-02 00:21:17 - eval: epoch: 088, acc1: 32.470%, acc5: 62.170%, test_loss: 2.7558, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:21:18 - until epoch: 088, best_acc1: 33.040%
2023-07-02 00:21:18 - epoch 089 lr: 0.020000
2023-07-02 00:21:20 - train: epoch 0089, iter [00050, 00390], lr: 0.020000, loss: 3.6096
2023-07-02 00:21:21 - train: epoch 0089, iter [00100, 00390], lr: 0.020000, loss: 2.8237
2023-07-02 00:21:23 - train: epoch 0089, iter [00150, 00390], lr: 0.020000, loss: 4.0108
2023-07-02 00:21:24 - train: epoch 0089, iter [00200, 00390], lr: 0.020000, loss: 3.9369
2023-07-02 00:21:26 - train: epoch 0089, iter [00250, 00390], lr: 0.020000, loss: 4.0034
2023-07-02 00:21:27 - train: epoch 0089, iter [00300, 00390], lr: 0.020000, loss: 3.7761
2023-07-02 00:21:29 - train: epoch 0089, iter [00350, 00390], lr: 0.020000, loss: 3.1360
2023-07-02 00:21:31 - train: epoch 089, train_loss: 3.5710
2023-07-02 00:21:32 - eval: epoch: 089, acc1: 32.060%, acc5: 62.180%, test_loss: 2.7790, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:21:32 - until epoch: 089, best_acc1: 33.040%
2023-07-02 00:21:32 - epoch 090 lr: 0.020000
2023-07-02 00:21:35 - train: epoch 0090, iter [00050, 00390], lr: 0.020000, loss: 2.8444
2023-07-02 00:21:36 - train: epoch 0090, iter [00100, 00390], lr: 0.020000, loss: 2.8300
2023-07-02 00:21:37 - train: epoch 0090, iter [00150, 00390], lr: 0.020000, loss: 3.7109
2023-07-02 00:21:39 - train: epoch 0090, iter [00200, 00390], lr: 0.020000, loss: 3.7332
2023-07-02 00:21:40 - train: epoch 0090, iter [00250, 00390], lr: 0.020000, loss: 3.3105
2023-07-02 00:21:42 - train: epoch 0090, iter [00300, 00390], lr: 0.020000, loss: 3.0033
2023-07-02 00:21:43 - train: epoch 0090, iter [00350, 00390], lr: 0.020000, loss: 3.7164
2023-07-02 00:21:44 - train: epoch 090, train_loss: 3.5369
2023-07-02 00:21:46 - eval: epoch: 090, acc1: 32.580%, acc5: 62.960%, test_loss: 2.7364, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:21:46 - until epoch: 090, best_acc1: 33.040%
2023-07-02 00:21:46 - epoch 091 lr: 0.020000
2023-07-02 00:21:48 - train: epoch 0091, iter [00050, 00390], lr: 0.020000, loss: 2.6105
2023-07-02 00:21:49 - train: epoch 0091, iter [00100, 00390], lr: 0.020000, loss: 3.7148
2023-07-02 00:21:51 - train: epoch 0091, iter [00150, 00390], lr: 0.020000, loss: 2.8486
2023-07-02 00:21:52 - train: epoch 0091, iter [00200, 00390], lr: 0.020000, loss: 2.8019
2023-07-02 00:21:54 - train: epoch 0091, iter [00250, 00390], lr: 0.020000, loss: 4.2230
2023-07-02 00:21:55 - train: epoch 0091, iter [00300, 00390], lr: 0.020000, loss: 3.1107
2023-07-02 00:21:56 - train: epoch 0091, iter [00350, 00390], lr: 0.020000, loss: 4.2806
2023-07-02 00:21:58 - train: epoch 091, train_loss: 3.5490
2023-07-02 00:21:59 - eval: epoch: 091, acc1: 32.630%, acc5: 63.060%, test_loss: 2.7371, per_image_load_time: 0.069ms, per_image_inference_time: 0.068ms
2023-07-02 00:21:59 - until epoch: 091, best_acc1: 33.040%
2023-07-02 00:21:59 - epoch 092 lr: 0.020000
2023-07-02 00:22:02 - train: epoch 0092, iter [00050, 00390], lr: 0.020000, loss: 2.9457
2023-07-02 00:22:03 - train: epoch 0092, iter [00100, 00390], lr: 0.020000, loss: 3.2697
2023-07-02 00:22:04 - train: epoch 0092, iter [00150, 00390], lr: 0.020000, loss: 3.6871
2023-07-02 00:22:06 - train: epoch 0092, iter [00200, 00390], lr: 0.020000, loss: 3.9415
2023-07-02 00:22:07 - train: epoch 0092, iter [00250, 00390], lr: 0.020000, loss: 3.6834
2023-07-02 00:22:09 - train: epoch 0092, iter [00300, 00390], lr: 0.020000, loss: 3.5066
2023-07-02 00:22:10 - train: epoch 0092, iter [00350, 00390], lr: 0.020000, loss: 3.9183
2023-07-02 00:22:11 - train: epoch 092, train_loss: 3.5385
2023-07-02 00:22:12 - eval: epoch: 092, acc1: 33.710%, acc5: 64.030%, test_loss: 2.6871, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 00:22:13 - until epoch: 092, best_acc1: 33.710%
2023-07-02 00:22:13 - epoch 093 lr: 0.020000
2023-07-02 00:22:15 - train: epoch 0093, iter [00050, 00390], lr: 0.020000, loss: 3.8149
2023-07-02 00:22:17 - train: epoch 0093, iter [00100, 00390], lr: 0.020000, loss: 2.7274
2023-07-02 00:22:18 - train: epoch 0093, iter [00150, 00390], lr: 0.020000, loss: 3.5945
2023-07-02 00:22:19 - train: epoch 0093, iter [00200, 00390], lr: 0.020000, loss: 2.7690
2023-07-02 00:22:21 - train: epoch 0093, iter [00250, 00390], lr: 0.020000, loss: 3.9695
2023-07-02 00:22:22 - train: epoch 0093, iter [00300, 00390], lr: 0.020000, loss: 3.8556
2023-07-02 00:22:24 - train: epoch 0093, iter [00350, 00390], lr: 0.020000, loss: 3.4786
2023-07-02 00:22:25 - train: epoch 093, train_loss: 3.5217
2023-07-02 00:22:26 - eval: epoch: 093, acc1: 32.990%, acc5: 63.330%, test_loss: 2.7096, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:22:26 - until epoch: 093, best_acc1: 33.710%
2023-07-02 00:22:26 - epoch 094 lr: 0.020000
2023-07-02 00:22:29 - train: epoch 0094, iter [00050, 00390], lr: 0.020000, loss: 2.5499
2023-07-02 00:22:30 - train: epoch 0094, iter [00100, 00390], lr: 0.020000, loss: 3.8040
2023-07-02 00:22:32 - train: epoch 0094, iter [00150, 00390], lr: 0.020000, loss: 2.7873
2023-07-02 00:22:33 - train: epoch 0094, iter [00200, 00390], lr: 0.020000, loss: 3.3947
2023-07-02 00:22:34 - train: epoch 0094, iter [00250, 00390], lr: 0.020000, loss: 3.2261
2023-07-02 00:22:36 - train: epoch 0094, iter [00300, 00390], lr: 0.020000, loss: 3.7916
2023-07-02 00:22:37 - train: epoch 0094, iter [00350, 00390], lr: 0.020000, loss: 3.7049
2023-07-02 00:22:38 - train: epoch 094, train_loss: 3.5446
2023-07-02 00:22:40 - eval: epoch: 094, acc1: 32.470%, acc5: 62.940%, test_loss: 2.7369, per_image_load_time: 0.074ms, per_image_inference_time: 0.055ms
2023-07-02 00:22:40 - until epoch: 094, best_acc1: 33.710%
2023-07-02 00:22:40 - epoch 095 lr: 0.020000
2023-07-02 00:22:42 - train: epoch 0095, iter [00050, 00390], lr: 0.020000, loss: 3.6078
2023-07-02 00:22:44 - train: epoch 0095, iter [00100, 00390], lr: 0.020000, loss: 3.1228
2023-07-02 00:22:45 - train: epoch 0095, iter [00150, 00390], lr: 0.020000, loss: 3.0578
2023-07-02 00:22:47 - train: epoch 0095, iter [00200, 00390], lr: 0.020000, loss: 3.7337
2023-07-02 00:22:48 - train: epoch 0095, iter [00250, 00390], lr: 0.020000, loss: 3.5728
2023-07-02 00:22:49 - train: epoch 0095, iter [00300, 00390], lr: 0.020000, loss: 3.8015
2023-07-02 00:22:51 - train: epoch 0095, iter [00350, 00390], lr: 0.020000, loss: 2.7912
2023-07-02 00:22:52 - train: epoch 095, train_loss: 3.5573
2023-07-02 00:22:53 - eval: epoch: 095, acc1: 33.740%, acc5: 63.610%, test_loss: 2.7280, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:22:54 - until epoch: 095, best_acc1: 33.740%
2023-07-02 00:22:54 - epoch 096 lr: 0.020000
2023-07-02 00:22:56 - train: epoch 0096, iter [00050, 00390], lr: 0.020000, loss: 2.7949
2023-07-02 00:22:58 - train: epoch 0096, iter [00100, 00390], lr: 0.020000, loss: 3.5178
2023-07-02 00:22:59 - train: epoch 0096, iter [00150, 00390], lr: 0.020000, loss: 3.7053
2023-07-02 00:23:00 - train: epoch 0096, iter [00200, 00390], lr: 0.020000, loss: 2.8196
2023-07-02 00:23:02 - train: epoch 0096, iter [00250, 00390], lr: 0.020000, loss: 3.7601
2023-07-02 00:23:03 - train: epoch 0096, iter [00300, 00390], lr: 0.020000, loss: 3.4530
2023-07-02 00:23:05 - train: epoch 0096, iter [00350, 00390], lr: 0.020000, loss: 3.3859
2023-07-02 00:23:06 - train: epoch 096, train_loss: 3.5504
2023-07-02 00:23:07 - eval: epoch: 096, acc1: 33.550%, acc5: 63.970%, test_loss: 2.6746, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:23:08 - until epoch: 096, best_acc1: 33.740%
2023-07-02 00:23:08 - epoch 097 lr: 0.020000
2023-07-02 00:23:10 - train: epoch 0097, iter [00050, 00390], lr: 0.020000, loss: 3.9714
2023-07-02 00:23:11 - train: epoch 0097, iter [00100, 00390], lr: 0.020000, loss: 2.6903
2023-07-02 00:23:13 - train: epoch 0097, iter [00150, 00390], lr: 0.020000, loss: 3.2172
2023-07-02 00:23:14 - train: epoch 0097, iter [00200, 00390], lr: 0.020000, loss: 3.7720
2023-07-02 00:23:15 - train: epoch 0097, iter [00250, 00390], lr: 0.020000, loss: 3.6346
2023-07-02 00:23:17 - train: epoch 0097, iter [00300, 00390], lr: 0.020000, loss: 3.1529
2023-07-02 00:23:19 - train: epoch 0097, iter [00350, 00390], lr: 0.020000, loss: 3.8972
2023-07-02 00:23:20 - train: epoch 097, train_loss: 3.4817
2023-07-02 00:23:22 - eval: epoch: 097, acc1: 33.390%, acc5: 63.330%, test_loss: 2.6986, per_image_load_time: 0.088ms, per_image_inference_time: 0.053ms
2023-07-02 00:23:22 - until epoch: 097, best_acc1: 33.740%
2023-07-02 00:23:22 - epoch 098 lr: 0.020000
2023-07-02 00:23:24 - train: epoch 0098, iter [00050, 00390], lr: 0.020000, loss: 2.7804
2023-07-02 00:23:26 - train: epoch 0098, iter [00100, 00390], lr: 0.020000, loss: 3.5868
2023-07-02 00:23:27 - train: epoch 0098, iter [00150, 00390], lr: 0.020000, loss: 3.1356
2023-07-02 00:23:29 - train: epoch 0098, iter [00200, 00390], lr: 0.020000, loss: 2.9175
2023-07-02 00:23:30 - train: epoch 0098, iter [00250, 00390], lr: 0.020000, loss: 3.7791
2023-07-02 00:23:32 - train: epoch 0098, iter [00300, 00390], lr: 0.020000, loss: 3.9519
2023-07-02 00:23:33 - train: epoch 0098, iter [00350, 00390], lr: 0.020000, loss: 3.3314
2023-07-02 00:23:34 - train: epoch 098, train_loss: 3.5321
2023-07-02 00:23:35 - eval: epoch: 098, acc1: 32.920%, acc5: 63.350%, test_loss: 2.7283, per_image_load_time: 0.070ms, per_image_inference_time: 0.055ms
2023-07-02 00:23:36 - until epoch: 098, best_acc1: 33.740%
2023-07-02 00:23:36 - epoch 099 lr: 0.020000
2023-07-02 00:23:38 - train: epoch 0099, iter [00050, 00390], lr: 0.020000, loss: 4.0620
2023-07-02 00:23:40 - train: epoch 0099, iter [00100, 00390], lr: 0.020000, loss: 2.7565
2023-07-02 00:23:41 - train: epoch 0099, iter [00150, 00390], lr: 0.020000, loss: 3.8466
2023-07-02 00:23:42 - train: epoch 0099, iter [00200, 00390], lr: 0.020000, loss: 2.9411
2023-07-02 00:23:44 - train: epoch 0099, iter [00250, 00390], lr: 0.020000, loss: 3.9600
2023-07-02 00:23:45 - train: epoch 0099, iter [00300, 00390], lr: 0.020000, loss: 2.7933
2023-07-02 00:23:46 - train: epoch 0099, iter [00350, 00390], lr: 0.020000, loss: 4.1930
2023-07-02 00:23:48 - train: epoch 099, train_loss: 3.5274
2023-07-02 00:23:49 - eval: epoch: 099, acc1: 33.570%, acc5: 63.730%, test_loss: 2.7054, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:23:49 - until epoch: 099, best_acc1: 33.740%
2023-07-02 00:23:49 - epoch 100 lr: 0.020000
2023-07-02 00:23:51 - train: epoch 0100, iter [00050, 00390], lr: 0.020000, loss: 3.2177
2023-07-02 00:23:53 - train: epoch 0100, iter [00100, 00390], lr: 0.020000, loss: 2.3396
2023-07-02 00:23:54 - train: epoch 0100, iter [00150, 00390], lr: 0.020000, loss: 3.8857
2023-07-02 00:23:55 - train: epoch 0100, iter [00200, 00390], lr: 0.020000, loss: 3.9729
2023-07-02 00:23:57 - train: epoch 0100, iter [00250, 00390], lr: 0.020000, loss: 3.8891
2023-07-02 00:23:58 - train: epoch 0100, iter [00300, 00390], lr: 0.020000, loss: 3.8804
2023-07-02 00:24:00 - train: epoch 0100, iter [00350, 00390], lr: 0.020000, loss: 3.1206
2023-07-02 00:24:01 - train: epoch 100, train_loss: 3.5716
2023-07-02 00:24:02 - eval: epoch: 100, acc1: 33.490%, acc5: 64.220%, test_loss: 2.7163, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:24:03 - until epoch: 100, best_acc1: 33.740%
2023-07-02 00:24:03 - epoch 101 lr: 0.020000
2023-07-02 00:24:05 - train: epoch 0101, iter [00050, 00390], lr: 0.020000, loss: 3.5060
2023-07-02 00:24:06 - train: epoch 0101, iter [00100, 00390], lr: 0.020000, loss: 4.0033
2023-07-02 00:24:08 - train: epoch 0101, iter [00150, 00390], lr: 0.020000, loss: 3.0283
2023-07-02 00:24:09 - train: epoch 0101, iter [00200, 00390], lr: 0.020000, loss: 3.7242
2023-07-02 00:24:11 - train: epoch 0101, iter [00250, 00390], lr: 0.020000, loss: 3.6012
2023-07-02 00:24:12 - train: epoch 0101, iter [00300, 00390], lr: 0.020000, loss: 3.8228
2023-07-02 00:24:14 - train: epoch 0101, iter [00350, 00390], lr: 0.020000, loss: 3.8817
2023-07-02 00:24:15 - train: epoch 101, train_loss: 3.5230
2023-07-02 00:24:16 - eval: epoch: 101, acc1: 33.080%, acc5: 63.460%, test_loss: 2.7019, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:24:17 - until epoch: 101, best_acc1: 33.740%
2023-07-02 00:24:17 - epoch 102 lr: 0.020000
2023-07-02 00:24:19 - train: epoch 0102, iter [00050, 00390], lr: 0.020000, loss: 3.9032
2023-07-02 00:24:20 - train: epoch 0102, iter [00100, 00390], lr: 0.020000, loss: 3.5000
2023-07-02 00:24:22 - train: epoch 0102, iter [00150, 00390], lr: 0.020000, loss: 3.6753
2023-07-02 00:24:23 - train: epoch 0102, iter [00200, 00390], lr: 0.020000, loss: 2.5841
2023-07-02 00:24:24 - train: epoch 0102, iter [00250, 00390], lr: 0.020000, loss: 3.8563
2023-07-02 00:24:26 - train: epoch 0102, iter [00300, 00390], lr: 0.020000, loss: 4.1155
2023-07-02 00:24:27 - train: epoch 0102, iter [00350, 00390], lr: 0.020000, loss: 3.2806
2023-07-02 00:24:28 - train: epoch 102, train_loss: 3.5556
2023-07-02 00:24:30 - eval: epoch: 102, acc1: 33.430%, acc5: 64.270%, test_loss: 2.6918, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:24:30 - until epoch: 102, best_acc1: 33.740%
2023-07-02 00:24:30 - epoch 103 lr: 0.020000
2023-07-02 00:24:32 - train: epoch 0103, iter [00050, 00390], lr: 0.020000, loss: 3.8877
2023-07-02 00:24:34 - train: epoch 0103, iter [00100, 00390], lr: 0.020000, loss: 3.6418
2023-07-02 00:24:35 - train: epoch 0103, iter [00150, 00390], lr: 0.020000, loss: 3.6887
2023-07-02 00:24:36 - train: epoch 0103, iter [00200, 00390], lr: 0.020000, loss: 3.9086
2023-07-02 00:24:38 - train: epoch 0103, iter [00250, 00390], lr: 0.020000, loss: 2.8686
2023-07-02 00:24:39 - train: epoch 0103, iter [00300, 00390], lr: 0.020000, loss: 4.0427
2023-07-02 00:24:41 - train: epoch 0103, iter [00350, 00390], lr: 0.020000, loss: 3.2853
2023-07-02 00:24:42 - train: epoch 103, train_loss: 3.4841
2023-07-02 00:24:43 - eval: epoch: 103, acc1: 33.660%, acc5: 64.320%, test_loss: 2.6779, per_image_load_time: 0.070ms, per_image_inference_time: 0.055ms
2023-07-02 00:24:44 - until epoch: 103, best_acc1: 33.740%
2023-07-02 00:24:44 - epoch 104 lr: 0.020000
2023-07-02 00:24:46 - train: epoch 0104, iter [00050, 00390], lr: 0.020000, loss: 3.4181
2023-07-02 00:24:47 - train: epoch 0104, iter [00100, 00390], lr: 0.020000, loss: 3.7074
2023-07-02 00:24:49 - train: epoch 0104, iter [00150, 00390], lr: 0.020000, loss: 3.9320
2023-07-02 00:24:50 - train: epoch 0104, iter [00200, 00390], lr: 0.020000, loss: 3.8736
2023-07-02 00:24:52 - train: epoch 0104, iter [00250, 00390], lr: 0.020000, loss: 2.6157
2023-07-02 00:24:53 - train: epoch 0104, iter [00300, 00390], lr: 0.020000, loss: 3.6627
2023-07-02 00:24:55 - train: epoch 0104, iter [00350, 00390], lr: 0.020000, loss: 3.6067
2023-07-02 00:24:56 - train: epoch 104, train_loss: 3.5145
2023-07-02 00:24:57 - eval: epoch: 104, acc1: 33.780%, acc5: 64.580%, test_loss: 2.6932, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-07-02 00:24:58 - until epoch: 104, best_acc1: 33.780%
2023-07-02 00:24:58 - epoch 105 lr: 0.020000
2023-07-02 00:25:00 - train: epoch 0105, iter [00050, 00390], lr: 0.020000, loss: 3.8009
2023-07-02 00:25:01 - train: epoch 0105, iter [00100, 00390], lr: 0.020000, loss: 3.9184
2023-07-02 00:25:03 - train: epoch 0105, iter [00150, 00390], lr: 0.020000, loss: 3.3101
2023-07-02 00:25:04 - train: epoch 0105, iter [00200, 00390], lr: 0.020000, loss: 3.1241
2023-07-02 00:25:06 - train: epoch 0105, iter [00250, 00390], lr: 0.020000, loss: 2.6743
2023-07-02 00:25:07 - train: epoch 0105, iter [00300, 00390], lr: 0.020000, loss: 3.7640
2023-07-02 00:25:08 - train: epoch 0105, iter [00350, 00390], lr: 0.020000, loss: 2.9232
2023-07-02 00:25:09 - train: epoch 105, train_loss: 3.5040
2023-07-02 00:25:11 - eval: epoch: 105, acc1: 33.560%, acc5: 64.780%, test_loss: 2.6850, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:25:11 - until epoch: 105, best_acc1: 33.780%
2023-07-02 00:25:11 - epoch 106 lr: 0.020000
2023-07-02 00:25:13 - train: epoch 0106, iter [00050, 00390], lr: 0.020000, loss: 4.0315
2023-07-02 00:25:15 - train: epoch 0106, iter [00100, 00390], lr: 0.020000, loss: 2.6444
2023-07-02 00:25:16 - train: epoch 0106, iter [00150, 00390], lr: 0.020000, loss: 3.8199
2023-07-02 00:25:18 - train: epoch 0106, iter [00200, 00390], lr: 0.020000, loss: 3.4426
2023-07-02 00:25:20 - train: epoch 0106, iter [00250, 00390], lr: 0.020000, loss: 3.6477
2023-07-02 00:25:21 - train: epoch 0106, iter [00300, 00390], lr: 0.020000, loss: 3.7039
2023-07-02 00:25:23 - train: epoch 0106, iter [00350, 00390], lr: 0.020000, loss: 3.5802
2023-07-02 00:25:24 - train: epoch 106, train_loss: 3.5179
2023-07-02 00:25:26 - eval: epoch: 106, acc1: 34.320%, acc5: 64.790%, test_loss: 2.6642, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:25:26 - until epoch: 106, best_acc1: 34.320%
2023-07-02 00:25:26 - epoch 107 lr: 0.020000
2023-07-02 00:25:28 - train: epoch 0107, iter [00050, 00390], lr: 0.020000, loss: 2.6773
2023-07-02 00:25:30 - train: epoch 0107, iter [00100, 00390], lr: 0.020000, loss: 2.6548
2023-07-02 00:25:31 - train: epoch 0107, iter [00150, 00390], lr: 0.020000, loss: 3.0128
2023-07-02 00:25:33 - train: epoch 0107, iter [00200, 00390], lr: 0.020000, loss: 3.4647
2023-07-02 00:25:34 - train: epoch 0107, iter [00250, 00390], lr: 0.020000, loss: 2.9569
2023-07-02 00:25:35 - train: epoch 0107, iter [00300, 00390], lr: 0.020000, loss: 3.6475
2023-07-02 00:25:37 - train: epoch 0107, iter [00350, 00390], lr: 0.020000, loss: 3.6548
2023-07-02 00:25:38 - train: epoch 107, train_loss: 3.4827
2023-07-02 00:25:39 - eval: epoch: 107, acc1: 34.290%, acc5: 64.500%, test_loss: 2.6868, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:25:40 - until epoch: 107, best_acc1: 34.320%
2023-07-02 00:25:40 - epoch 108 lr: 0.020000
2023-07-02 00:25:42 - train: epoch 0108, iter [00050, 00390], lr: 0.020000, loss: 3.8834
2023-07-02 00:25:43 - train: epoch 0108, iter [00100, 00390], lr: 0.020000, loss: 3.8888
2023-07-02 00:25:45 - train: epoch 0108, iter [00150, 00390], lr: 0.020000, loss: 3.9250
2023-07-02 00:25:46 - train: epoch 0108, iter [00200, 00390], lr: 0.020000, loss: 3.4249
2023-07-02 00:25:48 - train: epoch 0108, iter [00250, 00390], lr: 0.020000, loss: 3.9646
2023-07-02 00:25:49 - train: epoch 0108, iter [00300, 00390], lr: 0.020000, loss: 3.7703
2023-07-02 00:25:51 - train: epoch 0108, iter [00350, 00390], lr: 0.020000, loss: 2.9095
2023-07-02 00:25:52 - train: epoch 108, train_loss: 3.5336
2023-07-02 00:25:53 - eval: epoch: 108, acc1: 34.290%, acc5: 63.900%, test_loss: 2.6815, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:25:53 - until epoch: 108, best_acc1: 34.320%
2023-07-02 00:25:53 - epoch 109 lr: 0.020000
2023-07-02 00:25:55 - train: epoch 0109, iter [00050, 00390], lr: 0.020000, loss: 3.6330
2023-07-02 00:25:57 - train: epoch 0109, iter [00100, 00390], lr: 0.020000, loss: 2.7802
2023-07-02 00:25:58 - train: epoch 0109, iter [00150, 00390], lr: 0.020000, loss: 3.7691
2023-07-02 00:26:00 - train: epoch 0109, iter [00200, 00390], lr: 0.020000, loss: 3.5929
2023-07-02 00:26:01 - train: epoch 0109, iter [00250, 00390], lr: 0.020000, loss: 3.9721
2023-07-02 00:26:02 - train: epoch 0109, iter [00300, 00390], lr: 0.020000, loss: 2.7532
2023-07-02 00:26:04 - train: epoch 0109, iter [00350, 00390], lr: 0.020000, loss: 3.8865
2023-07-02 00:26:05 - train: epoch 109, train_loss: 3.4823
2023-07-02 00:26:06 - eval: epoch: 109, acc1: 35.030%, acc5: 64.680%, test_loss: 2.6826, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:26:08 - until epoch: 109, best_acc1: 35.030%
2023-07-02 00:26:08 - epoch 110 lr: 0.020000
2023-07-02 00:26:10 - train: epoch 0110, iter [00050, 00390], lr: 0.020000, loss: 3.5948
2023-07-02 00:26:11 - train: epoch 0110, iter [00100, 00390], lr: 0.020000, loss: 3.6521
2023-07-02 00:26:13 - train: epoch 0110, iter [00150, 00390], lr: 0.020000, loss: 3.8595
2023-07-02 00:26:14 - train: epoch 0110, iter [00200, 00390], lr: 0.020000, loss: 3.0599
2023-07-02 00:26:16 - train: epoch 0110, iter [00250, 00390], lr: 0.020000, loss: 4.1939
2023-07-02 00:26:17 - train: epoch 0110, iter [00300, 00390], lr: 0.020000, loss: 4.0361
2023-07-02 00:26:18 - train: epoch 0110, iter [00350, 00390], lr: 0.020000, loss: 3.2374
2023-07-02 00:26:20 - train: epoch 110, train_loss: 3.5098
2023-07-02 00:26:21 - eval: epoch: 110, acc1: 34.620%, acc5: 64.990%, test_loss: 2.6732, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:26:21 - until epoch: 110, best_acc1: 35.030%
2023-07-02 00:26:21 - epoch 111 lr: 0.020000
2023-07-02 00:26:23 - train: epoch 0111, iter [00050, 00390], lr: 0.020000, loss: 2.9230
2023-07-02 00:26:25 - train: epoch 0111, iter [00100, 00390], lr: 0.020000, loss: 3.2562
2023-07-02 00:26:26 - train: epoch 0111, iter [00150, 00390], lr: 0.020000, loss: 4.0769
2023-07-02 00:26:28 - train: epoch 0111, iter [00200, 00390], lr: 0.020000, loss: 2.7407
2023-07-02 00:26:29 - train: epoch 0111, iter [00250, 00390], lr: 0.020000, loss: 2.8433
2023-07-02 00:26:30 - train: epoch 0111, iter [00300, 00390], lr: 0.020000, loss: 3.0260
2023-07-02 00:26:32 - train: epoch 0111, iter [00350, 00390], lr: 0.020000, loss: 3.8508
2023-07-02 00:26:33 - train: epoch 111, train_loss: 3.5345
2023-07-02 00:26:34 - eval: epoch: 111, acc1: 34.840%, acc5: 65.130%, test_loss: 2.6564, per_image_load_time: 0.071ms, per_image_inference_time: 0.058ms
2023-07-02 00:26:35 - until epoch: 111, best_acc1: 35.030%
2023-07-02 00:26:35 - epoch 112 lr: 0.020000
2023-07-02 00:26:37 - train: epoch 0112, iter [00050, 00390], lr: 0.020000, loss: 3.8020
2023-07-02 00:26:39 - train: epoch 0112, iter [00100, 00390], lr: 0.020000, loss: 2.7562
2023-07-02 00:26:40 - train: epoch 0112, iter [00150, 00390], lr: 0.020000, loss: 3.8463
2023-07-02 00:26:42 - train: epoch 0112, iter [00200, 00390], lr: 0.020000, loss: 3.6983
2023-07-02 00:26:43 - train: epoch 0112, iter [00250, 00390], lr: 0.020000, loss: 3.7722
2023-07-02 00:26:45 - train: epoch 0112, iter [00300, 00390], lr: 0.020000, loss: 3.8656
2023-07-02 00:26:46 - train: epoch 0112, iter [00350, 00390], lr: 0.020000, loss: 2.7863
2023-07-02 00:26:47 - train: epoch 112, train_loss: 3.5045
2023-07-02 00:26:49 - eval: epoch: 112, acc1: 33.920%, acc5: 64.240%, test_loss: 2.6719, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:26:49 - until epoch: 112, best_acc1: 35.030%
2023-07-02 00:26:49 - epoch 113 lr: 0.020000
2023-07-02 00:26:51 - train: epoch 0113, iter [00050, 00390], lr: 0.020000, loss: 3.6981
2023-07-02 00:26:52 - train: epoch 0113, iter [00100, 00390], lr: 0.020000, loss: 3.6308
2023-07-02 00:26:54 - train: epoch 0113, iter [00150, 00390], lr: 0.020000, loss: 3.8154
2023-07-02 00:26:55 - train: epoch 0113, iter [00200, 00390], lr: 0.020000, loss: 3.7415
2023-07-02 00:26:57 - train: epoch 0113, iter [00250, 00390], lr: 0.020000, loss: 3.6890
2023-07-02 00:26:58 - train: epoch 0113, iter [00300, 00390], lr: 0.020000, loss: 3.6068
2023-07-02 00:26:59 - train: epoch 0113, iter [00350, 00390], lr: 0.020000, loss: 3.0126
2023-07-02 00:27:01 - train: epoch 113, train_loss: 3.5324
2023-07-02 00:27:02 - eval: epoch: 113, acc1: 34.810%, acc5: 65.170%, test_loss: 2.6397, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 00:27:02 - until epoch: 113, best_acc1: 35.030%
2023-07-02 00:27:02 - epoch 114 lr: 0.020000
2023-07-02 00:27:04 - train: epoch 0114, iter [00050, 00390], lr: 0.020000, loss: 3.6821
2023-07-02 00:27:06 - train: epoch 0114, iter [00100, 00390], lr: 0.020000, loss: 4.0589
2023-07-02 00:27:07 - train: epoch 0114, iter [00150, 00390], lr: 0.020000, loss: 3.2959
2023-07-02 00:27:09 - train: epoch 0114, iter [00200, 00390], lr: 0.020000, loss: 3.7850
2023-07-02 00:27:10 - train: epoch 0114, iter [00250, 00390], lr: 0.020000, loss: 3.7874
2023-07-02 00:27:11 - train: epoch 0114, iter [00300, 00390], lr: 0.020000, loss: 3.5423
2023-07-02 00:27:13 - train: epoch 0114, iter [00350, 00390], lr: 0.020000, loss: 3.9701
2023-07-02 00:27:14 - train: epoch 114, train_loss: 3.4406
2023-07-02 00:27:15 - eval: epoch: 114, acc1: 35.000%, acc5: 64.480%, test_loss: 2.6264, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-07-02 00:27:16 - until epoch: 114, best_acc1: 35.030%
2023-07-02 00:27:16 - epoch 115 lr: 0.020000
2023-07-02 00:27:19 - train: epoch 0115, iter [00050, 00390], lr: 0.020000, loss: 3.9762
2023-07-02 00:27:20 - train: epoch 0115, iter [00100, 00390], lr: 0.020000, loss: 3.6259
2023-07-02 00:27:22 - train: epoch 0115, iter [00150, 00390], lr: 0.020000, loss: 2.9037
2023-07-02 00:27:23 - train: epoch 0115, iter [00200, 00390], lr: 0.020000, loss: 3.8361
2023-07-02 00:27:24 - train: epoch 0115, iter [00250, 00390], lr: 0.020000, loss: 3.8228
2023-07-02 00:27:26 - train: epoch 0115, iter [00300, 00390], lr: 0.020000, loss: 4.0505
2023-07-02 00:27:27 - train: epoch 0115, iter [00350, 00390], lr: 0.020000, loss: 3.9710
2023-07-02 00:27:28 - train: epoch 115, train_loss: 3.5713
2023-07-02 00:27:30 - eval: epoch: 115, acc1: 34.810%, acc5: 65.390%, test_loss: 2.6720, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:27:30 - until epoch: 115, best_acc1: 35.030%
2023-07-02 00:27:30 - epoch 116 lr: 0.020000
2023-07-02 00:27:32 - train: epoch 0116, iter [00050, 00390], lr: 0.020000, loss: 3.6507
2023-07-02 00:27:34 - train: epoch 0116, iter [00100, 00390], lr: 0.020000, loss: 3.7249
2023-07-02 00:27:35 - train: epoch 0116, iter [00150, 00390], lr: 0.020000, loss: 2.7662
2023-07-02 00:27:36 - train: epoch 0116, iter [00200, 00390], lr: 0.020000, loss: 2.7057
2023-07-02 00:27:38 - train: epoch 0116, iter [00250, 00390], lr: 0.020000, loss: 4.0224
2023-07-02 00:27:39 - train: epoch 0116, iter [00300, 00390], lr: 0.020000, loss: 3.6628
2023-07-02 00:27:41 - train: epoch 0116, iter [00350, 00390], lr: 0.020000, loss: 3.8208
2023-07-02 00:27:42 - train: epoch 116, train_loss: 3.4989
2023-07-02 00:27:43 - eval: epoch: 116, acc1: 34.650%, acc5: 65.150%, test_loss: 2.6454, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:27:44 - until epoch: 116, best_acc1: 35.030%
2023-07-02 00:27:44 - epoch 117 lr: 0.020000
2023-07-02 00:27:46 - train: epoch 0117, iter [00050, 00390], lr: 0.020000, loss: 3.6804
2023-07-02 00:27:47 - train: epoch 0117, iter [00100, 00390], lr: 0.020000, loss: 3.3210
2023-07-02 00:27:49 - train: epoch 0117, iter [00150, 00390], lr: 0.020000, loss: 3.0919
2023-07-02 00:27:50 - train: epoch 0117, iter [00200, 00390], lr: 0.020000, loss: 3.7114
2023-07-02 00:27:52 - train: epoch 0117, iter [00250, 00390], lr: 0.020000, loss: 4.0232
2023-07-02 00:27:53 - train: epoch 0117, iter [00300, 00390], lr: 0.020000, loss: 3.7971
2023-07-02 00:27:55 - train: epoch 0117, iter [00350, 00390], lr: 0.020000, loss: 2.7897
2023-07-02 00:27:56 - train: epoch 117, train_loss: 3.4991
2023-07-02 00:27:57 - eval: epoch: 117, acc1: 35.550%, acc5: 65.290%, test_loss: 2.6070, per_image_load_time: 0.073ms, per_image_inference_time: 0.064ms
2023-07-02 00:27:58 - until epoch: 117, best_acc1: 35.550%
2023-07-02 00:27:58 - epoch 118 lr: 0.020000
2023-07-02 00:28:00 - train: epoch 0118, iter [00050, 00390], lr: 0.020000, loss: 3.4945
2023-07-02 00:28:01 - train: epoch 0118, iter [00100, 00390], lr: 0.020000, loss: 4.1058
2023-07-02 00:28:03 - train: epoch 0118, iter [00150, 00390], lr: 0.020000, loss: 3.5624
2023-07-02 00:28:04 - train: epoch 0118, iter [00200, 00390], lr: 0.020000, loss: 3.9466
2023-07-02 00:28:06 - train: epoch 0118, iter [00250, 00390], lr: 0.020000, loss: 2.6315
2023-07-02 00:28:07 - train: epoch 0118, iter [00300, 00390], lr: 0.020000, loss: 3.8052
2023-07-02 00:28:08 - train: epoch 0118, iter [00350, 00390], lr: 0.020000, loss: 4.0217
2023-07-02 00:28:09 - train: epoch 118, train_loss: 3.4947
2023-07-02 00:28:11 - eval: epoch: 118, acc1: 34.760%, acc5: 65.150%, test_loss: 2.6345, per_image_load_time: 0.090ms, per_image_inference_time: 0.053ms
2023-07-02 00:28:11 - until epoch: 118, best_acc1: 35.550%
2023-07-02 00:28:11 - epoch 119 lr: 0.020000
2023-07-02 00:28:13 - train: epoch 0119, iter [00050, 00390], lr: 0.020000, loss: 2.8021
2023-07-02 00:28:15 - train: epoch 0119, iter [00100, 00390], lr: 0.020000, loss: 2.7409
2023-07-02 00:28:16 - train: epoch 0119, iter [00150, 00390], lr: 0.020000, loss: 3.4003
2023-07-02 00:28:18 - train: epoch 0119, iter [00200, 00390], lr: 0.020000, loss: 3.1445
2023-07-02 00:28:19 - train: epoch 0119, iter [00250, 00390], lr: 0.020000, loss: 3.3326
2023-07-02 00:28:20 - train: epoch 0119, iter [00300, 00390], lr: 0.020000, loss: 3.7376
2023-07-02 00:28:22 - train: epoch 0119, iter [00350, 00390], lr: 0.020000, loss: 3.9385
2023-07-02 00:28:23 - train: epoch 119, train_loss: 3.5385
2023-07-02 00:28:24 - eval: epoch: 119, acc1: 35.060%, acc5: 65.350%, test_loss: 2.6459, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:28:25 - until epoch: 119, best_acc1: 35.550%
2023-07-02 00:28:25 - epoch 120 lr: 0.020000
2023-07-02 00:28:27 - train: epoch 0120, iter [00050, 00390], lr: 0.020000, loss: 4.1136
2023-07-02 00:28:29 - train: epoch 0120, iter [00100, 00390], lr: 0.020000, loss: 3.6313
2023-07-02 00:28:30 - train: epoch 0120, iter [00150, 00390], lr: 0.020000, loss: 3.7859
2023-07-02 00:28:31 - train: epoch 0120, iter [00200, 00390], lr: 0.020000, loss: 3.4341
2023-07-02 00:28:33 - train: epoch 0120, iter [00250, 00390], lr: 0.020000, loss: 3.6972
2023-07-02 00:28:34 - train: epoch 0120, iter [00300, 00390], lr: 0.020000, loss: 2.9784
2023-07-02 00:28:36 - train: epoch 0120, iter [00350, 00390], lr: 0.020000, loss: 4.2494
2023-07-02 00:28:37 - train: epoch 120, train_loss: 3.5083
2023-07-02 00:28:38 - eval: epoch: 120, acc1: 34.060%, acc5: 64.550%, test_loss: 2.6651, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 00:28:38 - until epoch: 120, best_acc1: 35.550%
2023-07-02 00:28:38 - epoch 121 lr: 0.004000
2023-07-02 00:28:41 - train: epoch 0121, iter [00050, 00390], lr: 0.004000, loss: 3.6934
2023-07-02 00:28:42 - train: epoch 0121, iter [00100, 00390], lr: 0.004000, loss: 3.6675
2023-07-02 00:28:43 - train: epoch 0121, iter [00150, 00390], lr: 0.004000, loss: 3.2471
2023-07-02 00:28:45 - train: epoch 0121, iter [00200, 00390], lr: 0.004000, loss: 3.5700
2023-07-02 00:28:46 - train: epoch 0121, iter [00250, 00390], lr: 0.004000, loss: 3.2185
2023-07-02 00:28:48 - train: epoch 0121, iter [00300, 00390], lr: 0.004000, loss: 2.8949
2023-07-02 00:28:49 - train: epoch 0121, iter [00350, 00390], lr: 0.004000, loss: 3.1190
2023-07-02 00:28:50 - train: epoch 121, train_loss: 3.3423
2023-07-02 00:28:52 - eval: epoch: 121, acc1: 37.770%, acc5: 67.990%, test_loss: 2.4980, per_image_load_time: 0.075ms, per_image_inference_time: 0.054ms
2023-07-02 00:28:52 - until epoch: 121, best_acc1: 37.770%
2023-07-02 00:28:52 - epoch 122 lr: 0.004000
2023-07-02 00:28:55 - train: epoch 0122, iter [00050, 00390], lr: 0.004000, loss: 3.6674
2023-07-02 00:28:56 - train: epoch 0122, iter [00100, 00390], lr: 0.004000, loss: 3.5204
2023-07-02 00:28:58 - train: epoch 0122, iter [00150, 00390], lr: 0.004000, loss: 3.0531
2023-07-02 00:28:59 - train: epoch 0122, iter [00200, 00390], lr: 0.004000, loss: 3.7895
2023-07-02 00:29:00 - train: epoch 0122, iter [00250, 00390], lr: 0.004000, loss: 3.7452
2023-07-02 00:29:02 - train: epoch 0122, iter [00300, 00390], lr: 0.004000, loss: 4.0048
2023-07-02 00:29:03 - train: epoch 0122, iter [00350, 00390], lr: 0.004000, loss: 3.8131
2023-07-02 00:29:04 - train: epoch 122, train_loss: 3.3413
2023-07-02 00:29:06 - eval: epoch: 122, acc1: 38.910%, acc5: 68.650%, test_loss: 2.4667, per_image_load_time: 0.076ms, per_image_inference_time: 0.053ms
2023-07-02 00:29:06 - until epoch: 122, best_acc1: 38.910%
2023-07-02 00:29:06 - epoch 123 lr: 0.004000
2023-07-02 00:29:08 - train: epoch 0123, iter [00050, 00390], lr: 0.004000, loss: 3.7737
2023-07-02 00:29:10 - train: epoch 0123, iter [00100, 00390], lr: 0.004000, loss: 3.4192
2023-07-02 00:29:11 - train: epoch 0123, iter [00150, 00390], lr: 0.004000, loss: 3.4676
2023-07-02 00:29:13 - train: epoch 0123, iter [00200, 00390], lr: 0.004000, loss: 2.4625
2023-07-02 00:29:14 - train: epoch 0123, iter [00250, 00390], lr: 0.004000, loss: 3.0472
2023-07-02 00:29:15 - train: epoch 0123, iter [00300, 00390], lr: 0.004000, loss: 2.2002
2023-07-02 00:29:17 - train: epoch 0123, iter [00350, 00390], lr: 0.004000, loss: 3.6124
2023-07-02 00:29:18 - train: epoch 123, train_loss: 3.3272
2023-07-02 00:29:19 - eval: epoch: 123, acc1: 38.750%, acc5: 68.710%, test_loss: 2.4583, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-07-02 00:29:20 - until epoch: 123, best_acc1: 38.910%
2023-07-02 00:29:20 - epoch 124 lr: 0.004000
2023-07-02 00:29:22 - train: epoch 0124, iter [00050, 00390], lr: 0.004000, loss: 2.4814
2023-07-02 00:29:23 - train: epoch 0124, iter [00100, 00390], lr: 0.004000, loss: 3.3104
2023-07-02 00:29:25 - train: epoch 0124, iter [00150, 00390], lr: 0.004000, loss: 4.1965
2023-07-02 00:29:26 - train: epoch 0124, iter [00200, 00390], lr: 0.004000, loss: 3.5705
2023-07-02 00:29:28 - train: epoch 0124, iter [00250, 00390], lr: 0.004000, loss: 3.6781
2023-07-02 00:29:29 - train: epoch 0124, iter [00300, 00390], lr: 0.004000, loss: 3.6504
2023-07-02 00:29:30 - train: epoch 0124, iter [00350, 00390], lr: 0.004000, loss: 3.3439
2023-07-02 00:29:32 - train: epoch 124, train_loss: 3.2840
2023-07-02 00:29:33 - eval: epoch: 124, acc1: 39.360%, acc5: 69.320%, test_loss: 2.4385, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:29:34 - until epoch: 124, best_acc1: 39.360%
2023-07-02 00:29:34 - epoch 125 lr: 0.004000
2023-07-02 00:29:36 - train: epoch 0125, iter [00050, 00390], lr: 0.004000, loss: 2.3642
2023-07-02 00:29:37 - train: epoch 0125, iter [00100, 00390], lr: 0.004000, loss: 2.7644
2023-07-02 00:29:39 - train: epoch 0125, iter [00150, 00390], lr: 0.004000, loss: 2.4997
2023-07-02 00:29:40 - train: epoch 0125, iter [00200, 00390], lr: 0.004000, loss: 3.3347
2023-07-02 00:29:42 - train: epoch 0125, iter [00250, 00390], lr: 0.004000, loss: 3.7898
2023-07-02 00:29:43 - train: epoch 0125, iter [00300, 00390], lr: 0.004000, loss: 3.0338
2023-07-02 00:29:44 - train: epoch 0125, iter [00350, 00390], lr: 0.004000, loss: 3.7413
2023-07-02 00:29:45 - train: epoch 125, train_loss: 3.3354
2023-07-02 00:29:47 - eval: epoch: 125, acc1: 39.520%, acc5: 69.080%, test_loss: 2.4416, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:29:47 - until epoch: 125, best_acc1: 39.520%
2023-07-02 00:29:47 - epoch 126 lr: 0.004000
2023-07-02 00:29:50 - train: epoch 0126, iter [00050, 00390], lr: 0.004000, loss: 2.6681
2023-07-02 00:29:51 - train: epoch 0126, iter [00100, 00390], lr: 0.004000, loss: 2.8868
2023-07-02 00:29:53 - train: epoch 0126, iter [00150, 00390], lr: 0.004000, loss: 4.1249
2023-07-02 00:29:54 - train: epoch 0126, iter [00200, 00390], lr: 0.004000, loss: 3.4906
2023-07-02 00:29:55 - train: epoch 0126, iter [00250, 00390], lr: 0.004000, loss: 3.3717
2023-07-02 00:29:57 - train: epoch 0126, iter [00300, 00390], lr: 0.004000, loss: 3.7211
2023-07-02 00:29:58 - train: epoch 0126, iter [00350, 00390], lr: 0.004000, loss: 3.9229
2023-07-02 00:29:59 - train: epoch 126, train_loss: 3.3251
2023-07-02 00:30:01 - eval: epoch: 126, acc1: 39.710%, acc5: 69.060%, test_loss: 2.4371, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:30:02 - until epoch: 126, best_acc1: 39.710%
2023-07-02 00:30:02 - epoch 127 lr: 0.004000
2023-07-02 00:30:04 - train: epoch 0127, iter [00050, 00390], lr: 0.004000, loss: 2.4006
2023-07-02 00:30:05 - train: epoch 0127, iter [00100, 00390], lr: 0.004000, loss: 3.9909
2023-07-02 00:30:07 - train: epoch 0127, iter [00150, 00390], lr: 0.004000, loss: 2.8991
2023-07-02 00:30:08 - train: epoch 0127, iter [00200, 00390], lr: 0.004000, loss: 2.3830
2023-07-02 00:30:09 - train: epoch 0127, iter [00250, 00390], lr: 0.004000, loss: 2.5693
2023-07-02 00:30:11 - train: epoch 0127, iter [00300, 00390], lr: 0.004000, loss: 2.4687
2023-07-02 00:30:12 - train: epoch 0127, iter [00350, 00390], lr: 0.004000, loss: 2.5094
2023-07-02 00:30:13 - train: epoch 127, train_loss: 3.3065
2023-07-02 00:30:15 - eval: epoch: 127, acc1: 39.490%, acc5: 69.120%, test_loss: 2.4305, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:30:15 - until epoch: 127, best_acc1: 39.710%
2023-07-02 00:30:15 - epoch 128 lr: 0.004000
2023-07-02 00:30:17 - train: epoch 0128, iter [00050, 00390], lr: 0.004000, loss: 3.8634
2023-07-02 00:30:19 - train: epoch 0128, iter [00100, 00390], lr: 0.004000, loss: 2.7689
2023-07-02 00:30:20 - train: epoch 0128, iter [00150, 00390], lr: 0.004000, loss: 3.7489
2023-07-02 00:30:21 - train: epoch 0128, iter [00200, 00390], lr: 0.004000, loss: 3.0517
2023-07-02 00:30:23 - train: epoch 0128, iter [00250, 00390], lr: 0.004000, loss: 3.8644
2023-07-02 00:30:24 - train: epoch 0128, iter [00300, 00390], lr: 0.004000, loss: 3.8582
2023-07-02 00:30:26 - train: epoch 0128, iter [00350, 00390], lr: 0.004000, loss: 3.2281
2023-07-02 00:30:27 - train: epoch 128, train_loss: 3.3187
2023-07-02 00:30:28 - eval: epoch: 128, acc1: 39.430%, acc5: 69.460%, test_loss: 2.4302, per_image_load_time: 0.069ms, per_image_inference_time: 0.055ms
2023-07-02 00:30:28 - until epoch: 128, best_acc1: 39.710%
2023-07-02 00:30:28 - epoch 129 lr: 0.004000
2023-07-02 00:30:31 - train: epoch 0129, iter [00050, 00390], lr: 0.004000, loss: 3.0777
2023-07-02 00:30:32 - train: epoch 0129, iter [00100, 00390], lr: 0.004000, loss: 3.8036
2023-07-02 00:30:33 - train: epoch 0129, iter [00150, 00390], lr: 0.004000, loss: 3.8588
2023-07-02 00:30:35 - train: epoch 0129, iter [00200, 00390], lr: 0.004000, loss: 3.7588
2023-07-02 00:30:36 - train: epoch 0129, iter [00250, 00390], lr: 0.004000, loss: 3.4958
2023-07-02 00:30:37 - train: epoch 0129, iter [00300, 00390], lr: 0.004000, loss: 3.9008
2023-07-02 00:30:39 - train: epoch 0129, iter [00350, 00390], lr: 0.004000, loss: 2.4149
2023-07-02 00:30:40 - train: epoch 129, train_loss: 3.3453
2023-07-02 00:30:41 - eval: epoch: 129, acc1: 39.330%, acc5: 68.950%, test_loss: 2.4315, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-07-02 00:30:42 - until epoch: 129, best_acc1: 39.710%
2023-07-02 00:30:42 - epoch 130 lr: 0.004000
2023-07-02 00:30:44 - train: epoch 0130, iter [00050, 00390], lr: 0.004000, loss: 3.7243
2023-07-02 00:30:45 - train: epoch 0130, iter [00100, 00390], lr: 0.004000, loss: 3.6265
2023-07-02 00:30:47 - train: epoch 0130, iter [00150, 00390], lr: 0.004000, loss: 3.9442
2023-07-02 00:30:48 - train: epoch 0130, iter [00200, 00390], lr: 0.004000, loss: 2.9178
2023-07-02 00:30:50 - train: epoch 0130, iter [00250, 00390], lr: 0.004000, loss: 2.7345
2023-07-02 00:30:51 - train: epoch 0130, iter [00300, 00390], lr: 0.004000, loss: 3.5637
2023-07-02 00:30:52 - train: epoch 0130, iter [00350, 00390], lr: 0.004000, loss: 3.6262
2023-07-02 00:30:54 - train: epoch 130, train_loss: 3.3094
2023-07-02 00:30:55 - eval: epoch: 130, acc1: 39.490%, acc5: 69.340%, test_loss: 2.4215, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 00:30:55 - until epoch: 130, best_acc1: 39.710%
2023-07-02 00:30:55 - epoch 131 lr: 0.004000
2023-07-02 00:30:57 - train: epoch 0131, iter [00050, 00390], lr: 0.004000, loss: 3.6437
2023-07-02 00:30:59 - train: epoch 0131, iter [00100, 00390], lr: 0.004000, loss: 4.0060
2023-07-02 00:31:00 - train: epoch 0131, iter [00150, 00390], lr: 0.004000, loss: 3.8276
2023-07-02 00:31:01 - train: epoch 0131, iter [00200, 00390], lr: 0.004000, loss: 3.4908
2023-07-02 00:31:03 - train: epoch 0131, iter [00250, 00390], lr: 0.004000, loss: 3.7351
2023-07-02 00:31:04 - train: epoch 0131, iter [00300, 00390], lr: 0.004000, loss: 4.0218
2023-07-02 00:31:06 - train: epoch 0131, iter [00350, 00390], lr: 0.004000, loss: 3.6690
2023-07-02 00:31:07 - train: epoch 131, train_loss: 3.3031
2023-07-02 00:31:08 - eval: epoch: 131, acc1: 39.820%, acc5: 69.530%, test_loss: 2.4162, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:31:10 - until epoch: 131, best_acc1: 39.820%
2023-07-02 00:31:10 - epoch 132 lr: 0.004000
2023-07-02 00:31:12 - train: epoch 0132, iter [00050, 00390], lr: 0.004000, loss: 2.3300
2023-07-02 00:31:13 - train: epoch 0132, iter [00100, 00390], lr: 0.004000, loss: 3.8286
2023-07-02 00:31:15 - train: epoch 0132, iter [00150, 00390], lr: 0.004000, loss: 3.4571
2023-07-02 00:31:16 - train: epoch 0132, iter [00200, 00390], lr: 0.004000, loss: 3.5650
2023-07-02 00:31:17 - train: epoch 0132, iter [00250, 00390], lr: 0.004000, loss: 3.8430
2023-07-02 00:31:19 - train: epoch 0132, iter [00300, 00390], lr: 0.004000, loss: 3.3012
2023-07-02 00:31:20 - train: epoch 0132, iter [00350, 00390], lr: 0.004000, loss: 2.3289
2023-07-02 00:31:21 - train: epoch 132, train_loss: 3.3139
2023-07-02 00:31:23 - eval: epoch: 132, acc1: 39.910%, acc5: 69.720%, test_loss: 2.4090, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 00:31:23 - until epoch: 132, best_acc1: 39.910%
2023-07-02 00:31:23 - epoch 133 lr: 0.004000
2023-07-02 00:31:25 - train: epoch 0133, iter [00050, 00390], lr: 0.004000, loss: 2.3095
2023-07-02 00:31:27 - train: epoch 0133, iter [00100, 00390], lr: 0.004000, loss: 2.4006
2023-07-02 00:31:28 - train: epoch 0133, iter [00150, 00390], lr: 0.004000, loss: 2.6783
2023-07-02 00:31:30 - train: epoch 0133, iter [00200, 00390], lr: 0.004000, loss: 3.7126
2023-07-02 00:31:31 - train: epoch 0133, iter [00250, 00390], lr: 0.004000, loss: 3.8166
2023-07-02 00:31:32 - train: epoch 0133, iter [00300, 00390], lr: 0.004000, loss: 3.2694
2023-07-02 00:31:34 - train: epoch 0133, iter [00350, 00390], lr: 0.004000, loss: 2.7539
2023-07-02 00:31:35 - train: epoch 133, train_loss: 3.2465
2023-07-02 00:31:36 - eval: epoch: 133, acc1: 39.650%, acc5: 69.140%, test_loss: 2.4079, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-07-02 00:31:37 - until epoch: 133, best_acc1: 39.910%
2023-07-02 00:31:37 - epoch 134 lr: 0.004000
2023-07-02 00:31:40 - train: epoch 0134, iter [00050, 00390], lr: 0.004000, loss: 4.0043
2023-07-02 00:31:41 - train: epoch 0134, iter [00100, 00390], lr: 0.004000, loss: 3.4049
2023-07-02 00:31:42 - train: epoch 0134, iter [00150, 00390], lr: 0.004000, loss: 3.8259
2023-07-02 00:31:44 - train: epoch 0134, iter [00200, 00390], lr: 0.004000, loss: 2.2477
2023-07-02 00:31:45 - train: epoch 0134, iter [00250, 00390], lr: 0.004000, loss: 3.8167
2023-07-02 00:31:46 - train: epoch 0134, iter [00300, 00390], lr: 0.004000, loss: 2.7002
2023-07-02 00:31:48 - train: epoch 0134, iter [00350, 00390], lr: 0.004000, loss: 3.7582
2023-07-02 00:31:49 - train: epoch 134, train_loss: 3.3316
2023-07-02 00:31:50 - eval: epoch: 134, acc1: 39.350%, acc5: 69.240%, test_loss: 2.4365, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:31:51 - until epoch: 134, best_acc1: 39.910%
2023-07-02 00:31:51 - epoch 135 lr: 0.004000
2023-07-02 00:31:53 - train: epoch 0135, iter [00050, 00390], lr: 0.004000, loss: 3.5850
2023-07-02 00:31:54 - train: epoch 0135, iter [00100, 00390], lr: 0.004000, loss: 2.3000
2023-07-02 00:31:56 - train: epoch 0135, iter [00150, 00390], lr: 0.004000, loss: 3.2319
2023-07-02 00:31:57 - train: epoch 0135, iter [00200, 00390], lr: 0.004000, loss: 3.6874
2023-07-02 00:31:58 - train: epoch 0135, iter [00250, 00390], lr: 0.004000, loss: 3.7105
2023-07-02 00:32:00 - train: epoch 0135, iter [00300, 00390], lr: 0.004000, loss: 2.9597
2023-07-02 00:32:01 - train: epoch 0135, iter [00350, 00390], lr: 0.004000, loss: 3.5712
2023-07-02 00:32:02 - train: epoch 135, train_loss: 3.3320
2023-07-02 00:32:04 - eval: epoch: 135, acc1: 40.110%, acc5: 69.830%, test_loss: 2.4145, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:32:04 - until epoch: 135, best_acc1: 40.110%
2023-07-02 00:32:04 - epoch 136 lr: 0.004000
2023-07-02 00:32:07 - train: epoch 0136, iter [00050, 00390], lr: 0.004000, loss: 2.1052
2023-07-02 00:32:08 - train: epoch 0136, iter [00100, 00390], lr: 0.004000, loss: 2.3236
2023-07-02 00:32:10 - train: epoch 0136, iter [00150, 00390], lr: 0.004000, loss: 2.7580
2023-07-02 00:32:11 - train: epoch 0136, iter [00200, 00390], lr: 0.004000, loss: 3.2203
2023-07-02 00:32:12 - train: epoch 0136, iter [00250, 00390], lr: 0.004000, loss: 2.4732
2023-07-02 00:32:14 - train: epoch 0136, iter [00300, 00390], lr: 0.004000, loss: 3.7300
2023-07-02 00:32:15 - train: epoch 0136, iter [00350, 00390], lr: 0.004000, loss: 3.9049
2023-07-02 00:32:16 - train: epoch 136, train_loss: 3.3027
2023-07-02 00:32:18 - eval: epoch: 136, acc1: 39.760%, acc5: 69.870%, test_loss: 2.4068, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:32:18 - until epoch: 136, best_acc1: 40.110%
2023-07-02 00:32:18 - epoch 137 lr: 0.004000
2023-07-02 00:32:20 - train: epoch 0137, iter [00050, 00390], lr: 0.004000, loss: 3.7101
2023-07-02 00:32:22 - train: epoch 0137, iter [00100, 00390], lr: 0.004000, loss: 3.6893
2023-07-02 00:32:23 - train: epoch 0137, iter [00150, 00390], lr: 0.004000, loss: 3.1351
2023-07-02 00:32:25 - train: epoch 0137, iter [00200, 00390], lr: 0.004000, loss: 3.0981
2023-07-02 00:32:26 - train: epoch 0137, iter [00250, 00390], lr: 0.004000, loss: 3.5903
2023-07-02 00:32:27 - train: epoch 0137, iter [00300, 00390], lr: 0.004000, loss: 3.2852
2023-07-02 00:32:29 - train: epoch 0137, iter [00350, 00390], lr: 0.004000, loss: 2.4959
2023-07-02 00:32:30 - train: epoch 137, train_loss: 3.3046
2023-07-02 00:32:31 - eval: epoch: 137, acc1: 39.780%, acc5: 69.560%, test_loss: 2.4088, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:32:31 - until epoch: 137, best_acc1: 40.110%
2023-07-02 00:32:31 - epoch 138 lr: 0.004000
2023-07-02 00:32:34 - train: epoch 0138, iter [00050, 00390], lr: 0.004000, loss: 3.3180
2023-07-02 00:32:35 - train: epoch 0138, iter [00100, 00390], lr: 0.004000, loss: 3.7082
2023-07-02 00:32:37 - train: epoch 0138, iter [00150, 00390], lr: 0.004000, loss: 3.6630
2023-07-02 00:32:38 - train: epoch 0138, iter [00200, 00390], lr: 0.004000, loss: 4.1025
2023-07-02 00:32:39 - train: epoch 0138, iter [00250, 00390], lr: 0.004000, loss: 3.0463
2023-07-02 00:32:41 - train: epoch 0138, iter [00300, 00390], lr: 0.004000, loss: 2.8752
2023-07-02 00:32:42 - train: epoch 0138, iter [00350, 00390], lr: 0.004000, loss: 3.6391
2023-07-02 00:32:43 - train: epoch 138, train_loss: 3.2833
2023-07-02 00:32:45 - eval: epoch: 138, acc1: 40.130%, acc5: 69.510%, test_loss: 2.4087, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:32:46 - until epoch: 138, best_acc1: 40.130%
2023-07-02 00:32:46 - epoch 139 lr: 0.004000
2023-07-02 00:32:49 - train: epoch 0139, iter [00050, 00390], lr: 0.004000, loss: 3.0804
2023-07-02 00:32:50 - train: epoch 0139, iter [00100, 00390], lr: 0.004000, loss: 3.5672
2023-07-02 00:32:52 - train: epoch 0139, iter [00150, 00390], lr: 0.004000, loss: 3.6309
2023-07-02 00:32:53 - train: epoch 0139, iter [00200, 00390], lr: 0.004000, loss: 2.7240
2023-07-02 00:32:54 - train: epoch 0139, iter [00250, 00390], lr: 0.004000, loss: 3.6185
2023-07-02 00:32:56 - train: epoch 0139, iter [00300, 00390], lr: 0.004000, loss: 3.6907
2023-07-02 00:32:57 - train: epoch 0139, iter [00350, 00390], lr: 0.004000, loss: 3.7440
2023-07-02 00:32:59 - train: epoch 139, train_loss: 3.3720
2023-07-02 00:33:00 - eval: epoch: 139, acc1: 39.900%, acc5: 69.600%, test_loss: 2.4200, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:33:00 - until epoch: 139, best_acc1: 40.130%
2023-07-02 00:33:00 - epoch 140 lr: 0.004000
2023-07-02 00:33:03 - train: epoch 0140, iter [00050, 00390], lr: 0.004000, loss: 3.3998
2023-07-02 00:33:04 - train: epoch 0140, iter [00100, 00390], lr: 0.004000, loss: 3.7094
2023-07-02 00:33:05 - train: epoch 0140, iter [00150, 00390], lr: 0.004000, loss: 3.3673
2023-07-02 00:33:07 - train: epoch 0140, iter [00200, 00390], lr: 0.004000, loss: 2.8424
2023-07-02 00:33:08 - train: epoch 0140, iter [00250, 00390], lr: 0.004000, loss: 3.8376
2023-07-02 00:33:10 - train: epoch 0140, iter [00300, 00390], lr: 0.004000, loss: 2.5301
2023-07-02 00:33:11 - train: epoch 0140, iter [00350, 00390], lr: 0.004000, loss: 4.1756
2023-07-02 00:33:12 - train: epoch 140, train_loss: 3.2950
2023-07-02 00:33:13 - eval: epoch: 140, acc1: 39.980%, acc5: 69.830%, test_loss: 2.4010, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 00:33:14 - until epoch: 140, best_acc1: 40.130%
2023-07-02 00:33:14 - epoch 141 lr: 0.004000
2023-07-02 00:33:16 - train: epoch 0141, iter [00050, 00390], lr: 0.004000, loss: 2.8474
2023-07-02 00:33:18 - train: epoch 0141, iter [00100, 00390], lr: 0.004000, loss: 3.6660
2023-07-02 00:33:19 - train: epoch 0141, iter [00150, 00390], lr: 0.004000, loss: 2.2668
2023-07-02 00:33:21 - train: epoch 0141, iter [00200, 00390], lr: 0.004000, loss: 3.4714
2023-07-02 00:33:22 - train: epoch 0141, iter [00250, 00390], lr: 0.004000, loss: 3.4334
2023-07-02 00:33:23 - train: epoch 0141, iter [00300, 00390], lr: 0.004000, loss: 3.7074
2023-07-02 00:33:25 - train: epoch 0141, iter [00350, 00390], lr: 0.004000, loss: 3.0370
2023-07-02 00:33:26 - train: epoch 141, train_loss: 3.2660
2023-07-02 00:33:27 - eval: epoch: 141, acc1: 40.540%, acc5: 69.920%, test_loss: 2.3909, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:33:28 - until epoch: 141, best_acc1: 40.540%
2023-07-02 00:33:28 - epoch 142 lr: 0.004000
2023-07-02 00:33:30 - train: epoch 0142, iter [00050, 00390], lr: 0.004000, loss: 3.1880
2023-07-02 00:33:32 - train: epoch 0142, iter [00100, 00390], lr: 0.004000, loss: 2.1495
2023-07-02 00:33:33 - train: epoch 0142, iter [00150, 00390], lr: 0.004000, loss: 2.3901
2023-07-02 00:33:34 - train: epoch 0142, iter [00200, 00390], lr: 0.004000, loss: 3.8918
2023-07-02 00:33:36 - train: epoch 0142, iter [00250, 00390], lr: 0.004000, loss: 3.3250
2023-07-02 00:33:37 - train: epoch 0142, iter [00300, 00390], lr: 0.004000, loss: 3.8344
2023-07-02 00:33:39 - train: epoch 0142, iter [00350, 00390], lr: 0.004000, loss: 3.4898
2023-07-02 00:33:40 - train: epoch 142, train_loss: 3.3216
2023-07-02 00:33:42 - eval: epoch: 142, acc1: 40.410%, acc5: 69.280%, test_loss: 2.4141, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:33:42 - until epoch: 142, best_acc1: 40.540%
2023-07-02 00:33:42 - epoch 143 lr: 0.004000
2023-07-02 00:33:44 - train: epoch 0143, iter [00050, 00390], lr: 0.004000, loss: 4.1544
2023-07-02 00:33:46 - train: epoch 0143, iter [00100, 00390], lr: 0.004000, loss: 3.0053
2023-07-02 00:33:47 - train: epoch 0143, iter [00150, 00390], lr: 0.004000, loss: 3.8100
2023-07-02 00:33:48 - train: epoch 0143, iter [00200, 00390], lr: 0.004000, loss: 3.4006
2023-07-02 00:33:50 - train: epoch 0143, iter [00250, 00390], lr: 0.004000, loss: 3.5673
2023-07-02 00:33:51 - train: epoch 0143, iter [00300, 00390], lr: 0.004000, loss: 3.7732
2023-07-02 00:33:53 - train: epoch 0143, iter [00350, 00390], lr: 0.004000, loss: 3.0302
2023-07-02 00:33:54 - train: epoch 143, train_loss: 3.3047
2023-07-02 00:33:55 - eval: epoch: 143, acc1: 39.860%, acc5: 69.210%, test_loss: 2.4217, per_image_load_time: 0.088ms, per_image_inference_time: 0.054ms
2023-07-02 00:33:56 - until epoch: 143, best_acc1: 40.540%
2023-07-02 00:33:56 - epoch 144 lr: 0.004000
2023-07-02 00:33:58 - train: epoch 0144, iter [00050, 00390], lr: 0.004000, loss: 2.1552
2023-07-02 00:33:59 - train: epoch 0144, iter [00100, 00390], lr: 0.004000, loss: 3.2753
2023-07-02 00:34:01 - train: epoch 0144, iter [00150, 00390], lr: 0.004000, loss: 3.7590
2023-07-02 00:34:02 - train: epoch 0144, iter [00200, 00390], lr: 0.004000, loss: 3.9073
2023-07-02 00:34:04 - train: epoch 0144, iter [00250, 00390], lr: 0.004000, loss: 3.7828
2023-07-02 00:34:05 - train: epoch 0144, iter [00300, 00390], lr: 0.004000, loss: 2.5659
2023-07-02 00:34:06 - train: epoch 0144, iter [00350, 00390], lr: 0.004000, loss: 3.1390
2023-07-02 00:34:07 - train: epoch 144, train_loss: 3.3375
2023-07-02 00:34:09 - eval: epoch: 144, acc1: 40.160%, acc5: 69.960%, test_loss: 2.4167, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:34:09 - until epoch: 144, best_acc1: 40.540%
2023-07-02 00:34:09 - epoch 145 lr: 0.004000
2023-07-02 00:34:12 - train: epoch 0145, iter [00050, 00390], lr: 0.004000, loss: 2.4484
2023-07-02 00:34:13 - train: epoch 0145, iter [00100, 00390], lr: 0.004000, loss: 3.2287
2023-07-02 00:34:15 - train: epoch 0145, iter [00150, 00390], lr: 0.004000, loss: 3.0611
2023-07-02 00:34:16 - train: epoch 0145, iter [00200, 00390], lr: 0.004000, loss: 3.9930
2023-07-02 00:34:18 - train: epoch 0145, iter [00250, 00390], lr: 0.004000, loss: 2.4518
2023-07-02 00:34:19 - train: epoch 0145, iter [00300, 00390], lr: 0.004000, loss: 2.6707
2023-07-02 00:34:20 - train: epoch 0145, iter [00350, 00390], lr: 0.004000, loss: 2.5836
2023-07-02 00:34:21 - train: epoch 145, train_loss: 3.2516
2023-07-02 00:34:23 - eval: epoch: 145, acc1: 40.400%, acc5: 70.380%, test_loss: 2.3795, per_image_load_time: 0.073ms, per_image_inference_time: 0.055ms
2023-07-02 00:34:23 - until epoch: 145, best_acc1: 40.540%
2023-07-02 00:34:23 - epoch 146 lr: 0.004000
2023-07-02 00:34:25 - train: epoch 0146, iter [00050, 00390], lr: 0.004000, loss: 2.2631
2023-07-02 00:34:27 - train: epoch 0146, iter [00100, 00390], lr: 0.004000, loss: 3.9172
2023-07-02 00:34:28 - train: epoch 0146, iter [00150, 00390], lr: 0.004000, loss: 3.7502
2023-07-02 00:34:29 - train: epoch 0146, iter [00200, 00390], lr: 0.004000, loss: 3.6467
2023-07-02 00:34:31 - train: epoch 0146, iter [00250, 00390], lr: 0.004000, loss: 3.9058
2023-07-02 00:34:32 - train: epoch 0146, iter [00300, 00390], lr: 0.004000, loss: 3.1625
2023-07-02 00:34:34 - train: epoch 0146, iter [00350, 00390], lr: 0.004000, loss: 2.1554
2023-07-02 00:34:35 - train: epoch 146, train_loss: 3.2595
2023-07-02 00:34:36 - eval: epoch: 146, acc1: 40.100%, acc5: 69.530%, test_loss: 2.4000, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-07-02 00:34:38 - until epoch: 146, best_acc1: 40.540%
2023-07-02 00:34:38 - epoch 147 lr: 0.004000
2023-07-02 00:34:40 - train: epoch 0147, iter [00050, 00390], lr: 0.004000, loss: 3.6342
2023-07-02 00:34:41 - train: epoch 0147, iter [00100, 00390], lr: 0.004000, loss: 3.9951
2023-07-02 00:34:43 - train: epoch 0147, iter [00150, 00390], lr: 0.004000, loss: 3.4432
2023-07-02 00:34:44 - train: epoch 0147, iter [00200, 00390], lr: 0.004000, loss: 3.7017
2023-07-02 00:34:45 - train: epoch 0147, iter [00250, 00390], lr: 0.004000, loss: 3.8813
2023-07-02 00:34:47 - train: epoch 0147, iter [00300, 00390], lr: 0.004000, loss: 3.8398
2023-07-02 00:34:48 - train: epoch 0147, iter [00350, 00390], lr: 0.004000, loss: 3.9230
2023-07-02 00:34:49 - train: epoch 147, train_loss: 3.3080
2023-07-02 00:34:51 - eval: epoch: 147, acc1: 40.490%, acc5: 69.960%, test_loss: 2.3935, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:34:51 - until epoch: 147, best_acc1: 40.540%
2023-07-02 00:34:51 - epoch 148 lr: 0.004000
2023-07-02 00:34:53 - train: epoch 0148, iter [00050, 00390], lr: 0.004000, loss: 3.6938
2023-07-02 00:34:55 - train: epoch 0148, iter [00100, 00390], lr: 0.004000, loss: 3.8596
2023-07-02 00:34:56 - train: epoch 0148, iter [00150, 00390], lr: 0.004000, loss: 2.3377
2023-07-02 00:34:58 - train: epoch 0148, iter [00200, 00390], lr: 0.004000, loss: 3.2303
2023-07-02 00:34:59 - train: epoch 0148, iter [00250, 00390], lr: 0.004000, loss: 3.8188
2023-07-02 00:35:01 - train: epoch 0148, iter [00300, 00390], lr: 0.004000, loss: 3.5625
2023-07-02 00:35:02 - train: epoch 0148, iter [00350, 00390], lr: 0.004000, loss: 3.2205
2023-07-02 00:35:03 - train: epoch 148, train_loss: 3.2889
2023-07-02 00:35:05 - eval: epoch: 148, acc1: 40.260%, acc5: 70.090%, test_loss: 2.3948, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:35:05 - until epoch: 148, best_acc1: 40.540%
2023-07-02 00:35:05 - epoch 149 lr: 0.004000
2023-07-02 00:35:07 - train: epoch 0149, iter [00050, 00390], lr: 0.004000, loss: 3.5218
2023-07-02 00:35:09 - train: epoch 0149, iter [00100, 00390], lr: 0.004000, loss: 3.9525
2023-07-02 00:35:10 - train: epoch 0149, iter [00150, 00390], lr: 0.004000, loss: 2.8809
2023-07-02 00:35:12 - train: epoch 0149, iter [00200, 00390], lr: 0.004000, loss: 3.6677
2023-07-02 00:35:13 - train: epoch 0149, iter [00250, 00390], lr: 0.004000, loss: 2.8062
2023-07-02 00:35:15 - train: epoch 0149, iter [00300, 00390], lr: 0.004000, loss: 2.9933
2023-07-02 00:35:16 - train: epoch 0149, iter [00350, 00390], lr: 0.004000, loss: 3.8219
2023-07-02 00:35:18 - train: epoch 149, train_loss: 3.2801
2023-07-02 00:35:19 - eval: epoch: 149, acc1: 40.390%, acc5: 69.960%, test_loss: 2.3948, per_image_load_time: 0.078ms, per_image_inference_time: 0.056ms
2023-07-02 00:35:20 - until epoch: 149, best_acc1: 40.540%
2023-07-02 00:35:20 - epoch 150 lr: 0.004000
2023-07-02 00:35:22 - train: epoch 0150, iter [00050, 00390], lr: 0.004000, loss: 2.7658
2023-07-02 00:35:23 - train: epoch 0150, iter [00100, 00390], lr: 0.004000, loss: 2.4644
2023-07-02 00:35:25 - train: epoch 0150, iter [00150, 00390], lr: 0.004000, loss: 2.6527
2023-07-02 00:35:26 - train: epoch 0150, iter [00200, 00390], lr: 0.004000, loss: 3.3434
2023-07-02 00:35:28 - train: epoch 0150, iter [00250, 00390], lr: 0.004000, loss: 3.8048
2023-07-02 00:35:29 - train: epoch 0150, iter [00300, 00390], lr: 0.004000, loss: 3.8601
2023-07-02 00:35:30 - train: epoch 0150, iter [00350, 00390], lr: 0.004000, loss: 3.5370
2023-07-02 00:35:32 - train: epoch 150, train_loss: 3.2881
2023-07-02 00:35:33 - eval: epoch: 150, acc1: 40.210%, acc5: 70.040%, test_loss: 2.3844, per_image_load_time: 0.073ms, per_image_inference_time: 0.061ms
2023-07-02 00:35:33 - until epoch: 150, best_acc1: 40.540%
2023-07-02 00:35:33 - epoch 151 lr: 0.004000
2023-07-02 00:35:36 - train: epoch 0151, iter [00050, 00390], lr: 0.004000, loss: 3.3887
2023-07-02 00:35:37 - train: epoch 0151, iter [00100, 00390], lr: 0.004000, loss: 3.6213
2023-07-02 00:35:39 - train: epoch 0151, iter [00150, 00390], lr: 0.004000, loss: 3.7557
2023-07-02 00:35:40 - train: epoch 0151, iter [00200, 00390], lr: 0.004000, loss: 3.9324
2023-07-02 00:35:42 - train: epoch 0151, iter [00250, 00390], lr: 0.004000, loss: 3.1496
2023-07-02 00:35:43 - train: epoch 0151, iter [00300, 00390], lr: 0.004000, loss: 2.2282
2023-07-02 00:35:44 - train: epoch 0151, iter [00350, 00390], lr: 0.004000, loss: 2.4820
2023-07-02 00:35:46 - train: epoch 151, train_loss: 3.3213
2023-07-02 00:35:47 - eval: epoch: 151, acc1: 39.910%, acc5: 69.980%, test_loss: 2.3933, per_image_load_time: 0.075ms, per_image_inference_time: 0.053ms
2023-07-02 00:35:47 - until epoch: 151, best_acc1: 40.540%
2023-07-02 00:35:47 - epoch 152 lr: 0.004000
2023-07-02 00:35:50 - train: epoch 0152, iter [00050, 00390], lr: 0.004000, loss: 3.3193
2023-07-02 00:35:52 - train: epoch 0152, iter [00100, 00390], lr: 0.004000, loss: 2.1354
2023-07-02 00:35:53 - train: epoch 0152, iter [00150, 00390], lr: 0.004000, loss: 2.3072
2023-07-02 00:35:55 - train: epoch 0152, iter [00200, 00390], lr: 0.004000, loss: 2.0558
2023-07-02 00:35:56 - train: epoch 0152, iter [00250, 00390], lr: 0.004000, loss: 2.1766
2023-07-02 00:35:58 - train: epoch 0152, iter [00300, 00390], lr: 0.004000, loss: 3.6602
2023-07-02 00:35:59 - train: epoch 0152, iter [00350, 00390], lr: 0.004000, loss: 3.2560
2023-07-02 00:36:01 - train: epoch 152, train_loss: 3.2719
2023-07-02 00:36:02 - eval: epoch: 152, acc1: 40.770%, acc5: 70.380%, test_loss: 2.3842, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:36:02 - until epoch: 152, best_acc1: 40.770%
2023-07-02 00:36:02 - epoch 153 lr: 0.004000
2023-07-02 00:36:05 - train: epoch 0153, iter [00050, 00390], lr: 0.004000, loss: 2.3707
2023-07-02 00:36:06 - train: epoch 0153, iter [00100, 00390], lr: 0.004000, loss: 3.8143
2023-07-02 00:36:08 - train: epoch 0153, iter [00150, 00390], lr: 0.004000, loss: 3.8505
2023-07-02 00:36:09 - train: epoch 0153, iter [00200, 00390], lr: 0.004000, loss: 3.8405
2023-07-02 00:36:11 - train: epoch 0153, iter [00250, 00390], lr: 0.004000, loss: 3.1723
2023-07-02 00:36:12 - train: epoch 0153, iter [00300, 00390], lr: 0.004000, loss: 3.8269
2023-07-02 00:36:13 - train: epoch 0153, iter [00350, 00390], lr: 0.004000, loss: 3.7462
2023-07-02 00:36:14 - train: epoch 153, train_loss: 3.2874
2023-07-02 00:36:16 - eval: epoch: 153, acc1: 40.610%, acc5: 70.410%, test_loss: 2.3752, per_image_load_time: 0.071ms, per_image_inference_time: 0.055ms
2023-07-02 00:36:16 - until epoch: 153, best_acc1: 40.770%
2023-07-02 00:36:16 - epoch 154 lr: 0.004000
2023-07-02 00:36:18 - train: epoch 0154, iter [00050, 00390], lr: 0.004000, loss: 3.8308
2023-07-02 00:36:20 - train: epoch 0154, iter [00100, 00390], lr: 0.004000, loss: 3.7091
2023-07-02 00:36:21 - train: epoch 0154, iter [00150, 00390], lr: 0.004000, loss: 3.2789
2023-07-02 00:36:23 - train: epoch 0154, iter [00200, 00390], lr: 0.004000, loss: 3.1552
2023-07-02 00:36:24 - train: epoch 0154, iter [00250, 00390], lr: 0.004000, loss: 3.2371
2023-07-02 00:36:25 - train: epoch 0154, iter [00300, 00390], lr: 0.004000, loss: 3.2728
2023-07-02 00:36:27 - train: epoch 0154, iter [00350, 00390], lr: 0.004000, loss: 2.5159
2023-07-02 00:36:28 - train: epoch 154, train_loss: 3.1820
2023-07-02 00:36:29 - eval: epoch: 154, acc1: 40.930%, acc5: 70.140%, test_loss: 2.3749, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:36:31 - until epoch: 154, best_acc1: 40.930%
2023-07-02 00:36:31 - epoch 155 lr: 0.004000
2023-07-02 00:36:33 - train: epoch 0155, iter [00050, 00390], lr: 0.004000, loss: 3.9529
2023-07-02 00:36:34 - train: epoch 0155, iter [00100, 00390], lr: 0.004000, loss: 3.8809
2023-07-02 00:36:36 - train: epoch 0155, iter [00150, 00390], lr: 0.004000, loss: 3.6935
2023-07-02 00:36:37 - train: epoch 0155, iter [00200, 00390], lr: 0.004000, loss: 3.5484
2023-07-02 00:36:38 - train: epoch 0155, iter [00250, 00390], lr: 0.004000, loss: 3.6074
2023-07-02 00:36:40 - train: epoch 0155, iter [00300, 00390], lr: 0.004000, loss: 2.7387
2023-07-02 00:36:41 - train: epoch 0155, iter [00350, 00390], lr: 0.004000, loss: 3.8647
2023-07-02 00:36:42 - train: epoch 155, train_loss: 3.2757
2023-07-02 00:36:44 - eval: epoch: 155, acc1: 40.150%, acc5: 70.070%, test_loss: 2.3847, per_image_load_time: 0.070ms, per_image_inference_time: 0.061ms
2023-07-02 00:36:44 - until epoch: 155, best_acc1: 40.930%
2023-07-02 00:36:44 - epoch 156 lr: 0.004000
2023-07-02 00:36:46 - train: epoch 0156, iter [00050, 00390], lr: 0.004000, loss: 3.4541
2023-07-02 00:36:48 - train: epoch 0156, iter [00100, 00390], lr: 0.004000, loss: 3.0499
2023-07-02 00:36:49 - train: epoch 0156, iter [00150, 00390], lr: 0.004000, loss: 3.2319
2023-07-02 00:36:51 - train: epoch 0156, iter [00200, 00390], lr: 0.004000, loss: 2.3180
2023-07-02 00:36:52 - train: epoch 0156, iter [00250, 00390], lr: 0.004000, loss: 2.5335
2023-07-02 00:36:53 - train: epoch 0156, iter [00300, 00390], lr: 0.004000, loss: 3.6309
2023-07-02 00:36:55 - train: epoch 0156, iter [00350, 00390], lr: 0.004000, loss: 3.6352
2023-07-02 00:36:56 - train: epoch 156, train_loss: 3.2127
2023-07-02 00:36:57 - eval: epoch: 156, acc1: 40.470%, acc5: 70.190%, test_loss: 2.3785, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:36:58 - until epoch: 156, best_acc1: 40.930%
2023-07-02 00:36:58 - epoch 157 lr: 0.004000
2023-07-02 00:37:00 - train: epoch 0157, iter [00050, 00390], lr: 0.004000, loss: 3.7961
2023-07-02 00:37:01 - train: epoch 0157, iter [00100, 00390], lr: 0.004000, loss: 2.2273
2023-07-02 00:37:03 - train: epoch 0157, iter [00150, 00390], lr: 0.004000, loss: 3.7755
2023-07-02 00:37:04 - train: epoch 0157, iter [00200, 00390], lr: 0.004000, loss: 3.7523
2023-07-02 00:37:05 - train: epoch 0157, iter [00250, 00390], lr: 0.004000, loss: 3.7054
2023-07-02 00:37:07 - train: epoch 0157, iter [00300, 00390], lr: 0.004000, loss: 2.5232
2023-07-02 00:37:08 - train: epoch 0157, iter [00350, 00390], lr: 0.004000, loss: 3.6265
2023-07-02 00:37:09 - train: epoch 157, train_loss: 3.2519
2023-07-02 00:37:11 - eval: epoch: 157, acc1: 40.510%, acc5: 70.230%, test_loss: 2.3815, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:37:11 - until epoch: 157, best_acc1: 40.930%
2023-07-02 00:37:11 - epoch 158 lr: 0.004000
2023-07-02 00:37:13 - train: epoch 0158, iter [00050, 00390], lr: 0.004000, loss: 3.0207
2023-07-02 00:37:15 - train: epoch 0158, iter [00100, 00390], lr: 0.004000, loss: 3.7813
2023-07-02 00:37:16 - train: epoch 0158, iter [00150, 00390], lr: 0.004000, loss: 3.5353
2023-07-02 00:37:17 - train: epoch 0158, iter [00200, 00390], lr: 0.004000, loss: 3.8573
2023-07-02 00:37:19 - train: epoch 0158, iter [00250, 00390], lr: 0.004000, loss: 3.5031
2023-07-02 00:37:20 - train: epoch 0158, iter [00300, 00390], lr: 0.004000, loss: 3.0829
2023-07-02 00:37:22 - train: epoch 0158, iter [00350, 00390], lr: 0.004000, loss: 3.8540
2023-07-02 00:37:23 - train: epoch 158, train_loss: 3.3048
2023-07-02 00:37:24 - eval: epoch: 158, acc1: 40.810%, acc5: 70.620%, test_loss: 2.3740, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:37:25 - until epoch: 158, best_acc1: 40.930%
2023-07-02 00:37:25 - epoch 159 lr: 0.004000
2023-07-02 00:37:27 - train: epoch 0159, iter [00050, 00390], lr: 0.004000, loss: 3.8140
2023-07-02 00:37:29 - train: epoch 0159, iter [00100, 00390], lr: 0.004000, loss: 3.8130
2023-07-02 00:37:30 - train: epoch 0159, iter [00150, 00390], lr: 0.004000, loss: 2.5973
2023-07-02 00:37:31 - train: epoch 0159, iter [00200, 00390], lr: 0.004000, loss: 2.3561
2023-07-02 00:37:33 - train: epoch 0159, iter [00250, 00390], lr: 0.004000, loss: 3.7391
2023-07-02 00:37:34 - train: epoch 0159, iter [00300, 00390], lr: 0.004000, loss: 3.8713
2023-07-02 00:37:36 - train: epoch 0159, iter [00350, 00390], lr: 0.004000, loss: 2.9647
2023-07-02 00:37:37 - train: epoch 159, train_loss: 3.2730
2023-07-02 00:37:38 - eval: epoch: 159, acc1: 40.880%, acc5: 69.730%, test_loss: 2.3919, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-07-02 00:37:39 - until epoch: 159, best_acc1: 40.930%
2023-07-02 00:37:39 - epoch 160 lr: 0.004000
2023-07-02 00:37:41 - train: epoch 0160, iter [00050, 00390], lr: 0.004000, loss: 3.7598
2023-07-02 00:37:42 - train: epoch 0160, iter [00100, 00390], lr: 0.004000, loss: 3.4655
2023-07-02 00:37:44 - train: epoch 0160, iter [00150, 00390], lr: 0.004000, loss: 3.7545
2023-07-02 00:37:45 - train: epoch 0160, iter [00200, 00390], lr: 0.004000, loss: 3.4603
2023-07-02 00:37:46 - train: epoch 0160, iter [00250, 00390], lr: 0.004000, loss: 3.7695
2023-07-02 00:37:48 - train: epoch 0160, iter [00300, 00390], lr: 0.004000, loss: 3.1689
2023-07-02 00:37:49 - train: epoch 0160, iter [00350, 00390], lr: 0.004000, loss: 3.0216
2023-07-02 00:37:50 - train: epoch 160, train_loss: 3.2916
2023-07-02 00:37:52 - eval: epoch: 160, acc1: 40.910%, acc5: 70.060%, test_loss: 2.3790, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-07-02 00:37:52 - until epoch: 160, best_acc1: 40.930%
2023-07-02 00:37:52 - epoch 161 lr: 0.000800
2023-07-02 00:37:54 - train: epoch 0161, iter [00050, 00390], lr: 0.000800, loss: 3.5839
2023-07-02 00:37:55 - train: epoch 0161, iter [00100, 00390], lr: 0.000800, loss: 2.2074
2023-07-02 00:37:57 - train: epoch 0161, iter [00150, 00390], lr: 0.000800, loss: 2.1808
2023-07-02 00:37:58 - train: epoch 0161, iter [00200, 00390], lr: 0.000800, loss: 3.9870
2023-07-02 00:38:00 - train: epoch 0161, iter [00250, 00390], lr: 0.000800, loss: 2.6458
2023-07-02 00:38:01 - train: epoch 0161, iter [00300, 00390], lr: 0.000800, loss: 3.8482
2023-07-02 00:38:02 - train: epoch 0161, iter [00350, 00390], lr: 0.000800, loss: 3.4884
2023-07-02 00:38:04 - train: epoch 161, train_loss: 3.2163
2023-07-02 00:38:05 - eval: epoch: 161, acc1: 42.240%, acc5: 71.150%, test_loss: 2.3213, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:38:06 - until epoch: 161, best_acc1: 42.240%
2023-07-02 00:38:06 - epoch 162 lr: 0.000800
2023-07-02 00:38:09 - train: epoch 0162, iter [00050, 00390], lr: 0.000800, loss: 3.8174
2023-07-02 00:38:10 - train: epoch 0162, iter [00100, 00390], lr: 0.000800, loss: 3.1285
2023-07-02 00:38:11 - train: epoch 0162, iter [00150, 00390], lr: 0.000800, loss: 3.4648
2023-07-02 00:38:13 - train: epoch 0162, iter [00200, 00390], lr: 0.000800, loss: 3.7271
2023-07-02 00:38:14 - train: epoch 0162, iter [00250, 00390], lr: 0.000800, loss: 2.1964
2023-07-02 00:38:16 - train: epoch 0162, iter [00300, 00390], lr: 0.000800, loss: 3.7175
2023-07-02 00:38:17 - train: epoch 0162, iter [00350, 00390], lr: 0.000800, loss: 3.4489
2023-07-02 00:38:18 - train: epoch 162, train_loss: 3.2447
2023-07-02 00:38:20 - eval: epoch: 162, acc1: 42.360%, acc5: 71.310%, test_loss: 2.3183, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:38:20 - until epoch: 162, best_acc1: 42.360%
2023-07-02 00:38:20 - epoch 163 lr: 0.000800
2023-07-02 00:38:22 - train: epoch 0163, iter [00050, 00390], lr: 0.000800, loss: 3.0828
2023-07-02 00:38:24 - train: epoch 0163, iter [00100, 00390], lr: 0.000800, loss: 3.1380
2023-07-02 00:38:25 - train: epoch 0163, iter [00150, 00390], lr: 0.000800, loss: 3.1684
2023-07-02 00:38:26 - train: epoch 0163, iter [00200, 00390], lr: 0.000800, loss: 3.3527
2023-07-02 00:38:28 - train: epoch 0163, iter [00250, 00390], lr: 0.000800, loss: 3.0416
2023-07-02 00:38:29 - train: epoch 0163, iter [00300, 00390], lr: 0.000800, loss: 3.8465
2023-07-02 00:38:30 - train: epoch 0163, iter [00350, 00390], lr: 0.000800, loss: 4.1280
2023-07-02 00:38:32 - train: epoch 163, train_loss: 3.2110
2023-07-02 00:38:33 - eval: epoch: 163, acc1: 42.270%, acc5: 71.250%, test_loss: 2.3182, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:38:33 - until epoch: 163, best_acc1: 42.360%
2023-07-02 00:38:33 - epoch 164 lr: 0.000800
2023-07-02 00:38:35 - train: epoch 0164, iter [00050, 00390], lr: 0.000800, loss: 3.3018
2023-07-02 00:38:37 - train: epoch 0164, iter [00100, 00390], lr: 0.000800, loss: 3.9383
2023-07-02 00:38:38 - train: epoch 0164, iter [00150, 00390], lr: 0.000800, loss: 3.7694
2023-07-02 00:38:40 - train: epoch 0164, iter [00200, 00390], lr: 0.000800, loss: 3.5307
2023-07-02 00:38:41 - train: epoch 0164, iter [00250, 00390], lr: 0.000800, loss: 2.3645
2023-07-02 00:38:42 - train: epoch 0164, iter [00300, 00390], lr: 0.000800, loss: 2.9259
2023-07-02 00:38:44 - train: epoch 0164, iter [00350, 00390], lr: 0.000800, loss: 3.7306
2023-07-02 00:38:45 - train: epoch 164, train_loss: 3.2426
2023-07-02 00:38:46 - eval: epoch: 164, acc1: 42.130%, acc5: 71.130%, test_loss: 2.3174, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:38:47 - until epoch: 164, best_acc1: 42.360%
2023-07-02 00:38:47 - epoch 165 lr: 0.000800
2023-07-02 00:38:49 - train: epoch 0165, iter [00050, 00390], lr: 0.000800, loss: 2.4579
2023-07-02 00:38:50 - train: epoch 0165, iter [00100, 00390], lr: 0.000800, loss: 2.2022
2023-07-02 00:38:52 - train: epoch 0165, iter [00150, 00390], lr: 0.000800, loss: 3.9652
2023-07-02 00:38:53 - train: epoch 0165, iter [00200, 00390], lr: 0.000800, loss: 3.5087
2023-07-02 00:38:55 - train: epoch 0165, iter [00250, 00390], lr: 0.000800, loss: 3.6929
2023-07-02 00:38:56 - train: epoch 0165, iter [00300, 00390], lr: 0.000800, loss: 2.2224
2023-07-02 00:38:58 - train: epoch 0165, iter [00350, 00390], lr: 0.000800, loss: 2.8196
2023-07-02 00:38:59 - train: epoch 165, train_loss: 3.2310
2023-07-02 00:39:00 - eval: epoch: 165, acc1: 42.570%, acc5: 71.350%, test_loss: 2.3074, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 00:39:01 - until epoch: 165, best_acc1: 42.570%
2023-07-02 00:39:01 - epoch 166 lr: 0.000800
2023-07-02 00:39:03 - train: epoch 0166, iter [00050, 00390], lr: 0.000800, loss: 3.5254
2023-07-02 00:39:04 - train: epoch 0166, iter [00100, 00390], lr: 0.000800, loss: 3.7731
2023-07-02 00:39:06 - train: epoch 0166, iter [00150, 00390], lr: 0.000800, loss: 3.6048
2023-07-02 00:39:07 - train: epoch 0166, iter [00200, 00390], lr: 0.000800, loss: 3.4522
2023-07-02 00:39:09 - train: epoch 0166, iter [00250, 00390], lr: 0.000800, loss: 3.7343
2023-07-02 00:39:10 - train: epoch 0166, iter [00300, 00390], lr: 0.000800, loss: 3.6589
2023-07-02 00:39:11 - train: epoch 0166, iter [00350, 00390], lr: 0.000800, loss: 3.7449
2023-07-02 00:39:13 - train: epoch 166, train_loss: 3.1649
2023-07-02 00:39:14 - eval: epoch: 166, acc1: 42.290%, acc5: 71.350%, test_loss: 2.3064, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:39:14 - until epoch: 166, best_acc1: 42.570%
2023-07-02 00:39:14 - epoch 167 lr: 0.000800
2023-07-02 00:39:17 - train: epoch 0167, iter [00050, 00390], lr: 0.000800, loss: 2.3751
2023-07-02 00:39:18 - train: epoch 0167, iter [00100, 00390], lr: 0.000800, loss: 3.5901
2023-07-02 00:39:19 - train: epoch 0167, iter [00150, 00390], lr: 0.000800, loss: 3.0958
2023-07-02 00:39:21 - train: epoch 0167, iter [00200, 00390], lr: 0.000800, loss: 3.3878
2023-07-02 00:39:23 - train: epoch 0167, iter [00250, 00390], lr: 0.000800, loss: 3.6852
2023-07-02 00:39:24 - train: epoch 0167, iter [00300, 00390], lr: 0.000800, loss: 2.1739
2023-07-02 00:39:26 - train: epoch 0167, iter [00350, 00390], lr: 0.000800, loss: 2.2613
2023-07-02 00:39:27 - train: epoch 167, train_loss: 3.2221
2023-07-02 00:39:29 - eval: epoch: 167, acc1: 42.510%, acc5: 71.340%, test_loss: 2.3090, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:39:29 - until epoch: 167, best_acc1: 42.570%
2023-07-02 00:39:29 - epoch 168 lr: 0.000800
2023-07-02 00:39:31 - train: epoch 0168, iter [00050, 00390], lr: 0.000800, loss: 3.7701
2023-07-02 00:39:33 - train: epoch 0168, iter [00100, 00390], lr: 0.000800, loss: 3.9208
2023-07-02 00:39:34 - train: epoch 0168, iter [00150, 00390], lr: 0.000800, loss: 3.8265
2023-07-02 00:39:36 - train: epoch 0168, iter [00200, 00390], lr: 0.000800, loss: 3.8806
2023-07-02 00:39:37 - train: epoch 0168, iter [00250, 00390], lr: 0.000800, loss: 3.4146
2023-07-02 00:39:39 - train: epoch 0168, iter [00300, 00390], lr: 0.000800, loss: 2.1418
2023-07-02 00:39:40 - train: epoch 0168, iter [00350, 00390], lr: 0.000800, loss: 3.4740
2023-07-02 00:39:42 - train: epoch 168, train_loss: 3.1995
2023-07-02 00:39:43 - eval: epoch: 168, acc1: 42.790%, acc5: 71.620%, test_loss: 2.2972, per_image_load_time: 0.073ms, per_image_inference_time: 0.054ms
2023-07-02 00:39:44 - until epoch: 168, best_acc1: 42.790%
2023-07-02 00:39:44 - epoch 169 lr: 0.000800
2023-07-02 00:39:47 - train: epoch 0169, iter [00050, 00390], lr: 0.000800, loss: 2.1625
2023-07-02 00:39:48 - train: epoch 0169, iter [00100, 00390], lr: 0.000800, loss: 3.6190
2023-07-02 00:39:49 - train: epoch 0169, iter [00150, 00390], lr: 0.000800, loss: 3.6391
2023-07-02 00:39:51 - train: epoch 0169, iter [00200, 00390], lr: 0.000800, loss: 3.7114
2023-07-02 00:39:52 - train: epoch 0169, iter [00250, 00390], lr: 0.000800, loss: 2.2959
2023-07-02 00:39:54 - train: epoch 0169, iter [00300, 00390], lr: 0.000800, loss: 4.0739
2023-07-02 00:39:55 - train: epoch 0169, iter [00350, 00390], lr: 0.000800, loss: 2.8809
2023-07-02 00:39:56 - train: epoch 169, train_loss: 3.2077
2023-07-02 00:39:58 - eval: epoch: 169, acc1: 43.070%, acc5: 71.590%, test_loss: 2.2928, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:39:58 - until epoch: 169, best_acc1: 43.070%
2023-07-02 00:39:58 - epoch 170 lr: 0.000800
2023-07-02 00:40:01 - train: epoch 0170, iter [00050, 00390], lr: 0.000800, loss: 3.9790
2023-07-02 00:40:02 - train: epoch 0170, iter [00100, 00390], lr: 0.000800, loss: 3.6442
2023-07-02 00:40:04 - train: epoch 0170, iter [00150, 00390], lr: 0.000800, loss: 3.4204
2023-07-02 00:40:05 - train: epoch 0170, iter [00200, 00390], lr: 0.000800, loss: 2.9921
2023-07-02 00:40:07 - train: epoch 0170, iter [00250, 00390], lr: 0.000800, loss: 3.5827
2023-07-02 00:40:08 - train: epoch 0170, iter [00300, 00390], lr: 0.000800, loss: 3.8402
2023-07-02 00:40:10 - train: epoch 0170, iter [00350, 00390], lr: 0.000800, loss: 2.9965
2023-07-02 00:40:11 - train: epoch 170, train_loss: 3.2169
2023-07-02 00:40:13 - eval: epoch: 170, acc1: 42.520%, acc5: 71.390%, test_loss: 2.3024, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:40:13 - until epoch: 170, best_acc1: 43.070%
2023-07-02 00:40:13 - epoch 171 lr: 0.000800
2023-07-02 00:40:15 - train: epoch 0171, iter [00050, 00390], lr: 0.000800, loss: 2.8730
2023-07-02 00:40:17 - train: epoch 0171, iter [00100, 00390], lr: 0.000800, loss: 3.6882
2023-07-02 00:40:18 - train: epoch 0171, iter [00150, 00390], lr: 0.000800, loss: 2.5713
2023-07-02 00:40:20 - train: epoch 0171, iter [00200, 00390], lr: 0.000800, loss: 2.8766
2023-07-02 00:40:22 - train: epoch 0171, iter [00250, 00390], lr: 0.000800, loss: 1.9930
2023-07-02 00:40:23 - train: epoch 0171, iter [00300, 00390], lr: 0.000800, loss: 3.7192
2023-07-02 00:40:24 - train: epoch 0171, iter [00350, 00390], lr: 0.000800, loss: 3.3030
2023-07-02 00:40:26 - train: epoch 171, train_loss: 3.1987
2023-07-02 00:40:27 - eval: epoch: 171, acc1: 42.440%, acc5: 71.640%, test_loss: 2.2995, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-07-02 00:40:27 - until epoch: 171, best_acc1: 43.070%
2023-07-02 00:40:27 - epoch 172 lr: 0.000800
2023-07-02 00:40:30 - train: epoch 0172, iter [00050, 00390], lr: 0.000800, loss: 3.1909
2023-07-02 00:40:31 - train: epoch 0172, iter [00100, 00390], lr: 0.000800, loss: 2.3158
2023-07-02 00:40:33 - train: epoch 0172, iter [00150, 00390], lr: 0.000800, loss: 3.3732
2023-07-02 00:40:34 - train: epoch 0172, iter [00200, 00390], lr: 0.000800, loss: 3.3865
2023-07-02 00:40:35 - train: epoch 0172, iter [00250, 00390], lr: 0.000800, loss: 2.8198
2023-07-02 00:40:37 - train: epoch 0172, iter [00300, 00390], lr: 0.000800, loss: 3.7022
2023-07-02 00:40:38 - train: epoch 0172, iter [00350, 00390], lr: 0.000800, loss: 2.3193
2023-07-02 00:40:39 - train: epoch 172, train_loss: 3.1454
2023-07-02 00:40:41 - eval: epoch: 172, acc1: 43.040%, acc5: 71.720%, test_loss: 2.2854, per_image_load_time: 0.070ms, per_image_inference_time: 0.058ms
2023-07-02 00:40:41 - until epoch: 172, best_acc1: 43.070%
2023-07-02 00:40:41 - epoch 173 lr: 0.000800
2023-07-02 00:40:43 - train: epoch 0173, iter [00050, 00390], lr: 0.000800, loss: 3.3580
2023-07-02 00:40:45 - train: epoch 0173, iter [00100, 00390], lr: 0.000800, loss: 2.5523
2023-07-02 00:40:46 - train: epoch 0173, iter [00150, 00390], lr: 0.000800, loss: 4.0008
2023-07-02 00:40:48 - train: epoch 0173, iter [00200, 00390], lr: 0.000800, loss: 3.2971
2023-07-02 00:40:49 - train: epoch 0173, iter [00250, 00390], lr: 0.000800, loss: 3.5213
2023-07-02 00:40:51 - train: epoch 0173, iter [00300, 00390], lr: 0.000800, loss: 2.4342
2023-07-02 00:40:52 - train: epoch 0173, iter [00350, 00390], lr: 0.000800, loss: 3.6233
2023-07-02 00:40:53 - train: epoch 173, train_loss: 3.1545
2023-07-02 00:40:55 - eval: epoch: 173, acc1: 43.100%, acc5: 71.480%, test_loss: 2.2855, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:40:56 - until epoch: 173, best_acc1: 43.100%
2023-07-02 00:40:56 - epoch 174 lr: 0.000800
2023-07-02 00:40:58 - train: epoch 0174, iter [00050, 00390], lr: 0.000800, loss: 3.8494
2023-07-02 00:41:00 - train: epoch 0174, iter [00100, 00390], lr: 0.000800, loss: 3.7138
2023-07-02 00:41:01 - train: epoch 0174, iter [00150, 00390], lr: 0.000800, loss: 2.7702
2023-07-02 00:41:03 - train: epoch 0174, iter [00200, 00390], lr: 0.000800, loss: 2.3831
2023-07-02 00:41:04 - train: epoch 0174, iter [00250, 00390], lr: 0.000800, loss: 3.2103
2023-07-02 00:41:06 - train: epoch 0174, iter [00300, 00390], lr: 0.000800, loss: 2.2421
2023-07-02 00:41:07 - train: epoch 0174, iter [00350, 00390], lr: 0.000800, loss: 2.0366
2023-07-02 00:41:08 - train: epoch 174, train_loss: 3.1970
2023-07-02 00:41:10 - eval: epoch: 174, acc1: 42.740%, acc5: 71.880%, test_loss: 2.2946, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:41:10 - until epoch: 174, best_acc1: 43.100%
2023-07-02 00:41:10 - epoch 175 lr: 0.000800
2023-07-02 00:41:12 - train: epoch 0175, iter [00050, 00390], lr: 0.000800, loss: 3.9373
2023-07-02 00:41:14 - train: epoch 0175, iter [00100, 00390], lr: 0.000800, loss: 3.7530
2023-07-02 00:41:15 - train: epoch 0175, iter [00150, 00390], lr: 0.000800, loss: 3.8190
2023-07-02 00:41:16 - train: epoch 0175, iter [00200, 00390], lr: 0.000800, loss: 2.5938
2023-07-02 00:41:18 - train: epoch 0175, iter [00250, 00390], lr: 0.000800, loss: 3.2412
2023-07-02 00:41:19 - train: epoch 0175, iter [00300, 00390], lr: 0.000800, loss: 3.3566
2023-07-02 00:41:21 - train: epoch 0175, iter [00350, 00390], lr: 0.000800, loss: 2.3214
2023-07-02 00:41:22 - train: epoch 175, train_loss: 3.2252
2023-07-02 00:41:23 - eval: epoch: 175, acc1: 42.700%, acc5: 71.790%, test_loss: 2.3015, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:41:23 - until epoch: 175, best_acc1: 43.100%
2023-07-02 00:41:23 - epoch 176 lr: 0.000800
2023-07-02 00:41:26 - train: epoch 0176, iter [00050, 00390], lr: 0.000800, loss: 3.7744
2023-07-02 00:41:27 - train: epoch 0176, iter [00100, 00390], lr: 0.000800, loss: 3.6339
2023-07-02 00:41:28 - train: epoch 0176, iter [00150, 00390], lr: 0.000800, loss: 4.0169
2023-07-02 00:41:30 - train: epoch 0176, iter [00200, 00390], lr: 0.000800, loss: 2.6506
2023-07-02 00:41:31 - train: epoch 0176, iter [00250, 00390], lr: 0.000800, loss: 3.7542
2023-07-02 00:41:33 - train: epoch 0176, iter [00300, 00390], lr: 0.000800, loss: 3.8611
2023-07-02 00:41:34 - train: epoch 0176, iter [00350, 00390], lr: 0.000800, loss: 3.3429
2023-07-02 00:41:35 - train: epoch 176, train_loss: 3.2128
2023-07-02 00:41:37 - eval: epoch: 176, acc1: 42.980%, acc5: 72.100%, test_loss: 2.2929, per_image_load_time: 0.071ms, per_image_inference_time: 0.061ms
2023-07-02 00:41:37 - until epoch: 176, best_acc1: 43.100%
2023-07-02 00:41:37 - epoch 177 lr: 0.000800
2023-07-02 00:41:39 - train: epoch 0177, iter [00050, 00390], lr: 0.000800, loss: 3.0268
2023-07-02 00:41:41 - train: epoch 0177, iter [00100, 00390], lr: 0.000800, loss: 3.2916
2023-07-02 00:41:42 - train: epoch 0177, iter [00150, 00390], lr: 0.000800, loss: 2.6139
2023-07-02 00:41:43 - train: epoch 0177, iter [00200, 00390], lr: 0.000800, loss: 3.3765
2023-07-02 00:41:45 - train: epoch 0177, iter [00250, 00390], lr: 0.000800, loss: 2.3574
2023-07-02 00:41:46 - train: epoch 0177, iter [00300, 00390], lr: 0.000800, loss: 3.2318
2023-07-02 00:41:47 - train: epoch 0177, iter [00350, 00390], lr: 0.000800, loss: 2.6840
2023-07-02 00:41:49 - train: epoch 177, train_loss: 3.1821
2023-07-02 00:41:50 - eval: epoch: 177, acc1: 42.980%, acc5: 71.720%, test_loss: 2.2884, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:41:50 - until epoch: 177, best_acc1: 43.100%
2023-07-02 00:41:50 - epoch 178 lr: 0.000800
2023-07-02 00:41:52 - train: epoch 0178, iter [00050, 00390], lr: 0.000800, loss: 2.1022
2023-07-02 00:41:54 - train: epoch 0178, iter [00100, 00390], lr: 0.000800, loss: 3.0899
2023-07-02 00:41:55 - train: epoch 0178, iter [00150, 00390], lr: 0.000800, loss: 3.1683
2023-07-02 00:41:57 - train: epoch 0178, iter [00200, 00390], lr: 0.000800, loss: 2.7114
2023-07-02 00:41:58 - train: epoch 0178, iter [00250, 00390], lr: 0.000800, loss: 2.4521
2023-07-02 00:41:59 - train: epoch 0178, iter [00300, 00390], lr: 0.000800, loss: 3.7641
2023-07-02 00:42:01 - train: epoch 0178, iter [00350, 00390], lr: 0.000800, loss: 2.1842
2023-07-02 00:42:02 - train: epoch 178, train_loss: 3.1337
2023-07-02 00:42:03 - eval: epoch: 178, acc1: 42.630%, acc5: 71.740%, test_loss: 2.2874, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-07-02 00:42:04 - until epoch: 178, best_acc1: 43.100%
2023-07-02 00:42:04 - epoch 179 lr: 0.000800
2023-07-02 00:42:06 - train: epoch 0179, iter [00050, 00390], lr: 0.000800, loss: 3.3767
2023-07-02 00:42:07 - train: epoch 0179, iter [00100, 00390], lr: 0.000800, loss: 2.5992
2023-07-02 00:42:09 - train: epoch 0179, iter [00150, 00390], lr: 0.000800, loss: 3.7025
2023-07-02 00:42:10 - train: epoch 0179, iter [00200, 00390], lr: 0.000800, loss: 3.5329
2023-07-02 00:42:12 - train: epoch 0179, iter [00250, 00390], lr: 0.000800, loss: 3.9213
2023-07-02 00:42:13 - train: epoch 0179, iter [00300, 00390], lr: 0.000800, loss: 2.2213
2023-07-02 00:42:14 - train: epoch 0179, iter [00350, 00390], lr: 0.000800, loss: 3.5481
2023-07-02 00:42:16 - train: epoch 179, train_loss: 3.2327
2023-07-02 00:42:17 - eval: epoch: 179, acc1: 42.650%, acc5: 71.760%, test_loss: 2.2963, per_image_load_time: 0.070ms, per_image_inference_time: 0.059ms
2023-07-02 00:42:17 - until epoch: 179, best_acc1: 43.100%
2023-07-02 00:42:17 - epoch 180 lr: 0.000800
2023-07-02 00:42:19 - train: epoch 0180, iter [00050, 00390], lr: 0.000800, loss: 3.6122
2023-07-02 00:42:21 - train: epoch 0180, iter [00100, 00390], lr: 0.000800, loss: 2.8893
2023-07-02 00:42:22 - train: epoch 0180, iter [00150, 00390], lr: 0.000800, loss: 2.2273
2023-07-02 00:42:24 - train: epoch 0180, iter [00200, 00390], lr: 0.000800, loss: 2.4486
2023-07-02 00:42:25 - train: epoch 0180, iter [00250, 00390], lr: 0.000800, loss: 2.1478
2023-07-02 00:42:26 - train: epoch 0180, iter [00300, 00390], lr: 0.000800, loss: 3.5178
2023-07-02 00:42:28 - train: epoch 0180, iter [00350, 00390], lr: 0.000800, loss: 2.4459
2023-07-02 00:42:29 - train: epoch 180, train_loss: 3.2014
2023-07-02 00:42:30 - eval: epoch: 180, acc1: 43.060%, acc5: 71.820%, test_loss: 2.2910, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:42:31 - until epoch: 180, best_acc1: 43.100%
2023-07-02 00:42:31 - epoch 181 lr: 0.000800
2023-07-02 00:42:33 - train: epoch 0181, iter [00050, 00390], lr: 0.000800, loss: 3.8806
2023-07-02 00:42:34 - train: epoch 0181, iter [00100, 00390], lr: 0.000800, loss: 3.5649
2023-07-02 00:42:36 - train: epoch 0181, iter [00150, 00390], lr: 0.000800, loss: 3.5228
2023-07-02 00:42:37 - train: epoch 0181, iter [00200, 00390], lr: 0.000800, loss: 2.5097
2023-07-02 00:42:38 - train: epoch 0181, iter [00250, 00390], lr: 0.000800, loss: 2.7107
2023-07-02 00:42:40 - train: epoch 0181, iter [00300, 00390], lr: 0.000800, loss: 3.7272
2023-07-02 00:42:41 - train: epoch 0181, iter [00350, 00390], lr: 0.000800, loss: 2.1565
2023-07-02 00:42:42 - train: epoch 181, train_loss: 3.1633
2023-07-02 00:42:44 - eval: epoch: 181, acc1: 43.000%, acc5: 72.210%, test_loss: 2.2805, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:42:44 - until epoch: 181, best_acc1: 43.100%
2023-07-02 00:42:44 - epoch 182 lr: 0.000800
2023-07-02 00:42:46 - train: epoch 0182, iter [00050, 00390], lr: 0.000800, loss: 3.3367
2023-07-02 00:42:47 - train: epoch 0182, iter [00100, 00390], lr: 0.000800, loss: 3.4073
2023-07-02 00:42:49 - train: epoch 0182, iter [00150, 00390], lr: 0.000800, loss: 3.6650
2023-07-02 00:42:50 - train: epoch 0182, iter [00200, 00390], lr: 0.000800, loss: 3.0039
2023-07-02 00:42:52 - train: epoch 0182, iter [00250, 00390], lr: 0.000800, loss: 3.4095
2023-07-02 00:42:53 - train: epoch 0182, iter [00300, 00390], lr: 0.000800, loss: 2.9310
2023-07-02 00:42:54 - train: epoch 0182, iter [00350, 00390], lr: 0.000800, loss: 3.5840
2023-07-02 00:42:56 - train: epoch 182, train_loss: 3.2559
2023-07-02 00:42:57 - eval: epoch: 182, acc1: 42.680%, acc5: 71.710%, test_loss: 2.2939, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:42:58 - until epoch: 182, best_acc1: 43.100%
2023-07-02 00:42:58 - epoch 183 lr: 0.000800
2023-07-02 00:43:00 - train: epoch 0183, iter [00050, 00390], lr: 0.000800, loss: 2.0948
2023-07-02 00:43:01 - train: epoch 0183, iter [00100, 00390], lr: 0.000800, loss: 2.8165
2023-07-02 00:43:03 - train: epoch 0183, iter [00150, 00390], lr: 0.000800, loss: 3.4577
2023-07-02 00:43:04 - train: epoch 0183, iter [00200, 00390], lr: 0.000800, loss: 3.6182
2023-07-02 00:43:05 - train: epoch 0183, iter [00250, 00390], lr: 0.000800, loss: 3.7519
2023-07-02 00:43:07 - train: epoch 0183, iter [00300, 00390], lr: 0.000800, loss: 3.4681
2023-07-02 00:43:08 - train: epoch 0183, iter [00350, 00390], lr: 0.000800, loss: 3.3926
2023-07-02 00:43:09 - train: epoch 183, train_loss: 3.1743
2023-07-02 00:43:11 - eval: epoch: 183, acc1: 42.910%, acc5: 71.860%, test_loss: 2.2864, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:43:11 - until epoch: 183, best_acc1: 43.100%
2023-07-02 00:43:11 - epoch 184 lr: 0.000800
2023-07-02 00:43:13 - train: epoch 0184, iter [00050, 00390], lr: 0.000800, loss: 2.9194
2023-07-02 00:43:15 - train: epoch 0184, iter [00100, 00390], lr: 0.000800, loss: 3.4319
2023-07-02 00:43:16 - train: epoch 0184, iter [00150, 00390], lr: 0.000800, loss: 2.6953
2023-07-02 00:43:18 - train: epoch 0184, iter [00200, 00390], lr: 0.000800, loss: 3.3385
2023-07-02 00:43:19 - train: epoch 0184, iter [00250, 00390], lr: 0.000800, loss: 2.8584
2023-07-02 00:43:20 - train: epoch 0184, iter [00300, 00390], lr: 0.000800, loss: 2.3463
2023-07-02 00:43:22 - train: epoch 0184, iter [00350, 00390], lr: 0.000800, loss: 3.4288
2023-07-02 00:43:23 - train: epoch 184, train_loss: 3.1484
2023-07-02 00:43:24 - eval: epoch: 184, acc1: 42.600%, acc5: 71.880%, test_loss: 2.2868, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-07-02 00:43:25 - until epoch: 184, best_acc1: 43.100%
2023-07-02 00:43:25 - epoch 185 lr: 0.000800
2023-07-02 00:43:27 - train: epoch 0185, iter [00050, 00390], lr: 0.000800, loss: 3.2264
2023-07-02 00:43:28 - train: epoch 0185, iter [00100, 00390], lr: 0.000800, loss: 3.6300
2023-07-02 00:43:30 - train: epoch 0185, iter [00150, 00390], lr: 0.000800, loss: 2.7089
2023-07-02 00:43:31 - train: epoch 0185, iter [00200, 00390], lr: 0.000800, loss: 2.1362
2023-07-02 00:43:33 - train: epoch 0185, iter [00250, 00390], lr: 0.000800, loss: 3.0352
2023-07-02 00:43:34 - train: epoch 0185, iter [00300, 00390], lr: 0.000800, loss: 2.4674
2023-07-02 00:43:36 - train: epoch 0185, iter [00350, 00390], lr: 0.000800, loss: 2.7212
2023-07-02 00:43:37 - train: epoch 185, train_loss: 3.2212
2023-07-02 00:43:39 - eval: epoch: 185, acc1: 43.150%, acc5: 72.050%, test_loss: 2.2792, per_image_load_time: 0.090ms, per_image_inference_time: 0.053ms
2023-07-02 00:43:39 - until epoch: 185, best_acc1: 43.150%
2023-07-02 00:43:39 - epoch 186 lr: 0.000800
2023-07-02 00:43:42 - train: epoch 0186, iter [00050, 00390], lr: 0.000800, loss: 2.3480
2023-07-02 00:43:43 - train: epoch 0186, iter [00100, 00390], lr: 0.000800, loss: 2.8314
2023-07-02 00:43:44 - train: epoch 0186, iter [00150, 00390], lr: 0.000800, loss: 3.6384
2023-07-02 00:43:46 - train: epoch 0186, iter [00200, 00390], lr: 0.000800, loss: 2.4010
2023-07-02 00:43:47 - train: epoch 0186, iter [00250, 00390], lr: 0.000800, loss: 3.8751
2023-07-02 00:43:48 - train: epoch 0186, iter [00300, 00390], lr: 0.000800, loss: 3.6887
2023-07-02 00:43:50 - train: epoch 0186, iter [00350, 00390], lr: 0.000800, loss: 3.2053
2023-07-02 00:43:51 - train: epoch 186, train_loss: 3.1538
2023-07-02 00:43:52 - eval: epoch: 186, acc1: 42.880%, acc5: 71.610%, test_loss: 2.2797, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-07-02 00:43:53 - until epoch: 186, best_acc1: 43.150%
2023-07-02 00:43:53 - epoch 187 lr: 0.000800
2023-07-02 00:43:55 - train: epoch 0187, iter [00050, 00390], lr: 0.000800, loss: 3.3325
2023-07-02 00:43:56 - train: epoch 0187, iter [00100, 00390], lr: 0.000800, loss: 2.7394
2023-07-02 00:43:58 - train: epoch 0187, iter [00150, 00390], lr: 0.000800, loss: 3.7399
2023-07-02 00:43:59 - train: epoch 0187, iter [00200, 00390], lr: 0.000800, loss: 3.5696
2023-07-02 00:44:00 - train: epoch 0187, iter [00250, 00390], lr: 0.000800, loss: 2.5243
2023-07-02 00:44:02 - train: epoch 0187, iter [00300, 00390], lr: 0.000800, loss: 3.6547
2023-07-02 00:44:03 - train: epoch 0187, iter [00350, 00390], lr: 0.000800, loss: 2.4479
2023-07-02 00:44:04 - train: epoch 187, train_loss: 3.2187
2023-07-02 00:44:06 - eval: epoch: 187, acc1: 43.240%, acc5: 71.860%, test_loss: 2.2776, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 00:44:07 - until epoch: 187, best_acc1: 43.240%
2023-07-02 00:44:07 - epoch 188 lr: 0.000800
2023-07-02 00:44:09 - train: epoch 0188, iter [00050, 00390], lr: 0.000800, loss: 3.7678
2023-07-02 00:44:10 - train: epoch 0188, iter [00100, 00390], lr: 0.000800, loss: 3.4394
2023-07-02 00:44:12 - train: epoch 0188, iter [00150, 00390], lr: 0.000800, loss: 3.6237
2023-07-02 00:44:13 - train: epoch 0188, iter [00200, 00390], lr: 0.000800, loss: 3.8076
2023-07-02 00:44:15 - train: epoch 0188, iter [00250, 00390], lr: 0.000800, loss: 3.6541
2023-07-02 00:44:16 - train: epoch 0188, iter [00300, 00390], lr: 0.000800, loss: 3.5471
2023-07-02 00:44:17 - train: epoch 0188, iter [00350, 00390], lr: 0.000800, loss: 3.4738
2023-07-02 00:44:19 - train: epoch 188, train_loss: 3.2143
2023-07-02 00:44:20 - eval: epoch: 188, acc1: 42.640%, acc5: 71.830%, test_loss: 2.2815, per_image_load_time: 0.072ms, per_image_inference_time: 0.052ms
2023-07-02 00:44:21 - until epoch: 188, best_acc1: 43.240%
2023-07-02 00:44:21 - epoch 189 lr: 0.000800
2023-07-02 00:44:23 - train: epoch 0189, iter [00050, 00390], lr: 0.000800, loss: 2.8720
2023-07-02 00:44:24 - train: epoch 0189, iter [00100, 00390], lr: 0.000800, loss: 3.6429
2023-07-02 00:44:25 - train: epoch 0189, iter [00150, 00390], lr: 0.000800, loss: 3.1407
2023-07-02 00:44:27 - train: epoch 0189, iter [00200, 00390], lr: 0.000800, loss: 3.7566
2023-07-02 00:44:28 - train: epoch 0189, iter [00250, 00390], lr: 0.000800, loss: 3.5220
2023-07-02 00:44:30 - train: epoch 0189, iter [00300, 00390], lr: 0.000800, loss: 3.4674
2023-07-02 00:44:31 - train: epoch 0189, iter [00350, 00390], lr: 0.000800, loss: 3.7447
2023-07-02 00:44:32 - train: epoch 189, train_loss: 3.1671
2023-07-02 00:44:33 - eval: epoch: 189, acc1: 42.780%, acc5: 71.730%, test_loss: 2.2899, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-07-02 00:44:34 - until epoch: 189, best_acc1: 43.240%
2023-07-02 00:44:34 - epoch 190 lr: 0.000800
2023-07-02 00:44:36 - train: epoch 0190, iter [00050, 00390], lr: 0.000800, loss: 3.5613
2023-07-02 00:44:37 - train: epoch 0190, iter [00100, 00390], lr: 0.000800, loss: 3.6166
2023-07-02 00:44:39 - train: epoch 0190, iter [00150, 00390], lr: 0.000800, loss: 3.4933
2023-07-02 00:44:40 - train: epoch 0190, iter [00200, 00390], lr: 0.000800, loss: 2.4315
2023-07-02 00:44:42 - train: epoch 0190, iter [00250, 00390], lr: 0.000800, loss: 3.2036
2023-07-02 00:44:43 - train: epoch 0190, iter [00300, 00390], lr: 0.000800, loss: 3.2529
2023-07-02 00:44:45 - train: epoch 0190, iter [00350, 00390], lr: 0.000800, loss: 3.8003
2023-07-02 00:44:46 - train: epoch 190, train_loss: 3.2036
2023-07-02 00:44:47 - eval: epoch: 190, acc1: 42.890%, acc5: 71.970%, test_loss: 2.2861, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:44:47 - until epoch: 190, best_acc1: 43.240%
2023-07-02 00:44:47 - epoch 191 lr: 0.000800
2023-07-02 00:44:50 - train: epoch 0191, iter [00050, 00390], lr: 0.000800, loss: 1.9366
2023-07-02 00:44:51 - train: epoch 0191, iter [00100, 00390], lr: 0.000800, loss: 3.7925
2023-07-02 00:44:52 - train: epoch 0191, iter [00150, 00390], lr: 0.000800, loss: 2.0941
2023-07-02 00:44:54 - train: epoch 0191, iter [00200, 00390], lr: 0.000800, loss: 3.5605
2023-07-02 00:44:55 - train: epoch 0191, iter [00250, 00390], lr: 0.000800, loss: 2.8808
2023-07-02 00:44:57 - train: epoch 0191, iter [00300, 00390], lr: 0.000800, loss: 2.0877
2023-07-02 00:44:58 - train: epoch 0191, iter [00350, 00390], lr: 0.000800, loss: 3.4202
2023-07-02 00:44:59 - train: epoch 191, train_loss: 3.1340
2023-07-02 00:45:01 - eval: epoch: 191, acc1: 43.100%, acc5: 71.800%, test_loss: 2.2783, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 00:45:01 - until epoch: 191, best_acc1: 43.240%
2023-07-02 00:45:01 - epoch 192 lr: 0.000800
2023-07-02 00:45:03 - train: epoch 0192, iter [00050, 00390], lr: 0.000800, loss: 3.5381
2023-07-02 00:45:04 - train: epoch 0192, iter [00100, 00390], lr: 0.000800, loss: 3.2255
2023-07-02 00:45:06 - train: epoch 0192, iter [00150, 00390], lr: 0.000800, loss: 3.0814
2023-07-02 00:45:07 - train: epoch 0192, iter [00200, 00390], lr: 0.000800, loss: 3.3244
2023-07-02 00:45:09 - train: epoch 0192, iter [00250, 00390], lr: 0.000800, loss: 3.5881
2023-07-02 00:45:10 - train: epoch 0192, iter [00300, 00390], lr: 0.000800, loss: 3.5949
2023-07-02 00:45:11 - train: epoch 0192, iter [00350, 00390], lr: 0.000800, loss: 3.2728
2023-07-02 00:45:13 - train: epoch 192, train_loss: 3.1698
2023-07-02 00:45:14 - eval: epoch: 192, acc1: 43.200%, acc5: 71.650%, test_loss: 2.2934, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:45:15 - until epoch: 192, best_acc1: 43.240%
2023-07-02 00:45:15 - epoch 193 lr: 0.000800
2023-07-02 00:45:17 - train: epoch 0193, iter [00050, 00390], lr: 0.000800, loss: 3.8296
2023-07-02 00:45:18 - train: epoch 0193, iter [00100, 00390], lr: 0.000800, loss: 3.8739
2023-07-02 00:45:20 - train: epoch 0193, iter [00150, 00390], lr: 0.000800, loss: 2.9906
2023-07-02 00:45:21 - train: epoch 0193, iter [00200, 00390], lr: 0.000800, loss: 3.7533
2023-07-02 00:45:23 - train: epoch 0193, iter [00250, 00390], lr: 0.000800, loss: 2.4277
2023-07-02 00:45:24 - train: epoch 0193, iter [00300, 00390], lr: 0.000800, loss: 3.3497
2023-07-02 00:45:25 - train: epoch 0193, iter [00350, 00390], lr: 0.000800, loss: 3.7655
2023-07-02 00:45:26 - train: epoch 193, train_loss: 3.1860
2023-07-02 00:45:28 - eval: epoch: 193, acc1: 42.950%, acc5: 71.670%, test_loss: 2.2906, per_image_load_time: 0.069ms, per_image_inference_time: 0.052ms
2023-07-02 00:45:28 - until epoch: 193, best_acc1: 43.240%
2023-07-02 00:45:28 - epoch 194 lr: 0.000800
2023-07-02 00:45:30 - train: epoch 0194, iter [00050, 00390], lr: 0.000800, loss: 3.3362
2023-07-02 00:45:32 - train: epoch 0194, iter [00100, 00390], lr: 0.000800, loss: 3.7415
2023-07-02 00:45:33 - train: epoch 0194, iter [00150, 00390], lr: 0.000800, loss: 2.2775
2023-07-02 00:45:35 - train: epoch 0194, iter [00200, 00390], lr: 0.000800, loss: 3.7344
2023-07-02 00:45:36 - train: epoch 0194, iter [00250, 00390], lr: 0.000800, loss: 3.6773
2023-07-02 00:45:37 - train: epoch 0194, iter [00300, 00390], lr: 0.000800, loss: 2.3011
2023-07-02 00:45:39 - train: epoch 0194, iter [00350, 00390], lr: 0.000800, loss: 3.6288
2023-07-02 00:45:40 - train: epoch 194, train_loss: 3.1662
2023-07-02 00:45:41 - eval: epoch: 194, acc1: 43.360%, acc5: 71.880%, test_loss: 2.2828, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-07-02 00:45:42 - until epoch: 194, best_acc1: 43.360%
2023-07-02 00:45:42 - epoch 195 lr: 0.000800
2023-07-02 00:45:44 - train: epoch 0195, iter [00050, 00390], lr: 0.000800, loss: 3.7231
2023-07-02 00:45:45 - train: epoch 0195, iter [00100, 00390], lr: 0.000800, loss: 3.2814
2023-07-02 00:45:47 - train: epoch 0195, iter [00150, 00390], lr: 0.000800, loss: 2.6762
2023-07-02 00:45:48 - train: epoch 0195, iter [00200, 00390], lr: 0.000800, loss: 3.4834
2023-07-02 00:45:49 - train: epoch 0195, iter [00250, 00390], lr: 0.000800, loss: 3.8242
2023-07-02 00:45:51 - train: epoch 0195, iter [00300, 00390], lr: 0.000800, loss: 2.0998
2023-07-02 00:45:52 - train: epoch 0195, iter [00350, 00390], lr: 0.000800, loss: 2.0788
2023-07-02 00:45:53 - train: epoch 195, train_loss: 3.1723
2023-07-02 00:45:55 - eval: epoch: 195, acc1: 43.350%, acc5: 72.080%, test_loss: 2.2763, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-07-02 00:45:55 - until epoch: 195, best_acc1: 43.360%
2023-07-02 00:45:55 - epoch 196 lr: 0.000800
2023-07-02 00:45:57 - train: epoch 0196, iter [00050, 00390], lr: 0.000800, loss: 3.5472
2023-07-02 00:45:59 - train: epoch 0196, iter [00100, 00390], lr: 0.000800, loss: 2.4697
2023-07-02 00:46:00 - train: epoch 0196, iter [00150, 00390], lr: 0.000800, loss: 3.7451
2023-07-02 00:46:02 - train: epoch 0196, iter [00200, 00390], lr: 0.000800, loss: 2.6901
2023-07-02 00:46:03 - train: epoch 0196, iter [00250, 00390], lr: 0.000800, loss: 2.0893
2023-07-02 00:46:04 - train: epoch 0196, iter [00300, 00390], lr: 0.000800, loss: 2.6770
2023-07-02 00:46:06 - train: epoch 0196, iter [00350, 00390], lr: 0.000800, loss: 3.0764
2023-07-02 00:46:07 - train: epoch 196, train_loss: 3.2003
2023-07-02 00:46:08 - eval: epoch: 196, acc1: 43.050%, acc5: 71.770%, test_loss: 2.2866, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:46:09 - until epoch: 196, best_acc1: 43.360%
2023-07-02 00:46:09 - epoch 197 lr: 0.000800
2023-07-02 00:46:11 - train: epoch 0197, iter [00050, 00390], lr: 0.000800, loss: 2.6888
2023-07-02 00:46:12 - train: epoch 0197, iter [00100, 00390], lr: 0.000800, loss: 3.4233
2023-07-02 00:46:14 - train: epoch 0197, iter [00150, 00390], lr: 0.000800, loss: 3.2920
2023-07-02 00:46:15 - train: epoch 0197, iter [00200, 00390], lr: 0.000800, loss: 3.8629
2023-07-02 00:46:17 - train: epoch 0197, iter [00250, 00390], lr: 0.000800, loss: 2.0004
2023-07-02 00:46:18 - train: epoch 0197, iter [00300, 00390], lr: 0.000800, loss: 3.7348
2023-07-02 00:46:19 - train: epoch 0197, iter [00350, 00390], lr: 0.000800, loss: 3.6832
2023-07-02 00:46:21 - train: epoch 197, train_loss: 3.1961
2023-07-02 00:46:22 - eval: epoch: 197, acc1: 43.270%, acc5: 72.060%, test_loss: 2.2799, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:46:22 - until epoch: 197, best_acc1: 43.360%
2023-07-02 00:46:22 - epoch 198 lr: 0.000800
2023-07-02 00:46:24 - train: epoch 0198, iter [00050, 00390], lr: 0.000800, loss: 3.0470
2023-07-02 00:46:26 - train: epoch 0198, iter [00100, 00390], lr: 0.000800, loss: 2.3171
2023-07-02 00:46:27 - train: epoch 0198, iter [00150, 00390], lr: 0.000800, loss: 2.2680
2023-07-02 00:46:29 - train: epoch 0198, iter [00200, 00390], lr: 0.000800, loss: 3.6963
2023-07-02 00:46:30 - train: epoch 0198, iter [00250, 00390], lr: 0.000800, loss: 3.1067
2023-07-02 00:46:31 - train: epoch 0198, iter [00300, 00390], lr: 0.000800, loss: 3.5700
2023-07-02 00:46:33 - train: epoch 0198, iter [00350, 00390], lr: 0.000800, loss: 2.7564
2023-07-02 00:46:34 - train: epoch 198, train_loss: 3.1946
2023-07-02 00:46:35 - eval: epoch: 198, acc1: 43.040%, acc5: 71.950%, test_loss: 2.2850, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 00:46:36 - until epoch: 198, best_acc1: 43.360%
2023-07-02 00:46:36 - epoch 199 lr: 0.000800
2023-07-02 00:46:38 - train: epoch 0199, iter [00050, 00390], lr: 0.000800, loss: 2.6101
2023-07-02 00:46:39 - train: epoch 0199, iter [00100, 00390], lr: 0.000800, loss: 2.2209
2023-07-02 00:46:41 - train: epoch 0199, iter [00150, 00390], lr: 0.000800, loss: 3.6835
2023-07-02 00:46:42 - train: epoch 0199, iter [00200, 00390], lr: 0.000800, loss: 2.5959
2023-07-02 00:46:43 - train: epoch 0199, iter [00250, 00390], lr: 0.000800, loss: 3.2124
2023-07-02 00:46:45 - train: epoch 0199, iter [00300, 00390], lr: 0.000800, loss: 3.3296
2023-07-02 00:46:46 - train: epoch 0199, iter [00350, 00390], lr: 0.000800, loss: 2.2464
2023-07-02 00:46:47 - train: epoch 199, train_loss: 3.1744
2023-07-02 00:46:49 - eval: epoch: 199, acc1: 42.960%, acc5: 71.940%, test_loss: 2.2764, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 00:46:49 - until epoch: 199, best_acc1: 43.360%
2023-07-02 00:46:49 - epoch 200 lr: 0.000800
2023-07-02 00:46:51 - train: epoch 0200, iter [00050, 00390], lr: 0.000800, loss: 4.0689
2023-07-02 00:46:52 - train: epoch 0200, iter [00100, 00390], lr: 0.000800, loss: 2.6841
2023-07-02 00:46:54 - train: epoch 0200, iter [00150, 00390], lr: 0.000800, loss: 3.6261
2023-07-02 00:46:55 - train: epoch 0200, iter [00200, 00390], lr: 0.000800, loss: 2.0558
2023-07-02 00:46:57 - train: epoch 0200, iter [00250, 00390], lr: 0.000800, loss: 3.6789
2023-07-02 00:46:58 - train: epoch 0200, iter [00300, 00390], lr: 0.000800, loss: 3.7729
2023-07-02 00:46:59 - train: epoch 0200, iter [00350, 00390], lr: 0.000800, loss: 3.6146
2023-07-02 00:47:01 - train: epoch 200, train_loss: 3.1307
2023-07-02 00:47:02 - eval: epoch: 200, acc1: 43.660%, acc5: 71.840%, test_loss: 2.2675, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 00:47:03 - until epoch: 200, best_acc1: 43.660%
2023-07-02 00:47:03 - train done. model: vit_mid_small_patch16, train time: 0.740 hours, best_acc1: 43.660%
2023-07-02 00:55:02 - network: vit_mid_small_patch16
2023-07-02 00:55:02 - num_classes: 100
2023-07-02 00:55:02 - input_image_size: 32
2023-07-02 00:55:02 - num_params: 12758116
2023-07-02 00:55:02 - trained_model_path: 
2023-07-02 00:55:02 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-02 00:55:02 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-02 00:55:02 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f1b6cf7b820>
2023-07-02 00:55:02 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f1b6cf7b7f0>
2023-07-02 00:55:02 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f1b6cf7b880>
2023-07-02 00:55:02 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f1b6cf7bb20>
2023-07-02 00:55:02 - seed: 0
2023-07-02 00:55:02 - batch_size: 128
2023-07-02 00:55:02 - num_workers: 16
2023-07-02 00:55:02 - accumulation_steps: 1
2023-07-02 00:55:02 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-02 00:55:02 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-07-02 00:55:02 - epochs: 200
2023-07-02 00:55:02 - print_interval: 50
2023-07-02 00:55:02 - sync_bn: False
2023-07-02 00:55:02 - apex: True
2023-07-02 00:55:02 - use_ema_model: False
2023-07-02 00:55:02 - ema_model_decay: 0.9999
2023-07-02 00:55:02 - AUG: cutout
2023-07-02 00:55:02 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-02 00:55:02 - gpus_num: 1
2023-07-02 00:55:02 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f1b6cf8ff30>
2023-07-02 00:55:02 - --------------------parameters--------------------
2023-07-02 00:55:02 - name: cls_token, grad: True
2023-07-02 00:55:02 - name: position_encoding, grad: True
2023-07-02 00:55:02 - name: patch_embedding.conv.weight, grad: True
2023-07-02 00:55:02 - name: patch_embedding.conv.bias, grad: True
2023-07-02 00:55:02 - name: blocks.0.norm1.weight, grad: True
2023-07-02 00:55:02 - name: blocks.0.norm1.bias, grad: True
2023-07-02 00:55:02 - name: blocks.0.attention.qkv_linear.weight, grad: True
2023-07-02 00:55:02 - name: blocks.0.attention.qkv_linear.bias, grad: True
2023-07-02 00:55:02 - name: blocks.0.attention.out_linear.weight, grad: True
2023-07-02 00:55:02 - name: blocks.0.attention.out_linear.bias, grad: True
2023-07-02 00:55:02 - name: blocks.0.norm2.weight, grad: True
2023-07-02 00:55:02 - name: blocks.0.norm2.bias, grad: True
2023-07-02 00:55:02 - name: blocks.0.feed_forward.fc1.weight, grad: True
2023-07-02 00:55:02 - name: blocks.0.feed_forward.fc1.bias, grad: True
2023-07-02 00:55:03 - name: blocks.0.feed_forward.fc2.weight, grad: True
2023-07-02 00:55:03 - name: blocks.0.feed_forward.fc2.bias, grad: True
2023-07-02 00:55:03 - name: blocks.1.norm1.weight, grad: True
2023-07-02 00:55:03 - name: blocks.1.norm1.bias, grad: True
2023-07-02 00:55:03 - name: blocks.1.attention.qkv_linear.weight, grad: True
2023-07-02 00:55:03 - name: blocks.1.attention.qkv_linear.bias, grad: True
2023-07-02 00:55:03 - name: blocks.1.attention.out_linear.weight, grad: True
2023-07-02 00:55:03 - name: blocks.1.attention.out_linear.bias, grad: True
2023-07-02 00:55:03 - name: blocks.1.norm2.weight, grad: True
2023-07-02 00:55:03 - name: blocks.1.norm2.bias, grad: True
2023-07-02 00:55:03 - name: blocks.1.feed_forward.fc1.weight, grad: True
2023-07-02 00:55:03 - name: blocks.1.feed_forward.fc1.bias, grad: True
2023-07-02 00:55:03 - name: blocks.1.feed_forward.fc2.weight, grad: True
2023-07-02 00:55:03 - name: blocks.1.feed_forward.fc2.bias, grad: True
2023-07-02 00:55:03 - name: blocks.2.norm1.weight, grad: True
2023-07-02 00:55:03 - name: blocks.2.norm1.bias, grad: True
2023-07-02 00:55:03 - name: blocks.2.attention.qkv_linear.weight, grad: True
2023-07-02 00:55:03 - name: blocks.2.attention.qkv_linear.bias, grad: True
2023-07-02 00:55:03 - name: blocks.2.attention.out_linear.weight, grad: True
2023-07-02 00:55:03 - name: blocks.2.attention.out_linear.bias, grad: True
2023-07-02 00:55:03 - name: blocks.2.norm2.weight, grad: True
2023-07-02 00:55:03 - name: blocks.2.norm2.bias, grad: True
2023-07-02 00:55:03 - name: blocks.2.feed_forward.fc1.weight, grad: True
2023-07-02 00:55:03 - name: blocks.2.feed_forward.fc1.bias, grad: True
2023-07-02 00:55:03 - name: blocks.2.feed_forward.fc2.weight, grad: True
2023-07-02 00:55:03 - name: blocks.2.feed_forward.fc2.bias, grad: True
2023-07-02 00:55:03 - name: blocks.3.norm1.weight, grad: True
2023-07-02 00:55:03 - name: blocks.3.norm1.bias, grad: True
2023-07-02 00:55:03 - name: blocks.3.attention.qkv_linear.weight, grad: True
2023-07-02 00:55:03 - name: blocks.3.attention.qkv_linear.bias, grad: True
2023-07-02 00:55:03 - name: blocks.3.attention.out_linear.weight, grad: True
2023-07-02 00:55:03 - name: blocks.3.attention.out_linear.bias, grad: True
2023-07-02 00:55:03 - name: blocks.3.norm2.weight, grad: True
2023-07-02 00:55:03 - name: blocks.3.norm2.bias, grad: True
2023-07-02 00:55:03 - name: blocks.3.feed_forward.fc1.weight, grad: True
2023-07-02 00:55:03 - name: blocks.3.feed_forward.fc1.bias, grad: True
2023-07-02 00:55:03 - name: blocks.3.feed_forward.fc2.weight, grad: True
2023-07-02 00:55:03 - name: blocks.3.feed_forward.fc2.bias, grad: True
2023-07-02 00:55:03 - name: blocks.4.norm1.weight, grad: True
2023-07-02 00:55:03 - name: blocks.4.norm1.bias, grad: True
2023-07-02 00:55:03 - name: blocks.4.attention.qkv_linear.weight, grad: True
2023-07-02 00:55:03 - name: blocks.4.attention.qkv_linear.bias, grad: True
2023-07-02 00:55:03 - name: blocks.4.attention.out_linear.weight, grad: True
2023-07-02 00:55:03 - name: blocks.4.attention.out_linear.bias, grad: True
2023-07-02 00:55:03 - name: blocks.4.norm2.weight, grad: True
2023-07-02 00:55:03 - name: blocks.4.norm2.bias, grad: True
2023-07-02 00:55:03 - name: blocks.4.feed_forward.fc1.weight, grad: True
2023-07-02 00:55:03 - name: blocks.4.feed_forward.fc1.bias, grad: True
2023-07-02 00:55:03 - name: blocks.4.feed_forward.fc2.weight, grad: True
2023-07-02 00:55:03 - name: blocks.4.feed_forward.fc2.bias, grad: True
2023-07-02 00:55:03 - name: blocks.5.norm1.weight, grad: True
2023-07-02 00:55:03 - name: blocks.5.norm1.bias, grad: True
2023-07-02 00:55:03 - name: blocks.5.attention.qkv_linear.weight, grad: True
2023-07-02 00:55:03 - name: blocks.5.attention.qkv_linear.bias, grad: True
2023-07-02 00:55:03 - name: blocks.5.attention.out_linear.weight, grad: True
2023-07-02 00:55:03 - name: blocks.5.attention.out_linear.bias, grad: True
2023-07-02 00:55:03 - name: blocks.5.norm2.weight, grad: True
2023-07-02 00:55:03 - name: blocks.5.norm2.bias, grad: True
2023-07-02 00:55:03 - name: blocks.5.feed_forward.fc1.weight, grad: True
2023-07-02 00:55:03 - name: blocks.5.feed_forward.fc1.bias, grad: True
2023-07-02 00:55:03 - name: blocks.5.feed_forward.fc2.weight, grad: True
2023-07-02 00:55:03 - name: blocks.5.feed_forward.fc2.bias, grad: True
2023-07-02 00:55:03 - name: blocks.6.norm1.weight, grad: True
2023-07-02 00:55:03 - name: blocks.6.norm1.bias, grad: True
2023-07-02 00:55:03 - name: blocks.6.attention.qkv_linear.weight, grad: True
2023-07-02 00:55:03 - name: blocks.6.attention.qkv_linear.bias, grad: True
2023-07-02 00:55:03 - name: blocks.6.attention.out_linear.weight, grad: True
2023-07-02 00:55:03 - name: blocks.6.attention.out_linear.bias, grad: True
2023-07-02 00:55:03 - name: blocks.6.norm2.weight, grad: True
2023-07-02 00:55:03 - name: blocks.6.norm2.bias, grad: True
2023-07-02 00:55:03 - name: blocks.6.feed_forward.fc1.weight, grad: True
2023-07-02 00:55:03 - name: blocks.6.feed_forward.fc1.bias, grad: True
2023-07-02 00:55:03 - name: blocks.6.feed_forward.fc2.weight, grad: True
2023-07-02 00:55:03 - name: blocks.6.feed_forward.fc2.bias, grad: True
2023-07-02 00:55:03 - name: norm.weight, grad: True
2023-07-02 00:55:03 - name: norm.bias, grad: True
2023-07-02 00:55:03 - name: fc.weight, grad: True
2023-07-02 00:55:03 - name: fc.bias, grad: True
2023-07-02 00:55:03 - --------------------buffers--------------------
2023-07-02 00:55:03 - -----------no weight decay layers--------------
2023-07-02 00:55:03 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: norm.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: norm.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:55:03 - -------------weight decay layers---------------
2023-07-02 00:55:03 - name: cls_token, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: position_encoding, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: patch_embedding.conv.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:55:03 - epoch 001 lr: 0.100000
2023-07-02 00:55:09 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.9016
2023-07-02 00:55:11 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.3485
2023-07-02 00:55:12 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 4.2137
2023-07-02 00:55:14 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 4.1030
2023-07-02 00:55:15 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 4.1485
2023-07-02 00:55:16 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 4.0734
2023-07-02 00:55:18 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 4.0894
2023-07-02 00:55:19 - train: epoch 001, train_loss: 4.3069
2023-07-02 00:55:20 - eval: epoch: 001, acc1: 8.300%, acc5: 25.800%, test_loss: 4.0613, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 00:55:21 - until epoch: 001, best_acc1: 8.300%
2023-07-02 00:55:21 - epoch 002 lr: 0.100000
2023-07-02 00:55:23 - train: epoch 0002, iter [00050, 00390], lr: 0.100000, loss: 4.0181
2023-07-02 00:55:24 - train: epoch 0002, iter [00100, 00390], lr: 0.100000, loss: 3.8932
2023-07-02 00:55:26 - train: epoch 0002, iter [00150, 00390], lr: 0.100000, loss: 3.9620
2023-07-02 00:55:27 - train: epoch 0002, iter [00200, 00390], lr: 0.100000, loss: 4.1461
2023-07-02 00:55:29 - train: epoch 0002, iter [00250, 00390], lr: 0.100000, loss: 4.0476
2023-07-02 00:55:30 - train: epoch 0002, iter [00300, 00390], lr: 0.100000, loss: 4.1374
2023-07-02 00:55:31 - train: epoch 0002, iter [00350, 00390], lr: 0.100000, loss: 3.8633
2023-07-02 00:55:33 - train: epoch 002, train_loss: 4.0150
2023-07-02 00:55:34 - eval: epoch: 002, acc1: 10.310%, acc5: 31.180%, test_loss: 3.8557, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 00:55:35 - until epoch: 002, best_acc1: 10.310%
2023-07-02 00:55:35 - epoch 003 lr: 0.100000
2023-07-02 00:55:37 - train: epoch 0003, iter [00050, 00390], lr: 0.100000, loss: 3.8657
2023-07-02 00:55:39 - train: epoch 0003, iter [00100, 00390], lr: 0.100000, loss: 3.8671
2023-07-02 00:55:40 - train: epoch 0003, iter [00150, 00390], lr: 0.100000, loss: 3.9617
2023-07-02 00:55:41 - train: epoch 0003, iter [00200, 00390], lr: 0.100000, loss: 4.0636
2023-07-02 00:55:43 - train: epoch 0003, iter [00250, 00390], lr: 0.100000, loss: 4.0676
2023-07-02 00:55:44 - train: epoch 0003, iter [00300, 00390], lr: 0.100000, loss: 4.0297
2023-07-02 00:55:46 - train: epoch 0003, iter [00350, 00390], lr: 0.100000, loss: 3.9720
2023-07-02 00:55:47 - train: epoch 003, train_loss: 3.9337
2023-07-02 00:55:48 - eval: epoch: 003, acc1: 11.270%, acc5: 33.070%, test_loss: 3.7998, per_image_load_time: 0.068ms, per_image_inference_time: 0.060ms
2023-07-02 00:55:49 - until epoch: 003, best_acc1: 11.270%
2023-07-02 00:55:49 - epoch 004 lr: 0.100000
2023-07-02 00:55:51 - train: epoch 0004, iter [00050, 00390], lr: 0.100000, loss: 3.7019
2023-07-02 00:55:53 - train: epoch 0004, iter [00100, 00390], lr: 0.100000, loss: 3.9075
2023-07-02 00:55:54 - train: epoch 0004, iter [00150, 00390], lr: 0.100000, loss: 3.8381
2023-07-02 00:55:56 - train: epoch 0004, iter [00200, 00390], lr: 0.100000, loss: 3.9917
2023-07-02 00:55:57 - train: epoch 0004, iter [00250, 00390], lr: 0.100000, loss: 3.6141
2023-07-02 00:55:59 - train: epoch 0004, iter [00300, 00390], lr: 0.100000, loss: 3.9021
2023-07-02 00:56:00 - train: epoch 0004, iter [00350, 00390], lr: 0.100000, loss: 3.7710
2023-07-02 00:56:01 - train: epoch 004, train_loss: 3.9050
2023-07-02 00:56:03 - eval: epoch: 004, acc1: 12.940%, acc5: 35.250%, test_loss: 3.7269, per_image_load_time: 0.070ms, per_image_inference_time: 0.055ms
2023-07-02 00:56:04 - until epoch: 004, best_acc1: 12.940%
2023-07-02 00:56:04 - epoch 005 lr: 0.100000
2023-07-02 00:56:06 - train: epoch 0005, iter [00050, 00390], lr: 0.100000, loss: 3.9568
2023-07-02 00:56:07 - train: epoch 0005, iter [00100, 00390], lr: 0.100000, loss: 3.6481
2023-07-02 00:56:09 - train: epoch 0005, iter [00150, 00390], lr: 0.100000, loss: 3.7625
2023-07-02 00:56:10 - train: epoch 0005, iter [00200, 00390], lr: 0.100000, loss: 3.8993
2023-07-02 00:56:11 - train: epoch 0005, iter [00250, 00390], lr: 0.100000, loss: 3.7666
2023-07-02 00:56:13 - train: epoch 0005, iter [00300, 00390], lr: 0.100000, loss: 3.9196
2023-07-02 00:56:14 - train: epoch 0005, iter [00350, 00390], lr: 0.100000, loss: 3.7971
2023-07-02 00:56:15 - train: epoch 005, train_loss: 3.8741
2023-07-02 00:56:17 - eval: epoch: 005, acc1: 12.850%, acc5: 35.790%, test_loss: 3.7187, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 00:56:17 - until epoch: 005, best_acc1: 12.940%
2023-07-02 00:56:17 - epoch 006 lr: 0.100000
2023-07-02 00:56:19 - train: epoch 0006, iter [00050, 00390], lr: 0.100000, loss: 3.7763
2023-07-02 00:56:21 - train: epoch 0006, iter [00100, 00390], lr: 0.100000, loss: 3.7626
2023-07-02 00:56:22 - train: epoch 0006, iter [00150, 00390], lr: 0.100000, loss: 3.9118
2023-07-02 00:56:24 - train: epoch 0006, iter [00200, 00390], lr: 0.100000, loss: 3.9469
2023-07-02 00:56:25 - train: epoch 0006, iter [00250, 00390], lr: 0.100000, loss: 3.9115
2023-07-02 00:56:26 - train: epoch 0006, iter [00300, 00390], lr: 0.100000, loss: 3.7873
2023-07-02 00:56:28 - train: epoch 0006, iter [00350, 00390], lr: 0.100000, loss: 3.9730
2023-07-02 00:56:29 - train: epoch 006, train_loss: 3.8285
2023-07-02 00:56:31 - eval: epoch: 006, acc1: 12.960%, acc5: 35.270%, test_loss: 3.7118, per_image_load_time: 0.074ms, per_image_inference_time: 0.056ms
2023-07-02 00:56:31 - until epoch: 006, best_acc1: 12.960%
2023-07-02 00:56:31 - epoch 007 lr: 0.100000
2023-07-02 00:56:33 - train: epoch 0007, iter [00050, 00390], lr: 0.100000, loss: 3.9926
2023-07-02 00:56:35 - train: epoch 0007, iter [00100, 00390], lr: 0.100000, loss: 4.0802
2023-07-02 00:56:36 - train: epoch 0007, iter [00150, 00390], lr: 0.100000, loss: 3.6816
2023-07-02 00:56:38 - train: epoch 0007, iter [00200, 00390], lr: 0.100000, loss: 4.0805
2023-07-02 00:56:39 - train: epoch 0007, iter [00250, 00390], lr: 0.100000, loss: 3.6174
2023-07-02 00:56:41 - train: epoch 0007, iter [00300, 00390], lr: 0.100000, loss: 3.8775
2023-07-02 00:56:42 - train: epoch 0007, iter [00350, 00390], lr: 0.100000, loss: 3.6330
2023-07-02 00:56:43 - train: epoch 007, train_loss: 3.8115
2023-07-02 00:56:45 - eval: epoch: 007, acc1: 14.620%, acc5: 39.590%, test_loss: 3.5983, per_image_load_time: 0.067ms, per_image_inference_time: 0.054ms
2023-07-02 00:56:45 - until epoch: 007, best_acc1: 14.620%
2023-07-02 00:56:45 - epoch 008 lr: 0.100000
2023-07-02 00:56:48 - train: epoch 0008, iter [00050, 00390], lr: 0.100000, loss: 3.8113
2023-07-02 00:56:49 - train: epoch 0008, iter [00100, 00390], lr: 0.100000, loss: 3.9006
2023-07-02 00:56:50 - train: epoch 0008, iter [00150, 00390], lr: 0.100000, loss: 3.8974
2023-07-02 00:56:52 - train: epoch 0008, iter [00200, 00390], lr: 0.100000, loss: 4.0775
2023-07-02 00:56:53 - train: epoch 0008, iter [00250, 00390], lr: 0.100000, loss: 3.6106
2023-07-02 00:56:55 - train: epoch 0008, iter [00300, 00390], lr: 0.100000, loss: 3.8822
2023-07-02 00:56:56 - train: epoch 0008, iter [00350, 00390], lr: 0.100000, loss: 3.7463
2023-07-02 00:56:57 - train: epoch 008, train_loss: 3.7838
2023-07-02 00:56:59 - eval: epoch: 008, acc1: 13.840%, acc5: 38.480%, test_loss: 3.6242, per_image_load_time: 0.074ms, per_image_inference_time: 0.055ms
2023-07-02 00:56:59 - until epoch: 008, best_acc1: 14.620%
2023-07-02 00:56:59 - epoch 009 lr: 0.100000
2023-07-02 00:57:01 - train: epoch 0009, iter [00050, 00390], lr: 0.100000, loss: 3.6538
2023-07-02 00:57:03 - train: epoch 0009, iter [00100, 00390], lr: 0.100000, loss: 3.7170
2023-07-02 00:57:04 - train: epoch 0009, iter [00150, 00390], lr: 0.100000, loss: 3.8358
2023-07-02 00:57:05 - train: epoch 0009, iter [00200, 00390], lr: 0.100000, loss: 3.6416
2023-07-02 00:57:07 - train: epoch 0009, iter [00250, 00390], lr: 0.100000, loss: 3.6718
2023-07-02 00:57:09 - train: epoch 0009, iter [00300, 00390], lr: 0.100000, loss: 3.7977
2023-07-02 00:57:10 - train: epoch 0009, iter [00350, 00390], lr: 0.100000, loss: 3.8587
2023-07-02 00:57:11 - train: epoch 009, train_loss: 3.7661
2023-07-02 00:57:13 - eval: epoch: 009, acc1: 16.290%, acc5: 40.760%, test_loss: 3.5340, per_image_load_time: 0.067ms, per_image_inference_time: 0.054ms
2023-07-02 00:57:13 - until epoch: 009, best_acc1: 16.290%
2023-07-02 00:57:13 - epoch 010 lr: 0.100000
2023-07-02 00:57:15 - train: epoch 0010, iter [00050, 00390], lr: 0.100000, loss: 3.8655
2023-07-02 00:57:17 - train: epoch 0010, iter [00100, 00390], lr: 0.100000, loss: 3.9801
2023-07-02 00:57:18 - train: epoch 0010, iter [00150, 00390], lr: 0.100000, loss: 3.8533
2023-07-02 00:57:20 - train: epoch 0010, iter [00200, 00390], lr: 0.100000, loss: 3.8445
2023-07-02 00:57:21 - train: epoch 0010, iter [00250, 00390], lr: 0.100000, loss: 3.7105
2023-07-02 00:57:22 - train: epoch 0010, iter [00300, 00390], lr: 0.100000, loss: 3.5560
2023-07-02 00:57:24 - train: epoch 0010, iter [00350, 00390], lr: 0.100000, loss: 3.8871
2023-07-02 00:57:25 - train: epoch 010, train_loss: 3.7308
2023-07-02 00:57:26 - eval: epoch: 010, acc1: 15.660%, acc5: 41.330%, test_loss: 3.5220, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 00:57:27 - until epoch: 010, best_acc1: 16.290%
2023-07-02 00:57:27 - epoch 011 lr: 0.100000
2023-07-02 00:57:29 - train: epoch 0011, iter [00050, 00390], lr: 0.100000, loss: 3.6023
2023-07-02 00:57:30 - train: epoch 0011, iter [00100, 00390], lr: 0.100000, loss: 3.7888
2023-07-02 00:57:32 - train: epoch 0011, iter [00150, 00390], lr: 0.100000, loss: 3.8853
2023-07-02 00:57:33 - train: epoch 0011, iter [00200, 00390], lr: 0.100000, loss: 3.6446
2023-07-02 00:57:35 - train: epoch 0011, iter [00250, 00390], lr: 0.100000, loss: 3.5922
2023-07-02 00:57:36 - train: epoch 0011, iter [00300, 00390], lr: 0.100000, loss: 3.4595
2023-07-02 00:57:38 - train: epoch 0011, iter [00350, 00390], lr: 0.100000, loss: 3.4803
2023-07-02 00:57:39 - train: epoch 011, train_loss: 3.7352
2023-07-02 00:57:41 - eval: epoch: 011, acc1: 16.330%, acc5: 40.940%, test_loss: 3.5303, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 00:57:41 - until epoch: 011, best_acc1: 16.330%
2023-07-02 00:57:41 - epoch 012 lr: 0.100000
2023-07-02 00:57:43 - train: epoch 0012, iter [00050, 00390], lr: 0.100000, loss: 3.6232
2023-07-02 00:57:45 - train: epoch 0012, iter [00100, 00390], lr: 0.100000, loss: 3.8093
2023-07-02 00:57:46 - train: epoch 0012, iter [00150, 00390], lr: 0.100000, loss: 3.9777
2023-07-02 00:57:48 - train: epoch 0012, iter [00200, 00390], lr: 0.100000, loss: 3.6840
2023-07-02 00:57:49 - train: epoch 0012, iter [00250, 00390], lr: 0.100000, loss: 3.7139
2023-07-02 00:57:51 - train: epoch 0012, iter [00300, 00390], lr: 0.100000, loss: 3.4894
2023-07-02 00:57:52 - train: epoch 0012, iter [00350, 00390], lr: 0.100000, loss: 3.6461
2023-07-02 00:57:53 - train: epoch 012, train_loss: 3.7081
2023-07-02 00:57:55 - eval: epoch: 012, acc1: 15.690%, acc5: 41.710%, test_loss: 3.5241, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 00:57:55 - until epoch: 012, best_acc1: 16.330%
2023-07-02 00:57:55 - epoch 013 lr: 0.100000
2023-07-02 00:57:57 - train: epoch 0013, iter [00050, 00390], lr: 0.100000, loss: 3.7122
2023-07-02 00:57:59 - train: epoch 0013, iter [00100, 00390], lr: 0.100000, loss: 3.7838
2023-07-02 00:58:00 - train: epoch 0013, iter [00150, 00390], lr: 0.100000, loss: 3.5123
2023-07-02 00:58:02 - train: epoch 0013, iter [00200, 00390], lr: 0.100000, loss: 3.6031
2023-07-02 00:58:03 - train: epoch 0013, iter [00250, 00390], lr: 0.100000, loss: 3.7733
2023-07-02 00:58:05 - train: epoch 0013, iter [00300, 00390], lr: 0.100000, loss: 3.6706
2023-07-02 00:58:13 - train: epoch 0013, iter [00350, 00390], lr: 0.100000, loss: 3.4879
2023-07-02 00:58:14 - train: epoch 013, train_loss: 3.6694
2023-07-02 00:58:15 - network: vit_mid_small_patch16
2023-07-02 00:58:15 - num_classes: 100
2023-07-02 00:58:15 - input_image_size: 32
2023-07-02 00:58:15 - num_params: 12758116
2023-07-02 00:58:15 - trained_model_path: 
2023-07-02 00:58:15 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-02 00:58:15 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-07-02 00:58:15 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fdc008df940>
2023-07-02 00:58:15 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fdc008dfa30>
2023-07-02 00:58:15 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fdc008dfbb0>
2023-07-02 00:58:15 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fdc008df880>
2023-07-02 00:58:15 - seed: 0
2023-07-02 00:58:15 - batch_size: 128
2023-07-02 00:58:15 - num_workers: 16
2023-07-02 00:58:15 - accumulation_steps: 1
2023-07-02 00:58:15 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-07-02 00:58:15 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-07-02 00:58:15 - epochs: 200
2023-07-02 00:58:15 - print_interval: 50
2023-07-02 00:58:15 - sync_bn: False
2023-07-02 00:58:15 - apex: True
2023-07-02 00:58:15 - use_ema_model: False
2023-07-02 00:58:15 - ema_model_decay: 0.9999
2023-07-02 00:58:15 - AUG: mixup
2023-07-02 00:58:15 - gpus_type: NVIDIA GeForce RTX 3090
2023-07-02 00:58:15 - gpus_num: 1
2023-07-02 00:58:15 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7fdc008f3570>
2023-07-02 00:58:15 - --------------------parameters--------------------
2023-07-02 00:58:15 - name: cls_token, grad: True
2023-07-02 00:58:15 - name: position_encoding, grad: True
2023-07-02 00:58:15 - name: patch_embedding.conv.weight, grad: True
2023-07-02 00:58:15 - name: patch_embedding.conv.bias, grad: True
2023-07-02 00:58:15 - name: blocks.0.norm1.weight, grad: True
2023-07-02 00:58:15 - name: blocks.0.norm1.bias, grad: True
2023-07-02 00:58:15 - name: blocks.0.attention.qkv_linear.weight, grad: True
2023-07-02 00:58:15 - name: blocks.0.attention.qkv_linear.bias, grad: True
2023-07-02 00:58:15 - name: blocks.0.attention.out_linear.weight, grad: True
2023-07-02 00:58:15 - name: blocks.0.attention.out_linear.bias, grad: True
2023-07-02 00:58:15 - name: blocks.0.norm2.weight, grad: True
2023-07-02 00:58:15 - name: blocks.0.norm2.bias, grad: True
2023-07-02 00:58:15 - name: blocks.0.feed_forward.fc1.weight, grad: True
2023-07-02 00:58:15 - name: blocks.0.feed_forward.fc1.bias, grad: True
2023-07-02 00:58:15 - name: blocks.0.feed_forward.fc2.weight, grad: True
2023-07-02 00:58:15 - name: blocks.0.feed_forward.fc2.bias, grad: True
2023-07-02 00:58:15 - name: blocks.1.norm1.weight, grad: True
2023-07-02 00:58:15 - name: blocks.1.norm1.bias, grad: True
2023-07-02 00:58:15 - name: blocks.1.attention.qkv_linear.weight, grad: True
2023-07-02 00:58:15 - name: blocks.1.attention.qkv_linear.bias, grad: True
2023-07-02 00:58:15 - name: blocks.1.attention.out_linear.weight, grad: True
2023-07-02 00:58:15 - name: blocks.1.attention.out_linear.bias, grad: True
2023-07-02 00:58:15 - name: blocks.1.norm2.weight, grad: True
2023-07-02 00:58:15 - name: blocks.1.norm2.bias, grad: True
2023-07-02 00:58:15 - name: blocks.1.feed_forward.fc1.weight, grad: True
2023-07-02 00:58:15 - name: blocks.1.feed_forward.fc1.bias, grad: True
2023-07-02 00:58:15 - name: blocks.1.feed_forward.fc2.weight, grad: True
2023-07-02 00:58:15 - name: blocks.1.feed_forward.fc2.bias, grad: True
2023-07-02 00:58:15 - name: blocks.2.norm1.weight, grad: True
2023-07-02 00:58:15 - name: blocks.2.norm1.bias, grad: True
2023-07-02 00:58:15 - name: blocks.2.attention.qkv_linear.weight, grad: True
2023-07-02 00:58:15 - name: blocks.2.attention.qkv_linear.bias, grad: True
2023-07-02 00:58:15 - name: blocks.2.attention.out_linear.weight, grad: True
2023-07-02 00:58:15 - name: blocks.2.attention.out_linear.bias, grad: True
2023-07-02 00:58:15 - name: blocks.2.norm2.weight, grad: True
2023-07-02 00:58:15 - name: blocks.2.norm2.bias, grad: True
2023-07-02 00:58:15 - name: blocks.2.feed_forward.fc1.weight, grad: True
2023-07-02 00:58:15 - name: blocks.2.feed_forward.fc1.bias, grad: True
2023-07-02 00:58:15 - name: blocks.2.feed_forward.fc2.weight, grad: True
2023-07-02 00:58:15 - name: blocks.2.feed_forward.fc2.bias, grad: True
2023-07-02 00:58:15 - name: blocks.3.norm1.weight, grad: True
2023-07-02 00:58:15 - name: blocks.3.norm1.bias, grad: True
2023-07-02 00:58:15 - name: blocks.3.attention.qkv_linear.weight, grad: True
2023-07-02 00:58:15 - name: blocks.3.attention.qkv_linear.bias, grad: True
2023-07-02 00:58:15 - name: blocks.3.attention.out_linear.weight, grad: True
2023-07-02 00:58:15 - name: blocks.3.attention.out_linear.bias, grad: True
2023-07-02 00:58:15 - name: blocks.3.norm2.weight, grad: True
2023-07-02 00:58:15 - name: blocks.3.norm2.bias, grad: True
2023-07-02 00:58:15 - name: blocks.3.feed_forward.fc1.weight, grad: True
2023-07-02 00:58:15 - name: blocks.3.feed_forward.fc1.bias, grad: True
2023-07-02 00:58:15 - name: blocks.3.feed_forward.fc2.weight, grad: True
2023-07-02 00:58:15 - name: blocks.3.feed_forward.fc2.bias, grad: True
2023-07-02 00:58:15 - name: blocks.4.norm1.weight, grad: True
2023-07-02 00:58:15 - name: blocks.4.norm1.bias, grad: True
2023-07-02 00:58:15 - name: blocks.4.attention.qkv_linear.weight, grad: True
2023-07-02 00:58:15 - name: blocks.4.attention.qkv_linear.bias, grad: True
2023-07-02 00:58:15 - name: blocks.4.attention.out_linear.weight, grad: True
2023-07-02 00:58:15 - name: blocks.4.attention.out_linear.bias, grad: True
2023-07-02 00:58:15 - name: blocks.4.norm2.weight, grad: True
2023-07-02 00:58:15 - name: blocks.4.norm2.bias, grad: True
2023-07-02 00:58:15 - name: blocks.4.feed_forward.fc1.weight, grad: True
2023-07-02 00:58:15 - name: blocks.4.feed_forward.fc1.bias, grad: True
2023-07-02 00:58:15 - name: blocks.4.feed_forward.fc2.weight, grad: True
2023-07-02 00:58:15 - name: blocks.4.feed_forward.fc2.bias, grad: True
2023-07-02 00:58:15 - name: blocks.5.norm1.weight, grad: True
2023-07-02 00:58:15 - name: blocks.5.norm1.bias, grad: True
2023-07-02 00:58:15 - name: blocks.5.attention.qkv_linear.weight, grad: True
2023-07-02 00:58:15 - name: blocks.5.attention.qkv_linear.bias, grad: True
2023-07-02 00:58:15 - name: blocks.5.attention.out_linear.weight, grad: True
2023-07-02 00:58:15 - name: blocks.5.attention.out_linear.bias, grad: True
2023-07-02 00:58:15 - name: blocks.5.norm2.weight, grad: True
2023-07-02 00:58:15 - name: blocks.5.norm2.bias, grad: True
2023-07-02 00:58:15 - name: blocks.5.feed_forward.fc1.weight, grad: True
2023-07-02 00:58:15 - name: blocks.5.feed_forward.fc1.bias, grad: True
2023-07-02 00:58:15 - name: blocks.5.feed_forward.fc2.weight, grad: True
2023-07-02 00:58:15 - name: blocks.5.feed_forward.fc2.bias, grad: True
2023-07-02 00:58:15 - name: blocks.6.norm1.weight, grad: True
2023-07-02 00:58:15 - name: blocks.6.norm1.bias, grad: True
2023-07-02 00:58:15 - name: blocks.6.attention.qkv_linear.weight, grad: True
2023-07-02 00:58:15 - name: blocks.6.attention.qkv_linear.bias, grad: True
2023-07-02 00:58:15 - name: blocks.6.attention.out_linear.weight, grad: True
2023-07-02 00:58:15 - name: blocks.6.attention.out_linear.bias, grad: True
2023-07-02 00:58:15 - name: blocks.6.norm2.weight, grad: True
2023-07-02 00:58:15 - name: blocks.6.norm2.bias, grad: True
2023-07-02 00:58:15 - name: blocks.6.feed_forward.fc1.weight, grad: True
2023-07-02 00:58:15 - name: blocks.6.feed_forward.fc1.bias, grad: True
2023-07-02 00:58:15 - name: blocks.6.feed_forward.fc2.weight, grad: True
2023-07-02 00:58:15 - name: blocks.6.feed_forward.fc2.bias, grad: True
2023-07-02 00:58:15 - name: norm.weight, grad: True
2023-07-02 00:58:15 - name: norm.bias, grad: True
2023-07-02 00:58:15 - name: fc.weight, grad: True
2023-07-02 00:58:15 - name: fc.bias, grad: True
2023-07-02 00:58:15 - --------------------buffers--------------------
2023-07-02 00:58:15 - -----------no weight decay layers--------------
2023-07-02 00:58:15 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: norm.weight, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: norm.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-07-02 00:58:15 - -------------weight decay layers---------------
2023-07-02 00:58:15 - name: cls_token, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:15 - name: position_encoding, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:15 - name: patch_embedding.conv.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:15 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-07-02 00:58:16 - epoch 001 lr: 0.100000
2023-07-02 00:58:17 - eval: epoch: 013, acc1: 16.970%, acc5: 43.420%, test_loss: 3.4586, per_image_load_time: 0.070ms, per_image_inference_time: 0.136ms
2023-07-02 00:58:19 - until epoch: 013, best_acc1: 16.970%
2023-07-02 00:58:19 - epoch 014 lr: 0.100000
2023-07-02 00:58:21 - train: epoch 0014, iter [00050, 00390], lr: 0.100000, loss: 4.0566
2023-07-02 00:58:23 - train: epoch 0014, iter [00100, 00390], lr: 0.100000, loss: 3.5682
2023-07-02 00:58:23 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.8490
2023-07-02 00:58:25 - train: epoch 0014, iter [00150, 00390], lr: 0.100000, loss: 3.7037
2023-07-02 00:58:25 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.3287
2023-07-02 00:58:27 - train: epoch 0014, iter [00200, 00390], lr: 0.100000, loss: 3.8919
2023-07-02 00:58:27 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 4.2491
2023-07-02 00:58:29 - train: epoch 0014, iter [00250, 00390], lr: 0.100000, loss: 3.7318
2023-07-02 00:58:29 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 4.1682
2023-07-02 00:58:31 - train: epoch 0014, iter [00300, 00390], lr: 0.100000, loss: 3.7338
2023-07-02 00:58:32 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 4.2106
2023-07-02 00:58:33 - train: epoch 0014, iter [00350, 00390], lr: 0.100000, loss: 3.7999
2023-07-02 00:58:34 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 4.1256
2023-07-02 00:58:35 - train: epoch 014, train_loss: 3.6685
2023-07-02 00:58:36 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 4.1344
2023-07-02 00:58:36 - eval: epoch: 014, acc1: 18.320%, acc5: 44.310%, test_loss: 3.4104, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 00:58:37 - train: epoch 001, train_loss: 4.3041
2023-07-02 00:58:38 - until epoch: 014, best_acc1: 18.320%
2023-07-02 00:58:38 - epoch 015 lr: 0.100000
2023-07-02 00:58:39 - eval: epoch: 001, acc1: 10.650%, acc5: 30.300%, test_loss: 3.8934, per_image_load_time: 0.074ms, per_image_inference_time: 0.057ms
2023-07-02 00:58:39 - until epoch: 001, best_acc1: 10.650%
2023-07-02 00:58:39 - epoch 002 lr: 0.100000
2023-07-02 00:58:41 - train: epoch 0015, iter [00050, 00390], lr: 0.100000, loss: 3.3829
2023-07-02 00:58:42 - train: epoch 0002, iter [00050, 00390], lr: 0.100000, loss: 4.0265
2023-07-02 00:58:43 - train: epoch 0015, iter [00100, 00390], lr: 0.100000, loss: 3.8727
2023-07-02 00:58:44 - train: epoch 0002, iter [00100, 00390], lr: 0.100000, loss: 4.0072
2023-07-02 00:58:45 - train: epoch 0015, iter [00150, 00390], lr: 0.100000, loss: 3.9679
2023-07-02 00:58:46 - train: epoch 0002, iter [00150, 00390], lr: 0.100000, loss: 3.9566
2023-07-02 00:58:47 - train: epoch 0015, iter [00200, 00390], lr: 0.100000, loss: 3.4866
2023-07-02 00:58:49 - train: epoch 0002, iter [00200, 00390], lr: 0.100000, loss: 4.1004
2023-07-02 00:58:49 - train: epoch 0015, iter [00250, 00390], lr: 0.100000, loss: 3.3626
2023-07-02 00:58:51 - train: epoch 0002, iter [00250, 00390], lr: 0.100000, loss: 3.9574
2023-07-02 00:58:51 - train: epoch 0015, iter [00300, 00390], lr: 0.100000, loss: 3.3476
2023-07-02 00:58:53 - train: epoch 0002, iter [00300, 00390], lr: 0.100000, loss: 4.0528
2023-07-02 00:58:53 - train: epoch 0015, iter [00350, 00390], lr: 0.100000, loss: 3.8422
2023-07-02 00:58:55 - train: epoch 015, train_loss: 3.6354
2023-07-02 00:58:55 - train: epoch 0002, iter [00350, 00390], lr: 0.100000, loss: 3.9293
2023-07-02 00:58:56 - eval: epoch: 015, acc1: 17.860%, acc5: 44.720%, test_loss: 3.4125, per_image_load_time: 0.071ms, per_image_inference_time: 0.055ms
2023-07-02 00:58:57 - train: epoch 002, train_loss: 3.9886
2023-07-02 00:58:57 - until epoch: 015, best_acc1: 18.320%
2023-07-02 00:58:57 - epoch 016 lr: 0.100000
2023-07-02 00:58:58 - eval: epoch: 002, acc1: 12.880%, acc5: 35.630%, test_loss: 3.7167, per_image_load_time: 0.071ms, per_image_inference_time: 0.067ms
2023-07-02 00:58:59 - until epoch: 002, best_acc1: 12.880%
2023-07-02 00:58:59 - epoch 003 lr: 0.100000
2023-07-02 00:58:59 - train: epoch 0016, iter [00050, 00390], lr: 0.100000, loss: 3.6450
2023-07-02 00:59:01 - train: epoch 0016, iter [00100, 00390], lr: 0.100000, loss: 3.4195
2023-07-02 00:59:02 - train: epoch 0003, iter [00050, 00390], lr: 0.100000, loss: 3.8885
2023-07-02 00:59:03 - train: epoch 0016, iter [00150, 00390], lr: 0.100000, loss: 3.6596
2023-07-02 00:59:04 - train: epoch 0003, iter [00100, 00390], lr: 0.100000, loss: 3.8236
2023-07-02 00:59:05 - train: epoch 0016, iter [00200, 00390], lr: 0.100000, loss: 3.6798
2023-07-02 00:59:06 - train: epoch 0003, iter [00150, 00390], lr: 0.100000, loss: 4.0676
2023-07-02 00:59:07 - train: epoch 0016, iter [00250, 00390], lr: 0.100000, loss: 3.4524
2023-07-02 00:59:08 - train: epoch 0003, iter [00200, 00390], lr: 0.100000, loss: 3.8357
2023-07-02 00:59:10 - train: epoch 0016, iter [00300, 00390], lr: 0.100000, loss: 3.8134
2023-07-02 00:59:11 - train: epoch 0003, iter [00250, 00390], lr: 0.100000, loss: 4.0585
2023-07-02 00:59:12 - train: epoch 0016, iter [00350, 00390], lr: 0.100000, loss: 3.7841
2023-07-02 00:59:13 - train: epoch 0003, iter [00300, 00390], lr: 0.100000, loss: 3.8822
2023-07-02 00:59:13 - train: epoch 016, train_loss: 3.6269
2023-07-02 00:59:15 - eval: epoch: 016, acc1: 18.430%, acc5: 45.100%, test_loss: 3.4011, per_image_load_time: 0.071ms, per_image_inference_time: 0.055ms
2023-07-02 00:59:15 - train: epoch 0003, iter [00350, 00390], lr: 0.100000, loss: 3.9359
2023-07-02 00:59:15 - until epoch: 016, best_acc1: 18.430%
2023-07-02 00:59:15 - epoch 017 lr: 0.100000
2023-07-02 00:59:16 - train: epoch 003, train_loss: 3.8693
2023-07-02 00:59:18 - train: epoch 0017, iter [00050, 00390], lr: 0.100000, loss: 3.9525
2023-07-02 00:59:18 - eval: epoch: 003, acc1: 14.720%, acc5: 38.950%, test_loss: 3.6137, per_image_load_time: 0.070ms, per_image_inference_time: 0.062ms
2023-07-02 00:59:19 - until epoch: 003, best_acc1: 14.720%
2023-07-02 00:59:19 - epoch 004 lr: 0.100000
2023-07-02 00:59:19 - train: epoch 0017, iter [00100, 00390], lr: 0.100000, loss: 3.6604
2023-07-02 00:59:21 - train: epoch 0017, iter [00150, 00390], lr: 0.100000, loss: 3.6204
2023-07-02 00:59:22 - train: epoch 0004, iter [00050, 00390], lr: 0.100000, loss: 3.7454
2023-07-02 00:59:23 - train: epoch 0017, iter [00200, 00390], lr: 0.100000, loss: 3.6676
2023-07-02 00:59:24 - train: epoch 0004, iter [00100, 00390], lr: 0.100000, loss: 3.8998
2023-07-02 00:59:25 - train: epoch 0017, iter [00250, 00390], lr: 0.100000, loss: 3.6565
2023-07-02 00:59:26 - train: epoch 0004, iter [00150, 00390], lr: 0.100000, loss: 3.8834
2023-07-02 00:59:27 - train: epoch 0017, iter [00300, 00390], lr: 0.100000, loss: 3.8877
2023-07-02 00:59:28 - train: epoch 0004, iter [00200, 00390], lr: 0.100000, loss: 3.8464
2023-07-02 00:59:29 - train: epoch 0017, iter [00350, 00390], lr: 0.100000, loss: 3.2560
2023-07-02 00:59:30 - train: epoch 0004, iter [00250, 00390], lr: 0.100000, loss: 3.5834
2023-07-02 00:59:31 - train: epoch 017, train_loss: 3.6197
2023-07-02 00:59:32 - train: epoch 0004, iter [00300, 00390], lr: 0.100000, loss: 3.8934
2023-07-02 00:59:32 - eval: epoch: 017, acc1: 18.850%, acc5: 45.500%, test_loss: 3.3813, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 00:59:34 - train: epoch 0004, iter [00350, 00390], lr: 0.100000, loss: 3.6425
2023-07-02 00:59:34 - until epoch: 017, best_acc1: 18.850%
2023-07-02 00:59:34 - epoch 018 lr: 0.100000
2023-07-02 00:59:35 - train: epoch 004, train_loss: 3.7908
2023-07-02 00:59:36 - train: epoch 0018, iter [00050, 00390], lr: 0.100000, loss: 3.8843
2023-07-02 00:59:37 - eval: epoch: 004, acc1: 16.390%, acc5: 40.990%, test_loss: 3.5390, per_image_load_time: 0.068ms, per_image_inference_time: 0.058ms
2023-07-02 00:59:37 - until epoch: 004, best_acc1: 16.390%
2023-07-02 00:59:37 - epoch 005 lr: 0.100000
2023-07-02 00:59:38 - train: epoch 0018, iter [00100, 00390], lr: 0.100000, loss: 3.8097
2023-07-02 00:59:40 - train: epoch 0018, iter [00150, 00390], lr: 0.100000, loss: 3.4194
2023-07-02 00:59:40 - train: epoch 0005, iter [00050, 00390], lr: 0.100000, loss: 3.6399
2023-07-02 00:59:42 - train: epoch 0018, iter [00200, 00390], lr: 0.100000, loss: 3.5145
2023-07-02 00:59:42 - train: epoch 0005, iter [00100, 00390], lr: 0.100000, loss: 3.6429
2023-07-02 00:59:44 - train: epoch 0018, iter [00250, 00390], lr: 0.100000, loss: 3.5979
2023-07-02 00:59:45 - train: epoch 0005, iter [00150, 00390], lr: 0.100000, loss: 3.5692
2023-07-02 00:59:46 - train: epoch 0018, iter [00300, 00390], lr: 0.100000, loss: 3.2498
2023-07-02 00:59:47 - train: epoch 0005, iter [00200, 00390], lr: 0.100000, loss: 3.8228
2023-07-02 00:59:48 - train: epoch 0018, iter [00350, 00390], lr: 0.100000, loss: 3.4243
2023-07-02 00:59:49 - train: epoch 0005, iter [00250, 00390], lr: 0.100000, loss: 3.6386
2023-07-02 00:59:50 - train: epoch 018, train_loss: 3.5997
2023-07-02 00:59:51 - train: epoch 0005, iter [00300, 00390], lr: 0.100000, loss: 3.6635
2023-07-02 00:59:52 - eval: epoch: 018, acc1: 18.300%, acc5: 45.810%, test_loss: 3.3825, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 00:59:52 - until epoch: 018, best_acc1: 18.850%
2023-07-02 00:59:52 - epoch 019 lr: 0.100000
2023-07-02 00:59:53 - train: epoch 0005, iter [00350, 00390], lr: 0.100000, loss: 3.7741
2023-07-02 00:59:54 - train: epoch 005, train_loss: 3.7337
2023-07-02 00:59:55 - train: epoch 0019, iter [00050, 00390], lr: 0.100000, loss: 3.2384
2023-07-02 00:59:56 - eval: epoch: 005, acc1: 18.400%, acc5: 44.730%, test_loss: 3.4374, per_image_load_time: 0.070ms, per_image_inference_time: 0.058ms
2023-07-02 00:59:56 - until epoch: 005, best_acc1: 18.400%
2023-07-02 00:59:56 - epoch 006 lr: 0.100000
2023-07-02 00:59:56 - train: epoch 0019, iter [00100, 00390], lr: 0.100000, loss: 3.4615
2023-07-02 00:59:58 - train: epoch 0019, iter [00150, 00390], lr: 0.100000, loss: 3.8732
2023-07-02 00:59:59 - train: epoch 0006, iter [00050, 00390], lr: 0.100000, loss: 3.7683
2023-07-02 01:00:00 - train: epoch 0019, iter [00200, 00390], lr: 0.100000, loss: 3.6776
2023-07-02 01:00:01 - train: epoch 0006, iter [00100, 00390], lr: 0.100000, loss: 3.6562
2023-07-02 01:00:02 - train: epoch 0019, iter [00250, 00390], lr: 0.100000, loss: 3.8223
2023-07-02 01:00:03 - train: epoch 0006, iter [00150, 00390], lr: 0.100000, loss: 3.6437
2023-07-02 01:00:05 - train: epoch 0019, iter [00300, 00390], lr: 0.100000, loss: 3.7628
2023-07-02 01:00:05 - train: epoch 0006, iter [00200, 00390], lr: 0.100000, loss: 3.4622
2023-07-02 01:00:07 - train: epoch 0019, iter [00350, 00390], lr: 0.100000, loss: 3.6945
2023-07-02 01:00:08 - train: epoch 0006, iter [00250, 00390], lr: 0.100000, loss: 3.6822
2023-07-02 01:00:08 - train: epoch 019, train_loss: 3.6021
2023-07-02 01:00:10 - train: epoch 0006, iter [00300, 00390], lr: 0.100000, loss: 3.5821
2023-07-02 01:00:10 - eval: epoch: 019, acc1: 19.150%, acc5: 46.640%, test_loss: 3.3395, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:00:10 - until epoch: 019, best_acc1: 19.150%
2023-07-02 01:00:10 - epoch 020 lr: 0.100000
2023-07-02 01:00:11 - train: epoch 0006, iter [00350, 00390], lr: 0.100000, loss: 3.7032
2023-07-02 01:00:13 - train: epoch 0020, iter [00050, 00390], lr: 0.100000, loss: 3.7117
2023-07-02 01:00:13 - train: epoch 006, train_loss: 3.6802
2023-07-02 01:00:15 - eval: epoch: 006, acc1: 18.980%, acc5: 45.630%, test_loss: 3.3958, per_image_load_time: 0.066ms, per_image_inference_time: 0.059ms
2023-07-02 01:00:15 - train: epoch 0020, iter [00100, 00390], lr: 0.100000, loss: 3.5430
2023-07-02 01:00:15 - until epoch: 006, best_acc1: 18.980%
2023-07-02 01:00:15 - epoch 007 lr: 0.100000
2023-07-02 01:00:16 - train: epoch 0020, iter [00150, 00390], lr: 0.100000, loss: 3.9163
2023-07-02 01:00:18 - train: epoch 0007, iter [00050, 00390], lr: 0.100000, loss: 3.7664
2023-07-02 01:00:18 - train: epoch 0020, iter [00200, 00390], lr: 0.100000, loss: 3.9609
2023-07-02 01:00:20 - train: epoch 0007, iter [00100, 00390], lr: 0.100000, loss: 3.6586
2023-07-02 01:00:20 - train: epoch 0020, iter [00250, 00390], lr: 0.100000, loss: 3.4174
2023-07-02 01:00:22 - train: epoch 0020, iter [00300, 00390], lr: 0.100000, loss: 3.5358
2023-07-02 01:00:22 - train: epoch 0007, iter [00150, 00390], lr: 0.100000, loss: 3.5391
2023-07-02 01:00:24 - train: epoch 0020, iter [00350, 00390], lr: 0.100000, loss: 3.4741
2023-07-02 01:00:24 - train: epoch 0007, iter [00200, 00390], lr: 0.100000, loss: 3.5943
2023-07-02 01:00:26 - train: epoch 020, train_loss: 3.5940
2023-07-02 01:00:26 - train: epoch 0007, iter [00250, 00390], lr: 0.100000, loss: 3.5323
2023-07-02 01:00:28 - eval: epoch: 020, acc1: 19.950%, acc5: 46.410%, test_loss: 3.3272, per_image_load_time: 0.071ms, per_image_inference_time: 0.071ms
2023-07-02 01:00:28 - train: epoch 0007, iter [00300, 00390], lr: 0.100000, loss: 3.5767
2023-07-02 01:00:28 - until epoch: 020, best_acc1: 19.950%
2023-07-02 01:00:28 - epoch 021 lr: 0.100000
2023-07-02 01:00:30 - train: epoch 0007, iter [00350, 00390], lr: 0.100000, loss: 3.6747
2023-07-02 01:00:31 - train: epoch 0021, iter [00050, 00390], lr: 0.100000, loss: 3.5981
2023-07-02 01:00:32 - train: epoch 007, train_loss: 3.6390
2023-07-02 01:00:33 - eval: epoch: 007, acc1: 19.840%, acc5: 46.620%, test_loss: 3.3558, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:00:33 - train: epoch 0021, iter [00100, 00390], lr: 0.100000, loss: 3.3409
2023-07-02 01:00:33 - until epoch: 007, best_acc1: 19.840%
2023-07-02 01:00:33 - epoch 008 lr: 0.100000
2023-07-02 01:00:35 - train: epoch 0021, iter [00150, 00390], lr: 0.100000, loss: 3.6991
2023-07-02 01:00:36 - train: epoch 0008, iter [00050, 00390], lr: 0.100000, loss: 3.7839
2023-07-02 01:00:37 - train: epoch 0021, iter [00200, 00390], lr: 0.100000, loss: 3.6504
2023-07-02 01:00:39 - train: epoch 0008, iter [00100, 00390], lr: 0.100000, loss: 3.6352
2023-07-02 01:00:39 - train: epoch 0021, iter [00250, 00390], lr: 0.100000, loss: 3.9360
2023-07-02 01:00:41 - train: epoch 0008, iter [00150, 00390], lr: 0.100000, loss: 3.5843
2023-07-02 01:00:41 - train: epoch 0021, iter [00300, 00390], lr: 0.100000, loss: 3.5479
2023-07-02 01:00:43 - train: epoch 0008, iter [00200, 00390], lr: 0.100000, loss: 3.4952
2023-07-02 01:00:43 - train: epoch 0021, iter [00350, 00390], lr: 0.100000, loss: 3.2325
2023-07-02 01:00:45 - train: epoch 021, train_loss: 3.5805
2023-07-02 01:00:45 - train: epoch 0008, iter [00250, 00390], lr: 0.100000, loss: 3.5551
2023-07-02 01:00:46 - eval: epoch: 021, acc1: 20.140%, acc5: 46.810%, test_loss: 3.3253, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 01:00:46 - until epoch: 021, best_acc1: 20.140%
2023-07-02 01:00:46 - epoch 022 lr: 0.100000
2023-07-02 01:00:47 - train: epoch 0008, iter [00300, 00390], lr: 0.100000, loss: 3.5860
2023-07-02 01:00:49 - train: epoch 0008, iter [00350, 00390], lr: 0.100000, loss: 3.5601
2023-07-02 01:00:49 - train: epoch 0022, iter [00050, 00390], lr: 0.100000, loss: 3.5236
2023-07-02 01:00:50 - train: epoch 008, train_loss: 3.6061
2023-07-02 01:00:51 - train: epoch 0022, iter [00100, 00390], lr: 0.100000, loss: 3.7203
2023-07-02 01:00:52 - eval: epoch: 008, acc1: 20.160%, acc5: 47.220%, test_loss: 3.3301, per_image_load_time: 0.066ms, per_image_inference_time: 0.058ms
2023-07-02 01:00:52 - until epoch: 008, best_acc1: 20.160%
2023-07-02 01:00:52 - epoch 009 lr: 0.100000
2023-07-02 01:00:53 - train: epoch 0022, iter [00150, 00390], lr: 0.100000, loss: 3.8318
2023-07-02 01:00:55 - train: epoch 0022, iter [00200, 00390], lr: 0.100000, loss: 3.4501
2023-07-02 01:00:55 - train: epoch 0009, iter [00050, 00390], lr: 0.100000, loss: 3.4565
2023-07-02 01:00:57 - train: epoch 0022, iter [00250, 00390], lr: 0.100000, loss: 3.6646
2023-07-02 01:00:57 - train: epoch 0009, iter [00100, 00390], lr: 0.100000, loss: 3.6535
2023-07-02 01:00:59 - train: epoch 0022, iter [00300, 00390], lr: 0.100000, loss: 3.4786
2023-07-02 01:01:00 - train: epoch 0009, iter [00150, 00390], lr: 0.100000, loss: 3.4403
2023-07-02 01:01:01 - train: epoch 0022, iter [00350, 00390], lr: 0.100000, loss: 3.3970
2023-07-02 01:01:02 - train: epoch 0009, iter [00200, 00390], lr: 0.100000, loss: 3.6225
2023-07-02 01:01:02 - train: epoch 022, train_loss: 3.5715
2023-07-02 01:01:04 - train: epoch 0009, iter [00250, 00390], lr: 0.100000, loss: 3.5811
2023-07-02 01:01:04 - eval: epoch: 022, acc1: 20.140%, acc5: 47.270%, test_loss: 3.3120, per_image_load_time: 0.074ms, per_image_inference_time: 0.084ms
2023-07-02 01:01:04 - until epoch: 022, best_acc1: 20.140%
2023-07-02 01:01:04 - epoch 023 lr: 0.100000
2023-07-02 01:01:05 - train: epoch 0009, iter [00300, 00390], lr: 0.100000, loss: 3.6789
2023-07-02 01:01:07 - train: epoch 0023, iter [00050, 00390], lr: 0.100000, loss: 3.8401
2023-07-02 01:01:08 - train: epoch 0009, iter [00350, 00390], lr: 0.100000, loss: 3.7717
2023-07-02 01:01:09 - train: epoch 0023, iter [00100, 00390], lr: 0.100000, loss: 3.4615
2023-07-02 01:01:09 - train: epoch 009, train_loss: 3.5797
2023-07-02 01:01:11 - eval: epoch: 009, acc1: 20.940%, acc5: 48.320%, test_loss: 3.3010, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:01:11 - train: epoch 0023, iter [00150, 00390], lr: 0.100000, loss: 3.4732
2023-07-02 01:01:11 - until epoch: 009, best_acc1: 20.940%
2023-07-02 01:01:11 - epoch 010 lr: 0.100000
2023-07-02 01:01:13 - train: epoch 0023, iter [00200, 00390], lr: 0.100000, loss: 3.4231
2023-07-02 01:01:14 - train: epoch 0010, iter [00050, 00390], lr: 0.100000, loss: 3.6671
2023-07-02 01:01:15 - train: epoch 0023, iter [00250, 00390], lr: 0.100000, loss: 3.5224
2023-07-02 01:01:16 - train: epoch 0010, iter [00100, 00390], lr: 0.100000, loss: 3.6839
2023-07-02 01:01:17 - train: epoch 0023, iter [00300, 00390], lr: 0.100000, loss: 3.3979
2023-07-02 01:01:18 - train: epoch 0010, iter [00150, 00390], lr: 0.100000, loss: 3.4487
2023-07-02 01:01:19 - train: epoch 0023, iter [00350, 00390], lr: 0.100000, loss: 3.4409
2023-07-02 01:01:20 - train: epoch 023, train_loss: 3.5599
2023-07-02 01:01:21 - train: epoch 0010, iter [00200, 00390], lr: 0.100000, loss: 3.5604
2023-07-02 01:01:22 - eval: epoch: 023, acc1: 20.170%, acc5: 47.910%, test_loss: 3.2876, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:01:22 - train: epoch 0010, iter [00250, 00390], lr: 0.100000, loss: 3.5834
2023-07-02 01:01:23 - until epoch: 023, best_acc1: 20.170%
2023-07-02 01:01:23 - epoch 024 lr: 0.100000
2023-07-02 01:01:24 - train: epoch 0010, iter [00300, 00390], lr: 0.100000, loss: 3.4381
2023-07-02 01:01:25 - train: epoch 0024, iter [00050, 00390], lr: 0.100000, loss: 3.6383
2023-07-02 01:01:26 - train: epoch 0010, iter [00350, 00390], lr: 0.100000, loss: 3.4714
2023-07-02 01:01:27 - train: epoch 0024, iter [00100, 00390], lr: 0.100000, loss: 3.3442
2023-07-02 01:01:28 - train: epoch 010, train_loss: 3.5566
2023-07-02 01:01:29 - train: epoch 0024, iter [00150, 00390], lr: 0.100000, loss: 3.4004
2023-07-02 01:01:29 - eval: epoch: 010, acc1: 20.550%, acc5: 47.340%, test_loss: 3.3122, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:01:30 - until epoch: 010, best_acc1: 20.940%
2023-07-02 01:01:30 - epoch 011 lr: 0.100000
2023-07-02 01:01:31 - train: epoch 0024, iter [00200, 00390], lr: 0.100000, loss: 3.3736
2023-07-02 01:01:33 - train: epoch 0011, iter [00050, 00390], lr: 0.100000, loss: 3.5320
2023-07-02 01:01:33 - train: epoch 0024, iter [00250, 00390], lr: 0.100000, loss: 3.5770
2023-07-02 01:01:35 - train: epoch 0011, iter [00100, 00390], lr: 0.100000, loss: 3.3518
2023-07-02 01:01:35 - train: epoch 0024, iter [00300, 00390], lr: 0.100000, loss: 3.2795
2023-07-02 01:01:37 - train: epoch 0024, iter [00350, 00390], lr: 0.100000, loss: 3.5877
2023-07-02 01:01:37 - train: epoch 0011, iter [00150, 00390], lr: 0.100000, loss: 3.6130
2023-07-02 01:01:39 - train: epoch 024, train_loss: 3.5251
2023-07-02 01:01:39 - train: epoch 0011, iter [00200, 00390], lr: 0.100000, loss: 3.4894
2023-07-02 01:01:40 - eval: epoch: 024, acc1: 19.600%, acc5: 46.480%, test_loss: 3.3365, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:01:40 - until epoch: 024, best_acc1: 20.170%
2023-07-02 01:01:40 - epoch 025 lr: 0.100000
2023-07-02 01:01:41 - train: epoch 0011, iter [00250, 00390], lr: 0.100000, loss: 3.4748
2023-07-02 01:01:43 - train: epoch 0011, iter [00300, 00390], lr: 0.100000, loss: 3.4722
2023-07-02 01:01:43 - train: epoch 0025, iter [00050, 00390], lr: 0.100000, loss: 3.6070
2023-07-02 01:01:45 - train: epoch 0011, iter [00350, 00390], lr: 0.100000, loss: 3.4100
2023-07-02 01:01:45 - train: epoch 0025, iter [00100, 00390], lr: 0.100000, loss: 3.6232
2023-07-02 01:01:47 - train: epoch 011, train_loss: 3.5386
2023-07-02 01:01:47 - train: epoch 0025, iter [00150, 00390], lr: 0.100000, loss: 3.3814
2023-07-02 01:01:48 - eval: epoch: 011, acc1: 21.340%, acc5: 49.740%, test_loss: 3.2441, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:01:49 - until epoch: 011, best_acc1: 21.340%
2023-07-02 01:01:49 - epoch 012 lr: 0.100000
2023-07-02 01:01:49 - train: epoch 0025, iter [00200, 00390], lr: 0.100000, loss: 3.4321
2023-07-02 01:01:51 - train: epoch 0025, iter [00250, 00390], lr: 0.100000, loss: 3.4000
2023-07-02 01:01:52 - train: epoch 0012, iter [00050, 00390], lr: 0.100000, loss: 3.3898
2023-07-02 01:01:53 - train: epoch 0025, iter [00300, 00390], lr: 0.100000, loss: 3.4772
2023-07-02 01:01:54 - train: epoch 0012, iter [00100, 00390], lr: 0.100000, loss: 3.6868
2023-07-02 01:01:55 - train: epoch 0025, iter [00350, 00390], lr: 0.100000, loss: 3.8621
2023-07-02 01:01:56 - train: epoch 0012, iter [00150, 00390], lr: 0.100000, loss: 3.5863
2023-07-02 01:01:56 - train: epoch 025, train_loss: 3.5419
2023-07-02 01:01:58 - eval: epoch: 025, acc1: 19.870%, acc5: 47.720%, test_loss: 3.3024, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:01:58 - train: epoch 0012, iter [00200, 00390], lr: 0.100000, loss: 3.5814
2023-07-02 01:01:58 - until epoch: 025, best_acc1: 20.170%
2023-07-02 01:01:58 - epoch 026 lr: 0.100000
2023-07-02 01:02:00 - train: epoch 0012, iter [00250, 00390], lr: 0.100000, loss: 3.4486
2023-07-02 01:02:01 - train: epoch 0026, iter [00050, 00390], lr: 0.100000, loss: 3.2042
2023-07-02 01:02:02 - train: epoch 0012, iter [00300, 00390], lr: 0.100000, loss: 3.4918
2023-07-02 01:02:03 - train: epoch 0026, iter [00100, 00390], lr: 0.100000, loss: 3.6904
2023-07-02 01:02:04 - train: epoch 0012, iter [00350, 00390], lr: 0.100000, loss: 3.4834
2023-07-02 01:02:05 - train: epoch 0026, iter [00150, 00390], lr: 0.100000, loss: 3.5692
2023-07-02 01:02:06 - train: epoch 012, train_loss: 3.5162
2023-07-02 01:02:07 - train: epoch 0026, iter [00200, 00390], lr: 0.100000, loss: 3.6633
2023-07-02 01:02:07 - eval: epoch: 012, acc1: 22.090%, acc5: 50.390%, test_loss: 3.2240, per_image_load_time: 0.070ms, per_image_inference_time: 0.056ms
2023-07-02 01:02:08 - until epoch: 012, best_acc1: 22.090%
2023-07-02 01:02:08 - epoch 013 lr: 0.100000
2023-07-02 01:02:08 - train: epoch 0026, iter [00250, 00390], lr: 0.100000, loss: 3.5309
2023-07-02 01:02:10 - train: epoch 0026, iter [00300, 00390], lr: 0.100000, loss: 3.3328
2023-07-02 01:02:11 - train: epoch 0013, iter [00050, 00390], lr: 0.100000, loss: 3.4790
2023-07-02 01:02:12 - train: epoch 0026, iter [00350, 00390], lr: 0.100000, loss: 3.2706
2023-07-02 01:02:13 - train: epoch 0013, iter [00100, 00390], lr: 0.100000, loss: 3.5002
2023-07-02 01:02:14 - train: epoch 026, train_loss: 3.5026
2023-07-02 01:02:15 - train: epoch 0013, iter [00150, 00390], lr: 0.100000, loss: 3.4145
2023-07-02 01:02:16 - eval: epoch: 026, acc1: 21.840%, acc5: 49.900%, test_loss: 3.2252, per_image_load_time: 0.080ms, per_image_inference_time: 0.053ms
2023-07-02 01:02:16 - until epoch: 026, best_acc1: 21.840%
2023-07-02 01:02:16 - epoch 027 lr: 0.100000
2023-07-02 01:02:17 - train: epoch 0013, iter [00200, 00390], lr: 0.100000, loss: 3.3615
2023-07-02 01:02:19 - train: epoch 0027, iter [00050, 00390], lr: 0.100000, loss: 3.4360
2023-07-02 01:02:19 - train: epoch 0013, iter [00250, 00390], lr: 0.100000, loss: 3.5642
2023-07-02 01:02:21 - train: epoch 0027, iter [00100, 00390], lr: 0.100000, loss: 3.4871
2023-07-02 01:02:21 - train: epoch 0013, iter [00300, 00390], lr: 0.100000, loss: 3.5371
2023-07-02 01:02:23 - train: epoch 0027, iter [00150, 00390], lr: 0.100000, loss: 3.3753
2023-07-02 01:02:23 - train: epoch 0013, iter [00350, 00390], lr: 0.100000, loss: 3.3700
2023-07-02 01:02:25 - train: epoch 0027, iter [00200, 00390], lr: 0.100000, loss: 3.4340
2023-07-02 01:02:25 - train: epoch 013, train_loss: 3.4995
2023-07-02 01:02:26 - eval: epoch: 013, acc1: 22.990%, acc5: 51.290%, test_loss: 3.1841, per_image_load_time: 0.069ms, per_image_inference_time: 0.058ms
2023-07-02 01:02:26 - train: epoch 0027, iter [00250, 00390], lr: 0.100000, loss: 3.4644
2023-07-02 01:02:27 - until epoch: 013, best_acc1: 22.990%
2023-07-02 01:02:27 - epoch 014 lr: 0.100000
2023-07-02 01:02:28 - train: epoch 0027, iter [00300, 00390], lr: 0.100000, loss: 3.7166
2023-07-02 01:02:30 - train: epoch 0014, iter [00050, 00390], lr: 0.100000, loss: 3.5148
2023-07-02 01:02:30 - train: epoch 0027, iter [00350, 00390], lr: 0.100000, loss: 3.3863
2023-07-02 01:02:32 - train: epoch 027, train_loss: 3.5299
2023-07-02 01:02:32 - train: epoch 0014, iter [00100, 00390], lr: 0.100000, loss: 3.4015
2023-07-02 01:02:33 - eval: epoch: 027, acc1: 20.810%, acc5: 48.460%, test_loss: 3.2899, per_image_load_time: 0.080ms, per_image_inference_time: 0.054ms
2023-07-02 01:02:34 - until epoch: 027, best_acc1: 21.840%
2023-07-02 01:02:34 - epoch 028 lr: 0.100000
2023-07-02 01:02:34 - train: epoch 0014, iter [00150, 00390], lr: 0.100000, loss: 3.4618
2023-07-02 01:02:36 - train: epoch 0014, iter [00200, 00390], lr: 0.100000, loss: 3.5700
2023-07-02 01:02:37 - train: epoch 0028, iter [00050, 00390], lr: 0.100000, loss: 3.3451
2023-07-02 01:02:38 - train: epoch 0014, iter [00250, 00390], lr: 0.100000, loss: 3.4881
2023-07-02 01:02:39 - train: epoch 0028, iter [00100, 00390], lr: 0.100000, loss: 3.2523
2023-07-02 01:02:40 - train: epoch 0014, iter [00300, 00390], lr: 0.100000, loss: 3.5404
2023-07-02 01:02:41 - train: epoch 0028, iter [00150, 00390], lr: 0.100000, loss: 3.1813
2023-07-02 01:02:42 - train: epoch 0014, iter [00350, 00390], lr: 0.100000, loss: 3.4876
2023-07-02 01:02:43 - train: epoch 0028, iter [00200, 00390], lr: 0.100000, loss: 3.5614
2023-07-02 01:02:44 - train: epoch 014, train_loss: 3.4820
2023-07-02 01:02:44 - train: epoch 0028, iter [00250, 00390], lr: 0.100000, loss: 3.6592
2023-07-02 01:02:46 - eval: epoch: 014, acc1: 23.650%, acc5: 51.820%, test_loss: 3.1745, per_image_load_time: 0.071ms, per_image_inference_time: 0.058ms
2023-07-02 01:02:46 - train: epoch 0028, iter [00300, 00390], lr: 0.100000, loss: 3.4152
2023-07-02 01:02:46 - until epoch: 014, best_acc1: 23.650%
2023-07-02 01:02:46 - epoch 015 lr: 0.100000
2023-07-02 01:02:48 - train: epoch 0028, iter [00350, 00390], lr: 0.100000, loss: 4.0224
2023-07-02 01:02:49 - train: epoch 0015, iter [00050, 00390], lr: 0.100000, loss: 3.3129
2023-07-02 01:02:49 - train: epoch 028, train_loss: 3.5132
2023-07-02 01:02:51 - eval: epoch: 028, acc1: 21.250%, acc5: 48.940%, test_loss: 3.2607, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:02:51 - train: epoch 0015, iter [00100, 00390], lr: 0.100000, loss: 3.5625
2023-07-02 01:02:51 - until epoch: 028, best_acc1: 21.840%
2023-07-02 01:02:51 - epoch 029 lr: 0.100000
2023-07-02 01:02:53 - train: epoch 0015, iter [00150, 00390], lr: 0.100000, loss: 3.6563
2023-07-02 01:02:54 - train: epoch 0029, iter [00050, 00390], lr: 0.100000, loss: 3.3374
2023-07-02 01:02:55 - train: epoch 0015, iter [00200, 00390], lr: 0.100000, loss: 3.4494
2023-07-02 01:02:56 - train: epoch 0029, iter [00100, 00390], lr: 0.100000, loss: 4.0414
2023-07-02 01:02:57 - train: epoch 0015, iter [00250, 00390], lr: 0.100000, loss: 3.4314
2023-07-02 01:02:58 - train: epoch 0029, iter [00150, 00390], lr: 0.100000, loss: 4.0077
2023-07-02 01:03:00 - train: epoch 0015, iter [00300, 00390], lr: 0.100000, loss: 3.2765
2023-07-02 01:03:00 - train: epoch 0029, iter [00200, 00390], lr: 0.100000, loss: 3.2787
2023-07-02 01:03:02 - train: epoch 0015, iter [00350, 00390], lr: 0.100000, loss: 3.4086
2023-07-02 01:03:02 - train: epoch 0029, iter [00250, 00390], lr: 0.100000, loss: 3.1745
2023-07-02 01:03:03 - train: epoch 015, train_loss: 3.4774
2023-07-02 01:03:04 - train: epoch 0029, iter [00300, 00390], lr: 0.100000, loss: 3.7677
2023-07-02 01:03:05 - eval: epoch: 015, acc1: 22.610%, acc5: 50.840%, test_loss: 3.1897, per_image_load_time: 0.068ms, per_image_inference_time: 0.058ms
2023-07-02 01:03:05 - until epoch: 015, best_acc1: 23.650%
2023-07-02 01:03:05 - epoch 016 lr: 0.100000
2023-07-02 01:03:06 - train: epoch 0029, iter [00350, 00390], lr: 0.100000, loss: 3.3402
2023-07-02 01:03:07 - train: epoch 029, train_loss: 3.5138
2023-07-02 01:03:08 - train: epoch 0016, iter [00050, 00390], lr: 0.100000, loss: 3.5695
2023-07-02 01:03:09 - eval: epoch: 029, acc1: 21.260%, acc5: 49.090%, test_loss: 3.2460, per_image_load_time: 0.089ms, per_image_inference_time: 0.053ms
2023-07-02 01:03:09 - until epoch: 029, best_acc1: 21.840%
2023-07-02 01:03:09 - epoch 030 lr: 0.100000
2023-07-02 01:03:10 - train: epoch 0016, iter [00100, 00390], lr: 0.100000, loss: 3.2681
2023-07-02 01:03:12 - train: epoch 0016, iter [00150, 00390], lr: 0.100000, loss: 3.6261
2023-07-02 01:03:12 - train: epoch 0030, iter [00050, 00390], lr: 0.100000, loss: 3.8852
2023-07-02 01:03:14 - train: epoch 0016, iter [00200, 00390], lr: 0.100000, loss: 3.5797
2023-07-02 01:03:14 - train: epoch 0030, iter [00100, 00390], lr: 0.100000, loss: 3.7853
2023-07-02 01:03:16 - train: epoch 0016, iter [00250, 00390], lr: 0.100000, loss: 3.4062
2023-07-02 01:03:16 - train: epoch 0030, iter [00150, 00390], lr: 0.100000, loss: 3.3374
2023-07-02 01:03:18 - train: epoch 0030, iter [00200, 00390], lr: 0.100000, loss: 3.7352
2023-07-02 01:03:18 - train: epoch 0016, iter [00300, 00390], lr: 0.100000, loss: 3.4689
2023-07-02 01:03:20 - train: epoch 0030, iter [00250, 00390], lr: 0.100000, loss: 3.5169
2023-07-02 01:03:20 - train: epoch 0016, iter [00350, 00390], lr: 0.100000, loss: 3.2780
2023-07-02 01:03:22 - train: epoch 0030, iter [00300, 00390], lr: 0.100000, loss: 3.3624
2023-07-02 01:03:22 - train: epoch 016, train_loss: 3.4634
2023-07-02 01:03:24 - eval: epoch: 016, acc1: 23.140%, acc5: 51.650%, test_loss: 3.1630, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:03:24 - until epoch: 016, best_acc1: 23.650%
2023-07-02 01:03:24 - epoch 017 lr: 0.100000
2023-07-02 01:03:24 - train: epoch 0030, iter [00350, 00390], lr: 0.100000, loss: 3.2043
2023-07-02 01:03:25 - train: epoch 030, train_loss: 3.5072
2023-07-02 01:03:27 - train: epoch 0017, iter [00050, 00390], lr: 0.100000, loss: 3.5901
2023-07-02 01:03:27 - eval: epoch: 030, acc1: 21.630%, acc5: 49.700%, test_loss: 3.2325, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 01:03:27 - until epoch: 030, best_acc1: 21.840%
2023-07-02 01:03:27 - epoch 031 lr: 0.100000
2023-07-02 01:03:28 - train: epoch 0017, iter [00100, 00390], lr: 0.100000, loss: 3.4230
2023-07-02 01:03:30 - train: epoch 0031, iter [00050, 00390], lr: 0.100000, loss: 3.5472
2023-07-02 01:03:31 - train: epoch 0017, iter [00150, 00390], lr: 0.100000, loss: 3.1622
2023-07-02 01:03:32 - train: epoch 0031, iter [00100, 00390], lr: 0.100000, loss: 3.6828
2023-07-02 01:03:33 - train: epoch 0017, iter [00200, 00390], lr: 0.100000, loss: 3.3802
2023-07-02 01:03:34 - train: epoch 0031, iter [00150, 00390], lr: 0.100000, loss: 3.4550
2023-07-02 01:03:35 - train: epoch 0017, iter [00250, 00390], lr: 0.100000, loss: 3.3318
2023-07-02 01:03:36 - train: epoch 0031, iter [00200, 00390], lr: 0.100000, loss: 3.5020
2023-07-02 01:03:37 - train: epoch 0017, iter [00300, 00390], lr: 0.100000, loss: 3.6896
2023-07-02 01:03:38 - train: epoch 0031, iter [00250, 00390], lr: 0.100000, loss: 3.5801
2023-07-02 01:03:39 - train: epoch 0017, iter [00350, 00390], lr: 0.100000, loss: 3.2096
2023-07-02 01:03:40 - train: epoch 0031, iter [00300, 00390], lr: 0.100000, loss: 3.7069
2023-07-02 01:03:41 - train: epoch 017, train_loss: 3.4489
2023-07-02 01:03:42 - train: epoch 0031, iter [00350, 00390], lr: 0.100000, loss: 3.8228
2023-07-02 01:03:42 - eval: epoch: 017, acc1: 23.290%, acc5: 50.840%, test_loss: 3.1945, per_image_load_time: 0.066ms, per_image_inference_time: 0.057ms
2023-07-02 01:03:43 - until epoch: 017, best_acc1: 23.650%
2023-07-02 01:03:43 - epoch 018 lr: 0.100000
2023-07-02 01:03:43 - train: epoch 031, train_loss: 3.4979
2023-07-02 01:03:45 - eval: epoch: 031, acc1: 21.170%, acc5: 49.170%, test_loss: 3.2405, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-07-02 01:03:45 - train: epoch 0018, iter [00050, 00390], lr: 0.100000, loss: 3.4039
2023-07-02 01:03:45 - until epoch: 031, best_acc1: 21.840%
2023-07-02 01:03:45 - epoch 032 lr: 0.100000
2023-07-02 01:03:47 - train: epoch 0018, iter [00100, 00390], lr: 0.100000, loss: 3.6232
2023-07-02 01:03:48 - train: epoch 0032, iter [00050, 00390], lr: 0.100000, loss: 3.6475
2023-07-02 01:03:49 - train: epoch 0018, iter [00150, 00390], lr: 0.100000, loss: 3.4914
2023-07-02 01:03:50 - train: epoch 0032, iter [00100, 00390], lr: 0.100000, loss: 3.6747
2023-07-02 01:03:51 - train: epoch 0018, iter [00200, 00390], lr: 0.100000, loss: 3.5185
2023-07-02 01:03:52 - train: epoch 0032, iter [00150, 00390], lr: 0.100000, loss: 3.9834
2023-07-02 01:03:53 - train: epoch 0018, iter [00250, 00390], lr: 0.100000, loss: 3.4724
2023-07-02 01:03:54 - train: epoch 0032, iter [00200, 00390], lr: 0.100000, loss: 3.5222
2023-07-02 01:03:55 - train: epoch 0018, iter [00300, 00390], lr: 0.100000, loss: 3.4106
2023-07-02 01:03:56 - train: epoch 0032, iter [00250, 00390], lr: 0.100000, loss: 3.4452
2023-07-02 01:03:58 - train: epoch 0018, iter [00350, 00390], lr: 0.100000, loss: 3.4831
2023-07-02 01:03:58 - train: epoch 0032, iter [00300, 00390], lr: 0.100000, loss: 3.3076
2023-07-02 01:03:59 - train: epoch 018, train_loss: 3.4351
2023-07-02 01:04:00 - train: epoch 0032, iter [00350, 00390], lr: 0.100000, loss: 3.3986
2023-07-02 01:04:01 - eval: epoch: 018, acc1: 24.210%, acc5: 52.000%, test_loss: 3.1400, per_image_load_time: 0.068ms, per_image_inference_time: 0.057ms
2023-07-02 01:04:01 - until epoch: 018, best_acc1: 24.210%
2023-07-02 01:04:01 - epoch 019 lr: 0.100000
2023-07-02 01:04:01 - train: epoch 032, train_loss: 3.4793
2023-07-02 01:04:03 - eval: epoch: 032, acc1: 22.000%, acc5: 49.480%, test_loss: 3.2224, per_image_load_time: 0.076ms, per_image_inference_time: 0.054ms
2023-07-02 01:04:03 - until epoch: 032, best_acc1: 22.000%
2023-07-02 01:04:03 - epoch 033 lr: 0.100000
2023-07-02 01:04:04 - train: epoch 0019, iter [00050, 00390], lr: 0.100000, loss: 3.2557
2023-07-02 01:04:06 - train: epoch 0019, iter [00100, 00390], lr: 0.100000, loss: 3.4345
2023-07-02 01:04:06 - train: epoch 0033, iter [00050, 00390], lr: 0.100000, loss: 3.3155
2023-07-02 01:04:08 - train: epoch 0019, iter [00150, 00390], lr: 0.100000, loss: 3.5317
2023-07-02 01:04:08 - train: epoch 0033, iter [00100, 00390], lr: 0.100000, loss: 3.2242
2023-07-02 01:04:10 - train: epoch 0019, iter [00200, 00390], lr: 0.100000, loss: 3.4710
2023-07-02 01:04:10 - train: epoch 0033, iter [00150, 00390], lr: 0.100000, loss: 3.4229
2023-07-02 01:04:12 - train: epoch 0019, iter [00250, 00390], lr: 0.100000, loss: 3.5791
2023-07-02 01:04:12 - train: epoch 0033, iter [00200, 00390], lr: 0.100000, loss: 3.8063
2023-07-02 01:04:14 - train: epoch 0033, iter [00250, 00390], lr: 0.100000, loss: 3.4609
2023-07-02 01:04:14 - train: epoch 0019, iter [00300, 00390], lr: 0.100000, loss: 3.5829
2023-07-02 01:04:16 - train: epoch 0033, iter [00300, 00390], lr: 0.100000, loss: 3.6817
2023-07-02 01:04:16 - train: epoch 0019, iter [00350, 00390], lr: 0.100000, loss: 3.3342
2023-07-02 01:04:18 - train: epoch 019, train_loss: 3.4189
2023-07-02 01:04:18 - train: epoch 0033, iter [00350, 00390], lr: 0.100000, loss: 3.3668
2023-07-02 01:04:19 - eval: epoch: 019, acc1: 23.540%, acc5: 52.520%, test_loss: 3.1407, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:04:20 - train: epoch 033, train_loss: 3.4871
2023-07-02 01:04:20 - until epoch: 019, best_acc1: 24.210%
2023-07-02 01:04:20 - epoch 020 lr: 0.100000
2023-07-02 01:04:21 - eval: epoch: 033, acc1: 21.780%, acc5: 50.150%, test_loss: 3.1932, per_image_load_time: 0.072ms, per_image_inference_time: 0.060ms
2023-07-02 01:04:21 - until epoch: 033, best_acc1: 22.000%
2023-07-02 01:04:21 - epoch 034 lr: 0.100000
2023-07-02 01:04:22 - train: epoch 0020, iter [00050, 00390], lr: 0.100000, loss: 3.5039
2023-07-02 01:04:24 - train: epoch 0034, iter [00050, 00390], lr: 0.100000, loss: 3.7208
2023-07-02 01:04:24 - train: epoch 0020, iter [00100, 00390], lr: 0.100000, loss: 3.4966
2023-07-02 01:04:26 - train: epoch 0034, iter [00100, 00390], lr: 0.100000, loss: 3.5435
2023-07-02 01:04:26 - train: epoch 0020, iter [00150, 00390], lr: 0.100000, loss: 3.4972
2023-07-02 01:04:28 - train: epoch 0034, iter [00150, 00390], lr: 0.100000, loss: 3.1892
2023-07-02 01:04:28 - train: epoch 0020, iter [00200, 00390], lr: 0.100000, loss: 3.4248
2023-07-02 01:04:30 - train: epoch 0034, iter [00200, 00390], lr: 0.100000, loss: 3.6817
2023-07-02 01:04:31 - train: epoch 0020, iter [00250, 00390], lr: 0.100000, loss: 3.3521
2023-07-02 01:04:32 - train: epoch 0034, iter [00250, 00390], lr: 0.100000, loss: 3.3129
2023-07-02 01:04:33 - train: epoch 0020, iter [00300, 00390], lr: 0.100000, loss: 3.4163
2023-07-02 01:04:35 - train: epoch 0020, iter [00350, 00390], lr: 0.100000, loss: 3.4105
2023-07-02 01:04:35 - train: epoch 0034, iter [00300, 00390], lr: 0.100000, loss: 3.4498
2023-07-02 01:04:36 - train: epoch 020, train_loss: 3.4152
2023-07-02 01:04:37 - train: epoch 0034, iter [00350, 00390], lr: 0.100000, loss: 3.8786
2023-07-02 01:04:38 - eval: epoch: 020, acc1: 24.270%, acc5: 53.190%, test_loss: 3.1087, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:04:38 - train: epoch 034, train_loss: 3.4869
2023-07-02 01:04:38 - until epoch: 020, best_acc1: 24.270%
2023-07-02 01:04:38 - epoch 021 lr: 0.100000
2023-07-02 01:04:39 - eval: epoch: 034, acc1: 22.300%, acc5: 50.050%, test_loss: 3.2065, per_image_load_time: 0.072ms, per_image_inference_time: 0.062ms
2023-07-02 01:04:41 - until epoch: 034, best_acc1: 22.300%
2023-07-02 01:04:41 - epoch 035 lr: 0.100000
2023-07-02 01:04:41 - train: epoch 0021, iter [00050, 00390], lr: 0.100000, loss: 3.3381
2023-07-02 01:04:43 - train: epoch 0021, iter [00100, 00390], lr: 0.100000, loss: 3.4009
2023-07-02 01:04:43 - train: epoch 0035, iter [00050, 00390], lr: 0.100000, loss: 3.3363
2023-07-02 01:04:45 - train: epoch 0021, iter [00150, 00390], lr: 0.100000, loss: 3.5584
2023-07-02 01:04:45 - train: epoch 0035, iter [00100, 00390], lr: 0.100000, loss: 3.3055
2023-07-02 01:04:47 - train: epoch 0021, iter [00200, 00390], lr: 0.100000, loss: 3.6391
2023-07-02 01:04:47 - train: epoch 0035, iter [00150, 00390], lr: 0.100000, loss: 3.3525
2023-07-02 01:04:49 - train: epoch 0021, iter [00250, 00390], lr: 0.100000, loss: 3.5440
2023-07-02 01:04:50 - train: epoch 0035, iter [00200, 00390], lr: 0.100000, loss: 3.2304
2023-07-02 01:04:52 - train: epoch 0035, iter [00250, 00390], lr: 0.100000, loss: 3.7571
2023-07-02 01:04:52 - train: epoch 0021, iter [00300, 00390], lr: 0.100000, loss: 3.5004
2023-07-02 01:04:54 - train: epoch 0035, iter [00300, 00390], lr: 0.100000, loss: 3.3674
2023-07-02 01:04:54 - train: epoch 0021, iter [00350, 00390], lr: 0.100000, loss: 3.2146
2023-07-02 01:04:55 - train: epoch 021, train_loss: 3.3999
2023-07-02 01:04:56 - train: epoch 0035, iter [00350, 00390], lr: 0.100000, loss: 3.8587
2023-07-02 01:04:57 - train: epoch 035, train_loss: 3.4730
2023-07-02 01:04:57 - eval: epoch: 021, acc1: 24.890%, acc5: 53.620%, test_loss: 3.0958, per_image_load_time: 0.069ms, per_image_inference_time: 0.057ms
2023-07-02 01:04:58 - until epoch: 021, best_acc1: 24.890%
2023-07-02 01:04:58 - epoch 022 lr: 0.100000
2023-07-02 01:04:58 - eval: epoch: 035, acc1: 21.130%, acc5: 49.760%, test_loss: 3.2315, per_image_load_time: 0.068ms, per_image_inference_time: 0.055ms
2023-07-02 01:04:59 - until epoch: 035, best_acc1: 22.300%
2023-07-02 01:04:59 - epoch 036 lr: 0.100000
2023-07-02 01:05:00 - train: epoch 0022, iter [00050, 00390], lr: 0.100000, loss: 3.5380
2023-07-02 01:05:02 - train: epoch 0022, iter [00100, 00390], lr: 0.100000, loss: 3.3224
2023-07-02 01:05:02 - train: epoch 0036, iter [00050, 00390], lr: 0.100000, loss: 3.4176
2023-07-02 01:05:04 - train: epoch 0022, iter [00150, 00390], lr: 0.100000, loss: 3.4505
2023-07-02 01:05:04 - train: epoch 0036, iter [00100, 00390], lr: 0.100000, loss: 3.1359
2023-07-02 01:05:06 - train: epoch 0036, iter [00150, 00390], lr: 0.100000, loss: 4.0465
2023-07-02 01:05:06 - train: epoch 0022, iter [00200, 00390], lr: 0.100000, loss: 3.4301
2023-07-02 01:05:08 - train: epoch 0036, iter [00200, 00390], lr: 0.100000, loss: 3.8490
2023-07-02 01:05:08 - train: epoch 0022, iter [00250, 00390], lr: 0.100000, loss: 3.5122
2023-07-02 01:05:10 - train: epoch 0036, iter [00250, 00390], lr: 0.100000, loss: 3.2331
2023-07-02 01:05:10 - train: epoch 0022, iter [00300, 00390], lr: 0.100000, loss: 3.4997
2023-07-02 01:05:12 - train: epoch 0036, iter [00300, 00390], lr: 0.100000, loss: 3.3126
2023-07-02 01:05:13 - train: epoch 0022, iter [00350, 00390], lr: 0.100000, loss: 3.4064
2023-07-02 01:05:14 - train: epoch 022, train_loss: 3.4009
2023-07-02 01:05:14 - train: epoch 0036, iter [00350, 00390], lr: 0.100000, loss: 3.3246
2023-07-02 01:05:16 - train: epoch 036, train_loss: 3.4812
2023-07-02 01:05:16 - eval: epoch: 022, acc1: 25.110%, acc5: 53.360%, test_loss: 3.0879, per_image_load_time: 0.069ms, per_image_inference_time: 0.060ms
2023-07-02 01:05:16 - until epoch: 022, best_acc1: 25.110%
2023-07-02 01:05:16 - epoch 023 lr: 0.100000
2023-07-02 01:05:17 - eval: epoch: 036, acc1: 20.840%, acc5: 48.840%, test_loss: 3.2436, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:05:18 - until epoch: 036, best_acc1: 22.300%
2023-07-02 01:05:18 - epoch 037 lr: 0.100000
2023-07-02 01:05:19 - train: epoch 0023, iter [00050, 00390], lr: 0.100000, loss: 3.4437
2023-07-02 01:05:20 - train: epoch 0037, iter [00050, 00390], lr: 0.100000, loss: 3.6772
2023-07-02 01:05:21 - train: epoch 0023, iter [00100, 00390], lr: 0.100000, loss: 3.4290
2023-07-02 01:05:22 - train: epoch 0037, iter [00100, 00390], lr: 0.100000, loss: 3.0059
2023-07-02 01:05:23 - train: epoch 0023, iter [00150, 00390], lr: 0.100000, loss: 3.4311
2023-07-02 01:05:24 - train: epoch 0037, iter [00150, 00390], lr: 0.100000, loss: 3.5390
2023-07-02 01:05:25 - train: epoch 0023, iter [00200, 00390], lr: 0.100000, loss: 3.4102
2023-07-02 01:05:27 - train: epoch 0037, iter [00200, 00390], lr: 0.100000, loss: 3.4394
2023-07-02 01:05:27 - train: epoch 0023, iter [00250, 00390], lr: 0.100000, loss: 3.3863
2023-07-02 01:05:29 - train: epoch 0037, iter [00250, 00390], lr: 0.100000, loss: 3.1830
2023-07-02 01:05:29 - train: epoch 0023, iter [00300, 00390], lr: 0.100000, loss: 3.3267
2023-07-02 01:05:31 - train: epoch 0037, iter [00300, 00390], lr: 0.100000, loss: 3.0818
2023-07-02 01:05:32 - train: epoch 0023, iter [00350, 00390], lr: 0.100000, loss: 3.3754
2023-07-02 01:05:33 - train: epoch 0037, iter [00350, 00390], lr: 0.100000, loss: 3.8710
2023-07-02 01:05:33 - train: epoch 023, train_loss: 3.3847
2023-07-02 01:05:34 - train: epoch 037, train_loss: 3.4767
2023-07-02 01:05:35 - eval: epoch: 023, acc1: 24.770%, acc5: 52.900%, test_loss: 3.1136, per_image_load_time: 0.066ms, per_image_inference_time: 0.060ms
2023-07-02 01:05:35 - until epoch: 023, best_acc1: 25.110%
2023-07-02 01:05:35 - epoch 024 lr: 0.100000
2023-07-02 01:05:35 - eval: epoch: 037, acc1: 22.090%, acc5: 50.010%, test_loss: 3.2089, per_image_load_time: 0.071ms, per_image_inference_time: 0.056ms
2023-07-02 01:05:36 - until epoch: 037, best_acc1: 22.300%
2023-07-02 01:05:36 - epoch 038 lr: 0.100000
2023-07-02 01:05:38 - train: epoch 0024, iter [00050, 00390], lr: 0.100000, loss: 3.2021
2023-07-02 01:05:39 - train: epoch 0038, iter [00050, 00390], lr: 0.100000, loss: 3.2822
2023-07-02 01:05:40 - train: epoch 0024, iter [00100, 00390], lr: 0.100000, loss: 3.3390
2023-07-02 01:05:41 - train: epoch 0038, iter [00100, 00390], lr: 0.100000, loss: 3.3786
2023-07-02 01:05:42 - train: epoch 0024, iter [00150, 00390], lr: 0.100000, loss: 3.1107
2023-07-02 01:05:43 - train: epoch 0038, iter [00150, 00390], lr: 0.100000, loss: 3.7320
2023-07-02 01:05:44 - train: epoch 0024, iter [00200, 00390], lr: 0.100000, loss: 3.6385
2023-07-02 01:05:45 - train: epoch 0038, iter [00200, 00390], lr: 0.100000, loss: 3.0925
2023-07-02 01:05:46 - train: epoch 0024, iter [00250, 00390], lr: 0.100000, loss: 3.3887
2023-07-02 01:05:47 - train: epoch 0038, iter [00250, 00390], lr: 0.100000, loss: 3.2652
2023-07-02 01:05:48 - train: epoch 0024, iter [00300, 00390], lr: 0.100000, loss: 3.2839
2023-07-02 01:05:49 - train: epoch 0038, iter [00300, 00390], lr: 0.100000, loss: 3.4400
2023-07-02 01:05:50 - train: epoch 0024, iter [00350, 00390], lr: 0.100000, loss: 3.4230
2023-07-02 01:05:51 - train: epoch 0038, iter [00350, 00390], lr: 0.100000, loss: 3.5497
2023-07-02 01:05:52 - train: epoch 024, train_loss: 3.3712
2023-07-02 01:05:52 - train: epoch 038, train_loss: 3.4525
2023-07-02 01:05:53 - eval: epoch: 024, acc1: 24.600%, acc5: 53.990%, test_loss: 3.0681, per_image_load_time: 0.067ms, per_image_inference_time: 0.058ms
2023-07-02 01:05:54 - until epoch: 024, best_acc1: 25.110%
2023-07-02 01:05:54 - epoch 025 lr: 0.100000
2023-07-02 01:05:54 - eval: epoch: 038, acc1: 22.650%, acc5: 50.300%, test_loss: 3.1841, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 01:05:54 - until epoch: 038, best_acc1: 22.650%
2023-07-02 01:05:54 - epoch 039 lr: 0.100000
2023-07-02 01:05:56 - train: epoch 0025, iter [00050, 00390], lr: 0.100000, loss: 3.3659
2023-07-02 01:05:57 - train: epoch 0039, iter [00050, 00390], lr: 0.100000, loss: 3.5402
2023-07-02 01:05:58 - train: epoch 0025, iter [00100, 00390], lr: 0.100000, loss: 3.1448
2023-07-02 01:05:59 - train: epoch 0039, iter [00100, 00390], lr: 0.100000, loss: 3.3311
2023-07-02 01:06:01 - train: epoch 0025, iter [00150, 00390], lr: 0.100000, loss: 3.3480
2023-07-02 01:06:01 - train: epoch 0039, iter [00150, 00390], lr: 0.100000, loss: 3.2282
2023-07-02 01:06:03 - train: epoch 0025, iter [00200, 00390], lr: 0.100000, loss: 3.4173
2023-07-02 01:06:03 - train: epoch 0039, iter [00200, 00390], lr: 0.100000, loss: 4.1255
2023-07-02 01:06:05 - train: epoch 0025, iter [00250, 00390], lr: 0.100000, loss: 3.4603
2023-07-02 01:06:05 - train: epoch 0039, iter [00250, 00390], lr: 0.100000, loss: 3.3143
2023-07-02 01:06:07 - train: epoch 0025, iter [00300, 00390], lr: 0.100000, loss: 3.3988
2023-07-02 01:06:07 - train: epoch 0039, iter [00300, 00390], lr: 0.100000, loss: 3.1213
2023-07-02 01:06:09 - train: epoch 0025, iter [00350, 00390], lr: 0.100000, loss: 3.3929
2023-07-02 01:06:09 - train: epoch 0039, iter [00350, 00390], lr: 0.100000, loss: 3.2053
2023-07-02 01:06:11 - train: epoch 025, train_loss: 3.3608
2023-07-02 01:06:11 - train: epoch 039, train_loss: 3.4479
2023-07-02 01:06:12 - eval: epoch: 025, acc1: 25.000%, acc5: 53.270%, test_loss: 3.0888, per_image_load_time: 0.066ms, per_image_inference_time: 0.058ms
2023-07-02 01:06:12 - until epoch: 025, best_acc1: 25.110%
2023-07-02 01:06:12 - epoch 026 lr: 0.100000
2023-07-02 01:06:12 - eval: epoch: 039, acc1: 21.840%, acc5: 50.680%, test_loss: 3.1956, per_image_load_time: 0.070ms, per_image_inference_time: 0.055ms
2023-07-02 01:06:13 - until epoch: 039, best_acc1: 22.650%
2023-07-02 01:06:13 - epoch 040 lr: 0.100000
2023-07-02 01:06:15 - train: epoch 0026, iter [00050, 00390], lr: 0.100000, loss: 3.2166
2023-07-02 01:06:16 - train: epoch 0040, iter [00050, 00390], lr: 0.100000, loss: 3.1071
2023-07-02 01:06:18 - train: epoch 0026, iter [00100, 00390], lr: 0.100000, loss: 3.4820
2023-07-02 01:06:18 - train: epoch 0040, iter [00100, 00390], lr: 0.100000, loss: 3.2199
2023-07-02 01:06:20 - train: epoch 0040, iter [00150, 00390], lr: 0.100000, loss: 3.5514
2023-07-02 01:06:20 - train: epoch 0026, iter [00150, 00390], lr: 0.100000, loss: 3.4293
2023-07-02 01:06:22 - train: epoch 0040, iter [00200, 00390], lr: 0.100000, loss: 3.5414
2023-07-02 01:06:22 - train: epoch 0026, iter [00200, 00390], lr: 0.100000, loss: 3.5015
2023-07-02 01:06:24 - train: epoch 0040, iter [00250, 00390], lr: 0.100000, loss: 3.4599
2023-07-02 01:06:24 - train: epoch 0026, iter [00250, 00390], lr: 0.100000, loss: 3.3627
2023-07-02 01:06:26 - train: epoch 0040, iter [00300, 00390], lr: 0.100000, loss: 3.3272
2023-07-02 01:06:26 - train: epoch 0026, iter [00300, 00390], lr: 0.100000, loss: 3.3649
2023-07-02 01:06:28 - train: epoch 0040, iter [00350, 00390], lr: 0.100000, loss: 3.2630
2023-07-02 01:06:28 - train: epoch 0026, iter [00350, 00390], lr: 0.100000, loss: 3.4288
2023-07-02 01:06:30 - train: epoch 040, train_loss: 3.4369
2023-07-02 01:06:30 - train: epoch 026, train_loss: 3.3583
2023-07-02 01:06:31 - eval: epoch: 040, acc1: 22.770%, acc5: 50.860%, test_loss: 3.1682, per_image_load_time: 0.070ms, per_image_inference_time: 0.056ms
2023-07-02 01:06:31 - eval: epoch: 026, acc1: 25.060%, acc5: 54.040%, test_loss: 3.0717, per_image_load_time: 0.068ms, per_image_inference_time: 0.058ms
2023-07-02 01:06:31 - until epoch: 026, best_acc1: 25.110%
2023-07-02 01:06:31 - epoch 027 lr: 0.100000
2023-07-02 01:06:32 - until epoch: 040, best_acc1: 22.770%
2023-07-02 01:06:32 - epoch 041 lr: 0.100000
2023-07-02 01:06:34 - train: epoch 0027, iter [00050, 00390], lr: 0.100000, loss: 3.3728
2023-07-02 01:06:35 - train: epoch 0041, iter [00050, 00390], lr: 0.100000, loss: 3.0564
2023-07-02 01:06:36 - train: epoch 0027, iter [00100, 00390], lr: 0.100000, loss: 3.4028
2023-07-02 01:06:37 - train: epoch 0041, iter [00100, 00390], lr: 0.100000, loss: 3.3142
2023-07-02 01:06:39 - train: epoch 0027, iter [00150, 00390], lr: 0.100000, loss: 3.3858
2023-07-02 01:06:39 - train: epoch 0041, iter [00150, 00390], lr: 0.100000, loss: 3.5694
2023-07-02 01:06:41 - train: epoch 0027, iter [00200, 00390], lr: 0.100000, loss: 3.5162
2023-07-02 01:06:41 - train: epoch 0041, iter [00200, 00390], lr: 0.100000, loss: 3.3494
2023-07-02 01:06:43 - train: epoch 0027, iter [00250, 00390], lr: 0.100000, loss: 3.4734
2023-07-02 01:06:43 - train: epoch 0041, iter [00250, 00390], lr: 0.100000, loss: 3.3591
2023-07-02 01:06:45 - train: epoch 0041, iter [00300, 00390], lr: 0.100000, loss: 3.1897
2023-07-02 01:06:45 - train: epoch 0027, iter [00300, 00390], lr: 0.100000, loss: 3.3522
2023-07-02 01:06:47 - train: epoch 0041, iter [00350, 00390], lr: 0.100000, loss: 3.4132
2023-07-02 01:06:47 - train: epoch 0027, iter [00350, 00390], lr: 0.100000, loss: 3.5148
2023-07-02 01:06:49 - train: epoch 041, train_loss: 3.4257
2023-07-02 01:06:49 - train: epoch 027, train_loss: 3.3478
2023-07-02 01:06:50 - eval: epoch: 041, acc1: 22.510%, acc5: 51.580%, test_loss: 3.1615, per_image_load_time: 0.079ms, per_image_inference_time: 0.053ms
2023-07-02 01:06:50 - eval: epoch: 027, acc1: 25.690%, acc5: 54.240%, test_loss: 3.0536, per_image_load_time: 0.067ms, per_image_inference_time: 0.061ms
2023-07-02 01:06:51 - until epoch: 041, best_acc1: 22.770%
2023-07-02 01:06:51 - epoch 042 lr: 0.100000
2023-07-02 01:06:52 - until epoch: 027, best_acc1: 25.690%
2023-07-02 01:06:52 - epoch 028 lr: 0.100000
2023-07-02 01:06:53 - train: epoch 0042, iter [00050, 00390], lr: 0.100000, loss: 3.2979
2023-07-02 01:06:55 - train: epoch 0028, iter [00050, 00390], lr: 0.100000, loss: 3.3303
2023-07-02 01:06:55 - train: epoch 0042, iter [00100, 00390], lr: 0.100000, loss: 3.6272
2023-07-02 01:06:57 - train: epoch 0028, iter [00100, 00390], lr: 0.100000, loss: 3.3597
2023-07-02 01:06:57 - train: epoch 0042, iter [00150, 00390], lr: 0.100000, loss: 3.6788
2023-07-02 01:06:59 - train: epoch 0028, iter [00150, 00390], lr: 0.100000, loss: 3.2875
2023-07-02 01:06:59 - train: epoch 0042, iter [00200, 00390], lr: 0.100000, loss: 3.3542
2023-07-02 01:07:01 - train: epoch 0028, iter [00200, 00390], lr: 0.100000, loss: 3.4752
2023-07-02 01:07:01 - train: epoch 0042, iter [00250, 00390], lr: 0.100000, loss: 3.1274
2023-07-02 01:07:03 - train: epoch 0028, iter [00250, 00390], lr: 0.100000, loss: 3.3120
2023-07-02 01:07:03 - train: epoch 0042, iter [00300, 00390], lr: 0.100000, loss: 3.1655
2023-07-02 01:07:05 - train: epoch 0028, iter [00300, 00390], lr: 0.100000, loss: 3.3584
2023-07-02 01:07:05 - train: epoch 0042, iter [00350, 00390], lr: 0.100000, loss: 3.1238
2023-07-02 01:07:07 - train: epoch 042, train_loss: 3.4394
2023-07-02 01:07:07 - train: epoch 0028, iter [00350, 00390], lr: 0.100000, loss: 3.2688
2023-07-02 01:07:09 - eval: epoch: 042, acc1: 21.500%, acc5: 50.370%, test_loss: 3.2109, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:07:09 - train: epoch 028, train_loss: 3.3287
2023-07-02 01:07:09 - until epoch: 042, best_acc1: 22.770%
2023-07-02 01:07:09 - epoch 043 lr: 0.100000
2023-07-02 01:07:10 - eval: epoch: 028, acc1: 25.280%, acc5: 53.030%, test_loss: 3.0981, per_image_load_time: 0.068ms, per_image_inference_time: 0.077ms
2023-07-02 01:07:11 - until epoch: 028, best_acc1: 25.690%
2023-07-02 01:07:11 - epoch 029 lr: 0.100000
2023-07-02 01:07:11 - train: epoch 0043, iter [00050, 00390], lr: 0.100000, loss: 3.6460
2023-07-02 01:07:13 - train: epoch 0043, iter [00100, 00390], lr: 0.100000, loss: 3.3081
2023-07-02 01:07:14 - train: epoch 0029, iter [00050, 00390], lr: 0.100000, loss: 3.2811
2023-07-02 01:07:16 - train: epoch 0043, iter [00150, 00390], lr: 0.100000, loss: 3.1354
2023-07-02 01:07:16 - train: epoch 0029, iter [00100, 00390], lr: 0.100000, loss: 3.4967
2023-07-02 01:07:18 - train: epoch 0043, iter [00200, 00390], lr: 0.100000, loss: 3.5095
2023-07-02 01:07:18 - train: epoch 0029, iter [00150, 00390], lr: 0.100000, loss: 3.3097
2023-07-02 01:07:20 - train: epoch 0043, iter [00250, 00390], lr: 0.100000, loss: 3.3251
2023-07-02 01:07:20 - train: epoch 0029, iter [00200, 00390], lr: 0.100000, loss: 3.2971
2023-07-02 01:07:22 - train: epoch 0043, iter [00300, 00390], lr: 0.100000, loss: 3.2341
2023-07-02 01:07:22 - train: epoch 0029, iter [00250, 00390], lr: 0.100000, loss: 3.1880
2023-07-02 01:07:24 - train: epoch 0043, iter [00350, 00390], lr: 0.100000, loss: 3.6490
2023-07-02 01:07:24 - train: epoch 0029, iter [00300, 00390], lr: 0.100000, loss: 3.2737
2023-07-02 01:07:26 - train: epoch 043, train_loss: 3.4123
2023-07-02 01:07:26 - train: epoch 0029, iter [00350, 00390], lr: 0.100000, loss: 3.4161
2023-07-02 01:07:27 - eval: epoch: 043, acc1: 22.860%, acc5: 51.550%, test_loss: 3.1567, per_image_load_time: 0.091ms, per_image_inference_time: 0.054ms
2023-07-02 01:07:27 - train: epoch 029, train_loss: 3.3231
2023-07-02 01:07:28 - until epoch: 043, best_acc1: 22.860%
2023-07-02 01:07:28 - epoch 044 lr: 0.100000
2023-07-02 01:07:29 - eval: epoch: 029, acc1: 25.220%, acc5: 54.390%, test_loss: 3.0293, per_image_load_time: 0.069ms, per_image_inference_time: 0.065ms
2023-07-02 01:07:29 - until epoch: 029, best_acc1: 25.690%
2023-07-02 01:07:29 - epoch 030 lr: 0.100000
2023-07-02 01:07:30 - train: epoch 0044, iter [00050, 00390], lr: 0.100000, loss: 3.4343
2023-07-02 01:07:32 - train: epoch 0044, iter [00100, 00390], lr: 0.100000, loss: 3.9626
2023-07-02 01:07:32 - train: epoch 0030, iter [00050, 00390], lr: 0.100000, loss: 3.3020
2023-07-02 01:07:34 - train: epoch 0044, iter [00150, 00390], lr: 0.100000, loss: 3.5638
2023-07-02 01:07:34 - train: epoch 0030, iter [00100, 00390], lr: 0.100000, loss: 3.2846
2023-07-02 01:07:36 - train: epoch 0044, iter [00200, 00390], lr: 0.100000, loss: 3.0111
2023-07-02 01:07:36 - train: epoch 0030, iter [00150, 00390], lr: 0.100000, loss: 3.3061
2023-07-02 01:07:38 - train: epoch 0044, iter [00250, 00390], lr: 0.100000, loss: 3.3992
2023-07-02 01:07:39 - train: epoch 0030, iter [00200, 00390], lr: 0.100000, loss: 3.4897
2023-07-02 01:07:40 - train: epoch 0044, iter [00300, 00390], lr: 0.100000, loss: 3.2481
2023-07-02 01:07:41 - train: epoch 0030, iter [00250, 00390], lr: 0.100000, loss: 3.2324
2023-07-02 01:07:42 - train: epoch 0044, iter [00350, 00390], lr: 0.100000, loss: 3.0217
2023-07-02 01:07:43 - train: epoch 0030, iter [00300, 00390], lr: 0.100000, loss: 3.4002
2023-07-02 01:07:44 - train: epoch 044, train_loss: 3.4145
2023-07-02 01:07:45 - train: epoch 0030, iter [00350, 00390], lr: 0.100000, loss: 3.1079
2023-07-02 01:07:45 - eval: epoch: 044, acc1: 23.110%, acc5: 52.300%, test_loss: 3.1338, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:07:46 - until epoch: 044, best_acc1: 23.110%
2023-07-02 01:07:46 - epoch 045 lr: 0.100000
2023-07-02 01:07:46 - train: epoch 030, train_loss: 3.3246
2023-07-02 01:07:48 - eval: epoch: 030, acc1: 26.140%, acc5: 55.720%, test_loss: 3.0077, per_image_load_time: 0.070ms, per_image_inference_time: 0.057ms
2023-07-02 01:07:48 - until epoch: 030, best_acc1: 26.140%
2023-07-02 01:07:48 - epoch 031 lr: 0.100000
2023-07-02 01:07:48 - train: epoch 0045, iter [00050, 00390], lr: 0.100000, loss: 3.2641
2023-07-02 01:07:50 - train: epoch 0045, iter [00100, 00390], lr: 0.100000, loss: 3.4847
2023-07-02 01:07:51 - train: epoch 0031, iter [00050, 00390], lr: 0.100000, loss: 3.4146
2023-07-02 01:07:52 - train: epoch 0045, iter [00150, 00390], lr: 0.100000, loss: 3.0954
2023-07-02 01:07:53 - train: epoch 0031, iter [00100, 00390], lr: 0.100000, loss: 3.5101
2023-07-02 01:07:54 - train: epoch 0045, iter [00200, 00390], lr: 0.100000, loss: 3.1764
2023-07-02 01:07:55 - train: epoch 0031, iter [00150, 00390], lr: 0.100000, loss: 3.3359
2023-07-02 01:07:57 - train: epoch 0045, iter [00250, 00390], lr: 0.100000, loss: 3.1628
2023-07-02 01:07:57 - train: epoch 0031, iter [00200, 00390], lr: 0.100000, loss: 3.4122
2023-07-02 01:07:59 - train: epoch 0045, iter [00300, 00390], lr: 0.100000, loss: 3.5635
2023-07-02 01:07:59 - train: epoch 0031, iter [00250, 00390], lr: 0.100000, loss: 3.3514
2023-07-02 01:08:01 - train: epoch 0045, iter [00350, 00390], lr: 0.100000, loss: 3.6016
2023-07-02 01:08:01 - train: epoch 0031, iter [00300, 00390], lr: 0.100000, loss: 3.4277
2023-07-02 01:08:03 - train: epoch 045, train_loss: 3.4359
2023-07-02 01:08:03 - train: epoch 0031, iter [00350, 00390], lr: 0.100000, loss: 3.0376
2023-07-02 01:08:05 - eval: epoch: 045, acc1: 23.850%, acc5: 52.750%, test_loss: 3.1055, per_image_load_time: 0.082ms, per_image_inference_time: 0.053ms
2023-07-02 01:08:05 - train: epoch 031, train_loss: 3.3123
2023-07-02 01:08:06 - until epoch: 045, best_acc1: 23.850%
2023-07-02 01:08:06 - epoch 046 lr: 0.100000
2023-07-02 01:08:06 - eval: epoch: 031, acc1: 27.190%, acc5: 56.160%, test_loss: 2.9966, per_image_load_time: 0.068ms, per_image_inference_time: 0.057ms
2023-07-02 01:08:07 - until epoch: 031, best_acc1: 27.190%
2023-07-02 01:08:07 - epoch 032 lr: 0.100000
2023-07-02 01:08:08 - train: epoch 0046, iter [00050, 00390], lr: 0.100000, loss: 3.3711
2023-07-02 01:08:10 - train: epoch 0032, iter [00050, 00390], lr: 0.100000, loss: 3.3776
2023-07-02 01:08:10 - train: epoch 0046, iter [00100, 00390], lr: 0.100000, loss: 3.2881
2023-07-02 01:08:12 - train: epoch 0032, iter [00100, 00390], lr: 0.100000, loss: 3.1864
2023-07-02 01:08:12 - train: epoch 0046, iter [00150, 00390], lr: 0.100000, loss: 3.1911
2023-07-02 01:08:14 - train: epoch 0032, iter [00150, 00390], lr: 0.100000, loss: 3.3013
2023-07-02 01:08:14 - train: epoch 0046, iter [00200, 00390], lr: 0.100000, loss: 3.9269
2023-07-02 01:08:16 - train: epoch 0032, iter [00200, 00390], lr: 0.100000, loss: 3.3439
2023-07-02 01:08:16 - train: epoch 0046, iter [00250, 00390], lr: 0.100000, loss: 3.2404
2023-07-02 01:08:18 - train: epoch 0032, iter [00250, 00390], lr: 0.100000, loss: 3.4778
2023-07-02 01:08:19 - train: epoch 0046, iter [00300, 00390], lr: 0.100000, loss: 3.0345
2023-07-02 01:08:20 - train: epoch 0032, iter [00300, 00390], lr: 0.100000, loss: 3.4062
2023-07-02 01:08:21 - train: epoch 0046, iter [00350, 00390], lr: 0.100000, loss: 3.5347
2023-07-02 01:08:22 - train: epoch 0032, iter [00350, 00390], lr: 0.100000, loss: 3.1705
2023-07-02 01:08:22 - train: epoch 046, train_loss: 3.4214
2023-07-02 01:08:23 - train: epoch 032, train_loss: 3.3052
2023-07-02 01:08:24 - eval: epoch: 046, acc1: 22.910%, acc5: 52.060%, test_loss: 3.1285, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-07-02 01:08:24 - until epoch: 046, best_acc1: 23.850%
2023-07-02 01:08:24 - epoch 047 lr: 0.100000
2023-07-02 01:08:25 - eval: epoch: 032, acc1: 26.930%, acc5: 55.450%, test_loss: 3.0036, per_image_load_time: 0.069ms, per_image_inference_time: 0.063ms
2023-07-02 01:08:25 - until epoch: 032, best_acc1: 27.190%
2023-07-02 01:08:25 - epoch 033 lr: 0.100000
2023-07-02 01:08:26 - train: epoch 0047, iter [00050, 00390], lr: 0.100000, loss: 3.1064
2023-07-02 01:08:28 - train: epoch 0033, iter [00050, 00390], lr: 0.100000, loss: 3.1415
2023-07-02 01:08:28 - train: epoch 0047, iter [00100, 00390], lr: 0.100000, loss: 3.1669
2023-07-02 01:08:30 - train: epoch 0033, iter [00100, 00390], lr: 0.100000, loss: 3.2280
2023-07-02 01:08:30 - train: epoch 0047, iter [00150, 00390], lr: 0.100000, loss: 3.2069
2023-07-02 01:08:32 - train: epoch 0033, iter [00150, 00390], lr: 0.100000, loss: 3.3976
2023-07-02 01:08:33 - train: epoch 0047, iter [00200, 00390], lr: 0.100000, loss: 3.3010
2023-07-02 01:08:34 - train: epoch 0033, iter [00200, 00390], lr: 0.100000, loss: 3.4006
2023-07-02 01:08:35 - train: epoch 0047, iter [00250, 00390], lr: 0.100000, loss: 3.3503
2023-07-02 01:08:36 - train: epoch 0033, iter [00250, 00390], lr: 0.100000, loss: 3.3938
2023-07-02 01:08:37 - train: epoch 0047, iter [00300, 00390], lr: 0.100000, loss: 2.8331
2023-07-02 01:08:39 - train: epoch 0033, iter [00300, 00390], lr: 0.100000, loss: 3.4186
2023-07-02 01:08:39 - train: epoch 0047, iter [00350, 00390], lr: 0.100000, loss: 3.3687
2023-07-02 01:08:40 - train: epoch 047, train_loss: 3.4125
2023-07-02 01:08:41 - train: epoch 0033, iter [00350, 00390], lr: 0.100000, loss: 3.2615
2023-07-02 01:08:42 - eval: epoch: 047, acc1: 22.010%, acc5: 51.570%, test_loss: 3.1505, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-07-02 01:08:42 - train: epoch 033, train_loss: 3.2973
2023-07-02 01:08:42 - until epoch: 047, best_acc1: 23.850%
2023-07-02 01:08:42 - epoch 048 lr: 0.100000
2023-07-02 01:08:43 - eval: epoch: 033, acc1: 26.890%, acc5: 56.280%, test_loss: 2.9753, per_image_load_time: 0.069ms, per_image_inference_time: 0.057ms
2023-07-02 01:08:44 - until epoch: 033, best_acc1: 27.190%
2023-07-02 01:08:44 - epoch 034 lr: 0.100000
2023-07-02 01:08:45 - train: epoch 0048, iter [00050, 00390], lr: 0.100000, loss: 3.3149
2023-07-02 01:08:47 - train: epoch 0034, iter [00050, 00390], lr: 0.100000, loss: 3.1911
2023-07-02 01:08:47 - train: epoch 0048, iter [00100, 00390], lr: 0.100000, loss: 3.8719
2023-07-02 01:08:49 - train: epoch 0034, iter [00100, 00390], lr: 0.100000, loss: 3.4002
2023-07-02 01:08:49 - train: epoch 0048, iter [00150, 00390], lr: 0.100000, loss: 2.9808
2023-07-02 01:08:51 - train: epoch 0034, iter [00150, 00390], lr: 0.100000, loss: 3.1864
2023-07-02 01:08:51 - train: epoch 0048, iter [00200, 00390], lr: 0.100000, loss: 3.5074
2023-07-02 01:08:53 - train: epoch 0048, iter [00250, 00390], lr: 0.100000, loss: 3.4355
2023-07-02 01:08:53 - train: epoch 0034, iter [00200, 00390], lr: 0.100000, loss: 3.1959
2023-07-02 01:08:55 - train: epoch 0048, iter [00300, 00390], lr: 0.100000, loss: 3.0351
2023-07-02 01:08:55 - train: epoch 0034, iter [00250, 00390], lr: 0.100000, loss: 3.2541
2023-07-02 01:08:57 - train: epoch 0048, iter [00350, 00390], lr: 0.100000, loss: 3.3248
2023-07-02 01:08:57 - train: epoch 0034, iter [00300, 00390], lr: 0.100000, loss: 3.3776
2023-07-02 01:08:59 - train: epoch 048, train_loss: 3.4117
2023-07-02 01:08:59 - train: epoch 0034, iter [00350, 00390], lr: 0.100000, loss: 3.1410
2023-07-02 01:09:00 - eval: epoch: 048, acc1: 23.080%, acc5: 51.840%, test_loss: 3.1338, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-07-02 01:09:00 - until epoch: 048, best_acc1: 23.850%
2023-07-02 01:09:00 - epoch 049 lr: 0.100000
2023-07-02 01:09:00 - train: epoch 034, train_loss: 3.2864
2023-07-02 01:09:02 - eval: epoch: 034, acc1: 26.960%, acc5: 56.000%, test_loss: 2.9940, per_image_load_time: 0.069ms, per_image_inference_time: 0.056ms
2023-07-02 01:09:02 - until epoch: 034, best_acc1: 27.190%
2023-07-02 01:09:02 - epoch 035 lr: 0.100000
2023-07-02 01:09:03 - train: epoch 0049, iter [00050, 00390], lr: 0.100000, loss: 3.2113
2023-07-02 01:09:05 - train: epoch 0049, iter [00100, 00390], lr: 0.100000, loss: 3.3134
2023-07-02 01:09:05 - train: epoch 0035, iter [00050, 00390], lr: 0.100000, loss: 3.1483
2023-07-02 01:09:07 - train: epoch 0049, iter [00150, 00390], lr: 0.100000, loss: 3.1578
2023-07-02 01:09:07 - train: epoch 0035, iter [00100, 00390], lr: 0.100000, loss: 3.3079
2023-07-02 01:09:09 - train: epoch 0049, iter [00200, 00390], lr: 0.100000, loss: 3.1433
2023-07-02 01:09:09 - train: epoch 0035, iter [00150, 00390], lr: 0.100000, loss: 3.2361
2023-07-02 01:09:11 - train: epoch 0049, iter [00250, 00390], lr: 0.100000, loss: 3.3766
2023-07-02 01:09:11 - train: epoch 0035, iter [00200, 00390], lr: 0.100000, loss: 3.2406
2023-07-02 01:09:13 - train: epoch 0049, iter [00300, 00390], lr: 0.100000, loss: 3.8128
2023-07-02 01:09:13 - train: epoch 0035, iter [00250, 00390], lr: 0.100000, loss: 3.2594
2023-07-02 01:09:15 - train: epoch 0049, iter [00350, 00390], lr: 0.100000, loss: 3.4304
2023-07-02 01:09:16 - train: epoch 0035, iter [00300, 00390], lr: 0.100000, loss: 3.2325
2023-07-02 01:09:16 - train: epoch 049, train_loss: 3.3729
2023-07-02 01:09:17 - train: epoch 0035, iter [00350, 00390], lr: 0.100000, loss: 3.4538
2023-07-02 01:09:18 - eval: epoch: 049, acc1: 23.160%, acc5: 51.380%, test_loss: 3.1416, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 01:09:18 - until epoch: 049, best_acc1: 23.850%
2023-07-02 01:09:18 - epoch 050 lr: 0.100000
2023-07-02 01:09:19 - train: epoch 035, train_loss: 3.2834
2023-07-02 01:09:20 - eval: epoch: 035, acc1: 27.560%, acc5: 57.080%, test_loss: 2.9411, per_image_load_time: 0.068ms, per_image_inference_time: 0.058ms
2023-07-02 01:09:21 - train: epoch 0050, iter [00050, 00390], lr: 0.100000, loss: 3.4773
2023-07-02 01:09:21 - until epoch: 035, best_acc1: 27.560%
2023-07-02 01:09:21 - epoch 036 lr: 0.100000
2023-07-02 01:09:22 - train: epoch 0050, iter [00100, 00390], lr: 0.100000, loss: 3.0249
2023-07-02 01:09:23 - train: epoch 0036, iter [00050, 00390], lr: 0.100000, loss: 3.2251
2023-07-02 01:09:24 - train: epoch 0050, iter [00150, 00390], lr: 0.100000, loss: 3.5542
2023-07-02 01:09:26 - train: epoch 0036, iter [00100, 00390], lr: 0.100000, loss: 3.0987
2023-07-02 01:09:26 - train: epoch 0050, iter [00200, 00390], lr: 0.100000, loss: 3.2977
2023-07-02 01:09:28 - train: epoch 0036, iter [00150, 00390], lr: 0.100000, loss: 3.3129
2023-07-02 01:09:28 - train: epoch 0050, iter [00250, 00390], lr: 0.100000, loss: 3.1676
2023-07-02 01:09:30 - train: epoch 0036, iter [00200, 00390], lr: 0.100000, loss: 3.4816
2023-07-02 01:09:31 - train: epoch 0050, iter [00300, 00390], lr: 0.100000, loss: 3.9594
2023-07-02 01:09:32 - train: epoch 0036, iter [00250, 00390], lr: 0.100000, loss: 3.2084
2023-07-02 01:09:33 - train: epoch 0050, iter [00350, 00390], lr: 0.100000, loss: 3.4932
2023-07-02 01:09:34 - train: epoch 0036, iter [00300, 00390], lr: 0.100000, loss: 3.3364
2023-07-02 01:09:34 - train: epoch 050, train_loss: 3.4062
2023-07-02 01:09:36 - eval: epoch: 050, acc1: 23.770%, acc5: 52.010%, test_loss: 3.1299, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 01:09:36 - train: epoch 0036, iter [00350, 00390], lr: 0.100000, loss: 2.9871
2023-07-02 01:09:36 - until epoch: 050, best_acc1: 23.850%
2023-07-02 01:09:36 - epoch 051 lr: 0.100000
2023-07-02 01:09:37 - train: epoch 036, train_loss: 3.2727
2023-07-02 01:09:39 - eval: epoch: 036, acc1: 27.210%, acc5: 56.510%, test_loss: 2.9649, per_image_load_time: 0.066ms, per_image_inference_time: 0.059ms
2023-07-02 01:09:39 - train: epoch 0051, iter [00050, 00390], lr: 0.100000, loss: 4.2560
2023-07-02 01:09:39 - until epoch: 036, best_acc1: 27.560%
2023-07-02 01:09:39 - epoch 037 lr: 0.100000
2023-07-02 01:09:41 - train: epoch 0051, iter [00100, 00390], lr: 0.100000, loss: 3.5294
2023-07-02 01:09:42 - train: epoch 0037, iter [00050, 00390], lr: 0.100000, loss: 3.4313
2023-07-02 01:09:43 - train: epoch 0051, iter [00150, 00390], lr: 0.100000, loss: 3.2846
2023-07-02 01:09:44 - train: epoch 0037, iter [00100, 00390], lr: 0.100000, loss: 3.0993
2023-07-02 01:09:46 - train: epoch 0051, iter [00200, 00390], lr: 0.100000, loss: 3.3874
2023-07-02 01:09:46 - train: epoch 0037, iter [00150, 00390], lr: 0.100000, loss: 3.2056
2023-07-02 01:09:48 - train: epoch 0037, iter [00200, 00390], lr: 0.100000, loss: 3.3225
2023-07-02 01:09:48 - train: epoch 0051, iter [00250, 00390], lr: 0.100000, loss: 3.6993
2023-07-02 01:09:50 - train: epoch 0037, iter [00250, 00390], lr: 0.100000, loss: 3.1947
2023-07-02 01:09:50 - train: epoch 0051, iter [00300, 00390], lr: 0.100000, loss: 2.9861
2023-07-02 01:09:52 - train: epoch 0037, iter [00300, 00390], lr: 0.100000, loss: 3.2231
2023-07-02 01:09:52 - train: epoch 0051, iter [00350, 00390], lr: 0.100000, loss: 3.4589
2023-07-02 01:09:54 - train: epoch 051, train_loss: 3.3878
2023-07-02 01:09:54 - train: epoch 0037, iter [00350, 00390], lr: 0.100000, loss: 3.3059
2023-07-02 01:09:56 - eval: epoch: 051, acc1: 23.280%, acc5: 53.580%, test_loss: 3.0935, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:09:56 - until epoch: 051, best_acc1: 23.850%
2023-07-02 01:09:56 - epoch 052 lr: 0.100000
2023-07-02 01:09:56 - train: epoch 037, train_loss: 3.2570
2023-07-02 01:09:57 - eval: epoch: 037, acc1: 26.900%, acc5: 56.370%, test_loss: 2.9834, per_image_load_time: 0.076ms, per_image_inference_time: 0.061ms
2023-07-02 01:09:58 - until epoch: 037, best_acc1: 27.560%
2023-07-02 01:09:58 - epoch 038 lr: 0.100000
2023-07-02 01:09:58 - train: epoch 0052, iter [00050, 00390], lr: 0.100000, loss: 3.3544
2023-07-02 01:10:00 - train: epoch 0052, iter [00100, 00390], lr: 0.100000, loss: 3.4189
2023-07-02 01:10:01 - train: epoch 0038, iter [00050, 00390], lr: 0.100000, loss: 3.2412
2023-07-02 01:10:02 - train: epoch 0052, iter [00150, 00390], lr: 0.100000, loss: 3.5866
2023-07-02 01:10:03 - train: epoch 0038, iter [00100, 00390], lr: 0.100000, loss: 3.3338
2023-07-02 01:10:04 - train: epoch 0052, iter [00200, 00390], lr: 0.100000, loss: 3.4425
2023-07-02 01:10:05 - train: epoch 0038, iter [00150, 00390], lr: 0.100000, loss: 3.3544
2023-07-02 01:10:06 - train: epoch 0052, iter [00250, 00390], lr: 0.100000, loss: 3.6083
2023-07-02 01:10:07 - train: epoch 0038, iter [00200, 00390], lr: 0.100000, loss: 3.1718
2023-07-02 01:10:08 - train: epoch 0052, iter [00300, 00390], lr: 0.100000, loss: 3.2989
2023-07-02 01:10:09 - train: epoch 0038, iter [00250, 00390], lr: 0.100000, loss: 3.2918
2023-07-02 01:10:10 - train: epoch 0052, iter [00350, 00390], lr: 0.100000, loss: 3.5892
2023-07-02 01:10:11 - train: epoch 0038, iter [00300, 00390], lr: 0.100000, loss: 3.2794
2023-07-02 01:10:12 - train: epoch 052, train_loss: 3.3834
2023-07-02 01:10:13 - train: epoch 0038, iter [00350, 00390], lr: 0.100000, loss: 3.4909
2023-07-02 01:10:13 - eval: epoch: 052, acc1: 23.940%, acc5: 53.210%, test_loss: 3.0946, per_image_load_time: 0.067ms, per_image_inference_time: 0.054ms
2023-07-02 01:10:14 - until epoch: 052, best_acc1: 23.940%
2023-07-02 01:10:14 - epoch 053 lr: 0.100000
2023-07-02 01:10:14 - train: epoch 038, train_loss: 3.2592
2023-07-02 01:10:16 - eval: epoch: 038, acc1: 27.430%, acc5: 56.810%, test_loss: 2.9733, per_image_load_time: 0.071ms, per_image_inference_time: 0.057ms
2023-07-02 01:10:16 - until epoch: 038, best_acc1: 27.560%
2023-07-02 01:10:16 - epoch 039 lr: 0.100000
2023-07-02 01:10:17 - train: epoch 0053, iter [00050, 00390], lr: 0.100000, loss: 3.0633
2023-07-02 01:10:18 - train: epoch 0053, iter [00100, 00390], lr: 0.100000, loss: 2.8914
2023-07-02 01:10:19 - train: epoch 0039, iter [00050, 00390], lr: 0.100000, loss: 3.1767
2023-07-02 01:10:21 - train: epoch 0053, iter [00150, 00390], lr: 0.100000, loss: 2.9316
2023-07-02 01:10:21 - train: epoch 0039, iter [00100, 00390], lr: 0.100000, loss: 3.1544
2023-07-02 01:10:23 - train: epoch 0053, iter [00200, 00390], lr: 0.100000, loss: 3.5901
2023-07-02 01:10:23 - train: epoch 0039, iter [00150, 00390], lr: 0.100000, loss: 3.1198
2023-07-02 01:10:25 - train: epoch 0053, iter [00250, 00390], lr: 0.100000, loss: 3.1961
2023-07-02 01:10:25 - train: epoch 0039, iter [00200, 00390], lr: 0.100000, loss: 3.0708
2023-07-02 01:10:27 - train: epoch 0053, iter [00300, 00390], lr: 0.100000, loss: 3.7338
2023-07-02 01:10:27 - train: epoch 0039, iter [00250, 00390], lr: 0.100000, loss: 3.2506
2023-07-02 01:10:29 - train: epoch 0053, iter [00350, 00390], lr: 0.100000, loss: 3.3722
2023-07-02 01:10:29 - train: epoch 0039, iter [00300, 00390], lr: 0.100000, loss: 3.0424
2023-07-02 01:10:31 - train: epoch 053, train_loss: 3.3805
2023-07-02 01:10:31 - train: epoch 0039, iter [00350, 00390], lr: 0.100000, loss: 3.2748
2023-07-02 01:10:32 - eval: epoch: 053, acc1: 24.790%, acc5: 53.460%, test_loss: 3.0613, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:10:33 - train: epoch 039, train_loss: 3.2480
2023-07-02 01:10:33 - until epoch: 053, best_acc1: 24.790%
2023-07-02 01:10:33 - epoch 054 lr: 0.100000
2023-07-02 01:10:34 - eval: epoch: 039, acc1: 27.190%, acc5: 57.050%, test_loss: 2.9676, per_image_load_time: 0.067ms, per_image_inference_time: 0.063ms
2023-07-02 01:10:34 - until epoch: 039, best_acc1: 27.560%
2023-07-02 01:10:34 - epoch 040 lr: 0.100000
2023-07-02 01:10:35 - train: epoch 0054, iter [00050, 00390], lr: 0.100000, loss: 3.5776
2023-07-02 01:10:37 - train: epoch 0040, iter [00050, 00390], lr: 0.100000, loss: 3.2425
2023-07-02 01:10:38 - train: epoch 0054, iter [00100, 00390], lr: 0.100000, loss: 3.5548
2023-07-02 01:10:39 - train: epoch 0040, iter [00100, 00390], lr: 0.100000, loss: 3.1202
2023-07-02 01:10:40 - train: epoch 0054, iter [00150, 00390], lr: 0.100000, loss: 3.0815
2023-07-02 01:10:41 - train: epoch 0040, iter [00150, 00390], lr: 0.100000, loss: 3.1103
2023-07-02 01:10:43 - train: epoch 0054, iter [00200, 00390], lr: 0.100000, loss: 3.3976
2023-07-02 01:10:44 - train: epoch 0040, iter [00200, 00390], lr: 0.100000, loss: 3.3404
2023-07-02 01:10:45 - train: epoch 0054, iter [00250, 00390], lr: 0.100000, loss: 3.2490
2023-07-02 01:10:46 - train: epoch 0040, iter [00250, 00390], lr: 0.100000, loss: 3.2960
2023-07-02 01:10:47 - train: epoch 0054, iter [00300, 00390], lr: 0.100000, loss: 3.3045
2023-07-02 01:10:48 - train: epoch 0040, iter [00300, 00390], lr: 0.100000, loss: 2.9297
2023-07-02 01:10:49 - train: epoch 0054, iter [00350, 00390], lr: 0.100000, loss: 2.9842
2023-07-02 01:10:50 - train: epoch 0040, iter [00350, 00390], lr: 0.100000, loss: 3.3313
2023-07-02 01:10:50 - train: epoch 054, train_loss: 3.3920
2023-07-02 01:10:51 - train: epoch 040, train_loss: 3.2412
2023-07-02 01:10:52 - eval: epoch: 054, acc1: 24.930%, acc5: 53.760%, test_loss: 3.0599, per_image_load_time: 0.066ms, per_image_inference_time: 0.054ms
2023-07-02 01:10:52 - until epoch: 054, best_acc1: 24.930%
2023-07-02 01:10:52 - epoch 055 lr: 0.100000
2023-07-02 01:10:53 - eval: epoch: 040, acc1: 28.860%, acc5: 58.500%, test_loss: 2.9150, per_image_load_time: 0.066ms, per_image_inference_time: 0.057ms
2023-07-02 01:10:53 - until epoch: 040, best_acc1: 28.860%
2023-07-02 01:10:53 - epoch 041 lr: 0.100000
2023-07-02 01:10:55 - train: epoch 0055, iter [00050, 00390], lr: 0.100000, loss: 3.5405
2023-07-02 01:10:56 - train: epoch 0041, iter [00050, 00390], lr: 0.100000, loss: 3.0868
2023-07-02 01:10:57 - train: epoch 0055, iter [00100, 00390], lr: 0.100000, loss: 3.4131
2023-07-02 01:10:58 - train: epoch 0041, iter [00100, 00390], lr: 0.100000, loss: 3.0914
2023-07-02 01:10:59 - train: epoch 0055, iter [00150, 00390], lr: 0.100000, loss: 3.2633
2023-07-02 01:11:00 - train: epoch 0041, iter [00150, 00390], lr: 0.100000, loss: 3.3173
2023-07-02 01:11:01 - train: epoch 0055, iter [00200, 00390], lr: 0.100000, loss: 3.4172
2023-07-02 01:11:03 - train: epoch 0041, iter [00200, 00390], lr: 0.100000, loss: 3.3766
2023-07-02 01:11:03 - train: epoch 0055, iter [00250, 00390], lr: 0.100000, loss: 3.2915
2023-07-02 01:11:05 - train: epoch 0041, iter [00250, 00390], lr: 0.100000, loss: 3.3050
2023-07-02 01:11:05 - train: epoch 0055, iter [00300, 00390], lr: 0.100000, loss: 3.5972
2023-07-02 01:11:07 - train: epoch 0041, iter [00300, 00390], lr: 0.100000, loss: 3.2128
2023-07-02 01:11:07 - train: epoch 0055, iter [00350, 00390], lr: 0.100000, loss: 3.3985
2023-07-02 01:11:09 - train: epoch 0041, iter [00350, 00390], lr: 0.100000, loss: 3.2657
2023-07-02 01:11:09 - train: epoch 055, train_loss: 3.3902
2023-07-02 01:11:10 - train: epoch 041, train_loss: 3.2357
2023-07-02 01:11:11 - eval: epoch: 055, acc1: 24.060%, acc5: 52.210%, test_loss: 3.1087, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 01:11:11 - until epoch: 055, best_acc1: 24.930%
2023-07-02 01:11:11 - epoch 056 lr: 0.100000
2023-07-02 01:11:12 - eval: epoch: 041, acc1: 27.670%, acc5: 57.470%, test_loss: 2.9174, per_image_load_time: 0.067ms, per_image_inference_time: 0.060ms
2023-07-02 01:11:12 - until epoch: 041, best_acc1: 28.860%
2023-07-02 01:11:12 - epoch 042 lr: 0.100000
2023-07-02 01:11:14 - train: epoch 0056, iter [00050, 00390], lr: 0.100000, loss: 3.4591
2023-07-02 01:11:15 - train: epoch 0042, iter [00050, 00390], lr: 0.100000, loss: 3.0265
2023-07-02 01:11:16 - train: epoch 0056, iter [00100, 00390], lr: 0.100000, loss: 2.9198
2023-07-02 01:11:17 - train: epoch 0042, iter [00100, 00390], lr: 0.100000, loss: 3.3082
2023-07-02 01:11:18 - train: epoch 0056, iter [00150, 00390], lr: 0.100000, loss: 3.6049
2023-07-02 01:11:19 - train: epoch 0042, iter [00150, 00390], lr: 0.100000, loss: 3.0619
2023-07-02 01:11:20 - train: epoch 0056, iter [00200, 00390], lr: 0.100000, loss: 3.2968
2023-07-02 01:11:21 - train: epoch 0042, iter [00200, 00390], lr: 0.100000, loss: 3.1810
2023-07-02 01:11:22 - train: epoch 0056, iter [00250, 00390], lr: 0.100000, loss: 2.9033
2023-07-02 01:11:24 - train: epoch 0042, iter [00250, 00390], lr: 0.100000, loss: 3.1656
2023-07-02 01:11:24 - train: epoch 0056, iter [00300, 00390], lr: 0.100000, loss: 4.0632
2023-07-02 01:11:26 - train: epoch 0056, iter [00350, 00390], lr: 0.100000, loss: 2.8702
2023-07-02 01:11:26 - train: epoch 0042, iter [00300, 00390], lr: 0.100000, loss: 3.0988
2023-07-02 01:11:27 - train: epoch 056, train_loss: 3.3665
2023-07-02 01:11:28 - train: epoch 0042, iter [00350, 00390], lr: 0.100000, loss: 3.0816
2023-07-02 01:11:29 - eval: epoch: 056, acc1: 23.220%, acc5: 52.040%, test_loss: 3.1348, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:11:29 - train: epoch 042, train_loss: 3.2264
2023-07-02 01:11:29 - until epoch: 056, best_acc1: 24.930%
2023-07-02 01:11:29 - epoch 057 lr: 0.100000
2023-07-02 01:11:31 - eval: epoch: 042, acc1: 28.300%, acc5: 58.210%, test_loss: 2.9151, per_image_load_time: 0.070ms, per_image_inference_time: 0.071ms
2023-07-02 01:11:31 - until epoch: 042, best_acc1: 28.860%
2023-07-02 01:11:31 - epoch 043 lr: 0.100000
2023-07-02 01:11:32 - train: epoch 0057, iter [00050, 00390], lr: 0.100000, loss: 3.3969
2023-07-02 01:11:34 - train: epoch 0057, iter [00100, 00390], lr: 0.100000, loss: 3.1148
2023-07-02 01:11:34 - train: epoch 0043, iter [00050, 00390], lr: 0.100000, loss: 3.2597
2023-07-02 01:11:36 - train: epoch 0057, iter [00150, 00390], lr: 0.100000, loss: 2.9258
2023-07-02 01:11:36 - train: epoch 0043, iter [00100, 00390], lr: 0.100000, loss: 3.0517
2023-07-02 01:11:38 - train: epoch 0057, iter [00200, 00390], lr: 0.100000, loss: 3.9186
2023-07-02 01:11:38 - train: epoch 0043, iter [00150, 00390], lr: 0.100000, loss: 3.1578
2023-07-02 01:11:40 - train: epoch 0057, iter [00250, 00390], lr: 0.100000, loss: 3.2751
2023-07-02 01:11:41 - train: epoch 0043, iter [00200, 00390], lr: 0.100000, loss: 3.4308
2023-07-02 01:11:42 - train: epoch 0057, iter [00300, 00390], lr: 0.100000, loss: 3.3141
2023-07-02 01:11:43 - train: epoch 0043, iter [00250, 00390], lr: 0.100000, loss: 3.3411
2023-07-02 01:11:44 - train: epoch 0057, iter [00350, 00390], lr: 0.100000, loss: 3.0499
2023-07-02 01:11:45 - train: epoch 0043, iter [00300, 00390], lr: 0.100000, loss: 3.2588
2023-07-02 01:11:46 - train: epoch 057, train_loss: 3.3572
2023-07-02 01:11:47 - train: epoch 0043, iter [00350, 00390], lr: 0.100000, loss: 3.4448
2023-07-02 01:11:47 - eval: epoch: 057, acc1: 24.120%, acc5: 53.120%, test_loss: 3.0815, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-07-02 01:11:47 - until epoch: 057, best_acc1: 24.930%
2023-07-02 01:11:47 - epoch 058 lr: 0.100000
2023-07-02 01:11:48 - train: epoch 043, train_loss: 3.2191
2023-07-02 01:11:50 - eval: epoch: 043, acc1: 28.290%, acc5: 58.480%, test_loss: 2.8938, per_image_load_time: 0.069ms, per_image_inference_time: 0.057ms
2023-07-02 01:11:50 - until epoch: 043, best_acc1: 28.860%
2023-07-02 01:11:50 - epoch 044 lr: 0.100000
2023-07-02 01:11:50 - train: epoch 0058, iter [00050, 00390], lr: 0.100000, loss: 3.7714
2023-07-02 01:11:52 - train: epoch 0058, iter [00100, 00390], lr: 0.100000, loss: 3.3225
2023-07-02 01:11:53 - train: epoch 0044, iter [00050, 00390], lr: 0.100000, loss: 3.3691
2023-07-02 01:11:54 - train: epoch 0058, iter [00150, 00390], lr: 0.100000, loss: 3.3786
2023-07-02 01:11:55 - train: epoch 0044, iter [00100, 00390], lr: 0.100000, loss: 3.2202
2023-07-02 01:11:56 - train: epoch 0058, iter [00200, 00390], lr: 0.100000, loss: 3.2694
2023-07-02 01:11:57 - train: epoch 0044, iter [00150, 00390], lr: 0.100000, loss: 3.1537
2023-07-02 01:11:58 - train: epoch 0058, iter [00250, 00390], lr: 0.100000, loss: 3.7192
2023-07-02 01:11:59 - train: epoch 0044, iter [00200, 00390], lr: 0.100000, loss: 3.1303
2023-07-02 01:12:00 - train: epoch 0058, iter [00300, 00390], lr: 0.100000, loss: 3.4227
2023-07-02 01:12:01 - train: epoch 0044, iter [00250, 00390], lr: 0.100000, loss: 3.2979
2023-07-02 01:12:02 - train: epoch 0058, iter [00350, 00390], lr: 0.100000, loss: 3.2683
2023-07-02 01:12:03 - train: epoch 0044, iter [00300, 00390], lr: 0.100000, loss: 3.1298
2023-07-02 01:12:04 - train: epoch 058, train_loss: 3.3690
2023-07-02 01:12:05 - train: epoch 0044, iter [00350, 00390], lr: 0.100000, loss: 3.0615
2023-07-02 01:12:05 - eval: epoch: 058, acc1: 24.400%, acc5: 53.550%, test_loss: 3.0800, per_image_load_time: 0.072ms, per_image_inference_time: 0.056ms
2023-07-02 01:12:06 - until epoch: 058, best_acc1: 24.930%
2023-07-02 01:12:06 - epoch 059 lr: 0.100000
2023-07-02 01:12:06 - train: epoch 044, train_loss: 3.2149
2023-07-02 01:12:08 - eval: epoch: 044, acc1: 28.690%, acc5: 58.740%, test_loss: 2.8938, per_image_load_time: 0.072ms, per_image_inference_time: 0.056ms
2023-07-02 01:12:08 - until epoch: 044, best_acc1: 28.860%
2023-07-02 01:12:08 - epoch 045 lr: 0.100000
2023-07-02 01:12:08 - train: epoch 0059, iter [00050, 00390], lr: 0.100000, loss: 3.8463
2023-07-02 01:12:10 - train: epoch 0059, iter [00100, 00390], lr: 0.100000, loss: 3.7340
2023-07-02 01:12:11 - train: epoch 0045, iter [00050, 00390], lr: 0.100000, loss: 3.0996
2023-07-02 01:12:12 - train: epoch 0059, iter [00150, 00390], lr: 0.100000, loss: 3.3817
2023-07-02 01:12:13 - train: epoch 0045, iter [00100, 00390], lr: 0.100000, loss: 3.3761
2023-07-02 01:12:14 - train: epoch 0059, iter [00200, 00390], lr: 0.100000, loss: 3.0779
2023-07-02 01:12:15 - train: epoch 0045, iter [00150, 00390], lr: 0.100000, loss: 3.1114
2023-07-02 01:12:16 - train: epoch 0059, iter [00250, 00390], lr: 0.100000, loss: 3.4275
2023-07-02 01:12:17 - train: epoch 0045, iter [00200, 00390], lr: 0.100000, loss: 3.1666
2023-07-02 01:12:19 - train: epoch 0059, iter [00300, 00390], lr: 0.100000, loss: 3.3739
2023-07-02 01:12:19 - train: epoch 0045, iter [00250, 00390], lr: 0.100000, loss: 3.0870
2023-07-02 01:12:21 - train: epoch 0059, iter [00350, 00390], lr: 0.100000, loss: 3.8028
2023-07-02 01:12:21 - train: epoch 0045, iter [00300, 00390], lr: 0.100000, loss: 3.2250
2023-07-02 01:12:22 - train: epoch 059, train_loss: 3.3428
2023-07-02 01:12:23 - train: epoch 0045, iter [00350, 00390], lr: 0.100000, loss: 3.3946
2023-07-02 01:12:24 - eval: epoch: 059, acc1: 25.080%, acc5: 54.310%, test_loss: 3.0485, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 01:12:24 - until epoch: 059, best_acc1: 25.080%
2023-07-02 01:12:24 - epoch 060 lr: 0.100000
2023-07-02 01:12:24 - train: epoch 045, train_loss: 3.2067
2023-07-02 01:12:26 - eval: epoch: 045, acc1: 28.910%, acc5: 57.830%, test_loss: 2.9134, per_image_load_time: 0.076ms, per_image_inference_time: 0.066ms
2023-07-02 01:12:27 - until epoch: 045, best_acc1: 28.910%
2023-07-02 01:12:27 - epoch 046 lr: 0.100000
2023-07-02 01:12:27 - train: epoch 0060, iter [00050, 00390], lr: 0.100000, loss: 3.2485
2023-07-02 01:12:29 - train: epoch 0060, iter [00100, 00390], lr: 0.100000, loss: 3.3403
2023-07-02 01:12:29 - train: epoch 0046, iter [00050, 00390], lr: 0.100000, loss: 3.3375
2023-07-02 01:12:31 - train: epoch 0060, iter [00150, 00390], lr: 0.100000, loss: 3.0441
2023-07-02 01:12:31 - train: epoch 0046, iter [00100, 00390], lr: 0.100000, loss: 3.2073
2023-07-02 01:12:33 - train: epoch 0060, iter [00200, 00390], lr: 0.100000, loss: 2.8199
2023-07-02 01:12:33 - train: epoch 0046, iter [00150, 00390], lr: 0.100000, loss: 3.1565
2023-07-02 01:12:35 - train: epoch 0060, iter [00250, 00390], lr: 0.100000, loss: 3.7448
2023-07-02 01:12:36 - train: epoch 0046, iter [00200, 00390], lr: 0.100000, loss: 3.0923
2023-07-02 01:12:37 - train: epoch 0060, iter [00300, 00390], lr: 0.100000, loss: 2.8641
2023-07-02 01:12:38 - train: epoch 0046, iter [00250, 00390], lr: 0.100000, loss: 3.1786
2023-07-02 01:12:39 - train: epoch 0060, iter [00350, 00390], lr: 0.100000, loss: 3.0724
2023-07-02 01:12:40 - train: epoch 0046, iter [00300, 00390], lr: 0.100000, loss: 3.2552
2023-07-02 01:12:40 - train: epoch 060, train_loss: 3.3409
2023-07-02 01:12:41 - train: epoch 0046, iter [00350, 00390], lr: 0.100000, loss: 3.0677
2023-07-02 01:12:42 - eval: epoch: 060, acc1: 24.040%, acc5: 53.110%, test_loss: 3.0734, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-07-02 01:12:42 - until epoch: 060, best_acc1: 25.080%
2023-07-02 01:12:42 - epoch 061 lr: 0.020000
2023-07-02 01:12:43 - train: epoch 046, train_loss: 3.2031
2023-07-02 01:12:44 - eval: epoch: 046, acc1: 28.500%, acc5: 58.300%, test_loss: 2.9060, per_image_load_time: 0.066ms, per_image_inference_time: 0.057ms
2023-07-02 01:12:44 - train: epoch 0061, iter [00050, 00390], lr: 0.020000, loss: 2.9174
2023-07-02 01:12:45 - until epoch: 046, best_acc1: 28.910%
2023-07-02 01:12:45 - epoch 047 lr: 0.100000
2023-07-02 01:12:46 - train: epoch 0061, iter [00100, 00390], lr: 0.020000, loss: 2.9749
2023-07-02 01:12:47 - train: epoch 0047, iter [00050, 00390], lr: 0.100000, loss: 3.1788
2023-07-02 01:12:48 - train: epoch 0061, iter [00150, 00390], lr: 0.020000, loss: 3.4490
2023-07-02 01:12:50 - train: epoch 0047, iter [00100, 00390], lr: 0.100000, loss: 3.2281
2023-07-02 01:12:50 - train: epoch 0061, iter [00200, 00390], lr: 0.020000, loss: 2.9255
2023-07-02 01:12:52 - train: epoch 0047, iter [00150, 00390], lr: 0.100000, loss: 3.0766
2023-07-02 01:12:52 - train: epoch 0061, iter [00250, 00390], lr: 0.020000, loss: 2.5280
2023-07-02 01:12:54 - train: epoch 0047, iter [00200, 00390], lr: 0.100000, loss: 3.0816
2023-07-02 01:12:54 - train: epoch 0061, iter [00300, 00390], lr: 0.020000, loss: 3.5087
2023-07-02 01:12:56 - train: epoch 0047, iter [00250, 00390], lr: 0.100000, loss: 3.1352
2023-07-02 01:12:56 - train: epoch 0061, iter [00350, 00390], lr: 0.020000, loss: 3.4975
2023-07-02 01:12:58 - train: epoch 0047, iter [00300, 00390], lr: 0.100000, loss: 2.9605
2023-07-02 01:12:58 - train: epoch 061, train_loss: 3.1247
2023-07-02 01:13:00 - eval: epoch: 061, acc1: 30.680%, acc5: 59.700%, test_loss: 2.7944, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:13:00 - train: epoch 0047, iter [00350, 00390], lr: 0.100000, loss: 3.1931
2023-07-02 01:13:00 - until epoch: 061, best_acc1: 30.680%
2023-07-02 01:13:00 - epoch 062 lr: 0.020000
2023-07-02 01:13:01 - train: epoch 047, train_loss: 3.1972
2023-07-02 01:13:02 - eval: epoch: 047, acc1: 28.650%, acc5: 59.310%, test_loss: 2.8912, per_image_load_time: 0.069ms, per_image_inference_time: 0.056ms
2023-07-02 01:13:02 - until epoch: 047, best_acc1: 28.910%
2023-07-02 01:13:02 - epoch 048 lr: 0.100000
2023-07-02 01:13:03 - train: epoch 0062, iter [00050, 00390], lr: 0.020000, loss: 2.4763
2023-07-02 01:13:04 - train: epoch 0062, iter [00100, 00390], lr: 0.020000, loss: 2.8734
2023-07-02 01:13:05 - train: epoch 0048, iter [00050, 00390], lr: 0.100000, loss: 3.1414
2023-07-02 01:13:07 - train: epoch 0062, iter [00150, 00390], lr: 0.020000, loss: 3.6500
2023-07-02 01:13:08 - train: epoch 0048, iter [00100, 00390], lr: 0.100000, loss: 3.0784
2023-07-02 01:13:09 - train: epoch 0062, iter [00200, 00390], lr: 0.020000, loss: 2.7115
2023-07-02 01:13:10 - train: epoch 0048, iter [00150, 00390], lr: 0.100000, loss: 3.1082
2023-07-02 01:13:11 - train: epoch 0062, iter [00250, 00390], lr: 0.020000, loss: 2.9717
2023-07-02 01:13:12 - train: epoch 0048, iter [00200, 00390], lr: 0.100000, loss: 3.4339
2023-07-02 01:13:13 - train: epoch 0062, iter [00300, 00390], lr: 0.020000, loss: 2.6764
2023-07-02 01:13:14 - train: epoch 0048, iter [00250, 00390], lr: 0.100000, loss: 3.3190
2023-07-02 01:13:15 - train: epoch 0062, iter [00350, 00390], lr: 0.020000, loss: 3.0135
2023-07-02 01:13:16 - train: epoch 0048, iter [00300, 00390], lr: 0.100000, loss: 3.1320
2023-07-02 01:13:17 - train: epoch 062, train_loss: 3.0735
2023-07-02 01:13:18 - train: epoch 0048, iter [00350, 00390], lr: 0.100000, loss: 3.3111
2023-07-02 01:13:18 - eval: epoch: 062, acc1: 31.300%, acc5: 61.160%, test_loss: 2.7551, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 01:13:18 - until epoch: 062, best_acc1: 31.300%
2023-07-02 01:13:18 - epoch 063 lr: 0.020000
2023-07-02 01:13:19 - train: epoch 048, train_loss: 3.1912
2023-07-02 01:13:21 - eval: epoch: 048, acc1: 27.960%, acc5: 57.840%, test_loss: 2.9251, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:13:21 - until epoch: 048, best_acc1: 28.910%
2023-07-02 01:13:21 - epoch 049 lr: 0.100000
2023-07-02 01:13:21 - train: epoch 0063, iter [00050, 00390], lr: 0.020000, loss: 2.9880
2023-07-02 01:13:23 - train: epoch 0063, iter [00100, 00390], lr: 0.020000, loss: 3.2710
2023-07-02 01:13:24 - train: epoch 0049, iter [00050, 00390], lr: 0.100000, loss: 3.2182
2023-07-02 01:13:25 - train: epoch 0063, iter [00150, 00390], lr: 0.020000, loss: 2.9737
2023-07-02 01:13:26 - train: epoch 0049, iter [00100, 00390], lr: 0.100000, loss: 3.0857
2023-07-02 01:13:27 - train: epoch 0063, iter [00200, 00390], lr: 0.020000, loss: 2.7203
2023-07-02 01:13:28 - train: epoch 0049, iter [00150, 00390], lr: 0.100000, loss: 3.2476
2023-07-02 01:13:29 - train: epoch 0063, iter [00250, 00390], lr: 0.020000, loss: 3.0662
2023-07-02 01:13:30 - train: epoch 0049, iter [00200, 00390], lr: 0.100000, loss: 3.0563
2023-07-02 01:13:31 - train: epoch 0063, iter [00300, 00390], lr: 0.020000, loss: 3.0900
2023-07-02 01:13:32 - train: epoch 0049, iter [00250, 00390], lr: 0.100000, loss: 3.1347
2023-07-02 01:13:33 - train: epoch 0063, iter [00350, 00390], lr: 0.020000, loss: 2.9047
2023-07-02 01:13:34 - train: epoch 0049, iter [00300, 00390], lr: 0.100000, loss: 3.1658
2023-07-02 01:13:35 - train: epoch 063, train_loss: 3.0304
2023-07-02 01:13:36 - train: epoch 0049, iter [00350, 00390], lr: 0.100000, loss: 3.2637
2023-07-02 01:13:36 - eval: epoch: 063, acc1: 31.310%, acc5: 61.250%, test_loss: 2.7488, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:13:37 - until epoch: 063, best_acc1: 31.310%
2023-07-02 01:13:37 - epoch 064 lr: 0.020000
2023-07-02 01:13:37 - train: epoch 049, train_loss: 3.1876
2023-07-02 01:13:39 - eval: epoch: 049, acc1: 29.080%, acc5: 58.670%, test_loss: 2.8889, per_image_load_time: 0.072ms, per_image_inference_time: 0.057ms
2023-07-02 01:13:39 - until epoch: 049, best_acc1: 29.080%
2023-07-02 01:13:39 - epoch 050 lr: 0.100000
2023-07-02 01:13:39 - train: epoch 0064, iter [00050, 00390], lr: 0.020000, loss: 3.4762
2023-07-02 01:13:41 - train: epoch 0064, iter [00100, 00390], lr: 0.020000, loss: 2.9253
2023-07-02 01:13:42 - train: epoch 0050, iter [00050, 00390], lr: 0.100000, loss: 3.2454
2023-07-02 01:13:43 - train: epoch 0064, iter [00150, 00390], lr: 0.020000, loss: 3.0157
2023-07-02 01:13:44 - train: epoch 0050, iter [00100, 00390], lr: 0.100000, loss: 3.1104
2023-07-02 01:13:45 - train: epoch 0064, iter [00200, 00390], lr: 0.020000, loss: 2.7679
2023-07-02 01:13:46 - train: epoch 0050, iter [00150, 00390], lr: 0.100000, loss: 3.0848
2023-07-02 01:13:47 - train: epoch 0064, iter [00250, 00390], lr: 0.020000, loss: 3.4770
2023-07-02 01:13:49 - train: epoch 0050, iter [00200, 00390], lr: 0.100000, loss: 3.1213
2023-07-02 01:13:49 - train: epoch 0064, iter [00300, 00390], lr: 0.020000, loss: 3.2589
2023-07-02 01:13:51 - train: epoch 0050, iter [00250, 00390], lr: 0.100000, loss: 3.2694
2023-07-02 01:13:52 - train: epoch 0064, iter [00350, 00390], lr: 0.020000, loss: 3.4762
2023-07-02 01:13:53 - train: epoch 0050, iter [00300, 00390], lr: 0.100000, loss: 3.2262
2023-07-02 01:13:53 - train: epoch 064, train_loss: 3.0188
2023-07-02 01:13:55 - train: epoch 0050, iter [00350, 00390], lr: 0.100000, loss: 3.1559
2023-07-02 01:13:55 - eval: epoch: 064, acc1: 32.250%, acc5: 62.480%, test_loss: 2.7113, per_image_load_time: 0.066ms, per_image_inference_time: 0.054ms
2023-07-02 01:13:55 - until epoch: 064, best_acc1: 32.250%
2023-07-02 01:13:55 - epoch 065 lr: 0.020000
2023-07-02 01:13:56 - train: epoch 050, train_loss: 3.1741
2023-07-02 01:13:57 - eval: epoch: 050, acc1: 29.340%, acc5: 59.660%, test_loss: 2.8677, per_image_load_time: 0.074ms, per_image_inference_time: 0.059ms
2023-07-02 01:13:58 - train: epoch 0065, iter [00050, 00390], lr: 0.020000, loss: 2.7442
2023-07-02 01:13:58 - until epoch: 050, best_acc1: 29.340%
2023-07-02 01:13:58 - epoch 051 lr: 0.100000
2023-07-02 01:13:59 - train: epoch 0065, iter [00100, 00390], lr: 0.020000, loss: 2.8822
2023-07-02 01:14:01 - train: epoch 0051, iter [00050, 00390], lr: 0.100000, loss: 3.3942
2023-07-02 01:14:01 - train: epoch 0065, iter [00150, 00390], lr: 0.020000, loss: 3.2016
2023-07-02 01:14:03 - train: epoch 0051, iter [00100, 00390], lr: 0.100000, loss: 3.1665
2023-07-02 01:14:04 - train: epoch 0065, iter [00200, 00390], lr: 0.020000, loss: 2.9764
2023-07-02 01:14:05 - train: epoch 0051, iter [00150, 00390], lr: 0.100000, loss: 3.0995
2023-07-02 01:14:06 - train: epoch 0065, iter [00250, 00390], lr: 0.020000, loss: 2.8313
2023-07-02 01:14:07 - train: epoch 0051, iter [00200, 00390], lr: 0.100000, loss: 3.1016
2023-07-02 01:14:08 - train: epoch 0065, iter [00300, 00390], lr: 0.020000, loss: 2.8316
2023-07-02 01:14:10 - train: epoch 0051, iter [00250, 00390], lr: 0.100000, loss: 3.2978
2023-07-02 01:14:10 - train: epoch 0065, iter [00350, 00390], lr: 0.020000, loss: 3.2195
2023-07-02 01:14:11 - train: epoch 065, train_loss: 3.0095
2023-07-02 01:14:12 - train: epoch 0051, iter [00300, 00390], lr: 0.100000, loss: 2.9685
2023-07-02 01:14:13 - eval: epoch: 065, acc1: 32.200%, acc5: 62.350%, test_loss: 2.7023, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:14:13 - until epoch: 065, best_acc1: 32.250%
2023-07-02 01:14:13 - epoch 066 lr: 0.020000
2023-07-02 01:14:13 - train: epoch 0051, iter [00350, 00390], lr: 0.100000, loss: 2.9025
2023-07-02 01:14:15 - train: epoch 051, train_loss: 3.1642
2023-07-02 01:14:16 - train: epoch 0066, iter [00050, 00390], lr: 0.020000, loss: 3.1060
2023-07-02 01:14:16 - eval: epoch: 051, acc1: 29.380%, acc5: 59.610%, test_loss: 2.8634, per_image_load_time: 0.070ms, per_image_inference_time: 0.056ms
2023-07-02 01:14:17 - until epoch: 051, best_acc1: 29.380%
2023-07-02 01:14:17 - epoch 052 lr: 0.100000
2023-07-02 01:14:17 - train: epoch 0066, iter [00100, 00390], lr: 0.020000, loss: 2.8025
2023-07-02 01:14:19 - train: epoch 0066, iter [00150, 00390], lr: 0.020000, loss: 2.9189
2023-07-02 01:14:20 - train: epoch 0052, iter [00050, 00390], lr: 0.100000, loss: 3.4478
2023-07-02 01:14:21 - train: epoch 0066, iter [00200, 00390], lr: 0.020000, loss: 2.9466
2023-07-02 01:14:22 - train: epoch 0052, iter [00100, 00390], lr: 0.100000, loss: 3.1842
2023-07-02 01:14:23 - train: epoch 0066, iter [00250, 00390], lr: 0.020000, loss: 2.8178
2023-07-02 01:14:24 - train: epoch 0052, iter [00150, 00390], lr: 0.100000, loss: 3.3488
2023-07-02 01:14:25 - train: epoch 0066, iter [00300, 00390], lr: 0.020000, loss: 2.5361
2023-07-02 01:14:26 - train: epoch 0052, iter [00200, 00390], lr: 0.100000, loss: 3.2342
2023-07-02 01:14:28 - train: epoch 0066, iter [00350, 00390], lr: 0.020000, loss: 2.7122
2023-07-02 01:14:28 - train: epoch 0052, iter [00250, 00390], lr: 0.100000, loss: 3.2809
2023-07-02 01:14:29 - train: epoch 066, train_loss: 3.0043
2023-07-02 01:14:30 - train: epoch 0052, iter [00300, 00390], lr: 0.100000, loss: 3.2001
2023-07-02 01:14:31 - eval: epoch: 066, acc1: 31.090%, acc5: 61.290%, test_loss: 2.7450, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 01:14:31 - until epoch: 066, best_acc1: 32.250%
2023-07-02 01:14:31 - epoch 067 lr: 0.020000
2023-07-02 01:14:31 - train: epoch 0052, iter [00350, 00390], lr: 0.100000, loss: 3.2102
2023-07-02 01:14:33 - train: epoch 052, train_loss: 3.1667
2023-07-02 01:14:34 - train: epoch 0067, iter [00050, 00390], lr: 0.020000, loss: 2.9062
2023-07-02 01:14:34 - eval: epoch: 052, acc1: 29.760%, acc5: 59.580%, test_loss: 2.8445, per_image_load_time: 0.066ms, per_image_inference_time: 0.058ms
2023-07-02 01:14:35 - until epoch: 052, best_acc1: 29.760%
2023-07-02 01:14:35 - epoch 053 lr: 0.100000
2023-07-02 01:14:35 - train: epoch 0067, iter [00100, 00390], lr: 0.020000, loss: 2.7718
2023-07-02 01:14:37 - train: epoch 0067, iter [00150, 00390], lr: 0.020000, loss: 2.6021
2023-07-02 01:14:38 - train: epoch 0053, iter [00050, 00390], lr: 0.100000, loss: 3.0353
2023-07-02 01:14:39 - train: epoch 0067, iter [00200, 00390], lr: 0.020000, loss: 2.6568
2023-07-02 01:14:40 - train: epoch 0053, iter [00100, 00390], lr: 0.100000, loss: 2.9322
2023-07-02 01:14:41 - train: epoch 0067, iter [00250, 00390], lr: 0.020000, loss: 2.4904
2023-07-02 01:14:42 - train: epoch 0053, iter [00150, 00390], lr: 0.100000, loss: 3.0070
2023-07-02 01:14:43 - train: epoch 0067, iter [00300, 00390], lr: 0.020000, loss: 3.0481
2023-07-02 01:14:44 - train: epoch 0053, iter [00200, 00390], lr: 0.100000, loss: 3.0534
2023-07-02 01:14:45 - train: epoch 0067, iter [00350, 00390], lr: 0.020000, loss: 3.1899
2023-07-02 01:14:46 - train: epoch 0053, iter [00250, 00390], lr: 0.100000, loss: 3.2594
2023-07-02 01:14:47 - train: epoch 067, train_loss: 2.9884
2023-07-02 01:14:48 - train: epoch 0053, iter [00300, 00390], lr: 0.100000, loss: 3.0350
2023-07-02 01:14:49 - eval: epoch: 067, acc1: 31.600%, acc5: 61.510%, test_loss: 2.7411, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 01:14:49 - until epoch: 067, best_acc1: 32.250%
2023-07-02 01:14:49 - epoch 068 lr: 0.020000
2023-07-02 01:14:50 - train: epoch 0053, iter [00350, 00390], lr: 0.100000, loss: 3.1440
2023-07-02 01:14:52 - train: epoch 053, train_loss: 3.1685
2023-07-02 01:14:52 - train: epoch 0068, iter [00050, 00390], lr: 0.020000, loss: 2.9113
2023-07-02 01:14:53 - eval: epoch: 053, acc1: 28.200%, acc5: 58.940%, test_loss: 2.8883, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:14:53 - until epoch: 053, best_acc1: 29.760%
2023-07-02 01:14:53 - epoch 054 lr: 0.100000
2023-07-02 01:14:53 - train: epoch 0068, iter [00100, 00390], lr: 0.020000, loss: 2.7804
2023-07-02 01:14:55 - train: epoch 0068, iter [00150, 00390], lr: 0.020000, loss: 3.5577
2023-07-02 01:14:56 - train: epoch 0054, iter [00050, 00390], lr: 0.100000, loss: 3.3050
2023-07-02 01:14:57 - train: epoch 0068, iter [00200, 00390], lr: 0.020000, loss: 3.0420
2023-07-02 01:14:58 - train: epoch 0054, iter [00100, 00390], lr: 0.100000, loss: 3.2520
2023-07-02 01:14:59 - train: epoch 0068, iter [00250, 00390], lr: 0.020000, loss: 3.2844
2023-07-02 01:15:00 - train: epoch 0054, iter [00150, 00390], lr: 0.100000, loss: 3.0600
2023-07-02 01:15:01 - train: epoch 0068, iter [00300, 00390], lr: 0.020000, loss: 3.0136
2023-07-02 01:15:02 - train: epoch 0054, iter [00200, 00390], lr: 0.100000, loss: 3.3736
2023-07-02 01:15:03 - train: epoch 0068, iter [00350, 00390], lr: 0.020000, loss: 2.9489
2023-07-02 01:15:04 - train: epoch 0054, iter [00250, 00390], lr: 0.100000, loss: 3.1901
2023-07-02 01:15:05 - train: epoch 068, train_loss: 3.0032
2023-07-02 01:15:06 - train: epoch 0054, iter [00300, 00390], lr: 0.100000, loss: 3.1930
2023-07-02 01:15:06 - eval: epoch: 068, acc1: 32.480%, acc5: 61.720%, test_loss: 2.7272, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 01:15:07 - until epoch: 068, best_acc1: 32.480%
2023-07-02 01:15:07 - epoch 069 lr: 0.020000
2023-07-02 01:15:08 - train: epoch 0054, iter [00350, 00390], lr: 0.100000, loss: 3.0413
2023-07-02 01:15:09 - train: epoch 0069, iter [00050, 00390], lr: 0.020000, loss: 3.0677
2023-07-02 01:15:10 - train: epoch 054, train_loss: 3.1543
2023-07-02 01:15:11 - eval: epoch: 054, acc1: 29.120%, acc5: 58.570%, test_loss: 2.8785, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:15:11 - until epoch: 054, best_acc1: 29.760%
2023-07-02 01:15:11 - epoch 055 lr: 0.100000
2023-07-02 01:15:11 - train: epoch 0069, iter [00100, 00390], lr: 0.020000, loss: 2.7467
2023-07-02 01:15:13 - train: epoch 0069, iter [00150, 00390], lr: 0.020000, loss: 2.7229
2023-07-02 01:15:14 - train: epoch 0055, iter [00050, 00390], lr: 0.100000, loss: 3.2473
2023-07-02 01:15:15 - train: epoch 0069, iter [00200, 00390], lr: 0.020000, loss: 3.3078
2023-07-02 01:15:16 - train: epoch 0055, iter [00100, 00390], lr: 0.100000, loss: 3.2111
2023-07-02 01:15:17 - train: epoch 0069, iter [00250, 00390], lr: 0.020000, loss: 3.0749
2023-07-02 01:15:18 - train: epoch 0055, iter [00150, 00390], lr: 0.100000, loss: 3.1865
2023-07-02 01:15:19 - train: epoch 0069, iter [00300, 00390], lr: 0.020000, loss: 2.9143
2023-07-02 01:15:20 - train: epoch 0055, iter [00200, 00390], lr: 0.100000, loss: 3.1713
2023-07-02 01:15:21 - train: epoch 0069, iter [00350, 00390], lr: 0.020000, loss: 3.1075
2023-07-02 01:15:23 - train: epoch 0055, iter [00250, 00390], lr: 0.100000, loss: 3.0481
2023-07-02 01:15:23 - train: epoch 069, train_loss: 2.9936
2023-07-02 01:15:24 - eval: epoch: 069, acc1: 32.320%, acc5: 62.630%, test_loss: 2.7026, per_image_load_time: 0.072ms, per_image_inference_time: 0.066ms
2023-07-02 01:15:24 - train: epoch 0055, iter [00300, 00390], lr: 0.100000, loss: 3.0903
2023-07-02 01:15:24 - until epoch: 069, best_acc1: 32.480%
2023-07-02 01:15:24 - epoch 070 lr: 0.020000
2023-07-02 01:15:26 - train: epoch 0055, iter [00350, 00390], lr: 0.100000, loss: 3.1513
2023-07-02 01:15:27 - train: epoch 0070, iter [00050, 00390], lr: 0.020000, loss: 3.1756
2023-07-02 01:15:28 - train: epoch 055, train_loss: 3.1532
2023-07-02 01:15:29 - train: epoch 0070, iter [00100, 00390], lr: 0.020000, loss: 3.2681
2023-07-02 01:15:29 - eval: epoch: 055, acc1: 30.420%, acc5: 60.710%, test_loss: 2.8107, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:15:30 - until epoch: 055, best_acc1: 30.420%
2023-07-02 01:15:30 - epoch 056 lr: 0.100000
2023-07-02 01:15:30 - train: epoch 0070, iter [00150, 00390], lr: 0.020000, loss: 2.8981
2023-07-02 01:15:32 - train: epoch 0070, iter [00200, 00390], lr: 0.020000, loss: 2.7308
2023-07-02 01:15:33 - train: epoch 0056, iter [00050, 00390], lr: 0.100000, loss: 3.3851
2023-07-02 01:15:35 - train: epoch 0070, iter [00250, 00390], lr: 0.020000, loss: 2.6641
2023-07-02 01:15:35 - train: epoch 0056, iter [00100, 00390], lr: 0.100000, loss: 2.8854
2023-07-02 01:15:37 - train: epoch 0070, iter [00300, 00390], lr: 0.020000, loss: 2.5116
2023-07-02 01:15:37 - train: epoch 0056, iter [00150, 00390], lr: 0.100000, loss: 2.8786
2023-07-02 01:15:39 - train: epoch 0070, iter [00350, 00390], lr: 0.020000, loss: 3.4477
2023-07-02 01:15:39 - train: epoch 0056, iter [00200, 00390], lr: 0.100000, loss: 3.1031
2023-07-02 01:15:40 - train: epoch 070, train_loss: 2.9655
2023-07-02 01:15:41 - train: epoch 0056, iter [00250, 00390], lr: 0.100000, loss: 3.0759
2023-07-02 01:15:42 - eval: epoch: 070, acc1: 32.900%, acc5: 63.300%, test_loss: 2.6775, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:15:42 - until epoch: 070, best_acc1: 32.900%
2023-07-02 01:15:42 - epoch 071 lr: 0.020000
2023-07-02 01:15:43 - train: epoch 0056, iter [00300, 00390], lr: 0.100000, loss: 3.4625
2023-07-02 01:15:45 - train: epoch 0056, iter [00350, 00390], lr: 0.100000, loss: 2.8029
2023-07-02 01:15:45 - train: epoch 0071, iter [00050, 00390], lr: 0.020000, loss: 3.0655
2023-07-02 01:15:47 - train: epoch 056, train_loss: 3.1474
2023-07-02 01:15:47 - train: epoch 0071, iter [00100, 00390], lr: 0.020000, loss: 3.1392
2023-07-02 01:15:48 - eval: epoch: 056, acc1: 29.840%, acc5: 60.130%, test_loss: 2.8470, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:15:48 - until epoch: 056, best_acc1: 30.420%
2023-07-02 01:15:48 - epoch 057 lr: 0.100000
2023-07-02 01:15:49 - train: epoch 0071, iter [00150, 00390], lr: 0.020000, loss: 3.2596
2023-07-02 01:15:51 - train: epoch 0071, iter [00200, 00390], lr: 0.020000, loss: 3.4968
2023-07-02 01:15:51 - train: epoch 0057, iter [00050, 00390], lr: 0.100000, loss: 3.1787
2023-07-02 01:15:53 - train: epoch 0071, iter [00250, 00390], lr: 0.020000, loss: 3.0016
2023-07-02 01:15:53 - train: epoch 0057, iter [00100, 00390], lr: 0.100000, loss: 3.2145
2023-07-02 01:15:55 - train: epoch 0071, iter [00300, 00390], lr: 0.020000, loss: 3.7728
2023-07-02 01:15:55 - train: epoch 0057, iter [00150, 00390], lr: 0.100000, loss: 2.8777
2023-07-02 01:15:57 - train: epoch 0071, iter [00350, 00390], lr: 0.020000, loss: 3.0331
2023-07-02 01:15:58 - train: epoch 0057, iter [00200, 00390], lr: 0.100000, loss: 3.3020
2023-07-02 01:15:58 - train: epoch 071, train_loss: 2.9909
2023-07-02 01:15:59 - train: epoch 0057, iter [00250, 00390], lr: 0.100000, loss: 3.3216
2023-07-02 01:16:00 - eval: epoch: 071, acc1: 31.780%, acc5: 62.800%, test_loss: 2.7050, per_image_load_time: 0.070ms, per_image_inference_time: 0.055ms
2023-07-02 01:16:00 - until epoch: 071, best_acc1: 32.900%
2023-07-02 01:16:00 - epoch 072 lr: 0.020000
2023-07-02 01:16:01 - train: epoch 0057, iter [00300, 00390], lr: 0.100000, loss: 3.0419
2023-07-02 01:16:03 - train: epoch 0072, iter [00050, 00390], lr: 0.020000, loss: 3.5927
2023-07-02 01:16:04 - train: epoch 0057, iter [00350, 00390], lr: 0.100000, loss: 3.1410
2023-07-02 01:16:05 - train: epoch 0072, iter [00100, 00390], lr: 0.020000, loss: 3.2967
2023-07-02 01:16:06 - train: epoch 057, train_loss: 3.1419
2023-07-02 01:16:07 - train: epoch 0072, iter [00150, 00390], lr: 0.020000, loss: 3.4719
2023-07-02 01:16:07 - eval: epoch: 057, acc1: 29.430%, acc5: 59.410%, test_loss: 2.8577, per_image_load_time: 0.069ms, per_image_inference_time: 0.057ms
2023-07-02 01:16:07 - until epoch: 057, best_acc1: 30.420%
2023-07-02 01:16:07 - epoch 058 lr: 0.100000
2023-07-02 01:16:09 - train: epoch 0072, iter [00200, 00390], lr: 0.020000, loss: 2.8866
2023-07-02 01:16:10 - train: epoch 0058, iter [00050, 00390], lr: 0.100000, loss: 3.0619
2023-07-02 01:16:11 - train: epoch 0072, iter [00250, 00390], lr: 0.020000, loss: 2.5452
2023-07-02 01:16:12 - train: epoch 0058, iter [00100, 00390], lr: 0.100000, loss: 3.1787
2023-07-02 01:16:13 - train: epoch 0072, iter [00300, 00390], lr: 0.020000, loss: 2.6696
2023-07-02 01:16:14 - train: epoch 0058, iter [00150, 00390], lr: 0.100000, loss: 3.0719
2023-07-02 01:16:15 - train: epoch 0072, iter [00350, 00390], lr: 0.020000, loss: 3.2999
2023-07-02 01:16:16 - train: epoch 0058, iter [00200, 00390], lr: 0.100000, loss: 3.2819
2023-07-02 01:16:17 - train: epoch 072, train_loss: 2.9781
2023-07-02 01:16:18 - eval: epoch: 072, acc1: 32.180%, acc5: 61.890%, test_loss: 2.7203, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 01:16:18 - train: epoch 0058, iter [00250, 00390], lr: 0.100000, loss: 3.2479
2023-07-02 01:16:18 - until epoch: 072, best_acc1: 32.900%
2023-07-02 01:16:18 - epoch 073 lr: 0.020000
2023-07-02 01:16:20 - train: epoch 0058, iter [00300, 00390], lr: 0.100000, loss: 3.2374
2023-07-02 01:16:21 - train: epoch 0073, iter [00050, 00390], lr: 0.020000, loss: 2.6883
2023-07-02 01:16:22 - train: epoch 0058, iter [00350, 00390], lr: 0.100000, loss: 3.2236
2023-07-02 01:16:23 - train: epoch 0073, iter [00100, 00390], lr: 0.020000, loss: 2.7014
2023-07-02 01:16:24 - train: epoch 058, train_loss: 3.1355
2023-07-02 01:16:25 - train: epoch 0073, iter [00150, 00390], lr: 0.020000, loss: 3.3320
2023-07-02 01:16:25 - eval: epoch: 058, acc1: 29.620%, acc5: 58.980%, test_loss: 2.8649, per_image_load_time: 0.070ms, per_image_inference_time: 0.056ms
2023-07-02 01:16:26 - until epoch: 058, best_acc1: 30.420%
2023-07-02 01:16:26 - epoch 059 lr: 0.100000
2023-07-02 01:16:27 - train: epoch 0073, iter [00200, 00390], lr: 0.020000, loss: 2.8843
2023-07-02 01:16:29 - train: epoch 0059, iter [00050, 00390], lr: 0.100000, loss: 3.0362
2023-07-02 01:16:29 - train: epoch 0073, iter [00250, 00390], lr: 0.020000, loss: 2.8706
2023-07-02 01:16:31 - train: epoch 0059, iter [00100, 00390], lr: 0.100000, loss: 3.1356
2023-07-02 01:16:31 - train: epoch 0073, iter [00300, 00390], lr: 0.020000, loss: 3.0794
2023-07-02 01:16:33 - train: epoch 0059, iter [00150, 00390], lr: 0.100000, loss: 3.2010
2023-07-02 01:16:33 - train: epoch 0073, iter [00350, 00390], lr: 0.020000, loss: 2.9028
2023-07-02 01:16:34 - train: epoch 073, train_loss: 2.9583
2023-07-02 01:16:35 - train: epoch 0059, iter [00200, 00390], lr: 0.100000, loss: 3.0965
2023-07-02 01:16:36 - eval: epoch: 073, acc1: 33.300%, acc5: 62.740%, test_loss: 2.6763, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 01:16:36 - train: epoch 0059, iter [00250, 00390], lr: 0.100000, loss: 3.4058
2023-07-02 01:16:37 - until epoch: 073, best_acc1: 33.300%
2023-07-02 01:16:37 - epoch 074 lr: 0.020000
2023-07-02 01:16:38 - train: epoch 0059, iter [00300, 00390], lr: 0.100000, loss: 3.2497
2023-07-02 01:16:40 - train: epoch 0059, iter [00350, 00390], lr: 0.100000, loss: 3.2523
2023-07-02 01:16:40 - train: epoch 0074, iter [00050, 00390], lr: 0.020000, loss: 3.3793
2023-07-02 01:16:42 - train: epoch 059, train_loss: 3.1416
2023-07-02 01:16:42 - train: epoch 0074, iter [00100, 00390], lr: 0.020000, loss: 2.8919
2023-07-02 01:16:43 - eval: epoch: 059, acc1: 30.390%, acc5: 60.000%, test_loss: 2.8255, per_image_load_time: 0.069ms, per_image_inference_time: 0.056ms
2023-07-02 01:16:43 - until epoch: 059, best_acc1: 30.420%
2023-07-02 01:16:43 - epoch 060 lr: 0.100000
2023-07-02 01:16:44 - train: epoch 0074, iter [00150, 00390], lr: 0.020000, loss: 2.6313
2023-07-02 01:16:45 - train: epoch 0074, iter [00200, 00390], lr: 0.020000, loss: 3.1118
2023-07-02 01:16:46 - train: epoch 0060, iter [00050, 00390], lr: 0.100000, loss: 3.3862
2023-07-02 01:16:47 - train: epoch 0074, iter [00250, 00390], lr: 0.020000, loss: 2.9033
2023-07-02 01:16:48 - train: epoch 0060, iter [00100, 00390], lr: 0.100000, loss: 3.1076
2023-07-02 01:16:50 - train: epoch 0074, iter [00300, 00390], lr: 0.020000, loss: 3.2322
2023-07-02 01:16:50 - train: epoch 0060, iter [00150, 00390], lr: 0.100000, loss: 2.9484
2023-07-02 01:16:52 - train: epoch 0074, iter [00350, 00390], lr: 0.020000, loss: 4.0041
2023-07-02 01:16:52 - train: epoch 0060, iter [00200, 00390], lr: 0.100000, loss: 2.8540
2023-07-02 01:16:53 - train: epoch 074, train_loss: 2.9570
2023-07-02 01:16:54 - train: epoch 0060, iter [00250, 00390], lr: 0.100000, loss: 3.2171
2023-07-02 01:16:55 - eval: epoch: 074, acc1: 32.140%, acc5: 62.630%, test_loss: 2.7024, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-07-02 01:16:55 - until epoch: 074, best_acc1: 33.300%
2023-07-02 01:16:55 - epoch 075 lr: 0.020000
2023-07-02 01:16:56 - train: epoch 0060, iter [00300, 00390], lr: 0.100000, loss: 2.9399
2023-07-02 01:16:58 - train: epoch 0075, iter [00050, 00390], lr: 0.020000, loss: 2.7120
2023-07-02 01:16:58 - train: epoch 0060, iter [00350, 00390], lr: 0.100000, loss: 3.0998
2023-07-02 01:17:00 - train: epoch 0075, iter [00100, 00390], lr: 0.020000, loss: 3.5998
2023-07-02 01:17:00 - train: epoch 060, train_loss: 3.1313
2023-07-02 01:17:01 - eval: epoch: 060, acc1: 30.030%, acc5: 60.090%, test_loss: 2.8182, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:17:01 - train: epoch 0075, iter [00150, 00390], lr: 0.020000, loss: 3.0401
2023-07-02 01:17:02 - until epoch: 060, best_acc1: 30.420%
2023-07-02 01:17:02 - epoch 061 lr: 0.020000
2023-07-02 01:17:03 - train: epoch 0075, iter [00200, 00390], lr: 0.020000, loss: 2.5938
2023-07-02 01:17:05 - train: epoch 0061, iter [00050, 00390], lr: 0.020000, loss: 2.8863
2023-07-02 01:17:05 - train: epoch 0075, iter [00250, 00390], lr: 0.020000, loss: 3.2576
2023-07-02 01:17:07 - train: epoch 0061, iter [00100, 00390], lr: 0.020000, loss: 2.8142
2023-07-02 01:17:07 - train: epoch 0075, iter [00300, 00390], lr: 0.020000, loss: 2.8933
2023-07-02 01:17:09 - train: epoch 0061, iter [00150, 00390], lr: 0.020000, loss: 2.8404
2023-07-02 01:17:09 - train: epoch 0075, iter [00350, 00390], lr: 0.020000, loss: 2.8729
2023-07-02 01:17:11 - train: epoch 0061, iter [00200, 00390], lr: 0.020000, loss: 2.9401
2023-07-02 01:17:11 - train: epoch 075, train_loss: 2.9430
2023-07-02 01:17:13 - eval: epoch: 075, acc1: 32.960%, acc5: 62.720%, test_loss: 2.6844, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 01:17:13 - train: epoch 0061, iter [00250, 00390], lr: 0.020000, loss: 2.5867
2023-07-02 01:17:13 - until epoch: 075, best_acc1: 33.300%
2023-07-02 01:17:13 - epoch 076 lr: 0.020000
2023-07-02 01:17:14 - train: epoch 0061, iter [00300, 00390], lr: 0.020000, loss: 2.6295
2023-07-02 01:17:15 - train: epoch 0076, iter [00050, 00390], lr: 0.020000, loss: 2.8134
2023-07-02 01:17:17 - train: epoch 0061, iter [00350, 00390], lr: 0.020000, loss: 2.7659
2023-07-02 01:17:18 - train: epoch 0076, iter [00100, 00390], lr: 0.020000, loss: 2.7008
2023-07-02 01:17:18 - train: epoch 061, train_loss: 2.8656
2023-07-02 01:17:19 - train: epoch 0076, iter [00150, 00390], lr: 0.020000, loss: 3.0682
2023-07-02 01:17:20 - eval: epoch: 061, acc1: 36.330%, acc5: 65.810%, test_loss: 2.5533, per_image_load_time: 0.066ms, per_image_inference_time: 0.057ms
2023-07-02 01:17:21 - until epoch: 061, best_acc1: 36.330%
2023-07-02 01:17:21 - epoch 062 lr: 0.020000
2023-07-02 01:17:21 - train: epoch 0076, iter [00200, 00390], lr: 0.020000, loss: 2.4358
2023-07-02 01:17:23 - train: epoch 0076, iter [00250, 00390], lr: 0.020000, loss: 3.0348
2023-07-02 01:17:23 - train: epoch 0062, iter [00050, 00390], lr: 0.020000, loss: 2.3823
2023-07-02 01:17:25 - train: epoch 0076, iter [00300, 00390], lr: 0.020000, loss: 2.7783
2023-07-02 01:17:26 - train: epoch 0062, iter [00100, 00390], lr: 0.020000, loss: 2.7546
2023-07-02 01:17:27 - train: epoch 0076, iter [00350, 00390], lr: 0.020000, loss: 3.4246
2023-07-02 01:17:28 - train: epoch 0062, iter [00150, 00390], lr: 0.020000, loss: 2.9096
2023-07-02 01:17:29 - train: epoch 076, train_loss: 2.9355
2023-07-02 01:17:29 - train: epoch 0062, iter [00200, 00390], lr: 0.020000, loss: 2.6214
2023-07-02 01:17:30 - eval: epoch: 076, acc1: 33.180%, acc5: 63.410%, test_loss: 2.6823, per_image_load_time: 0.069ms, per_image_inference_time: 0.055ms
2023-07-02 01:17:30 - until epoch: 076, best_acc1: 33.300%
2023-07-02 01:17:30 - epoch 077 lr: 0.020000
2023-07-02 01:17:31 - train: epoch 0062, iter [00250, 00390], lr: 0.020000, loss: 2.8509
2023-07-02 01:17:33 - train: epoch 0077, iter [00050, 00390], lr: 0.020000, loss: 2.6614
2023-07-02 01:17:33 - train: epoch 0062, iter [00300, 00390], lr: 0.020000, loss: 2.7685
2023-07-02 01:17:35 - train: epoch 0077, iter [00100, 00390], lr: 0.020000, loss: 3.4978
2023-07-02 01:17:35 - train: epoch 0062, iter [00350, 00390], lr: 0.020000, loss: 2.8601
2023-07-02 01:17:37 - train: epoch 062, train_loss: 2.7744
2023-07-02 01:17:37 - train: epoch 0077, iter [00150, 00390], lr: 0.020000, loss: 2.7868
2023-07-02 01:17:39 - eval: epoch: 062, acc1: 36.990%, acc5: 66.450%, test_loss: 2.5321, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:17:39 - train: epoch 0077, iter [00200, 00390], lr: 0.020000, loss: 2.9526
2023-07-02 01:17:39 - until epoch: 062, best_acc1: 36.990%
2023-07-02 01:17:39 - epoch 063 lr: 0.020000
2023-07-02 01:17:41 - train: epoch 0077, iter [00250, 00390], lr: 0.020000, loss: 3.1614
2023-07-02 01:17:42 - train: epoch 0063, iter [00050, 00390], lr: 0.020000, loss: 2.7640
2023-07-02 01:17:43 - train: epoch 0077, iter [00300, 00390], lr: 0.020000, loss: 2.8286
2023-07-02 01:17:44 - train: epoch 0063, iter [00100, 00390], lr: 0.020000, loss: 2.8404
2023-07-02 01:17:45 - train: epoch 0077, iter [00350, 00390], lr: 0.020000, loss: 3.3418
2023-07-02 01:17:46 - train: epoch 0063, iter [00150, 00390], lr: 0.020000, loss: 2.5441
2023-07-02 01:17:46 - train: epoch 077, train_loss: 2.9393
2023-07-02 01:17:48 - eval: epoch: 077, acc1: 32.380%, acc5: 62.280%, test_loss: 2.6992, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:17:48 - train: epoch 0063, iter [00200, 00390], lr: 0.020000, loss: 2.6871
2023-07-02 01:17:48 - until epoch: 077, best_acc1: 33.300%
2023-07-02 01:17:48 - epoch 078 lr: 0.020000
2023-07-02 01:17:50 - train: epoch 0063, iter [00250, 00390], lr: 0.020000, loss: 2.7838
2023-07-02 01:17:51 - train: epoch 0078, iter [00050, 00390], lr: 0.020000, loss: 3.6834
2023-07-02 01:17:52 - train: epoch 0063, iter [00300, 00390], lr: 0.020000, loss: 2.9190
2023-07-02 01:17:53 - train: epoch 0078, iter [00100, 00390], lr: 0.020000, loss: 2.6969
2023-07-02 01:17:54 - train: epoch 0063, iter [00350, 00390], lr: 0.020000, loss: 2.6023
2023-07-02 01:17:55 - train: epoch 0078, iter [00150, 00390], lr: 0.020000, loss: 2.7240
2023-07-02 01:17:55 - train: epoch 063, train_loss: 2.7294
2023-07-02 01:17:57 - train: epoch 0078, iter [00200, 00390], lr: 0.020000, loss: 3.1724
2023-07-02 01:17:57 - eval: epoch: 063, acc1: 36.810%, acc5: 66.770%, test_loss: 2.5218, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:17:57 - until epoch: 063, best_acc1: 36.990%
2023-07-02 01:17:57 - epoch 064 lr: 0.020000
2023-07-02 01:17:58 - train: epoch 0078, iter [00250, 00390], lr: 0.020000, loss: 3.6980
2023-07-02 01:18:00 - train: epoch 0064, iter [00050, 00390], lr: 0.020000, loss: 2.6305
2023-07-02 01:18:00 - train: epoch 0078, iter [00300, 00390], lr: 0.020000, loss: 3.3245
2023-07-02 01:18:02 - train: epoch 0064, iter [00100, 00390], lr: 0.020000, loss: 2.6456
2023-07-02 01:18:02 - train: epoch 0078, iter [00350, 00390], lr: 0.020000, loss: 2.5842
2023-07-02 01:18:04 - train: epoch 078, train_loss: 2.9503
2023-07-02 01:18:04 - train: epoch 0064, iter [00150, 00390], lr: 0.020000, loss: 2.8175
2023-07-02 01:18:05 - eval: epoch: 078, acc1: 33.100%, acc5: 62.710%, test_loss: 2.6865, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 01:18:06 - until epoch: 078, best_acc1: 33.300%
2023-07-02 01:18:06 - epoch 079 lr: 0.020000
2023-07-02 01:18:06 - train: epoch 0064, iter [00200, 00390], lr: 0.020000, loss: 2.4736
2023-07-02 01:18:08 - train: epoch 0064, iter [00250, 00390], lr: 0.020000, loss: 2.8845
2023-07-02 01:18:09 - train: epoch 0079, iter [00050, 00390], lr: 0.020000, loss: 2.6556
2023-07-02 01:18:10 - train: epoch 0064, iter [00300, 00390], lr: 0.020000, loss: 2.6226
2023-07-02 01:18:11 - train: epoch 0079, iter [00100, 00390], lr: 0.020000, loss: 2.5284
2023-07-02 01:18:12 - train: epoch 0064, iter [00350, 00390], lr: 0.020000, loss: 2.6644
2023-07-02 01:18:13 - train: epoch 0079, iter [00150, 00390], lr: 0.020000, loss: 2.9829
2023-07-02 01:18:14 - train: epoch 064, train_loss: 2.7110
2023-07-02 01:18:14 - train: epoch 0079, iter [00200, 00390], lr: 0.020000, loss: 2.9602
2023-07-02 01:18:15 - eval: epoch: 064, acc1: 37.080%, acc5: 66.840%, test_loss: 2.5120, per_image_load_time: 0.070ms, per_image_inference_time: 0.057ms
2023-07-02 01:18:16 - until epoch: 064, best_acc1: 37.080%
2023-07-02 01:18:16 - epoch 065 lr: 0.020000
2023-07-02 01:18:16 - train: epoch 0079, iter [00250, 00390], lr: 0.020000, loss: 3.2778
2023-07-02 01:18:18 - train: epoch 0079, iter [00300, 00390], lr: 0.020000, loss: 3.7965
2023-07-02 01:18:18 - train: epoch 0065, iter [00050, 00390], lr: 0.020000, loss: 2.6233
2023-07-02 01:18:20 - train: epoch 0079, iter [00350, 00390], lr: 0.020000, loss: 2.7153
2023-07-02 01:18:21 - train: epoch 0065, iter [00100, 00390], lr: 0.020000, loss: 2.5827
2023-07-02 01:18:22 - train: epoch 079, train_loss: 2.9368
2023-07-02 01:18:22 - train: epoch 0065, iter [00150, 00390], lr: 0.020000, loss: 2.7969
2023-07-02 01:18:23 - eval: epoch: 079, acc1: 33.430%, acc5: 63.010%, test_loss: 2.6640, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 01:18:24 - until epoch: 079, best_acc1: 33.430%
2023-07-02 01:18:24 - epoch 080 lr: 0.020000
2023-07-02 01:18:24 - train: epoch 0065, iter [00200, 00390], lr: 0.020000, loss: 2.7827
2023-07-02 01:18:26 - train: epoch 0080, iter [00050, 00390], lr: 0.020000, loss: 2.7943
2023-07-02 01:18:26 - train: epoch 0065, iter [00250, 00390], lr: 0.020000, loss: 2.6284
2023-07-02 01:18:28 - train: epoch 0080, iter [00100, 00390], lr: 0.020000, loss: 2.9803
2023-07-02 01:18:28 - train: epoch 0065, iter [00300, 00390], lr: 0.020000, loss: 2.7324
2023-07-02 01:18:30 - train: epoch 0080, iter [00150, 00390], lr: 0.020000, loss: 2.7924
2023-07-02 01:18:31 - train: epoch 0065, iter [00350, 00390], lr: 0.020000, loss: 2.8802
2023-07-02 01:18:32 - train: epoch 065, train_loss: 2.6870
2023-07-02 01:18:32 - train: epoch 0080, iter [00200, 00390], lr: 0.020000, loss: 3.3795
2023-07-02 01:18:34 - eval: epoch: 065, acc1: 36.920%, acc5: 66.820%, test_loss: 2.5177, per_image_load_time: 0.068ms, per_image_inference_time: 0.057ms
2023-07-02 01:18:34 - train: epoch 0080, iter [00250, 00390], lr: 0.020000, loss: 2.5047
2023-07-02 01:18:34 - until epoch: 065, best_acc1: 37.080%
2023-07-02 01:18:34 - epoch 066 lr: 0.020000
2023-07-02 01:18:36 - train: epoch 0080, iter [00300, 00390], lr: 0.020000, loss: 2.9311
2023-07-02 01:18:37 - train: epoch 0066, iter [00050, 00390], lr: 0.020000, loss: 2.4507
2023-07-02 01:18:38 - train: epoch 0080, iter [00350, 00390], lr: 0.020000, loss: 3.5808
2023-07-02 01:18:39 - train: epoch 0066, iter [00100, 00390], lr: 0.020000, loss: 2.5495
2023-07-02 01:18:39 - train: epoch 080, train_loss: 2.9347
2023-07-02 01:18:41 - train: epoch 0066, iter [00150, 00390], lr: 0.020000, loss: 2.5613
2023-07-02 01:18:41 - eval: epoch: 080, acc1: 32.750%, acc5: 63.230%, test_loss: 2.6823, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 01:18:41 - until epoch: 080, best_acc1: 33.430%
2023-07-02 01:18:41 - epoch 081 lr: 0.020000
2023-07-02 01:18:42 - train: epoch 0066, iter [00200, 00390], lr: 0.020000, loss: 2.7489
2023-07-02 01:18:44 - train: epoch 0081, iter [00050, 00390], lr: 0.020000, loss: 3.0542
2023-07-02 01:18:44 - train: epoch 0066, iter [00250, 00390], lr: 0.020000, loss: 2.7986
2023-07-02 01:18:46 - train: epoch 0081, iter [00100, 00390], lr: 0.020000, loss: 2.9582
2023-07-02 01:18:46 - train: epoch 0066, iter [00300, 00390], lr: 0.020000, loss: 2.3178
2023-07-02 01:18:48 - train: epoch 0081, iter [00150, 00390], lr: 0.020000, loss: 3.6389
2023-07-02 01:18:48 - train: epoch 0066, iter [00350, 00390], lr: 0.020000, loss: 2.7055
2023-07-02 01:18:50 - train: epoch 066, train_loss: 2.6786
2023-07-02 01:18:50 - train: epoch 0081, iter [00200, 00390], lr: 0.020000, loss: 2.5139
2023-07-02 01:18:52 - eval: epoch: 066, acc1: 37.340%, acc5: 66.920%, test_loss: 2.5163, per_image_load_time: 0.066ms, per_image_inference_time: 0.057ms
2023-07-02 01:18:52 - train: epoch 0081, iter [00250, 00390], lr: 0.020000, loss: 2.9743
2023-07-02 01:18:52 - until epoch: 066, best_acc1: 37.340%
2023-07-02 01:18:52 - epoch 067 lr: 0.020000
2023-07-02 01:18:54 - train: epoch 0081, iter [00300, 00390], lr: 0.020000, loss: 2.9712
2023-07-02 01:18:55 - train: epoch 0067, iter [00050, 00390], lr: 0.020000, loss: 2.6598
2023-07-02 01:18:56 - train: epoch 0081, iter [00350, 00390], lr: 0.020000, loss: 2.7296
2023-07-02 01:18:57 - train: epoch 0067, iter [00100, 00390], lr: 0.020000, loss: 2.6545
2023-07-02 01:18:57 - train: epoch 081, train_loss: 2.9422
2023-07-02 01:18:59 - eval: epoch: 081, acc1: 33.570%, acc5: 63.970%, test_loss: 2.6574, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:18:59 - train: epoch 0067, iter [00150, 00390], lr: 0.020000, loss: 2.5346
2023-07-02 01:18:59 - until epoch: 081, best_acc1: 33.570%
2023-07-02 01:18:59 - epoch 082 lr: 0.020000
2023-07-02 01:19:00 - train: epoch 0067, iter [00200, 00390], lr: 0.020000, loss: 2.6550
2023-07-02 01:19:02 - train: epoch 0082, iter [00050, 00390], lr: 0.020000, loss: 3.5109
2023-07-02 01:19:02 - train: epoch 0067, iter [00250, 00390], lr: 0.020000, loss: 2.5251
2023-07-02 01:19:04 - train: epoch 0082, iter [00100, 00390], lr: 0.020000, loss: 2.7530
2023-07-02 01:19:05 - train: epoch 0067, iter [00300, 00390], lr: 0.020000, loss: 2.5341
2023-07-02 01:19:06 - train: epoch 0082, iter [00150, 00390], lr: 0.020000, loss: 3.3458
2023-07-02 01:19:07 - train: epoch 0067, iter [00350, 00390], lr: 0.020000, loss: 2.6052
2023-07-02 01:19:08 - train: epoch 0082, iter [00200, 00390], lr: 0.020000, loss: 3.0057
2023-07-02 01:19:08 - train: epoch 067, train_loss: 2.6727
2023-07-02 01:19:10 - eval: epoch: 067, acc1: 36.860%, acc5: 66.720%, test_loss: 2.5338, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:19:10 - train: epoch 0082, iter [00250, 00390], lr: 0.020000, loss: 3.2390
2023-07-02 01:19:10 - until epoch: 067, best_acc1: 37.340%
2023-07-02 01:19:10 - epoch 068 lr: 0.020000
2023-07-02 01:19:12 - train: epoch 0082, iter [00300, 00390], lr: 0.020000, loss: 2.4868
2023-07-02 01:19:13 - train: epoch 0068, iter [00050, 00390], lr: 0.020000, loss: 2.4618
2023-07-02 01:19:14 - train: epoch 0082, iter [00350, 00390], lr: 0.020000, loss: 2.6678
2023-07-02 01:19:15 - train: epoch 0068, iter [00100, 00390], lr: 0.020000, loss: 2.5245
2023-07-02 01:19:15 - train: epoch 082, train_loss: 2.9430
2023-07-02 01:19:17 - train: epoch 0068, iter [00150, 00390], lr: 0.020000, loss: 2.5792
2023-07-02 01:19:17 - eval: epoch: 082, acc1: 32.360%, acc5: 62.690%, test_loss: 2.7018, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 01:19:17 - until epoch: 082, best_acc1: 33.570%
2023-07-02 01:19:17 - epoch 083 lr: 0.020000
2023-07-02 01:19:18 - train: epoch 0068, iter [00200, 00390], lr: 0.020000, loss: 2.8340
2023-07-02 01:19:20 - train: epoch 0083, iter [00050, 00390], lr: 0.020000, loss: 2.8173
2023-07-02 01:19:21 - train: epoch 0068, iter [00250, 00390], lr: 0.020000, loss: 2.6333
2023-07-02 01:19:22 - train: epoch 0083, iter [00100, 00390], lr: 0.020000, loss: 2.7769
2023-07-02 01:19:23 - train: epoch 0068, iter [00300, 00390], lr: 0.020000, loss: 2.7766
2023-07-02 01:19:24 - train: epoch 0083, iter [00150, 00390], lr: 0.020000, loss: 3.1097
2023-07-02 01:19:25 - train: epoch 0068, iter [00350, 00390], lr: 0.020000, loss: 2.8485
2023-07-02 01:19:26 - train: epoch 0083, iter [00200, 00390], lr: 0.020000, loss: 2.4578
2023-07-02 01:19:27 - train: epoch 068, train_loss: 2.6580
2023-07-02 01:19:28 - train: epoch 0083, iter [00250, 00390], lr: 0.020000, loss: 2.5017
2023-07-02 01:19:28 - eval: epoch: 068, acc1: 36.520%, acc5: 66.380%, test_loss: 2.5389, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:19:28 - until epoch: 068, best_acc1: 37.340%
2023-07-02 01:19:28 - epoch 069 lr: 0.020000
2023-07-02 01:19:29 - train: epoch 0083, iter [00300, 00390], lr: 0.020000, loss: 2.9327
2023-07-02 01:19:31 - train: epoch 0069, iter [00050, 00390], lr: 0.020000, loss: 2.9033
2023-07-02 01:19:31 - train: epoch 0083, iter [00350, 00390], lr: 0.020000, loss: 2.5502
2023-07-02 01:19:33 - train: epoch 083, train_loss: 2.9380
2023-07-02 01:19:33 - train: epoch 0069, iter [00100, 00390], lr: 0.020000, loss: 2.6534
2023-07-02 01:19:34 - eval: epoch: 083, acc1: 33.300%, acc5: 63.910%, test_loss: 2.6500, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:19:35 - until epoch: 083, best_acc1: 33.570%
2023-07-02 01:19:35 - epoch 084 lr: 0.020000
2023-07-02 01:19:35 - train: epoch 0069, iter [00150, 00390], lr: 0.020000, loss: 2.5962
2023-07-02 01:19:37 - train: epoch 0069, iter [00200, 00390], lr: 0.020000, loss: 2.6863
2023-07-02 01:19:38 - train: epoch 0084, iter [00050, 00390], lr: 0.020000, loss: 2.6754
2023-07-02 01:19:39 - train: epoch 0069, iter [00250, 00390], lr: 0.020000, loss: 2.8756
2023-07-02 01:19:40 - train: epoch 0084, iter [00100, 00390], lr: 0.020000, loss: 3.1741
2023-07-02 01:19:41 - train: epoch 0069, iter [00300, 00390], lr: 0.020000, loss: 2.6283
2023-07-02 01:19:42 - train: epoch 0084, iter [00150, 00390], lr: 0.020000, loss: 2.9374
2023-07-02 01:19:43 - train: epoch 0069, iter [00350, 00390], lr: 0.020000, loss: 2.5215
2023-07-02 01:19:44 - train: epoch 0084, iter [00200, 00390], lr: 0.020000, loss: 2.4402
2023-07-02 01:19:45 - train: epoch 069, train_loss: 2.6553
2023-07-02 01:19:45 - train: epoch 0084, iter [00250, 00390], lr: 0.020000, loss: 2.9346
2023-07-02 01:19:46 - eval: epoch: 069, acc1: 37.810%, acc5: 67.610%, test_loss: 2.4922, per_image_load_time: 0.068ms, per_image_inference_time: 0.062ms
2023-07-02 01:19:47 - until epoch: 069, best_acc1: 37.810%
2023-07-02 01:19:47 - epoch 070 lr: 0.020000
2023-07-02 01:19:47 - train: epoch 0084, iter [00300, 00390], lr: 0.020000, loss: 2.6818
2023-07-02 01:19:49 - train: epoch 0084, iter [00350, 00390], lr: 0.020000, loss: 3.2760
2023-07-02 01:19:50 - train: epoch 0070, iter [00050, 00390], lr: 0.020000, loss: 2.6130
2023-07-02 01:19:51 - train: epoch 084, train_loss: 2.9034
2023-07-02 01:19:52 - train: epoch 0070, iter [00100, 00390], lr: 0.020000, loss: 2.5442
2023-07-02 01:19:52 - eval: epoch: 084, acc1: 32.590%, acc5: 63.050%, test_loss: 2.6869, per_image_load_time: 0.069ms, per_image_inference_time: 0.071ms
2023-07-02 01:19:52 - until epoch: 084, best_acc1: 33.570%
2023-07-02 01:19:52 - epoch 085 lr: 0.020000
2023-07-02 01:19:53 - train: epoch 0070, iter [00150, 00390], lr: 0.020000, loss: 2.8365
2023-07-02 01:19:55 - train: epoch 0085, iter [00050, 00390], lr: 0.020000, loss: 2.7523
2023-07-02 01:19:55 - train: epoch 0070, iter [00200, 00390], lr: 0.020000, loss: 2.6394
2023-07-02 01:19:57 - train: epoch 0085, iter [00100, 00390], lr: 0.020000, loss: 3.2765
2023-07-02 01:19:58 - train: epoch 0070, iter [00250, 00390], lr: 0.020000, loss: 2.3027
2023-07-02 01:19:59 - train: epoch 0085, iter [00150, 00390], lr: 0.020000, loss: 2.7843
2023-07-02 01:20:00 - train: epoch 0070, iter [00300, 00390], lr: 0.020000, loss: 2.6278
2023-07-02 01:20:01 - train: epoch 0085, iter [00200, 00390], lr: 0.020000, loss: 2.2836
2023-07-02 01:20:02 - train: epoch 0070, iter [00350, 00390], lr: 0.020000, loss: 2.7203
2023-07-02 01:20:03 - train: epoch 070, train_loss: 2.6434
2023-07-02 01:20:03 - train: epoch 0085, iter [00250, 00390], lr: 0.020000, loss: 2.4785
2023-07-02 01:20:05 - eval: epoch: 070, acc1: 37.620%, acc5: 67.500%, test_loss: 2.4916, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:20:05 - until epoch: 070, best_acc1: 37.810%
2023-07-02 01:20:05 - epoch 071 lr: 0.020000
2023-07-02 01:20:05 - train: epoch 0085, iter [00300, 00390], lr: 0.020000, loss: 2.4733
2023-07-02 01:20:07 - train: epoch 0085, iter [00350, 00390], lr: 0.020000, loss: 3.7779
2023-07-02 01:20:08 - train: epoch 0071, iter [00050, 00390], lr: 0.020000, loss: 2.4984
2023-07-02 01:20:09 - train: epoch 085, train_loss: 2.9225
2023-07-02 01:20:10 - train: epoch 0071, iter [00100, 00390], lr: 0.020000, loss: 2.5010
2023-07-02 01:20:10 - eval: epoch: 085, acc1: 34.180%, acc5: 64.480%, test_loss: 2.6189, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:20:11 - until epoch: 085, best_acc1: 34.180%
2023-07-02 01:20:11 - epoch 086 lr: 0.020000
2023-07-02 01:20:11 - train: epoch 0071, iter [00150, 00390], lr: 0.020000, loss: 2.5882
2023-07-02 01:20:13 - train: epoch 0071, iter [00200, 00390], lr: 0.020000, loss: 2.5817
2023-07-02 01:20:13 - train: epoch 0086, iter [00050, 00390], lr: 0.020000, loss: 2.3859
2023-07-02 01:20:15 - train: epoch 0086, iter [00100, 00390], lr: 0.020000, loss: 2.3889
2023-07-02 01:20:15 - train: epoch 0071, iter [00250, 00390], lr: 0.020000, loss: 2.7107
2023-07-02 01:20:17 - train: epoch 0086, iter [00150, 00390], lr: 0.020000, loss: 2.6934
2023-07-02 01:20:18 - train: epoch 0071, iter [00300, 00390], lr: 0.020000, loss: 2.8813
2023-07-02 01:20:20 - train: epoch 0086, iter [00200, 00390], lr: 0.020000, loss: 2.5204
2023-07-02 01:20:20 - train: epoch 0071, iter [00350, 00390], lr: 0.020000, loss: 2.5650
2023-07-02 01:20:21 - train: epoch 071, train_loss: 2.6322
2023-07-02 01:20:21 - train: epoch 0086, iter [00250, 00390], lr: 0.020000, loss: 2.5271
2023-07-02 01:20:23 - eval: epoch: 071, acc1: 36.390%, acc5: 66.800%, test_loss: 2.5373, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:20:23 - until epoch: 071, best_acc1: 37.810%
2023-07-02 01:20:23 - epoch 072 lr: 0.020000
2023-07-02 01:20:23 - train: epoch 0086, iter [00300, 00390], lr: 0.020000, loss: 2.9996
2023-07-02 01:20:25 - train: epoch 0086, iter [00350, 00390], lr: 0.020000, loss: 2.6569
2023-07-02 01:20:26 - train: epoch 0072, iter [00050, 00390], lr: 0.020000, loss: 2.5572
2023-07-02 01:20:27 - train: epoch 086, train_loss: 2.9096
2023-07-02 01:20:28 - train: epoch 0072, iter [00100, 00390], lr: 0.020000, loss: 2.4261
2023-07-02 01:20:28 - eval: epoch: 086, acc1: 34.240%, acc5: 63.770%, test_loss: 2.6354, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-07-02 01:20:28 - until epoch: 086, best_acc1: 34.240%
2023-07-02 01:20:28 - epoch 087 lr: 0.020000
2023-07-02 01:20:29 - train: epoch 0072, iter [00150, 00390], lr: 0.020000, loss: 2.5767
2023-07-02 01:20:31 - train: epoch 0087, iter [00050, 00390], lr: 0.020000, loss: 2.5640
2023-07-02 01:20:32 - train: epoch 0072, iter [00200, 00390], lr: 0.020000, loss: 2.4067
2023-07-02 01:20:33 - train: epoch 0087, iter [00100, 00390], lr: 0.020000, loss: 2.7907
2023-07-02 01:20:34 - train: epoch 0072, iter [00250, 00390], lr: 0.020000, loss: 2.4706
2023-07-02 01:20:35 - train: epoch 0087, iter [00150, 00390], lr: 0.020000, loss: 2.8726
2023-07-02 01:20:36 - train: epoch 0072, iter [00300, 00390], lr: 0.020000, loss: 2.4571
2023-07-02 01:20:37 - train: epoch 0087, iter [00200, 00390], lr: 0.020000, loss: 3.1372
2023-07-02 01:20:38 - train: epoch 0072, iter [00350, 00390], lr: 0.020000, loss: 2.7352
2023-07-02 01:20:39 - train: epoch 0087, iter [00250, 00390], lr: 0.020000, loss: 2.4714
2023-07-02 01:20:40 - train: epoch 072, train_loss: 2.6218
2023-07-02 01:20:41 - eval: epoch: 072, acc1: 36.630%, acc5: 66.750%, test_loss: 2.5352, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:20:41 - train: epoch 0087, iter [00300, 00390], lr: 0.020000, loss: 2.8575
2023-07-02 01:20:41 - until epoch: 072, best_acc1: 37.810%
2023-07-02 01:20:41 - epoch 073 lr: 0.020000
2023-07-02 01:20:43 - train: epoch 0087, iter [00350, 00390], lr: 0.020000, loss: 2.6232
2023-07-02 01:20:44 - train: epoch 0073, iter [00050, 00390], lr: 0.020000, loss: 2.6577
2023-07-02 01:20:45 - train: epoch 087, train_loss: 2.9033
2023-07-02 01:20:46 - eval: epoch: 087, acc1: 33.690%, acc5: 63.940%, test_loss: 2.6428, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:20:46 - train: epoch 0073, iter [00100, 00390], lr: 0.020000, loss: 2.5305
2023-07-02 01:20:46 - until epoch: 087, best_acc1: 34.240%
2023-07-02 01:20:46 - epoch 088 lr: 0.020000
2023-07-02 01:20:48 - train: epoch 0073, iter [00150, 00390], lr: 0.020000, loss: 2.7576
2023-07-02 01:20:49 - train: epoch 0088, iter [00050, 00390], lr: 0.020000, loss: 2.6467
2023-07-02 01:20:50 - train: epoch 0073, iter [00200, 00390], lr: 0.020000, loss: 2.7504
2023-07-02 01:20:51 - train: epoch 0088, iter [00100, 00390], lr: 0.020000, loss: 2.7706
2023-07-02 01:20:52 - train: epoch 0073, iter [00250, 00390], lr: 0.020000, loss: 2.9036
2023-07-02 01:20:53 - train: epoch 0088, iter [00150, 00390], lr: 0.020000, loss: 3.5885
2023-07-02 01:20:54 - train: epoch 0073, iter [00300, 00390], lr: 0.020000, loss: 2.6783
2023-07-02 01:20:55 - train: epoch 0088, iter [00200, 00390], lr: 0.020000, loss: 2.2591
2023-07-02 01:20:56 - train: epoch 0073, iter [00350, 00390], lr: 0.020000, loss: 2.4843
2023-07-02 01:20:57 - train: epoch 0088, iter [00250, 00390], lr: 0.020000, loss: 3.0466
2023-07-02 01:20:58 - train: epoch 073, train_loss: 2.6166
2023-07-02 01:20:59 - train: epoch 0088, iter [00300, 00390], lr: 0.020000, loss: 3.5161
2023-07-02 01:20:59 - eval: epoch: 073, acc1: 37.330%, acc5: 67.090%, test_loss: 2.5197, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:21:00 - until epoch: 073, best_acc1: 37.810%
2023-07-02 01:21:00 - epoch 074 lr: 0.020000
2023-07-02 01:21:01 - train: epoch 0088, iter [00350, 00390], lr: 0.020000, loss: 2.8886
2023-07-02 01:21:02 - train: epoch 088, train_loss: 2.9151
2023-07-02 01:21:02 - train: epoch 0074, iter [00050, 00390], lr: 0.020000, loss: 2.8134
2023-07-02 01:21:04 - eval: epoch: 088, acc1: 33.590%, acc5: 63.560%, test_loss: 2.6505, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 01:21:04 - train: epoch 0074, iter [00100, 00390], lr: 0.020000, loss: 2.7653
2023-07-02 01:21:04 - until epoch: 088, best_acc1: 34.240%
2023-07-02 01:21:04 - epoch 089 lr: 0.020000
2023-07-02 01:21:06 - train: epoch 0074, iter [00150, 00390], lr: 0.020000, loss: 2.5207
2023-07-02 01:21:07 - train: epoch 0089, iter [00050, 00390], lr: 0.020000, loss: 2.6755
2023-07-02 01:21:08 - train: epoch 0074, iter [00200, 00390], lr: 0.020000, loss: 2.5092
2023-07-02 01:21:09 - train: epoch 0089, iter [00100, 00390], lr: 0.020000, loss: 2.4456
2023-07-02 01:21:10 - train: epoch 0074, iter [00250, 00390], lr: 0.020000, loss: 2.5857
2023-07-02 01:21:11 - train: epoch 0089, iter [00150, 00390], lr: 0.020000, loss: 2.9521
2023-07-02 01:21:12 - train: epoch 0074, iter [00300, 00390], lr: 0.020000, loss: 2.5860
2023-07-02 01:21:13 - train: epoch 0089, iter [00200, 00390], lr: 0.020000, loss: 3.0439
2023-07-02 01:21:14 - train: epoch 0074, iter [00350, 00390], lr: 0.020000, loss: 2.6764
2023-07-02 01:21:15 - train: epoch 0089, iter [00250, 00390], lr: 0.020000, loss: 3.5594
2023-07-02 01:21:16 - train: epoch 074, train_loss: 2.6081
2023-07-02 01:21:17 - train: epoch 0089, iter [00300, 00390], lr: 0.020000, loss: 2.8106
2023-07-02 01:21:17 - eval: epoch: 074, acc1: 37.710%, acc5: 66.850%, test_loss: 2.5221, per_image_load_time: 0.069ms, per_image_inference_time: 0.056ms
2023-07-02 01:21:18 - until epoch: 074, best_acc1: 37.810%
2023-07-02 01:21:18 - epoch 075 lr: 0.020000
2023-07-02 01:21:19 - train: epoch 0089, iter [00350, 00390], lr: 0.020000, loss: 2.5381
2023-07-02 01:21:20 - train: epoch 089, train_loss: 2.8916
2023-07-02 01:21:20 - train: epoch 0075, iter [00050, 00390], lr: 0.020000, loss: 2.7255
2023-07-02 01:21:22 - eval: epoch: 089, acc1: 33.160%, acc5: 63.350%, test_loss: 2.6773, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:21:22 - until epoch: 089, best_acc1: 34.240%
2023-07-02 01:21:22 - epoch 090 lr: 0.020000
2023-07-02 01:21:22 - train: epoch 0075, iter [00100, 00390], lr: 0.020000, loss: 2.7731
2023-07-02 01:21:24 - train: epoch 0075, iter [00150, 00390], lr: 0.020000, loss: 2.5038
2023-07-02 01:21:25 - train: epoch 0090, iter [00050, 00390], lr: 0.020000, loss: 2.5023
2023-07-02 01:21:26 - train: epoch 0075, iter [00200, 00390], lr: 0.020000, loss: 2.4194
2023-07-02 01:21:27 - train: epoch 0090, iter [00100, 00390], lr: 0.020000, loss: 2.6533
2023-07-02 01:21:28 - train: epoch 0075, iter [00250, 00390], lr: 0.020000, loss: 2.5923
2023-07-02 01:21:29 - train: epoch 0090, iter [00150, 00390], lr: 0.020000, loss: 2.8416
2023-07-02 01:21:30 - train: epoch 0075, iter [00300, 00390], lr: 0.020000, loss: 2.6304
2023-07-02 01:21:31 - train: epoch 0090, iter [00200, 00390], lr: 0.020000, loss: 3.1560
2023-07-02 01:21:32 - train: epoch 0075, iter [00350, 00390], lr: 0.020000, loss: 2.5891
2023-07-02 01:21:33 - train: epoch 0090, iter [00250, 00390], lr: 0.020000, loss: 2.4989
2023-07-02 01:21:34 - train: epoch 075, train_loss: 2.6036
2023-07-02 01:21:35 - train: epoch 0090, iter [00300, 00390], lr: 0.020000, loss: 2.6502
2023-07-02 01:21:36 - eval: epoch: 075, acc1: 36.900%, acc5: 66.910%, test_loss: 2.5290, per_image_load_time: 0.068ms, per_image_inference_time: 0.059ms
2023-07-02 01:21:36 - until epoch: 075, best_acc1: 37.810%
2023-07-02 01:21:36 - epoch 076 lr: 0.020000
2023-07-02 01:21:36 - train: epoch 0090, iter [00350, 00390], lr: 0.020000, loss: 2.7534
2023-07-02 01:21:38 - train: epoch 090, train_loss: 2.8834
2023-07-02 01:21:38 - train: epoch 0076, iter [00050, 00390], lr: 0.020000, loss: 2.3730
2023-07-02 01:21:40 - eval: epoch: 090, acc1: 33.980%, acc5: 64.470%, test_loss: 2.6348, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-07-02 01:21:40 - until epoch: 090, best_acc1: 34.240%
2023-07-02 01:21:40 - epoch 091 lr: 0.020000
2023-07-02 01:21:40 - train: epoch 0076, iter [00100, 00390], lr: 0.020000, loss: 2.6252
2023-07-02 01:21:42 - train: epoch 0076, iter [00150, 00390], lr: 0.020000, loss: 2.6630
2023-07-02 01:21:43 - train: epoch 0091, iter [00050, 00390], lr: 0.020000, loss: 2.3529
2023-07-02 01:21:44 - train: epoch 0076, iter [00200, 00390], lr: 0.020000, loss: 2.5785
2023-07-02 01:21:45 - train: epoch 0091, iter [00100, 00390], lr: 0.020000, loss: 2.8678
2023-07-02 01:21:46 - train: epoch 0076, iter [00250, 00390], lr: 0.020000, loss: 2.6266
2023-07-02 01:21:47 - train: epoch 0091, iter [00150, 00390], lr: 0.020000, loss: 2.5763
2023-07-02 01:21:48 - train: epoch 0076, iter [00300, 00390], lr: 0.020000, loss: 2.7374
2023-07-02 01:21:49 - train: epoch 0091, iter [00200, 00390], lr: 0.020000, loss: 2.5231
2023-07-02 01:21:50 - train: epoch 0076, iter [00350, 00390], lr: 0.020000, loss: 2.7284
2023-07-02 01:21:51 - train: epoch 0091, iter [00250, 00390], lr: 0.020000, loss: 3.1947
2023-07-02 01:21:52 - train: epoch 076, train_loss: 2.5891
2023-07-02 01:21:53 - train: epoch 0091, iter [00300, 00390], lr: 0.020000, loss: 2.3705
2023-07-02 01:21:53 - eval: epoch: 076, acc1: 36.940%, acc5: 66.340%, test_loss: 2.5520, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:21:54 - until epoch: 076, best_acc1: 37.810%
2023-07-02 01:21:54 - epoch 077 lr: 0.020000
2023-07-02 01:21:54 - train: epoch 0091, iter [00350, 00390], lr: 0.020000, loss: 3.4839
2023-07-02 01:21:56 - train: epoch 091, train_loss: 2.8961
2023-07-02 01:21:57 - train: epoch 0077, iter [00050, 00390], lr: 0.020000, loss: 2.4020
2023-07-02 01:21:57 - eval: epoch: 091, acc1: 34.590%, acc5: 64.170%, test_loss: 2.6277, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 01:21:58 - until epoch: 091, best_acc1: 34.590%
2023-07-02 01:21:58 - epoch 092 lr: 0.020000
2023-07-02 01:21:58 - train: epoch 0077, iter [00100, 00390], lr: 0.020000, loss: 2.3967
2023-07-02 01:22:00 - train: epoch 0077, iter [00150, 00390], lr: 0.020000, loss: 2.6310
2023-07-02 01:22:01 - train: epoch 0092, iter [00050, 00390], lr: 0.020000, loss: 2.5248
2023-07-02 01:22:02 - train: epoch 0077, iter [00200, 00390], lr: 0.020000, loss: 2.5467
2023-07-02 01:22:03 - train: epoch 0092, iter [00100, 00390], lr: 0.020000, loss: 4.0210
2023-07-02 01:22:04 - train: epoch 0077, iter [00250, 00390], lr: 0.020000, loss: 2.6369
2023-07-02 01:22:05 - train: epoch 0092, iter [00150, 00390], lr: 0.020000, loss: 2.7670
2023-07-02 01:22:06 - train: epoch 0077, iter [00300, 00390], lr: 0.020000, loss: 2.7048
2023-07-02 01:22:07 - train: epoch 0092, iter [00200, 00390], lr: 0.020000, loss: 3.6047
2023-07-02 01:22:08 - train: epoch 0077, iter [00350, 00390], lr: 0.020000, loss: 2.7045
2023-07-02 01:22:09 - train: epoch 0092, iter [00250, 00390], lr: 0.020000, loss: 2.7385
2023-07-02 01:22:10 - train: epoch 077, train_loss: 2.5851
2023-07-02 01:22:11 - train: epoch 0092, iter [00300, 00390], lr: 0.020000, loss: 2.7008
2023-07-02 01:22:12 - eval: epoch: 077, acc1: 37.630%, acc5: 66.860%, test_loss: 2.5164, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:22:12 - until epoch: 077, best_acc1: 37.810%
2023-07-02 01:22:12 - epoch 078 lr: 0.020000
2023-07-02 01:22:12 - train: epoch 0092, iter [00350, 00390], lr: 0.020000, loss: 3.1004
2023-07-02 01:22:14 - train: epoch 092, train_loss: 2.8986
2023-07-02 01:22:14 - train: epoch 0078, iter [00050, 00390], lr: 0.020000, loss: 2.5312
2023-07-02 01:22:15 - eval: epoch: 092, acc1: 34.870%, acc5: 64.510%, test_loss: 2.5962, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:22:16 - until epoch: 092, best_acc1: 34.870%
2023-07-02 01:22:16 - epoch 093 lr: 0.020000
2023-07-02 01:22:16 - train: epoch 0078, iter [00100, 00390], lr: 0.020000, loss: 2.5714
2023-07-02 01:22:18 - train: epoch 0078, iter [00150, 00390], lr: 0.020000, loss: 2.5423
2023-07-02 01:22:18 - train: epoch 0093, iter [00050, 00390], lr: 0.020000, loss: 2.7977
2023-07-02 01:22:20 - train: epoch 0078, iter [00200, 00390], lr: 0.020000, loss: 2.4585
2023-07-02 01:22:21 - train: epoch 0093, iter [00100, 00390], lr: 0.020000, loss: 2.5591
2023-07-02 01:22:22 - train: epoch 0078, iter [00250, 00390], lr: 0.020000, loss: 2.7224
2023-07-02 01:22:23 - train: epoch 0093, iter [00150, 00390], lr: 0.020000, loss: 2.9294
2023-07-02 01:22:24 - train: epoch 0078, iter [00300, 00390], lr: 0.020000, loss: 2.6596
2023-07-02 01:22:25 - train: epoch 0093, iter [00200, 00390], lr: 0.020000, loss: 2.3632
2023-07-02 01:22:27 - train: epoch 0078, iter [00350, 00390], lr: 0.020000, loss: 2.6209
2023-07-02 01:22:27 - train: epoch 0093, iter [00250, 00390], lr: 0.020000, loss: 3.1736
2023-07-02 01:22:28 - train: epoch 078, train_loss: 2.5772
2023-07-02 01:22:28 - train: epoch 0093, iter [00300, 00390], lr: 0.020000, loss: 2.9919
2023-07-02 01:22:30 - eval: epoch: 078, acc1: 37.500%, acc5: 67.030%, test_loss: 2.5348, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:22:30 - until epoch: 078, best_acc1: 37.810%
2023-07-02 01:22:30 - epoch 079 lr: 0.020000
2023-07-02 01:22:30 - train: epoch 0093, iter [00350, 00390], lr: 0.020000, loss: 2.7745
2023-07-02 01:22:32 - train: epoch 093, train_loss: 2.8721
2023-07-02 01:22:32 - train: epoch 0079, iter [00050, 00390], lr: 0.020000, loss: 2.3778
2023-07-02 01:22:33 - eval: epoch: 093, acc1: 33.980%, acc5: 64.350%, test_loss: 2.6108, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:22:33 - until epoch: 093, best_acc1: 34.870%
2023-07-02 01:22:33 - epoch 094 lr: 0.020000
2023-07-02 01:22:34 - train: epoch 0079, iter [00100, 00390], lr: 0.020000, loss: 2.5876
2023-07-02 01:22:36 - train: epoch 0094, iter [00050, 00390], lr: 0.020000, loss: 2.3860
2023-07-02 01:22:36 - train: epoch 0079, iter [00150, 00390], lr: 0.020000, loss: 2.7256
2023-07-02 01:22:38 - train: epoch 0094, iter [00100, 00390], lr: 0.020000, loss: 2.7459
2023-07-02 01:22:38 - train: epoch 0079, iter [00200, 00390], lr: 0.020000, loss: 2.6044
2023-07-02 01:22:40 - train: epoch 0079, iter [00250, 00390], lr: 0.020000, loss: 2.7377
2023-07-02 01:22:41 - train: epoch 0094, iter [00150, 00390], lr: 0.020000, loss: 2.4092
2023-07-02 01:22:42 - train: epoch 0079, iter [00300, 00390], lr: 0.020000, loss: 2.6968
2023-07-02 01:22:43 - train: epoch 0094, iter [00200, 00390], lr: 0.020000, loss: 2.4197
2023-07-02 01:22:45 - train: epoch 0079, iter [00350, 00390], lr: 0.020000, loss: 2.5711
2023-07-02 01:22:45 - train: epoch 0094, iter [00250, 00390], lr: 0.020000, loss: 2.6951
2023-07-02 01:22:46 - train: epoch 079, train_loss: 2.5692
2023-07-02 01:22:47 - train: epoch 0094, iter [00300, 00390], lr: 0.020000, loss: 2.7547
2023-07-02 01:22:48 - eval: epoch: 079, acc1: 37.350%, acc5: 66.930%, test_loss: 2.5209, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:22:48 - until epoch: 079, best_acc1: 37.810%
2023-07-02 01:22:48 - epoch 080 lr: 0.020000
2023-07-02 01:22:48 - train: epoch 0094, iter [00350, 00390], lr: 0.020000, loss: 2.7905
2023-07-02 01:22:50 - train: epoch 094, train_loss: 2.8762
2023-07-02 01:22:51 - train: epoch 0080, iter [00050, 00390], lr: 0.020000, loss: 2.5000
2023-07-02 01:22:51 - eval: epoch: 094, acc1: 33.640%, acc5: 64.170%, test_loss: 2.6477, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:22:51 - until epoch: 094, best_acc1: 34.870%
2023-07-02 01:22:51 - epoch 095 lr: 0.020000
2023-07-02 01:22:52 - train: epoch 0080, iter [00100, 00390], lr: 0.020000, loss: 2.3957
2023-07-02 01:22:54 - train: epoch 0095, iter [00050, 00390], lr: 0.020000, loss: 3.7637
2023-07-02 01:22:54 - train: epoch 0080, iter [00150, 00390], lr: 0.020000, loss: 2.6320
2023-07-02 01:22:56 - train: epoch 0095, iter [00100, 00390], lr: 0.020000, loss: 2.6496
2023-07-02 01:22:57 - train: epoch 0080, iter [00200, 00390], lr: 0.020000, loss: 2.6788
2023-07-02 01:22:58 - train: epoch 0095, iter [00150, 00390], lr: 0.020000, loss: 2.7324
2023-07-02 01:22:59 - train: epoch 0080, iter [00250, 00390], lr: 0.020000, loss: 2.4198
2023-07-02 01:23:00 - train: epoch 0095, iter [00200, 00390], lr: 0.020000, loss: 2.7693
2023-07-02 01:23:01 - train: epoch 0080, iter [00300, 00390], lr: 0.020000, loss: 2.6499
2023-07-02 01:23:02 - train: epoch 0095, iter [00250, 00390], lr: 0.020000, loss: 2.4753
2023-07-02 01:23:03 - train: epoch 0080, iter [00350, 00390], lr: 0.020000, loss: 2.7163
2023-07-02 01:23:04 - train: epoch 0095, iter [00300, 00390], lr: 0.020000, loss: 2.7849
2023-07-02 01:23:05 - train: epoch 080, train_loss: 2.5569
2023-07-02 01:23:06 - eval: epoch: 080, acc1: 37.440%, acc5: 66.750%, test_loss: 2.5191, per_image_load_time: 0.073ms, per_image_inference_time: 0.055ms
2023-07-02 01:23:06 - train: epoch 0095, iter [00350, 00390], lr: 0.020000, loss: 2.3704
2023-07-02 01:23:06 - until epoch: 080, best_acc1: 37.810%
2023-07-02 01:23:06 - epoch 081 lr: 0.020000
2023-07-02 01:23:07 - train: epoch 095, train_loss: 2.8957
2023-07-02 01:23:09 - eval: epoch: 095, acc1: 34.080%, acc5: 63.960%, test_loss: 2.6277, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 01:23:09 - train: epoch 0081, iter [00050, 00390], lr: 0.020000, loss: 2.6887
2023-07-02 01:23:09 - until epoch: 095, best_acc1: 34.870%
2023-07-02 01:23:09 - epoch 096 lr: 0.020000
2023-07-02 01:23:11 - train: epoch 0081, iter [00100, 00390], lr: 0.020000, loss: 2.6365
2023-07-02 01:23:12 - train: epoch 0096, iter [00050, 00390], lr: 0.020000, loss: 2.5574
2023-07-02 01:23:13 - train: epoch 0081, iter [00150, 00390], lr: 0.020000, loss: 2.5322
2023-07-02 01:23:14 - train: epoch 0096, iter [00100, 00390], lr: 0.020000, loss: 2.6269
2023-07-02 01:23:15 - train: epoch 0081, iter [00200, 00390], lr: 0.020000, loss: 2.4589
2023-07-02 01:23:16 - train: epoch 0096, iter [00150, 00390], lr: 0.020000, loss: 2.7992
2023-07-02 01:23:17 - train: epoch 0081, iter [00250, 00390], lr: 0.020000, loss: 2.6991
2023-07-02 01:23:18 - train: epoch 0096, iter [00200, 00390], lr: 0.020000, loss: 2.6233
2023-07-02 01:23:19 - train: epoch 0081, iter [00300, 00390], lr: 0.020000, loss: 2.6593
2023-07-02 01:23:20 - train: epoch 0096, iter [00250, 00390], lr: 0.020000, loss: 2.8243
2023-07-02 01:23:21 - train: epoch 0081, iter [00350, 00390], lr: 0.020000, loss: 2.6785
2023-07-02 01:23:22 - train: epoch 0096, iter [00300, 00390], lr: 0.020000, loss: 2.8292
2023-07-02 01:23:23 - train: epoch 081, train_loss: 2.5527
2023-07-02 01:23:24 - train: epoch 0096, iter [00350, 00390], lr: 0.020000, loss: 2.7473
2023-07-02 01:23:24 - eval: epoch: 081, acc1: 36.940%, acc5: 66.490%, test_loss: 2.5479, per_image_load_time: 0.068ms, per_image_inference_time: 0.059ms
2023-07-02 01:23:25 - until epoch: 081, best_acc1: 37.810%
2023-07-02 01:23:25 - epoch 082 lr: 0.020000
2023-07-02 01:23:25 - train: epoch 096, train_loss: 2.8764
2023-07-02 01:23:27 - eval: epoch: 096, acc1: 34.590%, acc5: 65.280%, test_loss: 2.5994, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 01:23:27 - train: epoch 0082, iter [00050, 00390], lr: 0.020000, loss: 2.5163
2023-07-02 01:23:27 - until epoch: 096, best_acc1: 34.870%
2023-07-02 01:23:27 - epoch 097 lr: 0.020000
2023-07-02 01:23:29 - train: epoch 0082, iter [00100, 00390], lr: 0.020000, loss: 2.4766
2023-07-02 01:23:30 - train: epoch 0097, iter [00050, 00390], lr: 0.020000, loss: 3.0734
2023-07-02 01:23:31 - train: epoch 0082, iter [00150, 00390], lr: 0.020000, loss: 2.2737
2023-07-02 01:23:32 - train: epoch 0097, iter [00100, 00390], lr: 0.020000, loss: 2.2760
2023-07-02 01:23:33 - train: epoch 0082, iter [00200, 00390], lr: 0.020000, loss: 2.5797
2023-07-02 01:23:34 - train: epoch 0097, iter [00150, 00390], lr: 0.020000, loss: 3.8071
2023-07-02 01:23:35 - train: epoch 0082, iter [00250, 00390], lr: 0.020000, loss: 2.8369
2023-07-02 01:23:36 - train: epoch 0097, iter [00200, 00390], lr: 0.020000, loss: 3.0168
2023-07-02 01:23:37 - train: epoch 0082, iter [00300, 00390], lr: 0.020000, loss: 2.5248
2023-07-02 01:23:38 - train: epoch 0097, iter [00250, 00390], lr: 0.020000, loss: 2.7351
2023-07-02 01:23:39 - train: epoch 0082, iter [00350, 00390], lr: 0.020000, loss: 2.6388
2023-07-02 01:23:40 - train: epoch 0097, iter [00300, 00390], lr: 0.020000, loss: 2.3372
2023-07-02 01:23:41 - train: epoch 082, train_loss: 2.5443
2023-07-02 01:23:42 - train: epoch 0097, iter [00350, 00390], lr: 0.020000, loss: 3.8876
2023-07-02 01:23:43 - eval: epoch: 082, acc1: 37.650%, acc5: 66.560%, test_loss: 2.5295, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:23:43 - until epoch: 082, best_acc1: 37.810%
2023-07-02 01:23:43 - epoch 083 lr: 0.020000
2023-07-02 01:23:43 - train: epoch 097, train_loss: 2.8319
2023-07-02 01:23:45 - eval: epoch: 097, acc1: 33.880%, acc5: 64.930%, test_loss: 2.6162, per_image_load_time: 0.077ms, per_image_inference_time: 0.054ms
2023-07-02 01:23:45 - until epoch: 097, best_acc1: 34.870%
2023-07-02 01:23:45 - epoch 098 lr: 0.020000
2023-07-02 01:23:45 - train: epoch 0083, iter [00050, 00390], lr: 0.020000, loss: 2.5415
2023-07-02 01:23:47 - train: epoch 0083, iter [00100, 00390], lr: 0.020000, loss: 2.6327
2023-07-02 01:23:48 - train: epoch 0098, iter [00050, 00390], lr: 0.020000, loss: 2.3602
2023-07-02 01:23:49 - train: epoch 0083, iter [00150, 00390], lr: 0.020000, loss: 2.4617
2023-07-02 01:23:50 - train: epoch 0098, iter [00100, 00390], lr: 0.020000, loss: 2.6650
2023-07-02 01:23:52 - train: epoch 0083, iter [00200, 00390], lr: 0.020000, loss: 2.3554
2023-07-02 01:23:52 - train: epoch 0098, iter [00150, 00390], lr: 0.020000, loss: 2.3810
2023-07-02 01:23:54 - train: epoch 0083, iter [00250, 00390], lr: 0.020000, loss: 2.4174
2023-07-02 01:23:54 - train: epoch 0098, iter [00200, 00390], lr: 0.020000, loss: 2.6178
2023-07-02 01:23:56 - train: epoch 0083, iter [00300, 00390], lr: 0.020000, loss: 2.6088
2023-07-02 01:23:56 - train: epoch 0098, iter [00250, 00390], lr: 0.020000, loss: 2.6793
2023-07-02 01:23:58 - train: epoch 0083, iter [00350, 00390], lr: 0.020000, loss: 2.5139
2023-07-02 01:23:58 - train: epoch 0098, iter [00300, 00390], lr: 0.020000, loss: 3.2525
2023-07-02 01:24:00 - train: epoch 083, train_loss: 2.5242
2023-07-02 01:24:00 - train: epoch 0098, iter [00350, 00390], lr: 0.020000, loss: 2.6317
2023-07-02 01:24:01 - eval: epoch: 083, acc1: 37.230%, acc5: 66.470%, test_loss: 2.5422, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:24:01 - train: epoch 098, train_loss: 2.8519
2023-07-02 01:24:01 - until epoch: 083, best_acc1: 37.810%
2023-07-02 01:24:01 - epoch 084 lr: 0.020000
2023-07-02 01:24:03 - eval: epoch: 098, acc1: 33.530%, acc5: 64.620%, test_loss: 2.6174, per_image_load_time: 0.073ms, per_image_inference_time: 0.058ms
2023-07-02 01:24:04 - train: epoch 0084, iter [00050, 00390], lr: 0.020000, loss: 2.5712
2023-07-02 01:24:04 - until epoch: 098, best_acc1: 34.870%
2023-07-02 01:24:04 - epoch 099 lr: 0.020000
2023-07-02 01:24:06 - train: epoch 0084, iter [00100, 00390], lr: 0.020000, loss: 2.6155
2023-07-02 01:24:07 - train: epoch 0099, iter [00050, 00390], lr: 0.020000, loss: 3.2828
2023-07-02 01:24:08 - train: epoch 0084, iter [00150, 00390], lr: 0.020000, loss: 2.6436
2023-07-02 01:24:09 - train: epoch 0099, iter [00100, 00390], lr: 0.020000, loss: 2.5303
2023-07-02 01:24:10 - train: epoch 0084, iter [00200, 00390], lr: 0.020000, loss: 2.3248
2023-07-02 01:24:11 - train: epoch 0099, iter [00150, 00390], lr: 0.020000, loss: 2.8649
2023-07-02 01:24:12 - train: epoch 0084, iter [00250, 00390], lr: 0.020000, loss: 2.5918
2023-07-02 01:24:13 - train: epoch 0099, iter [00200, 00390], lr: 0.020000, loss: 2.6777
2023-07-02 01:24:14 - train: epoch 0084, iter [00300, 00390], lr: 0.020000, loss: 2.8043
2023-07-02 01:24:15 - train: epoch 0099, iter [00250, 00390], lr: 0.020000, loss: 3.1100
2023-07-02 01:24:16 - train: epoch 0084, iter [00350, 00390], lr: 0.020000, loss: 2.5347
2023-07-02 01:24:17 - train: epoch 0099, iter [00300, 00390], lr: 0.020000, loss: 2.4010
2023-07-02 01:24:18 - train: epoch 084, train_loss: 2.5185
2023-07-02 01:24:19 - train: epoch 0099, iter [00350, 00390], lr: 0.020000, loss: 3.4892
2023-07-02 01:24:19 - eval: epoch: 084, acc1: 37.450%, acc5: 67.010%, test_loss: 2.5333, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:24:19 - until epoch: 084, best_acc1: 37.810%
2023-07-02 01:24:19 - epoch 085 lr: 0.020000
2023-07-02 01:24:20 - train: epoch 099, train_loss: 2.8449
2023-07-02 01:24:22 - eval: epoch: 099, acc1: 34.770%, acc5: 64.990%, test_loss: 2.6010, per_image_load_time: 0.071ms, per_image_inference_time: 0.056ms
2023-07-02 01:24:22 - until epoch: 099, best_acc1: 34.870%
2023-07-02 01:24:22 - epoch 100 lr: 0.020000
2023-07-02 01:24:22 - train: epoch 0085, iter [00050, 00390], lr: 0.020000, loss: 2.4607
2023-07-02 01:24:24 - train: epoch 0085, iter [00100, 00390], lr: 0.020000, loss: 2.4603
2023-07-02 01:24:25 - train: epoch 0100, iter [00050, 00390], lr: 0.020000, loss: 2.5073
2023-07-02 01:24:26 - train: epoch 0085, iter [00150, 00390], lr: 0.020000, loss: 2.5530
2023-07-02 01:24:27 - train: epoch 0100, iter [00100, 00390], lr: 0.020000, loss: 2.0502
2023-07-02 01:24:28 - train: epoch 0085, iter [00200, 00390], lr: 0.020000, loss: 2.2844
2023-07-02 01:24:29 - train: epoch 0100, iter [00150, 00390], lr: 0.020000, loss: 3.2800
2023-07-02 01:24:30 - train: epoch 0085, iter [00250, 00390], lr: 0.020000, loss: 2.5137
2023-07-02 01:24:31 - train: epoch 0100, iter [00200, 00390], lr: 0.020000, loss: 3.6682
2023-07-02 01:24:32 - train: epoch 0085, iter [00300, 00390], lr: 0.020000, loss: 2.4275
2023-07-02 01:24:33 - train: epoch 0100, iter [00250, 00390], lr: 0.020000, loss: 3.0692
2023-07-02 01:24:35 - train: epoch 0085, iter [00350, 00390], lr: 0.020000, loss: 2.5720
2023-07-02 01:24:35 - train: epoch 0100, iter [00300, 00390], lr: 0.020000, loss: 3.4654
2023-07-02 01:24:36 - train: epoch 085, train_loss: 2.5087
2023-07-02 01:24:37 - train: epoch 0100, iter [00350, 00390], lr: 0.020000, loss: 2.6043
2023-07-02 01:24:38 - eval: epoch: 085, acc1: 37.980%, acc5: 67.100%, test_loss: 2.5249, per_image_load_time: 0.069ms, per_image_inference_time: 0.056ms
2023-07-02 01:24:38 - train: epoch 100, train_loss: 2.8835
2023-07-02 01:24:38 - until epoch: 085, best_acc1: 37.980%
2023-07-02 01:24:38 - epoch 086 lr: 0.020000
2023-07-02 01:24:40 - eval: epoch: 100, acc1: 32.950%, acc5: 63.370%, test_loss: 2.6657, per_image_load_time: 0.077ms, per_image_inference_time: 0.065ms
2023-07-02 01:24:40 - until epoch: 100, best_acc1: 34.870%
2023-07-02 01:24:40 - epoch 101 lr: 0.020000
2023-07-02 01:24:41 - train: epoch 0086, iter [00050, 00390], lr: 0.020000, loss: 2.3225
2023-07-02 01:24:43 - train: epoch 0101, iter [00050, 00390], lr: 0.020000, loss: 2.7297
2023-07-02 01:24:43 - train: epoch 0086, iter [00100, 00390], lr: 0.020000, loss: 2.3742
2023-07-02 01:24:45 - train: epoch 0101, iter [00100, 00390], lr: 0.020000, loss: 3.4559
2023-07-02 01:24:45 - train: epoch 0086, iter [00150, 00390], lr: 0.020000, loss: 2.5709
2023-07-02 01:24:47 - train: epoch 0101, iter [00150, 00390], lr: 0.020000, loss: 2.7174
2023-07-02 01:24:47 - train: epoch 0086, iter [00200, 00390], lr: 0.020000, loss: 2.4157
2023-07-02 01:24:49 - train: epoch 0101, iter [00200, 00390], lr: 0.020000, loss: 2.6037
2023-07-02 01:24:49 - train: epoch 0086, iter [00250, 00390], lr: 0.020000, loss: 2.4276
2023-07-02 01:24:51 - train: epoch 0101, iter [00250, 00390], lr: 0.020000, loss: 2.6305
2023-07-02 01:24:51 - train: epoch 0086, iter [00300, 00390], lr: 0.020000, loss: 2.4282
2023-07-02 01:24:53 - train: epoch 0101, iter [00300, 00390], lr: 0.020000, loss: 2.8702
2023-07-02 01:24:53 - train: epoch 0086, iter [00350, 00390], lr: 0.020000, loss: 2.5850
2023-07-02 01:24:55 - train: epoch 0101, iter [00350, 00390], lr: 0.020000, loss: 2.8917
2023-07-02 01:24:55 - train: epoch 086, train_loss: 2.5044
2023-07-02 01:24:56 - train: epoch 101, train_loss: 2.8453
2023-07-02 01:24:57 - eval: epoch: 086, acc1: 37.260%, acc5: 66.660%, test_loss: 2.5356, per_image_load_time: 0.069ms, per_image_inference_time: 0.058ms
2023-07-02 01:24:57 - until epoch: 086, best_acc1: 37.980%
2023-07-02 01:24:57 - epoch 087 lr: 0.020000
2023-07-02 01:24:58 - eval: epoch: 101, acc1: 33.970%, acc5: 64.550%, test_loss: 2.6140, per_image_load_time: 0.084ms, per_image_inference_time: 0.064ms
2023-07-02 01:24:58 - until epoch: 101, best_acc1: 34.870%
2023-07-02 01:24:58 - epoch 102 lr: 0.020000
2023-07-02 01:25:00 - train: epoch 0087, iter [00050, 00390], lr: 0.020000, loss: 2.3840
2023-07-02 01:25:01 - train: epoch 0102, iter [00050, 00390], lr: 0.020000, loss: 2.8398
2023-07-02 01:25:02 - train: epoch 0087, iter [00100, 00390], lr: 0.020000, loss: 2.5398
2023-07-02 01:25:03 - train: epoch 0102, iter [00100, 00390], lr: 0.020000, loss: 2.6380
2023-07-02 01:25:04 - train: epoch 0087, iter [00150, 00390], lr: 0.020000, loss: 2.4645
2023-07-02 01:25:05 - train: epoch 0102, iter [00150, 00390], lr: 0.020000, loss: 2.7535
2023-07-02 01:25:06 - train: epoch 0087, iter [00200, 00390], lr: 0.020000, loss: 2.4151
2023-07-02 01:25:07 - train: epoch 0102, iter [00200, 00390], lr: 0.020000, loss: 2.2759
2023-07-02 01:25:08 - train: epoch 0087, iter [00250, 00390], lr: 0.020000, loss: 2.3349
2023-07-02 01:25:09 - train: epoch 0102, iter [00250, 00390], lr: 0.020000, loss: 3.1622
2023-07-02 01:25:10 - train: epoch 0087, iter [00300, 00390], lr: 0.020000, loss: 2.4827
2023-07-02 01:25:11 - train: epoch 0102, iter [00300, 00390], lr: 0.020000, loss: 2.9332
2023-07-02 01:25:12 - train: epoch 0087, iter [00350, 00390], lr: 0.020000, loss: 2.4966
2023-07-02 01:25:13 - train: epoch 0102, iter [00350, 00390], lr: 0.020000, loss: 2.6981
2023-07-02 01:25:14 - train: epoch 087, train_loss: 2.4974
2023-07-02 01:25:15 - train: epoch 102, train_loss: 2.8906
2023-07-02 01:25:15 - eval: epoch: 087, acc1: 37.600%, acc5: 66.960%, test_loss: 2.5156, per_image_load_time: 0.067ms, per_image_inference_time: 0.059ms
2023-07-02 01:25:15 - until epoch: 087, best_acc1: 37.980%
2023-07-02 01:25:15 - epoch 088 lr: 0.020000
2023-07-02 01:25:16 - eval: epoch: 102, acc1: 34.370%, acc5: 64.500%, test_loss: 2.6095, per_image_load_time: 0.073ms, per_image_inference_time: 0.056ms
2023-07-02 01:25:17 - until epoch: 102, best_acc1: 34.870%
2023-07-02 01:25:17 - epoch 103 lr: 0.020000
2023-07-02 01:25:18 - train: epoch 0088, iter [00050, 00390], lr: 0.020000, loss: 2.3101
2023-07-02 01:25:19 - train: epoch 0103, iter [00050, 00390], lr: 0.020000, loss: 3.2017
2023-07-02 01:25:20 - train: epoch 0088, iter [00100, 00390], lr: 0.020000, loss: 2.5756
2023-07-02 01:25:22 - train: epoch 0103, iter [00100, 00390], lr: 0.020000, loss: 2.6873
2023-07-02 01:25:22 - train: epoch 0088, iter [00150, 00390], lr: 0.020000, loss: 2.3424
2023-07-02 01:25:24 - train: epoch 0103, iter [00150, 00390], lr: 0.020000, loss: 2.7304
2023-07-02 01:25:24 - train: epoch 0088, iter [00200, 00390], lr: 0.020000, loss: 2.2936
2023-07-02 01:25:26 - train: epoch 0103, iter [00200, 00390], lr: 0.020000, loss: 2.9085
2023-07-02 01:25:26 - train: epoch 0088, iter [00250, 00390], lr: 0.020000, loss: 2.4192
2023-07-02 01:25:28 - train: epoch 0103, iter [00250, 00390], lr: 0.020000, loss: 2.5549
2023-07-02 01:25:28 - train: epoch 0088, iter [00300, 00390], lr: 0.020000, loss: 2.6884
2023-07-02 01:25:30 - train: epoch 0103, iter [00300, 00390], lr: 0.020000, loss: 3.2288
2023-07-02 01:25:30 - train: epoch 0088, iter [00350, 00390], lr: 0.020000, loss: 2.5678
2023-07-02 01:25:32 - train: epoch 0103, iter [00350, 00390], lr: 0.020000, loss: 2.5901
2023-07-02 01:25:32 - train: epoch 088, train_loss: 2.4885
2023-07-02 01:25:33 - train: epoch 103, train_loss: 2.8018
2023-07-02 01:25:33 - eval: epoch: 088, acc1: 38.170%, acc5: 67.310%, test_loss: 2.4970, per_image_load_time: 0.069ms, per_image_inference_time: 0.057ms
2023-07-02 01:25:34 - until epoch: 088, best_acc1: 38.170%
2023-07-02 01:25:34 - epoch 089 lr: 0.020000
2023-07-02 01:25:35 - eval: epoch: 103, acc1: 35.690%, acc5: 65.560%, test_loss: 2.5668, per_image_load_time: 0.069ms, per_image_inference_time: 0.060ms
2023-07-02 01:25:35 - until epoch: 103, best_acc1: 35.690%
2023-07-02 01:25:35 - epoch 104 lr: 0.020000
2023-07-02 01:25:36 - train: epoch 0089, iter [00050, 00390], lr: 0.020000, loss: 2.4062
2023-07-02 01:25:38 - train: epoch 0104, iter [00050, 00390], lr: 0.020000, loss: 2.5687
2023-07-02 01:25:38 - train: epoch 0089, iter [00100, 00390], lr: 0.020000, loss: 2.3813
2023-07-02 01:25:40 - train: epoch 0104, iter [00100, 00390], lr: 0.020000, loss: 2.8087
2023-07-02 01:25:40 - train: epoch 0089, iter [00150, 00390], lr: 0.020000, loss: 2.3403
2023-07-02 01:25:42 - train: epoch 0104, iter [00150, 00390], lr: 0.020000, loss: 3.6706
2023-07-02 01:25:43 - train: epoch 0089, iter [00200, 00390], lr: 0.020000, loss: 2.5566
2023-07-02 01:25:44 - train: epoch 0104, iter [00200, 00390], lr: 0.020000, loss: 2.9617
2023-07-02 01:25:45 - train: epoch 0089, iter [00250, 00390], lr: 0.020000, loss: 2.5232
2023-07-02 01:25:46 - train: epoch 0104, iter [00250, 00390], lr: 0.020000, loss: 2.3340
2023-07-02 01:25:47 - train: epoch 0089, iter [00300, 00390], lr: 0.020000, loss: 2.4907
2023-07-02 01:25:48 - train: epoch 0104, iter [00300, 00390], lr: 0.020000, loss: 2.7132
2023-07-02 01:25:49 - train: epoch 0089, iter [00350, 00390], lr: 0.020000, loss: 2.3485
2023-07-02 01:25:50 - train: epoch 0104, iter [00350, 00390], lr: 0.020000, loss: 2.8972
2023-07-02 01:25:51 - train: epoch 089, train_loss: 2.4860
2023-07-02 01:25:51 - train: epoch 104, train_loss: 2.8334
2023-07-02 01:25:52 - eval: epoch: 089, acc1: 37.500%, acc5: 67.010%, test_loss: 2.5323, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:25:53 - eval: epoch: 104, acc1: 34.260%, acc5: 65.410%, test_loss: 2.6045, per_image_load_time: 0.067ms, per_image_inference_time: 0.055ms
2023-07-02 01:25:53 - until epoch: 104, best_acc1: 35.690%
2023-07-02 01:25:53 - epoch 105 lr: 0.020000
2023-07-02 01:25:54 - until epoch: 089, best_acc1: 38.170%
2023-07-02 01:25:54 - epoch 090 lr: 0.020000
2023-07-02 01:25:56 - train: epoch 0105, iter [00050, 00390], lr: 0.020000, loss: 2.8362
2023-07-02 01:25:57 - train: epoch 0090, iter [00050, 00390], lr: 0.020000, loss: 2.4729
2023-07-02 01:25:58 - train: epoch 0105, iter [00100, 00390], lr: 0.020000, loss: 3.0012
2023-07-02 01:25:59 - train: epoch 0090, iter [00100, 00390], lr: 0.020000, loss: 2.4391
2023-07-02 01:26:00 - train: epoch 0105, iter [00150, 00390], lr: 0.020000, loss: 2.4867
2023-07-02 01:26:01 - train: epoch 0090, iter [00150, 00390], lr: 0.020000, loss: 2.6074
2023-07-02 01:26:02 - train: epoch 0105, iter [00200, 00390], lr: 0.020000, loss: 2.5681
2023-07-02 01:26:03 - train: epoch 0090, iter [00200, 00390], lr: 0.020000, loss: 2.5963
2023-07-02 01:26:04 - train: epoch 0105, iter [00250, 00390], lr: 0.020000, loss: 2.3193
2023-07-02 01:26:05 - train: epoch 0090, iter [00250, 00390], lr: 0.020000, loss: 2.3130
2023-07-02 01:26:06 - train: epoch 0105, iter [00300, 00390], lr: 0.020000, loss: 2.9487
2023-07-02 01:26:07 - train: epoch 0090, iter [00300, 00390], lr: 0.020000, loss: 2.4243
2023-07-02 01:26:08 - train: epoch 0105, iter [00350, 00390], lr: 0.020000, loss: 2.3791
2023-07-02 01:26:09 - train: epoch 0090, iter [00350, 00390], lr: 0.020000, loss: 2.4809
2023-07-02 01:26:10 - train: epoch 105, train_loss: 2.8309
2023-07-02 01:26:11 - train: epoch 090, train_loss: 2.4664
2023-07-02 01:26:11 - eval: epoch: 105, acc1: 34.480%, acc5: 65.360%, test_loss: 2.5865, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:26:12 - until epoch: 105, best_acc1: 35.690%
2023-07-02 01:26:12 - epoch 106 lr: 0.020000
2023-07-02 01:26:13 - eval: epoch: 090, acc1: 37.530%, acc5: 66.210%, test_loss: 2.5455, per_image_load_time: 0.080ms, per_image_inference_time: 0.069ms
2023-07-02 01:26:13 - until epoch: 090, best_acc1: 38.170%
2023-07-02 01:26:13 - epoch 091 lr: 0.020000
2023-07-02 01:26:14 - train: epoch 0106, iter [00050, 00390], lr: 0.020000, loss: 3.2840
2023-07-02 01:26:16 - train: epoch 0091, iter [00050, 00390], lr: 0.020000, loss: 2.3066
2023-07-02 01:26:16 - train: epoch 0106, iter [00100, 00390], lr: 0.020000, loss: 2.3237
2023-07-02 01:26:18 - train: epoch 0091, iter [00100, 00390], lr: 0.020000, loss: 2.2595
2023-07-02 01:26:18 - train: epoch 0106, iter [00150, 00390], lr: 0.020000, loss: 3.4402
2023-07-02 01:26:20 - train: epoch 0091, iter [00150, 00390], lr: 0.020000, loss: 2.5669
2023-07-02 01:26:20 - train: epoch 0106, iter [00200, 00390], lr: 0.020000, loss: 2.8594
2023-07-02 01:26:22 - train: epoch 0091, iter [00200, 00390], lr: 0.020000, loss: 2.4563
2023-07-02 01:26:22 - train: epoch 0106, iter [00250, 00390], lr: 0.020000, loss: 2.9427
2023-07-02 01:26:24 - train: epoch 0091, iter [00250, 00390], lr: 0.020000, loss: 2.7213
2023-07-02 01:26:25 - train: epoch 0106, iter [00300, 00390], lr: 0.020000, loss: 2.8499
2023-07-02 01:26:27 - train: epoch 0106, iter [00350, 00390], lr: 0.020000, loss: 2.5280
2023-07-02 01:26:27 - train: epoch 0091, iter [00300, 00390], lr: 0.020000, loss: 2.3793
2023-07-02 01:26:28 - train: epoch 106, train_loss: 2.8448
2023-07-02 01:26:29 - train: epoch 0091, iter [00350, 00390], lr: 0.020000, loss: 2.7784
2023-07-02 01:26:30 - eval: epoch: 106, acc1: 34.410%, acc5: 65.390%, test_loss: 2.5797, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:26:30 - until epoch: 106, best_acc1: 35.690%
2023-07-02 01:26:30 - epoch 107 lr: 0.020000
2023-07-02 01:26:30 - train: epoch 091, train_loss: 2.4657
2023-07-02 01:26:32 - eval: epoch: 091, acc1: 36.710%, acc5: 66.340%, test_loss: 2.5452, per_image_load_time: 0.077ms, per_image_inference_time: 0.056ms
2023-07-02 01:26:32 - until epoch: 091, best_acc1: 38.170%
2023-07-02 01:26:32 - epoch 092 lr: 0.020000
2023-07-02 01:26:32 - train: epoch 0107, iter [00050, 00390], lr: 0.020000, loss: 2.5184
2023-07-02 01:26:34 - train: epoch 0107, iter [00100, 00390], lr: 0.020000, loss: 2.4641
2023-07-02 01:26:35 - train: epoch 0092, iter [00050, 00390], lr: 0.020000, loss: 2.3581
2023-07-02 01:26:36 - train: epoch 0107, iter [00150, 00390], lr: 0.020000, loss: 2.6178
2023-07-02 01:26:37 - train: epoch 0092, iter [00100, 00390], lr: 0.020000, loss: 2.3863
2023-07-02 01:26:39 - train: epoch 0107, iter [00200, 00390], lr: 0.020000, loss: 2.5165
2023-07-02 01:26:39 - train: epoch 0092, iter [00150, 00390], lr: 0.020000, loss: 2.3670
2023-07-02 01:26:41 - train: epoch 0107, iter [00250, 00390], lr: 0.020000, loss: 2.7341
2023-07-02 01:26:41 - train: epoch 0092, iter [00200, 00390], lr: 0.020000, loss: 2.5480
2023-07-02 01:26:43 - train: epoch 0107, iter [00300, 00390], lr: 0.020000, loss: 2.6493
2023-07-02 01:26:44 - train: epoch 0092, iter [00250, 00390], lr: 0.020000, loss: 2.4932
2023-07-02 01:26:45 - train: epoch 0107, iter [00350, 00390], lr: 0.020000, loss: 3.9697
2023-07-02 01:26:46 - train: epoch 107, train_loss: 2.8055
2023-07-02 01:26:46 - train: epoch 0092, iter [00300, 00390], lr: 0.020000, loss: 2.3585
2023-07-02 01:26:48 - eval: epoch: 107, acc1: 35.310%, acc5: 65.360%, test_loss: 2.5770, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-07-02 01:26:48 - until epoch: 107, best_acc1: 35.690%
2023-07-02 01:26:48 - epoch 108 lr: 0.020000
2023-07-02 01:26:48 - train: epoch 0092, iter [00350, 00390], lr: 0.020000, loss: 2.3400
2023-07-02 01:26:50 - train: epoch 092, train_loss: 2.4533
2023-07-02 01:26:51 - train: epoch 0108, iter [00050, 00390], lr: 0.020000, loss: 3.0872
2023-07-02 01:26:51 - eval: epoch: 092, acc1: 37.800%, acc5: 66.760%, test_loss: 2.5260, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:26:51 - until epoch: 092, best_acc1: 38.170%
2023-07-02 01:26:51 - epoch 093 lr: 0.020000
2023-07-02 01:26:52 - train: epoch 0108, iter [00100, 00390], lr: 0.020000, loss: 3.1660
2023-07-02 01:26:54 - train: epoch 0093, iter [00050, 00390], lr: 0.020000, loss: 2.3009
2023-07-02 01:26:54 - train: epoch 0108, iter [00150, 00390], lr: 0.020000, loss: 2.9631
2023-07-02 01:26:56 - train: epoch 0093, iter [00100, 00390], lr: 0.020000, loss: 2.3895
2023-07-02 01:26:56 - train: epoch 0108, iter [00200, 00390], lr: 0.020000, loss: 2.6750
2023-07-02 01:26:58 - train: epoch 0093, iter [00150, 00390], lr: 0.020000, loss: 2.7198
2023-07-02 01:26:58 - train: epoch 0108, iter [00250, 00390], lr: 0.020000, loss: 3.0537
2023-07-02 01:27:00 - train: epoch 0093, iter [00200, 00390], lr: 0.020000, loss: 2.4908
2023-07-02 01:27:00 - train: epoch 0108, iter [00300, 00390], lr: 0.020000, loss: 2.9158
2023-07-02 01:27:02 - train: epoch 0093, iter [00250, 00390], lr: 0.020000, loss: 2.3957
2023-07-02 01:27:03 - train: epoch 0108, iter [00350, 00390], lr: 0.020000, loss: 2.5640
2023-07-02 01:27:04 - train: epoch 108, train_loss: 2.8435
2023-07-02 01:27:04 - train: epoch 0093, iter [00300, 00390], lr: 0.020000, loss: 2.4935
2023-07-02 01:27:06 - eval: epoch: 108, acc1: 34.230%, acc5: 64.950%, test_loss: 2.6049, per_image_load_time: 0.076ms, per_image_inference_time: 0.053ms
2023-07-02 01:27:06 - until epoch: 108, best_acc1: 35.690%
2023-07-02 01:27:06 - epoch 109 lr: 0.020000
2023-07-02 01:27:06 - train: epoch 0093, iter [00350, 00390], lr: 0.020000, loss: 2.5292
2023-07-02 01:27:08 - train: epoch 093, train_loss: 2.4545
2023-07-02 01:27:09 - train: epoch 0109, iter [00050, 00390], lr: 0.020000, loss: 2.5943
2023-07-02 01:27:09 - eval: epoch: 093, acc1: 38.260%, acc5: 67.210%, test_loss: 2.5090, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:27:10 - until epoch: 093, best_acc1: 38.260%
2023-07-02 01:27:10 - epoch 094 lr: 0.020000
2023-07-02 01:27:10 - train: epoch 0109, iter [00100, 00390], lr: 0.020000, loss: 2.2634
2023-07-02 01:27:12 - train: epoch 0109, iter [00150, 00390], lr: 0.020000, loss: 2.8257
2023-07-02 01:27:13 - train: epoch 0094, iter [00050, 00390], lr: 0.020000, loss: 2.1615
2023-07-02 01:27:14 - train: epoch 0109, iter [00200, 00390], lr: 0.020000, loss: 2.6531
2023-07-02 01:27:15 - train: epoch 0094, iter [00100, 00390], lr: 0.020000, loss: 2.3727
2023-07-02 01:27:16 - train: epoch 0109, iter [00250, 00390], lr: 0.020000, loss: 2.9865
2023-07-02 01:27:17 - train: epoch 0094, iter [00150, 00390], lr: 0.020000, loss: 2.3437
2023-07-02 01:27:18 - train: epoch 0109, iter [00300, 00390], lr: 0.020000, loss: 2.4377
2023-07-02 01:27:19 - train: epoch 0094, iter [00200, 00390], lr: 0.020000, loss: 2.4788
2023-07-02 01:27:20 - train: epoch 0109, iter [00350, 00390], lr: 0.020000, loss: 2.9681
2023-07-02 01:27:21 - train: epoch 0094, iter [00250, 00390], lr: 0.020000, loss: 2.4283
2023-07-02 01:27:22 - train: epoch 109, train_loss: 2.7851
2023-07-02 01:27:23 - train: epoch 0094, iter [00300, 00390], lr: 0.020000, loss: 2.3442
2023-07-02 01:27:23 - eval: epoch: 109, acc1: 35.330%, acc5: 65.830%, test_loss: 2.5712, per_image_load_time: 0.081ms, per_image_inference_time: 0.053ms
2023-07-02 01:27:24 - until epoch: 109, best_acc1: 35.690%
2023-07-02 01:27:24 - epoch 110 lr: 0.020000
2023-07-02 01:27:24 - train: epoch 0094, iter [00350, 00390], lr: 0.020000, loss: 2.4560
2023-07-02 01:27:26 - train: epoch 094, train_loss: 2.4376
2023-07-02 01:27:26 - train: epoch 0110, iter [00050, 00390], lr: 0.020000, loss: 2.6524
2023-07-02 01:27:28 - eval: epoch: 094, acc1: 38.140%, acc5: 66.980%, test_loss: 2.5277, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:27:28 - until epoch: 094, best_acc1: 38.260%
2023-07-02 01:27:28 - epoch 095 lr: 0.020000
2023-07-02 01:27:28 - train: epoch 0110, iter [00100, 00390], lr: 0.020000, loss: 3.5282
2023-07-02 01:27:30 - train: epoch 0110, iter [00150, 00390], lr: 0.020000, loss: 3.0936
2023-07-02 01:27:31 - train: epoch 0095, iter [00050, 00390], lr: 0.020000, loss: 2.4795
2023-07-02 01:27:33 - train: epoch 0110, iter [00200, 00390], lr: 0.020000, loss: 2.8695
2023-07-02 01:27:33 - train: epoch 0095, iter [00100, 00390], lr: 0.020000, loss: 2.4088
2023-07-02 01:27:35 - train: epoch 0110, iter [00250, 00390], lr: 0.020000, loss: 3.2947
2023-07-02 01:27:35 - train: epoch 0095, iter [00150, 00390], lr: 0.020000, loss: 2.5591
2023-07-02 01:27:37 - train: epoch 0110, iter [00300, 00390], lr: 0.020000, loss: 3.3989
2023-07-02 01:27:37 - train: epoch 0095, iter [00200, 00390], lr: 0.020000, loss: 2.3960
2023-07-02 01:27:39 - train: epoch 0110, iter [00350, 00390], lr: 0.020000, loss: 2.3581
2023-07-02 01:27:39 - train: epoch 0095, iter [00250, 00390], lr: 0.020000, loss: 2.3991
2023-07-02 01:27:41 - train: epoch 110, train_loss: 2.8143
2023-07-02 01:27:41 - train: epoch 0095, iter [00300, 00390], lr: 0.020000, loss: 2.4455
2023-07-02 01:27:42 - eval: epoch: 110, acc1: 35.020%, acc5: 65.950%, test_loss: 2.5591, per_image_load_time: 0.070ms, per_image_inference_time: 0.062ms
2023-07-02 01:27:42 - until epoch: 110, best_acc1: 35.690%
2023-07-02 01:27:42 - epoch 111 lr: 0.020000
2023-07-02 01:27:43 - train: epoch 0095, iter [00350, 00390], lr: 0.020000, loss: 2.4095
2023-07-02 01:27:44 - train: epoch 095, train_loss: 2.4361
2023-07-02 01:27:45 - train: epoch 0111, iter [00050, 00390], lr: 0.020000, loss: 2.3296
2023-07-02 01:27:46 - eval: epoch: 095, acc1: 37.300%, acc5: 66.870%, test_loss: 2.5397, per_image_load_time: 0.082ms, per_image_inference_time: 0.056ms
2023-07-02 01:27:46 - until epoch: 095, best_acc1: 38.260%
2023-07-02 01:27:46 - epoch 096 lr: 0.020000
2023-07-02 01:27:46 - train: epoch 0111, iter [00100, 00390], lr: 0.020000, loss: 2.7470
2023-07-02 01:27:49 - train: epoch 0111, iter [00150, 00390], lr: 0.020000, loss: 3.2890
2023-07-02 01:27:49 - train: epoch 0096, iter [00050, 00390], lr: 0.020000, loss: 2.2872
2023-07-02 01:27:51 - train: epoch 0111, iter [00200, 00390], lr: 0.020000, loss: 2.2492
2023-07-02 01:27:51 - train: epoch 0096, iter [00100, 00390], lr: 0.020000, loss: 2.1923
2023-07-02 01:27:53 - train: epoch 0111, iter [00250, 00390], lr: 0.020000, loss: 2.6263
2023-07-02 01:27:53 - train: epoch 0096, iter [00150, 00390], lr: 0.020000, loss: 2.3808
2023-07-02 01:27:55 - train: epoch 0111, iter [00300, 00390], lr: 0.020000, loss: 2.5125
2023-07-02 01:27:56 - train: epoch 0096, iter [00200, 00390], lr: 0.020000, loss: 2.3349
2023-07-02 01:27:57 - train: epoch 0111, iter [00350, 00390], lr: 0.020000, loss: 2.9997
2023-07-02 01:27:58 - train: epoch 0096, iter [00250, 00390], lr: 0.020000, loss: 2.4802
2023-07-02 01:27:59 - train: epoch 111, train_loss: 2.8421
2023-07-02 01:27:59 - train: epoch 0096, iter [00300, 00390], lr: 0.020000, loss: 2.5956
2023-07-02 01:28:00 - eval: epoch: 111, acc1: 35.380%, acc5: 65.130%, test_loss: 2.5816, per_image_load_time: 0.071ms, per_image_inference_time: 0.055ms
2023-07-02 01:28:00 - until epoch: 111, best_acc1: 35.690%
2023-07-02 01:28:00 - epoch 112 lr: 0.020000
2023-07-02 01:28:01 - train: epoch 0096, iter [00350, 00390], lr: 0.020000, loss: 2.4595
2023-07-02 01:28:03 - train: epoch 096, train_loss: 2.4292
2023-07-02 01:28:03 - train: epoch 0112, iter [00050, 00390], lr: 0.020000, loss: 2.9357
2023-07-02 01:28:04 - eval: epoch: 096, acc1: 37.110%, acc5: 66.230%, test_loss: 2.5544, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:28:04 - until epoch: 096, best_acc1: 38.260%
2023-07-02 01:28:04 - epoch 097 lr: 0.020000
2023-07-02 01:28:05 - train: epoch 0112, iter [00100, 00390], lr: 0.020000, loss: 2.2983
2023-07-02 01:28:07 - train: epoch 0112, iter [00150, 00390], lr: 0.020000, loss: 3.0704
2023-07-02 01:28:07 - train: epoch 0097, iter [00050, 00390], lr: 0.020000, loss: 2.4551
2023-07-02 01:28:09 - train: epoch 0112, iter [00200, 00390], lr: 0.020000, loss: 2.8047
2023-07-02 01:28:10 - train: epoch 0097, iter [00100, 00390], lr: 0.020000, loss: 2.2730
2023-07-02 01:28:11 - train: epoch 0112, iter [00250, 00390], lr: 0.020000, loss: 2.6096
2023-07-02 01:28:12 - train: epoch 0097, iter [00150, 00390], lr: 0.020000, loss: 2.2622
2023-07-02 01:28:13 - train: epoch 0112, iter [00300, 00390], lr: 0.020000, loss: 2.9624
2023-07-02 01:28:14 - train: epoch 0097, iter [00200, 00390], lr: 0.020000, loss: 2.7408
2023-07-02 01:28:15 - train: epoch 0112, iter [00350, 00390], lr: 0.020000, loss: 2.5092
2023-07-02 01:28:16 - train: epoch 0097, iter [00250, 00390], lr: 0.020000, loss: 2.3063
2023-07-02 01:28:16 - train: epoch 112, train_loss: 2.7907
2023-07-02 01:28:18 - train: epoch 0097, iter [00300, 00390], lr: 0.020000, loss: 2.2964
2023-07-02 01:28:18 - eval: epoch: 112, acc1: 33.920%, acc5: 65.530%, test_loss: 2.5915, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:28:18 - until epoch: 112, best_acc1: 35.690%
2023-07-02 01:28:18 - epoch 113 lr: 0.020000
2023-07-02 01:28:19 - train: epoch 0097, iter [00350, 00390], lr: 0.020000, loss: 2.5152
2023-07-02 01:28:21 - train: epoch 0113, iter [00050, 00390], lr: 0.020000, loss: 2.6898
2023-07-02 01:28:21 - train: epoch 097, train_loss: 2.4154
2023-07-02 01:28:23 - train: epoch 0113, iter [00100, 00390], lr: 0.020000, loss: 2.4707
2023-07-02 01:28:23 - eval: epoch: 097, acc1: 37.450%, acc5: 66.860%, test_loss: 2.5460, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:28:23 - until epoch: 097, best_acc1: 38.260%
2023-07-02 01:28:23 - epoch 098 lr: 0.020000
2023-07-02 01:28:24 - train: epoch 0113, iter [00150, 00390], lr: 0.020000, loss: 2.9922
2023-07-02 01:28:26 - train: epoch 0098, iter [00050, 00390], lr: 0.020000, loss: 2.2820
2023-07-02 01:28:26 - train: epoch 0113, iter [00200, 00390], lr: 0.020000, loss: 2.7495
2023-07-02 01:28:28 - train: epoch 0098, iter [00100, 00390], lr: 0.020000, loss: 2.2615
2023-07-02 01:28:28 - train: epoch 0113, iter [00250, 00390], lr: 0.020000, loss: 2.8506
2023-07-02 01:28:30 - train: epoch 0098, iter [00150, 00390], lr: 0.020000, loss: 2.3514
2023-07-02 01:28:30 - train: epoch 0113, iter [00300, 00390], lr: 0.020000, loss: 2.5387
2023-07-02 01:28:32 - train: epoch 0098, iter [00200, 00390], lr: 0.020000, loss: 2.4955
2023-07-02 01:28:32 - train: epoch 0113, iter [00350, 00390], lr: 0.020000, loss: 2.3600
2023-07-02 01:28:34 - train: epoch 0098, iter [00250, 00390], lr: 0.020000, loss: 2.4251
2023-07-02 01:28:34 - train: epoch 113, train_loss: 2.8100
2023-07-02 01:28:36 - eval: epoch: 113, acc1: 34.750%, acc5: 65.750%, test_loss: 2.5525, per_image_load_time: 0.070ms, per_image_inference_time: 0.055ms
2023-07-02 01:28:36 - train: epoch 0098, iter [00300, 00390], lr: 0.020000, loss: 2.6413
2023-07-02 01:28:36 - until epoch: 113, best_acc1: 35.690%
2023-07-02 01:28:36 - epoch 114 lr: 0.020000
2023-07-02 01:28:37 - train: epoch 0098, iter [00350, 00390], lr: 0.020000, loss: 2.5929
2023-07-02 01:28:39 - train: epoch 0114, iter [00050, 00390], lr: 0.020000, loss: 2.6567
2023-07-02 01:28:39 - train: epoch 098, train_loss: 2.4071
2023-07-02 01:28:40 - train: epoch 0114, iter [00100, 00390], lr: 0.020000, loss: 3.1902
2023-07-02 01:28:41 - eval: epoch: 098, acc1: 37.620%, acc5: 66.270%, test_loss: 2.5579, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:28:41 - until epoch: 098, best_acc1: 38.260%
2023-07-02 01:28:41 - epoch 099 lr: 0.020000
2023-07-02 01:28:42 - train: epoch 0114, iter [00150, 00390], lr: 0.020000, loss: 2.3853
2023-07-02 01:28:44 - train: epoch 0099, iter [00050, 00390], lr: 0.020000, loss: 2.5403
2023-07-02 01:28:44 - train: epoch 0114, iter [00200, 00390], lr: 0.020000, loss: 2.6831
2023-07-02 01:28:46 - train: epoch 0099, iter [00100, 00390], lr: 0.020000, loss: 2.2805
2023-07-02 01:28:46 - train: epoch 0114, iter [00250, 00390], lr: 0.020000, loss: 2.9122
2023-07-02 01:28:48 - train: epoch 0099, iter [00150, 00390], lr: 0.020000, loss: 2.2794
2023-07-02 01:28:48 - train: epoch 0114, iter [00300, 00390], lr: 0.020000, loss: 2.5239
2023-07-02 01:28:50 - train: epoch 0099, iter [00200, 00390], lr: 0.020000, loss: 2.4416
2023-07-02 01:28:50 - train: epoch 0114, iter [00350, 00390], lr: 0.020000, loss: 3.3571
2023-07-02 01:28:52 - train: epoch 114, train_loss: 2.7616
2023-07-02 01:28:52 - train: epoch 0099, iter [00250, 00390], lr: 0.020000, loss: 2.2743
2023-07-02 01:28:53 - eval: epoch: 114, acc1: 35.690%, acc5: 66.340%, test_loss: 2.5495, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:28:54 - until epoch: 114, best_acc1: 35.690%
2023-07-02 01:28:54 - epoch 115 lr: 0.020000
2023-07-02 01:28:54 - train: epoch 0099, iter [00300, 00390], lr: 0.020000, loss: 2.4505
2023-07-02 01:28:56 - train: epoch 0099, iter [00350, 00390], lr: 0.020000, loss: 2.6280
2023-07-02 01:28:57 - train: epoch 0115, iter [00050, 00390], lr: 0.020000, loss: 3.0675
2023-07-02 01:28:57 - train: epoch 099, train_loss: 2.4075
2023-07-02 01:28:58 - train: epoch 0115, iter [00100, 00390], lr: 0.020000, loss: 2.6359
2023-07-02 01:28:59 - eval: epoch: 099, acc1: 37.370%, acc5: 66.200%, test_loss: 2.5570, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:28:59 - until epoch: 099, best_acc1: 38.260%
2023-07-02 01:28:59 - epoch 100 lr: 0.020000
2023-07-02 01:29:00 - train: epoch 0115, iter [00150, 00390], lr: 0.020000, loss: 2.5483
2023-07-02 01:29:02 - train: epoch 0115, iter [00200, 00390], lr: 0.020000, loss: 2.9807
2023-07-02 01:29:02 - train: epoch 0100, iter [00050, 00390], lr: 0.020000, loss: 2.3471
2023-07-02 01:29:04 - train: epoch 0115, iter [00250, 00390], lr: 0.020000, loss: 3.2843
2023-07-02 01:29:04 - train: epoch 0100, iter [00100, 00390], lr: 0.020000, loss: 1.9626
2023-07-02 01:29:06 - train: epoch 0115, iter [00300, 00390], lr: 0.020000, loss: 3.2362
2023-07-02 01:29:06 - train: epoch 0100, iter [00150, 00390], lr: 0.020000, loss: 2.2481
2023-07-02 01:29:08 - train: epoch 0115, iter [00350, 00390], lr: 0.020000, loss: 3.3918
2023-07-02 01:29:09 - train: epoch 0100, iter [00200, 00390], lr: 0.020000, loss: 2.3700
2023-07-02 01:29:10 - train: epoch 115, train_loss: 2.8585
2023-07-02 01:29:10 - train: epoch 0100, iter [00250, 00390], lr: 0.020000, loss: 2.4289
2023-07-02 01:29:11 - eval: epoch: 115, acc1: 35.540%, acc5: 65.570%, test_loss: 2.5551, per_image_load_time: 0.075ms, per_image_inference_time: 0.053ms
2023-07-02 01:29:12 - until epoch: 115, best_acc1: 35.690%
2023-07-02 01:29:12 - epoch 116 lr: 0.020000
2023-07-02 01:29:12 - train: epoch 0100, iter [00300, 00390], lr: 0.020000, loss: 2.4570
2023-07-02 01:29:15 - train: epoch 0116, iter [00050, 00390], lr: 0.020000, loss: 3.4628
2023-07-02 01:29:15 - train: epoch 0100, iter [00350, 00390], lr: 0.020000, loss: 2.3496
2023-07-02 01:29:16 - train: epoch 100, train_loss: 2.3909
2023-07-02 01:29:17 - train: epoch 0116, iter [00100, 00390], lr: 0.020000, loss: 2.6444
2023-07-02 01:29:18 - eval: epoch: 100, acc1: 37.280%, acc5: 66.620%, test_loss: 2.5469, per_image_load_time: 0.068ms, per_image_inference_time: 0.057ms
2023-07-02 01:29:18 - until epoch: 100, best_acc1: 38.260%
2023-07-02 01:29:18 - epoch 101 lr: 0.020000
2023-07-02 01:29:18 - train: epoch 0116, iter [00150, 00390], lr: 0.020000, loss: 2.2633
2023-07-02 01:29:20 - train: epoch 0116, iter [00200, 00390], lr: 0.020000, loss: 2.5078
2023-07-02 01:29:21 - train: epoch 0101, iter [00050, 00390], lr: 0.020000, loss: 2.3390
2023-07-02 01:29:22 - train: epoch 0116, iter [00250, 00390], lr: 0.020000, loss: 3.7122
2023-07-02 01:29:23 - train: epoch 0101, iter [00100, 00390], lr: 0.020000, loss: 2.3851
2023-07-02 01:29:24 - train: epoch 0116, iter [00300, 00390], lr: 0.020000, loss: 2.9035
2023-07-02 01:29:25 - train: epoch 0101, iter [00150, 00390], lr: 0.020000, loss: 2.6034
2023-07-02 01:29:26 - train: epoch 0116, iter [00350, 00390], lr: 0.020000, loss: 2.9098
2023-07-02 01:29:27 - train: epoch 0101, iter [00200, 00390], lr: 0.020000, loss: 2.3065
2023-07-02 01:29:28 - train: epoch 116, train_loss: 2.8084
2023-07-02 01:29:29 - train: epoch 0101, iter [00250, 00390], lr: 0.020000, loss: 2.4245
2023-07-02 01:29:30 - eval: epoch: 116, acc1: 35.050%, acc5: 65.020%, test_loss: 2.5754, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-07-02 01:29:30 - until epoch: 116, best_acc1: 35.690%
2023-07-02 01:29:30 - epoch 117 lr: 0.020000
2023-07-02 01:29:31 - train: epoch 0101, iter [00300, 00390], lr: 0.020000, loss: 2.5161
2023-07-02 01:29:33 - train: epoch 0117, iter [00050, 00390], lr: 0.020000, loss: 2.7882
2023-07-02 01:29:33 - train: epoch 0101, iter [00350, 00390], lr: 0.020000, loss: 2.1764
2023-07-02 01:29:35 - train: epoch 101, train_loss: 2.3870
2023-07-02 01:29:35 - train: epoch 0117, iter [00100, 00390], lr: 0.020000, loss: 2.5415
2023-07-02 01:29:36 - eval: epoch: 101, acc1: 37.480%, acc5: 66.630%, test_loss: 2.5541, per_image_load_time: 0.069ms, per_image_inference_time: 0.056ms
2023-07-02 01:29:36 - train: epoch 0117, iter [00150, 00390], lr: 0.020000, loss: 2.3097
2023-07-02 01:29:37 - until epoch: 101, best_acc1: 38.260%
2023-07-02 01:29:37 - epoch 102 lr: 0.020000
2023-07-02 01:29:38 - train: epoch 0117, iter [00200, 00390], lr: 0.020000, loss: 2.7550
2023-07-02 01:29:40 - train: epoch 0102, iter [00050, 00390], lr: 0.020000, loss: 2.3837
2023-07-02 01:29:40 - train: epoch 0117, iter [00250, 00390], lr: 0.020000, loss: 3.3700
2023-07-02 01:29:42 - train: epoch 0102, iter [00100, 00390], lr: 0.020000, loss: 2.3942
2023-07-02 01:29:42 - train: epoch 0117, iter [00300, 00390], lr: 0.020000, loss: 2.9378
2023-07-02 01:29:44 - train: epoch 0102, iter [00150, 00390], lr: 0.020000, loss: 2.5621
2023-07-02 01:29:44 - train: epoch 0117, iter [00350, 00390], lr: 0.020000, loss: 2.4781
2023-07-02 01:29:46 - train: epoch 117, train_loss: 2.7937
2023-07-02 01:29:46 - train: epoch 0102, iter [00200, 00390], lr: 0.020000, loss: 2.1654
2023-07-02 01:29:47 - eval: epoch: 117, acc1: 36.500%, acc5: 66.320%, test_loss: 2.5309, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-07-02 01:29:48 - until epoch: 117, best_acc1: 36.500%
2023-07-02 01:29:48 - epoch 118 lr: 0.020000
2023-07-02 01:29:48 - train: epoch 0102, iter [00250, 00390], lr: 0.020000, loss: 2.4188
2023-07-02 01:29:50 - train: epoch 0102, iter [00300, 00390], lr: 0.020000, loss: 2.3402
2023-07-02 01:29:50 - train: epoch 0118, iter [00050, 00390], lr: 0.020000, loss: 2.5905
2023-07-02 01:29:52 - train: epoch 0102, iter [00350, 00390], lr: 0.020000, loss: 2.4689
2023-07-02 01:29:52 - train: epoch 0118, iter [00100, 00390], lr: 0.020000, loss: 3.1194
2023-07-02 01:29:53 - train: epoch 102, train_loss: 2.3801
2023-07-02 01:29:54 - train: epoch 0118, iter [00150, 00390], lr: 0.020000, loss: 2.5469
2023-07-02 01:29:55 - eval: epoch: 102, acc1: 37.400%, acc5: 66.990%, test_loss: 2.5454, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:29:55 - until epoch: 102, best_acc1: 38.260%
2023-07-02 01:29:55 - epoch 103 lr: 0.020000
2023-07-02 01:29:56 - train: epoch 0118, iter [00200, 00390], lr: 0.020000, loss: 3.2952
2023-07-02 01:29:58 - train: epoch 0118, iter [00250, 00390], lr: 0.020000, loss: 2.3987
2023-07-02 01:29:58 - train: epoch 0103, iter [00050, 00390], lr: 0.020000, loss: 2.1877
2023-07-02 01:30:00 - train: epoch 0118, iter [00300, 00390], lr: 0.020000, loss: 2.9015
2023-07-02 01:30:00 - train: epoch 0103, iter [00100, 00390], lr: 0.020000, loss: 2.4910
2023-07-02 01:30:02 - train: epoch 0118, iter [00350, 00390], lr: 0.020000, loss: 3.2069
2023-07-02 01:30:02 - train: epoch 0103, iter [00150, 00390], lr: 0.020000, loss: 2.2421
2023-07-02 01:30:04 - train: epoch 118, train_loss: 2.7870
2023-07-02 01:30:04 - train: epoch 0103, iter [00200, 00390], lr: 0.020000, loss: 2.4582
2023-07-02 01:30:05 - eval: epoch: 118, acc1: 35.940%, acc5: 66.210%, test_loss: 2.5446, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-07-02 01:30:05 - until epoch: 118, best_acc1: 36.500%
2023-07-02 01:30:05 - epoch 119 lr: 0.020000
2023-07-02 01:30:06 - train: epoch 0103, iter [00250, 00390], lr: 0.020000, loss: 2.3352
2023-07-02 01:30:08 - train: epoch 0103, iter [00300, 00390], lr: 0.020000, loss: 2.3749
2023-07-02 01:30:08 - train: epoch 0119, iter [00050, 00390], lr: 0.020000, loss: 2.3204
2023-07-02 01:30:10 - train: epoch 0103, iter [00350, 00390], lr: 0.020000, loss: 2.4798
2023-07-02 01:30:10 - train: epoch 0119, iter [00100, 00390], lr: 0.020000, loss: 2.5304
2023-07-02 01:30:12 - train: epoch 103, train_loss: 2.3670
2023-07-02 01:30:12 - train: epoch 0119, iter [00150, 00390], lr: 0.020000, loss: 2.5357
2023-07-02 01:30:13 - eval: epoch: 103, acc1: 37.750%, acc5: 67.060%, test_loss: 2.5362, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:30:14 - until epoch: 103, best_acc1: 38.260%
2023-07-02 01:30:14 - epoch 104 lr: 0.020000
2023-07-02 01:30:14 - train: epoch 0119, iter [00200, 00390], lr: 0.020000, loss: 2.7404
2023-07-02 01:30:16 - train: epoch 0119, iter [00250, 00390], lr: 0.020000, loss: 2.7781
2023-07-02 01:30:16 - train: epoch 0104, iter [00050, 00390], lr: 0.020000, loss: 2.2724
2023-07-02 01:30:18 - train: epoch 0119, iter [00300, 00390], lr: 0.020000, loss: 2.6716
2023-07-02 01:30:19 - train: epoch 0104, iter [00100, 00390], lr: 0.020000, loss: 2.4263
2023-07-02 01:30:20 - train: epoch 0119, iter [00350, 00390], lr: 0.020000, loss: 2.9794
2023-07-02 01:30:21 - train: epoch 0104, iter [00150, 00390], lr: 0.020000, loss: 2.2210
2023-07-02 01:30:21 - train: epoch 119, train_loss: 2.7917
2023-07-02 01:30:22 - train: epoch 0104, iter [00200, 00390], lr: 0.020000, loss: 2.3252
2023-07-02 01:30:23 - eval: epoch: 119, acc1: 35.200%, acc5: 65.910%, test_loss: 2.5650, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-07-02 01:30:23 - until epoch: 119, best_acc1: 36.500%
2023-07-02 01:30:23 - epoch 120 lr: 0.020000
2023-07-02 01:30:24 - train: epoch 0104, iter [00250, 00390], lr: 0.020000, loss: 2.2815
2023-07-02 01:30:26 - train: epoch 0120, iter [00050, 00390], lr: 0.020000, loss: 3.1604
2023-07-02 01:30:26 - train: epoch 0104, iter [00300, 00390], lr: 0.020000, loss: 2.4333
2023-07-02 01:30:28 - train: epoch 0120, iter [00100, 00390], lr: 0.020000, loss: 2.7494
2023-07-02 01:30:28 - train: epoch 0104, iter [00350, 00390], lr: 0.020000, loss: 2.5196
2023-07-02 01:30:30 - train: epoch 0120, iter [00150, 00390], lr: 0.020000, loss: 2.8787
2023-07-02 01:30:30 - train: epoch 104, train_loss: 2.3684
2023-07-02 01:30:32 - eval: epoch: 104, acc1: 37.760%, acc5: 66.370%, test_loss: 2.5589, per_image_load_time: 0.066ms, per_image_inference_time: 0.057ms
2023-07-02 01:30:32 - train: epoch 0120, iter [00200, 00390], lr: 0.020000, loss: 2.6666
2023-07-02 01:30:32 - until epoch: 104, best_acc1: 38.260%
2023-07-02 01:30:32 - epoch 105 lr: 0.020000
2023-07-02 01:30:33 - train: epoch 0120, iter [00250, 00390], lr: 0.020000, loss: 3.6617
2023-07-02 01:30:35 - train: epoch 0105, iter [00050, 00390], lr: 0.020000, loss: 2.2485
2023-07-02 01:30:35 - train: epoch 0120, iter [00300, 00390], lr: 0.020000, loss: 2.5373
2023-07-02 01:30:37 - train: epoch 0105, iter [00100, 00390], lr: 0.020000, loss: 2.3367
2023-07-02 01:30:37 - train: epoch 0120, iter [00350, 00390], lr: 0.020000, loss: 3.2476
2023-07-02 01:30:39 - train: epoch 0105, iter [00150, 00390], lr: 0.020000, loss: 2.2396
2023-07-02 01:30:39 - train: epoch 120, train_loss: 2.7749
2023-07-02 01:30:41 - eval: epoch: 120, acc1: 35.420%, acc5: 66.310%, test_loss: 2.5510, per_image_load_time: 0.068ms, per_image_inference_time: 0.055ms
2023-07-02 01:30:41 - train: epoch 0105, iter [00200, 00390], lr: 0.020000, loss: 2.3041
2023-07-02 01:30:41 - until epoch: 120, best_acc1: 36.500%
2023-07-02 01:30:41 - epoch 121 lr: 0.004000
2023-07-02 01:30:42 - train: epoch 0105, iter [00250, 00390], lr: 0.020000, loss: 2.3703
2023-07-02 01:30:44 - train: epoch 0121, iter [00050, 00390], lr: 0.004000, loss: 2.6854
2023-07-02 01:30:45 - train: epoch 0105, iter [00300, 00390], lr: 0.020000, loss: 2.3834
2023-07-02 01:30:46 - train: epoch 0121, iter [00100, 00390], lr: 0.004000, loss: 2.6775
2023-07-02 01:30:47 - train: epoch 0105, iter [00350, 00390], lr: 0.020000, loss: 2.4512
2023-07-02 01:30:48 - train: epoch 0121, iter [00150, 00390], lr: 0.004000, loss: 2.2324
2023-07-02 01:30:48 - train: epoch 105, train_loss: 2.3572
2023-07-02 01:30:49 - train: epoch 0121, iter [00200, 00390], lr: 0.004000, loss: 2.7132
2023-07-02 01:30:50 - eval: epoch: 105, acc1: 37.500%, acc5: 66.790%, test_loss: 2.5400, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:30:50 - until epoch: 105, best_acc1: 38.260%
2023-07-02 01:30:50 - epoch 106 lr: 0.020000
2023-07-02 01:30:51 - train: epoch 0121, iter [00250, 00390], lr: 0.004000, loss: 2.2981
2023-07-02 01:30:53 - train: epoch 0106, iter [00050, 00390], lr: 0.020000, loss: 2.1985
2023-07-02 01:30:53 - train: epoch 0121, iter [00300, 00390], lr: 0.004000, loss: 2.0505
2023-07-02 01:30:55 - train: epoch 0106, iter [00100, 00390], lr: 0.020000, loss: 2.3124
2023-07-02 01:30:55 - train: epoch 0121, iter [00350, 00390], lr: 0.004000, loss: 2.3376
2023-07-02 01:30:57 - train: epoch 121, train_loss: 2.5734
2023-07-02 01:30:57 - train: epoch 0106, iter [00150, 00390], lr: 0.020000, loss: 2.2991
2023-07-02 01:30:58 - eval: epoch: 121, acc1: 38.910%, acc5: 69.910%, test_loss: 2.3891, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 01:30:59 - train: epoch 0106, iter [00200, 00390], lr: 0.020000, loss: 2.5853
2023-07-02 01:30:59 - until epoch: 121, best_acc1: 38.910%
2023-07-02 01:30:59 - epoch 122 lr: 0.004000
2023-07-02 01:31:00 - train: epoch 0106, iter [00250, 00390], lr: 0.020000, loss: 2.4056
2023-07-02 01:31:02 - train: epoch 0122, iter [00050, 00390], lr: 0.004000, loss: 2.7604
2023-07-02 01:31:02 - train: epoch 0106, iter [00300, 00390], lr: 0.020000, loss: 2.5747
2023-07-02 01:31:04 - train: epoch 0122, iter [00100, 00390], lr: 0.004000, loss: 2.5390
2023-07-02 01:31:05 - train: epoch 0106, iter [00350, 00390], lr: 0.020000, loss: 2.2592
2023-07-02 01:31:06 - train: epoch 0122, iter [00150, 00390], lr: 0.004000, loss: 2.3693
2023-07-02 01:31:06 - train: epoch 106, train_loss: 2.3537
2023-07-02 01:31:08 - eval: epoch: 106, acc1: 37.040%, acc5: 65.950%, test_loss: 2.5879, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:31:08 - train: epoch 0122, iter [00200, 00390], lr: 0.004000, loss: 2.7800
2023-07-02 01:31:08 - until epoch: 106, best_acc1: 38.260%
2023-07-02 01:31:08 - epoch 107 lr: 0.020000
2023-07-02 01:31:10 - train: epoch 0122, iter [00250, 00390], lr: 0.004000, loss: 2.7691
2023-07-02 01:31:11 - train: epoch 0107, iter [00050, 00390], lr: 0.020000, loss: 2.3274
2023-07-02 01:31:12 - train: epoch 0122, iter [00300, 00390], lr: 0.004000, loss: 3.1759
2023-07-02 01:31:13 - train: epoch 0107, iter [00100, 00390], lr: 0.020000, loss: 2.3061
2023-07-02 01:31:15 - train: epoch 0122, iter [00350, 00390], lr: 0.004000, loss: 2.8041
2023-07-02 01:31:15 - train: epoch 0107, iter [00150, 00390], lr: 0.020000, loss: 2.5111
2023-07-02 01:31:17 - train: epoch 122, train_loss: 2.4885
2023-07-02 01:31:17 - train: epoch 0107, iter [00200, 00390], lr: 0.020000, loss: 2.2584
2023-07-02 01:31:18 - eval: epoch: 122, acc1: 39.730%, acc5: 69.800%, test_loss: 2.3664, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-07-02 01:31:19 - until epoch: 122, best_acc1: 39.730%
2023-07-02 01:31:19 - epoch 123 lr: 0.004000
2023-07-02 01:31:19 - train: epoch 0107, iter [00250, 00390], lr: 0.020000, loss: 2.4878
2023-07-02 01:31:21 - train: epoch 0107, iter [00300, 00390], lr: 0.020000, loss: 2.3058
2023-07-02 01:31:22 - train: epoch 0123, iter [00050, 00390], lr: 0.004000, loss: 2.6947
2023-07-02 01:31:23 - train: epoch 0107, iter [00350, 00390], lr: 0.020000, loss: 2.6501
2023-07-02 01:31:24 - train: epoch 0123, iter [00100, 00390], lr: 0.004000, loss: 2.0012
2023-07-02 01:31:25 - train: epoch 107, train_loss: 2.3392
2023-07-02 01:31:26 - train: epoch 0123, iter [00150, 00390], lr: 0.004000, loss: 2.4030
2023-07-02 01:31:26 - eval: epoch: 107, acc1: 37.210%, acc5: 66.260%, test_loss: 2.5688, per_image_load_time: 0.069ms, per_image_inference_time: 0.057ms
2023-07-02 01:31:26 - until epoch: 107, best_acc1: 38.260%
2023-07-02 01:31:26 - epoch 108 lr: 0.020000
2023-07-02 01:31:27 - train: epoch 0123, iter [00200, 00390], lr: 0.004000, loss: 2.0227
2023-07-02 01:31:29 - train: epoch 0108, iter [00050, 00390], lr: 0.020000, loss: 2.3263
2023-07-02 01:31:29 - train: epoch 0123, iter [00250, 00390], lr: 0.004000, loss: 2.2763
2023-07-02 01:31:31 - train: epoch 0108, iter [00100, 00390], lr: 0.020000, loss: 2.3624
2023-07-02 01:31:32 - train: epoch 0123, iter [00300, 00390], lr: 0.004000, loss: 1.8391
2023-07-02 01:31:33 - train: epoch 0108, iter [00150, 00390], lr: 0.020000, loss: 2.3963
2023-07-02 01:31:34 - train: epoch 0123, iter [00350, 00390], lr: 0.004000, loss: 2.3969
2023-07-02 01:31:35 - train: epoch 123, train_loss: 2.4973
2023-07-02 01:31:36 - train: epoch 0108, iter [00200, 00390], lr: 0.020000, loss: 2.4839
2023-07-02 01:31:37 - eval: epoch: 123, acc1: 39.940%, acc5: 69.710%, test_loss: 2.3659, per_image_load_time: 0.071ms, per_image_inference_time: 0.057ms
2023-07-02 01:31:37 - until epoch: 123, best_acc1: 39.940%
2023-07-02 01:31:37 - epoch 124 lr: 0.004000
2023-07-02 01:31:37 - train: epoch 0108, iter [00250, 00390], lr: 0.020000, loss: 2.4898
2023-07-02 01:31:39 - train: epoch 0108, iter [00300, 00390], lr: 0.020000, loss: 2.2924
2023-07-02 01:31:40 - train: epoch 0124, iter [00050, 00390], lr: 0.004000, loss: 2.1079
2023-07-02 01:31:41 - train: epoch 0108, iter [00350, 00390], lr: 0.020000, loss: 2.2931
2023-07-02 01:31:42 - train: epoch 0124, iter [00100, 00390], lr: 0.004000, loss: 2.3211
2023-07-02 01:31:43 - train: epoch 108, train_loss: 2.3400
2023-07-02 01:31:44 - eval: epoch: 108, acc1: 37.820%, acc5: 67.070%, test_loss: 2.5311, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:31:44 - train: epoch 0124, iter [00150, 00390], lr: 0.004000, loss: 3.2576
2023-07-02 01:31:45 - until epoch: 108, best_acc1: 38.260%
2023-07-02 01:31:45 - epoch 109 lr: 0.020000
2023-07-02 01:31:46 - train: epoch 0124, iter [00200, 00390], lr: 0.004000, loss: 2.5791
2023-07-02 01:31:48 - train: epoch 0109, iter [00050, 00390], lr: 0.020000, loss: 2.1219
2023-07-02 01:31:48 - train: epoch 0124, iter [00250, 00390], lr: 0.004000, loss: 2.8220
2023-07-02 01:31:50 - train: epoch 0109, iter [00100, 00390], lr: 0.020000, loss: 2.1773
2023-07-02 01:31:50 - train: epoch 0124, iter [00300, 00390], lr: 0.004000, loss: 2.7795
2023-07-02 01:31:52 - train: epoch 0109, iter [00150, 00390], lr: 0.020000, loss: 2.3335
2023-07-02 01:31:52 - train: epoch 0124, iter [00350, 00390], lr: 0.004000, loss: 2.2586
2023-07-02 01:31:54 - train: epoch 0109, iter [00200, 00390], lr: 0.020000, loss: 2.3158
2023-07-02 01:31:54 - train: epoch 124, train_loss: 2.4355
2023-07-02 01:31:56 - eval: epoch: 124, acc1: 40.190%, acc5: 70.240%, test_loss: 2.3432, per_image_load_time: 0.074ms, per_image_inference_time: 0.055ms
2023-07-02 01:31:56 - train: epoch 0109, iter [00250, 00390], lr: 0.020000, loss: 2.2877
2023-07-02 01:31:56 - until epoch: 124, best_acc1: 40.190%
2023-07-02 01:31:56 - epoch 125 lr: 0.004000
2023-07-02 01:31:58 - train: epoch 0109, iter [00300, 00390], lr: 0.020000, loss: 2.4771
2023-07-02 01:31:59 - train: epoch 0125, iter [00050, 00390], lr: 0.004000, loss: 2.0564
2023-07-02 01:32:00 - train: epoch 0109, iter [00350, 00390], lr: 0.020000, loss: 2.4758
2023-07-02 01:32:01 - train: epoch 0125, iter [00100, 00390], lr: 0.004000, loss: 2.1530
2023-07-02 01:32:01 - train: epoch 109, train_loss: 2.3240
2023-07-02 01:32:02 - train: epoch 0125, iter [00150, 00390], lr: 0.004000, loss: 2.0493
2023-07-02 01:32:03 - eval: epoch: 109, acc1: 37.550%, acc5: 67.130%, test_loss: 2.5468, per_image_load_time: 0.068ms, per_image_inference_time: 0.057ms
2023-07-02 01:32:03 - until epoch: 109, best_acc1: 38.260%
2023-07-02 01:32:03 - epoch 110 lr: 0.020000
2023-07-02 01:32:04 - train: epoch 0125, iter [00200, 00390], lr: 0.004000, loss: 2.3741
2023-07-02 01:32:06 - train: epoch 0110, iter [00050, 00390], lr: 0.020000, loss: 2.1360
2023-07-02 01:32:06 - train: epoch 0125, iter [00250, 00390], lr: 0.004000, loss: 2.7502
2023-07-02 01:32:08 - train: epoch 0110, iter [00100, 00390], lr: 0.020000, loss: 2.2971
2023-07-02 01:32:08 - train: epoch 0125, iter [00300, 00390], lr: 0.004000, loss: 2.3553
2023-07-02 01:32:10 - train: epoch 0110, iter [00150, 00390], lr: 0.020000, loss: 2.4804
2023-07-02 01:32:10 - train: epoch 0125, iter [00350, 00390], lr: 0.004000, loss: 2.4971
2023-07-02 01:32:12 - train: epoch 125, train_loss: 2.4637
2023-07-02 01:32:12 - train: epoch 0110, iter [00200, 00390], lr: 0.020000, loss: 2.5140
2023-07-02 01:32:13 - eval: epoch: 125, acc1: 40.210%, acc5: 69.900%, test_loss: 2.3548, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 01:32:14 - until epoch: 125, best_acc1: 40.210%
2023-07-02 01:32:14 - epoch 126 lr: 0.004000
2023-07-02 01:32:14 - train: epoch 0110, iter [00250, 00390], lr: 0.020000, loss: 2.4572
2023-07-02 01:32:16 - train: epoch 0110, iter [00300, 00390], lr: 0.020000, loss: 2.4355
2023-07-02 01:32:17 - train: epoch 0126, iter [00050, 00390], lr: 0.004000, loss: 2.0710
2023-07-02 01:32:18 - train: epoch 0110, iter [00350, 00390], lr: 0.020000, loss: 2.2079
2023-07-02 01:32:19 - train: epoch 0126, iter [00100, 00390], lr: 0.004000, loss: 1.9557
2023-07-02 01:32:20 - train: epoch 110, train_loss: 2.3187
2023-07-02 01:32:20 - train: epoch 0126, iter [00150, 00390], lr: 0.004000, loss: 2.9549
2023-07-02 01:32:21 - eval: epoch: 110, acc1: 37.990%, acc5: 66.820%, test_loss: 2.5424, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:32:21 - until epoch: 110, best_acc1: 38.260%
2023-07-02 01:32:21 - epoch 111 lr: 0.020000
2023-07-02 01:32:22 - train: epoch 0126, iter [00200, 00390], lr: 0.004000, loss: 2.4057
2023-07-02 01:32:24 - train: epoch 0126, iter [00250, 00390], lr: 0.004000, loss: 2.3443
2023-07-02 01:32:24 - train: epoch 0111, iter [00050, 00390], lr: 0.020000, loss: 2.1030
2023-07-02 01:32:26 - train: epoch 0126, iter [00300, 00390], lr: 0.004000, loss: 3.2490
2023-07-02 01:32:26 - train: epoch 0111, iter [00100, 00390], lr: 0.020000, loss: 2.3321
2023-07-02 01:32:28 - train: epoch 0126, iter [00350, 00390], lr: 0.004000, loss: 2.6849
2023-07-02 01:32:28 - train: epoch 0111, iter [00150, 00390], lr: 0.020000, loss: 2.2645
2023-07-02 01:32:30 - train: epoch 126, train_loss: 2.4368
2023-07-02 01:32:30 - train: epoch 0111, iter [00200, 00390], lr: 0.020000, loss: 2.2949
2023-07-02 01:32:31 - eval: epoch: 126, acc1: 40.320%, acc5: 70.100%, test_loss: 2.3475, per_image_load_time: 0.074ms, per_image_inference_time: 0.055ms
2023-07-02 01:32:32 - until epoch: 126, best_acc1: 40.320%
2023-07-02 01:32:32 - epoch 127 lr: 0.004000
2023-07-02 01:32:32 - train: epoch 0111, iter [00250, 00390], lr: 0.020000, loss: 2.5567
2023-07-02 01:32:34 - train: epoch 0111, iter [00300, 00390], lr: 0.020000, loss: 2.3728
2023-07-02 01:32:35 - train: epoch 0127, iter [00050, 00390], lr: 0.004000, loss: 1.8276
2023-07-02 01:32:36 - train: epoch 0111, iter [00350, 00390], lr: 0.020000, loss: 2.2704
2023-07-02 01:32:37 - train: epoch 0127, iter [00100, 00390], lr: 0.004000, loss: 2.9790
2023-07-02 01:32:38 - train: epoch 111, train_loss: 2.3227
2023-07-02 01:32:39 - train: epoch 0127, iter [00150, 00390], lr: 0.004000, loss: 1.8842
2023-07-02 01:32:39 - eval: epoch: 111, acc1: 37.620%, acc5: 66.810%, test_loss: 2.5326, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:32:39 - until epoch: 111, best_acc1: 38.260%
2023-07-02 01:32:39 - epoch 112 lr: 0.020000
2023-07-02 01:32:41 - train: epoch 0127, iter [00200, 00390], lr: 0.004000, loss: 2.0268
2023-07-02 01:32:42 - train: epoch 0112, iter [00050, 00390], lr: 0.020000, loss: 2.2032
2023-07-02 01:32:43 - train: epoch 0127, iter [00250, 00390], lr: 0.004000, loss: 2.0483
2023-07-02 01:32:44 - train: epoch 0112, iter [00100, 00390], lr: 0.020000, loss: 2.2666
2023-07-02 01:32:45 - train: epoch 0127, iter [00300, 00390], lr: 0.004000, loss: 1.9136
2023-07-02 01:32:46 - train: epoch 0112, iter [00150, 00390], lr: 0.020000, loss: 2.3177
2023-07-02 01:32:47 - train: epoch 0127, iter [00350, 00390], lr: 0.004000, loss: 2.1490
2023-07-02 01:32:48 - train: epoch 127, train_loss: 2.4567
2023-07-02 01:32:48 - train: epoch 0112, iter [00200, 00390], lr: 0.020000, loss: 2.2811
2023-07-02 01:32:50 - eval: epoch: 127, acc1: 40.150%, acc5: 70.130%, test_loss: 2.3565, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:32:50 - until epoch: 127, best_acc1: 40.320%
2023-07-02 01:32:50 - epoch 128 lr: 0.004000
2023-07-02 01:32:50 - train: epoch 0112, iter [00250, 00390], lr: 0.020000, loss: 2.2946
2023-07-02 01:32:52 - train: epoch 0112, iter [00300, 00390], lr: 0.020000, loss: 2.3759
2023-07-02 01:32:53 - train: epoch 0128, iter [00050, 00390], lr: 0.004000, loss: 3.1017
2023-07-02 01:32:54 - train: epoch 0112, iter [00350, 00390], lr: 0.020000, loss: 2.3528
2023-07-02 01:32:55 - train: epoch 0128, iter [00100, 00390], lr: 0.004000, loss: 2.1029
2023-07-02 01:32:56 - train: epoch 112, train_loss: 2.3008
2023-07-02 01:32:57 - train: epoch 0128, iter [00150, 00390], lr: 0.004000, loss: 3.5906
2023-07-02 01:32:57 - eval: epoch: 112, acc1: 37.550%, acc5: 66.350%, test_loss: 2.5751, per_image_load_time: 0.068ms, per_image_inference_time: 0.057ms
2023-07-02 01:32:58 - until epoch: 112, best_acc1: 38.260%
2023-07-02 01:32:58 - epoch 113 lr: 0.020000
2023-07-02 01:32:58 - train: epoch 0128, iter [00200, 00390], lr: 0.004000, loss: 2.2419
2023-07-02 01:33:00 - train: epoch 0128, iter [00250, 00390], lr: 0.004000, loss: 3.2602
2023-07-02 01:33:01 - train: epoch 0113, iter [00050, 00390], lr: 0.020000, loss: 2.1546
2023-07-02 01:33:02 - train: epoch 0128, iter [00300, 00390], lr: 0.004000, loss: 2.6687
2023-07-02 01:33:03 - train: epoch 0113, iter [00100, 00390], lr: 0.020000, loss: 2.1061
2023-07-02 01:33:04 - train: epoch 0128, iter [00350, 00390], lr: 0.004000, loss: 2.1076
2023-07-02 01:33:05 - train: epoch 0113, iter [00150, 00390], lr: 0.020000, loss: 2.1047
2023-07-02 01:33:06 - train: epoch 128, train_loss: 2.4376
2023-07-02 01:33:07 - train: epoch 0113, iter [00200, 00390], lr: 0.020000, loss: 2.4971
2023-07-02 01:33:08 - eval: epoch: 128, acc1: 40.570%, acc5: 70.600%, test_loss: 2.3414, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:33:08 - until epoch: 128, best_acc1: 40.570%
2023-07-02 01:33:08 - epoch 129 lr: 0.004000
2023-07-02 01:33:08 - train: epoch 0113, iter [00250, 00390], lr: 0.020000, loss: 2.2475
2023-07-02 01:33:10 - train: epoch 0113, iter [00300, 00390], lr: 0.020000, loss: 2.3172
2023-07-02 01:33:11 - train: epoch 0129, iter [00050, 00390], lr: 0.004000, loss: 1.9790
2023-07-02 01:33:12 - train: epoch 0113, iter [00350, 00390], lr: 0.020000, loss: 2.3254
2023-07-02 01:33:13 - train: epoch 0129, iter [00100, 00390], lr: 0.004000, loss: 3.0098
2023-07-02 01:33:14 - train: epoch 113, train_loss: 2.3099
2023-07-02 01:33:15 - train: epoch 0129, iter [00150, 00390], lr: 0.004000, loss: 2.8493
2023-07-02 01:33:16 - eval: epoch: 113, acc1: 37.530%, acc5: 66.420%, test_loss: 2.5837, per_image_load_time: 0.070ms, per_image_inference_time: 0.057ms
2023-07-02 01:33:16 - until epoch: 113, best_acc1: 38.260%
2023-07-02 01:33:16 - epoch 114 lr: 0.020000
2023-07-02 01:33:16 - train: epoch 0129, iter [00200, 00390], lr: 0.004000, loss: 2.9128
2023-07-02 01:33:18 - train: epoch 0129, iter [00250, 00390], lr: 0.004000, loss: 2.2277
2023-07-02 01:33:19 - train: epoch 0114, iter [00050, 00390], lr: 0.020000, loss: 2.0701
2023-07-02 01:33:20 - train: epoch 0129, iter [00300, 00390], lr: 0.004000, loss: 3.0269
2023-07-02 01:33:21 - train: epoch 0114, iter [00100, 00390], lr: 0.020000, loss: 2.1891
2023-07-02 01:33:22 - train: epoch 0129, iter [00350, 00390], lr: 0.004000, loss: 1.9754
2023-07-02 01:33:23 - train: epoch 0114, iter [00150, 00390], lr: 0.020000, loss: 2.3189
2023-07-02 01:33:24 - train: epoch 129, train_loss: 2.4187
2023-07-02 01:33:25 - train: epoch 0114, iter [00200, 00390], lr: 0.020000, loss: 2.2366
2023-07-02 01:33:25 - eval: epoch: 129, acc1: 40.690%, acc5: 70.250%, test_loss: 2.3399, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 01:33:26 - until epoch: 129, best_acc1: 40.690%
2023-07-02 01:33:26 - epoch 130 lr: 0.004000
2023-07-02 01:33:27 - train: epoch 0114, iter [00250, 00390], lr: 0.020000, loss: 2.2247
2023-07-02 01:33:29 - train: epoch 0114, iter [00300, 00390], lr: 0.020000, loss: 2.2975
2023-07-02 01:33:29 - train: epoch 0130, iter [00050, 00390], lr: 0.004000, loss: 2.4259
2023-07-02 01:33:31 - train: epoch 0114, iter [00350, 00390], lr: 0.020000, loss: 2.3851
2023-07-02 01:33:31 - train: epoch 0130, iter [00100, 00390], lr: 0.004000, loss: 2.4175
2023-07-02 01:33:32 - train: epoch 114, train_loss: 2.2886
2023-07-02 01:33:33 - train: epoch 0130, iter [00150, 00390], lr: 0.004000, loss: 2.8536
2023-07-02 01:33:34 - eval: epoch: 114, acc1: 37.740%, acc5: 66.130%, test_loss: 2.5681, per_image_load_time: 0.067ms, per_image_inference_time: 0.058ms
2023-07-02 01:33:34 - until epoch: 114, best_acc1: 38.260%
2023-07-02 01:33:34 - epoch 115 lr: 0.020000
2023-07-02 01:33:34 - train: epoch 0130, iter [00200, 00390], lr: 0.004000, loss: 1.8799
2023-07-02 01:33:36 - train: epoch 0130, iter [00250, 00390], lr: 0.004000, loss: 1.9475
2023-07-02 01:33:37 - train: epoch 0115, iter [00050, 00390], lr: 0.020000, loss: 2.2135
2023-07-02 01:33:38 - train: epoch 0130, iter [00300, 00390], lr: 0.004000, loss: 2.3310
2023-07-02 01:33:39 - train: epoch 0115, iter [00100, 00390], lr: 0.020000, loss: 2.2825
2023-07-02 01:33:40 - train: epoch 0130, iter [00350, 00390], lr: 0.004000, loss: 2.4449
2023-07-02 01:33:41 - train: epoch 0115, iter [00150, 00390], lr: 0.020000, loss: 2.4870
2023-07-02 01:33:42 - train: epoch 130, train_loss: 2.4151
2023-07-02 01:33:43 - train: epoch 0115, iter [00200, 00390], lr: 0.020000, loss: 2.2795
2023-07-02 01:33:44 - eval: epoch: 130, acc1: 40.060%, acc5: 70.220%, test_loss: 2.3635, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:33:44 - until epoch: 130, best_acc1: 40.690%
2023-07-02 01:33:44 - epoch 131 lr: 0.004000
2023-07-02 01:33:45 - train: epoch 0115, iter [00250, 00390], lr: 0.020000, loss: 2.2081
2023-07-02 01:33:47 - train: epoch 0115, iter [00300, 00390], lr: 0.020000, loss: 2.4682
2023-07-02 01:33:47 - train: epoch 0131, iter [00050, 00390], lr: 0.004000, loss: 3.2031
2023-07-02 01:33:49 - train: epoch 0115, iter [00350, 00390], lr: 0.020000, loss: 2.4438
2023-07-02 01:33:49 - train: epoch 0131, iter [00100, 00390], lr: 0.004000, loss: 2.8035
2023-07-02 01:33:51 - train: epoch 115, train_loss: 2.2855
2023-07-02 01:33:51 - train: epoch 0131, iter [00150, 00390], lr: 0.004000, loss: 2.4802
2023-07-02 01:33:52 - eval: epoch: 115, acc1: 38.100%, acc5: 66.870%, test_loss: 2.5459, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:33:52 - until epoch: 115, best_acc1: 38.260%
2023-07-02 01:33:52 - epoch 116 lr: 0.020000
2023-07-02 01:33:53 - train: epoch 0131, iter [00200, 00390], lr: 0.004000, loss: 2.3643
2023-07-02 01:33:54 - train: epoch 0131, iter [00250, 00390], lr: 0.004000, loss: 2.5110
2023-07-02 01:33:55 - train: epoch 0116, iter [00050, 00390], lr: 0.020000, loss: 2.1747
2023-07-02 01:33:57 - train: epoch 0131, iter [00300, 00390], lr: 0.004000, loss: 2.8711
2023-07-02 01:33:57 - train: epoch 0116, iter [00100, 00390], lr: 0.020000, loss: 2.2441
2023-07-02 01:33:59 - train: epoch 0131, iter [00350, 00390], lr: 0.004000, loss: 3.4817
2023-07-02 01:33:59 - train: epoch 0116, iter [00150, 00390], lr: 0.020000, loss: 2.3972
2023-07-02 01:34:00 - train: epoch 131, train_loss: 2.4339
2023-07-02 01:34:01 - train: epoch 0116, iter [00200, 00390], lr: 0.020000, loss: 2.3187
2023-07-02 01:34:02 - eval: epoch: 131, acc1: 40.170%, acc5: 70.520%, test_loss: 2.3419, per_image_load_time: 0.067ms, per_image_inference_time: 0.054ms
2023-07-02 01:34:02 - until epoch: 131, best_acc1: 40.690%
2023-07-02 01:34:02 - epoch 132 lr: 0.004000
2023-07-02 01:34:03 - train: epoch 0116, iter [00250, 00390], lr: 0.020000, loss: 2.5815
2023-07-02 01:34:05 - train: epoch 0132, iter [00050, 00390], lr: 0.004000, loss: 1.7546
2023-07-02 01:34:05 - train: epoch 0116, iter [00300, 00390], lr: 0.020000, loss: 2.4965
2023-07-02 01:34:07 - train: epoch 0132, iter [00100, 00390], lr: 0.004000, loss: 2.7540
2023-07-02 01:34:07 - train: epoch 0116, iter [00350, 00390], lr: 0.020000, loss: 2.3029
2023-07-02 01:34:09 - train: epoch 116, train_loss: 2.2833
2023-07-02 01:34:09 - train: epoch 0132, iter [00150, 00390], lr: 0.004000, loss: 2.2209
2023-07-02 01:34:10 - eval: epoch: 116, acc1: 37.480%, acc5: 66.180%, test_loss: 2.5639, per_image_load_time: 0.079ms, per_image_inference_time: 0.056ms
2023-07-02 01:34:11 - train: epoch 0132, iter [00200, 00390], lr: 0.004000, loss: 2.3332
2023-07-02 01:34:11 - until epoch: 116, best_acc1: 38.260%
2023-07-02 01:34:11 - epoch 117 lr: 0.020000
2023-07-02 01:34:12 - train: epoch 0132, iter [00250, 00390], lr: 0.004000, loss: 3.1524
2023-07-02 01:34:14 - train: epoch 0117, iter [00050, 00390], lr: 0.020000, loss: 2.2369
2023-07-02 01:34:14 - train: epoch 0132, iter [00300, 00390], lr: 0.004000, loss: 2.2615
2023-07-02 01:34:16 - train: epoch 0117, iter [00100, 00390], lr: 0.020000, loss: 2.3074
2023-07-02 01:34:16 - train: epoch 0132, iter [00350, 00390], lr: 0.004000, loss: 1.9650
2023-07-02 01:34:18 - train: epoch 0117, iter [00150, 00390], lr: 0.020000, loss: 2.1228
2023-07-02 01:34:18 - train: epoch 132, train_loss: 2.4309
2023-07-02 01:34:19 - eval: epoch: 132, acc1: 40.630%, acc5: 70.700%, test_loss: 2.3426, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 01:34:20 - train: epoch 0117, iter [00200, 00390], lr: 0.020000, loss: 2.1662
2023-07-02 01:34:20 - until epoch: 132, best_acc1: 40.690%
2023-07-02 01:34:20 - epoch 133 lr: 0.004000
2023-07-02 01:34:21 - train: epoch 0117, iter [00250, 00390], lr: 0.020000, loss: 2.3443
2023-07-02 01:34:22 - train: epoch 0133, iter [00050, 00390], lr: 0.004000, loss: 1.9508
2023-07-02 01:34:23 - train: epoch 0117, iter [00300, 00390], lr: 0.020000, loss: 2.4599
2023-07-02 01:34:24 - train: epoch 0133, iter [00100, 00390], lr: 0.004000, loss: 1.9345
2023-07-02 01:34:25 - train: epoch 0117, iter [00350, 00390], lr: 0.020000, loss: 2.4446
2023-07-02 01:34:26 - train: epoch 0133, iter [00150, 00390], lr: 0.004000, loss: 1.8659
2023-07-02 01:34:27 - train: epoch 117, train_loss: 2.2746
2023-07-02 01:34:28 - train: epoch 0133, iter [00200, 00390], lr: 0.004000, loss: 2.4583
2023-07-02 01:34:29 - eval: epoch: 117, acc1: 37.770%, acc5: 66.410%, test_loss: 2.5777, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:34:29 - until epoch: 117, best_acc1: 38.260%
2023-07-02 01:34:29 - epoch 118 lr: 0.020000
2023-07-02 01:34:30 - train: epoch 0133, iter [00250, 00390], lr: 0.004000, loss: 2.7154
2023-07-02 01:34:32 - train: epoch 0118, iter [00050, 00390], lr: 0.020000, loss: 2.1324
2023-07-02 01:34:32 - train: epoch 0133, iter [00300, 00390], lr: 0.004000, loss: 2.4366
2023-07-02 01:34:34 - train: epoch 0118, iter [00100, 00390], lr: 0.020000, loss: 2.3235
2023-07-02 01:34:34 - train: epoch 0133, iter [00350, 00390], lr: 0.004000, loss: 2.0267
2023-07-02 01:34:36 - train: epoch 133, train_loss: 2.3597
2023-07-02 01:34:36 - train: epoch 0118, iter [00150, 00390], lr: 0.020000, loss: 2.2482
2023-07-02 01:34:37 - eval: epoch: 133, acc1: 40.600%, acc5: 70.930%, test_loss: 2.3430, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 01:34:37 - until epoch: 133, best_acc1: 40.690%
2023-07-02 01:34:37 - epoch 134 lr: 0.004000
2023-07-02 01:34:37 - train: epoch 0118, iter [00200, 00390], lr: 0.020000, loss: 2.2984
2023-07-02 01:34:39 - train: epoch 0118, iter [00250, 00390], lr: 0.020000, loss: 2.2342
2023-07-02 01:34:40 - train: epoch 0134, iter [00050, 00390], lr: 0.004000, loss: 3.2902
2023-07-02 01:34:41 - train: epoch 0118, iter [00300, 00390], lr: 0.020000, loss: 2.2271
2023-07-02 01:34:42 - train: epoch 0134, iter [00100, 00390], lr: 0.004000, loss: 2.2373
2023-07-02 01:34:44 - train: epoch 0118, iter [00350, 00390], lr: 0.020000, loss: 2.3821
2023-07-02 01:34:44 - train: epoch 0134, iter [00150, 00390], lr: 0.004000, loss: 2.7048
2023-07-02 01:34:45 - train: epoch 118, train_loss: 2.2677
2023-07-02 01:34:46 - train: epoch 0134, iter [00200, 00390], lr: 0.004000, loss: 1.9386
2023-07-02 01:34:47 - eval: epoch: 118, acc1: 37.860%, acc5: 66.810%, test_loss: 2.5494, per_image_load_time: 0.069ms, per_image_inference_time: 0.060ms
2023-07-02 01:34:47 - until epoch: 118, best_acc1: 38.260%
2023-07-02 01:34:47 - epoch 119 lr: 0.020000
2023-07-02 01:34:48 - train: epoch 0134, iter [00250, 00390], lr: 0.004000, loss: 2.8068
2023-07-02 01:34:50 - train: epoch 0134, iter [00300, 00390], lr: 0.004000, loss: 2.1811
2023-07-02 01:34:50 - train: epoch 0119, iter [00050, 00390], lr: 0.020000, loss: 2.2502
2023-07-02 01:34:52 - train: epoch 0134, iter [00350, 00390], lr: 0.004000, loss: 2.4519
2023-07-02 01:34:52 - train: epoch 0119, iter [00100, 00390], lr: 0.020000, loss: 2.3485
2023-07-02 01:34:53 - train: epoch 134, train_loss: 2.4279
2023-07-02 01:34:54 - train: epoch 0119, iter [00150, 00390], lr: 0.020000, loss: 2.2372
2023-07-02 01:34:55 - eval: epoch: 134, acc1: 40.010%, acc5: 70.200%, test_loss: 2.3551, per_image_load_time: 0.073ms, per_image_inference_time: 0.054ms
2023-07-02 01:34:55 - until epoch: 134, best_acc1: 40.690%
2023-07-02 01:34:55 - epoch 135 lr: 0.004000
2023-07-02 01:34:56 - train: epoch 0119, iter [00200, 00390], lr: 0.020000, loss: 2.3154
2023-07-02 01:34:58 - train: epoch 0119, iter [00250, 00390], lr: 0.020000, loss: 2.1460
2023-07-02 01:34:58 - train: epoch 0135, iter [00050, 00390], lr: 0.004000, loss: 2.5852
2023-07-02 01:35:00 - train: epoch 0119, iter [00300, 00390], lr: 0.020000, loss: 2.3007
2023-07-02 01:35:00 - train: epoch 0135, iter [00100, 00390], lr: 0.004000, loss: 1.9088
2023-07-02 01:35:02 - train: epoch 0119, iter [00350, 00390], lr: 0.020000, loss: 2.2855
2023-07-02 01:35:02 - train: epoch 0135, iter [00150, 00390], lr: 0.004000, loss: 3.7562
2023-07-02 01:35:04 - train: epoch 119, train_loss: 2.2664
2023-07-02 01:35:04 - train: epoch 0135, iter [00200, 00390], lr: 0.004000, loss: 2.3621
2023-07-02 01:35:05 - eval: epoch: 119, acc1: 37.620%, acc5: 66.860%, test_loss: 2.5744, per_image_load_time: 0.067ms, per_image_inference_time: 0.059ms
2023-07-02 01:35:05 - until epoch: 119, best_acc1: 38.260%
2023-07-02 01:35:05 - epoch 120 lr: 0.020000
2023-07-02 01:35:06 - train: epoch 0135, iter [00250, 00390], lr: 0.004000, loss: 2.6940
2023-07-02 01:35:08 - train: epoch 0135, iter [00300, 00390], lr: 0.004000, loss: 2.2783
2023-07-02 01:35:08 - train: epoch 0120, iter [00050, 00390], lr: 0.020000, loss: 2.1554
2023-07-02 01:35:10 - train: epoch 0135, iter [00350, 00390], lr: 0.004000, loss: 2.3004
2023-07-02 01:35:10 - train: epoch 0120, iter [00100, 00390], lr: 0.020000, loss: 2.2649
2023-07-02 01:35:11 - train: epoch 135, train_loss: 2.4096
2023-07-02 01:35:12 - train: epoch 0120, iter [00150, 00390], lr: 0.020000, loss: 2.2653
2023-07-02 01:35:13 - eval: epoch: 135, acc1: 40.670%, acc5: 70.510%, test_loss: 2.3416, per_image_load_time: 0.068ms, per_image_inference_time: 0.057ms
2023-07-02 01:35:13 - until epoch: 135, best_acc1: 40.690%
2023-07-02 01:35:13 - epoch 136 lr: 0.004000
2023-07-02 01:35:14 - train: epoch 0120, iter [00200, 00390], lr: 0.020000, loss: 2.1855
2023-07-02 01:35:16 - train: epoch 0120, iter [00250, 00390], lr: 0.020000, loss: 2.3786
2023-07-02 01:35:16 - train: epoch 0136, iter [00050, 00390], lr: 0.004000, loss: 1.6847
2023-07-02 01:35:18 - train: epoch 0120, iter [00300, 00390], lr: 0.020000, loss: 2.1677
2023-07-02 01:35:18 - train: epoch 0136, iter [00100, 00390], lr: 0.004000, loss: 1.7185
2023-07-02 01:35:20 - train: epoch 0120, iter [00350, 00390], lr: 0.020000, loss: 2.1969
2023-07-02 01:35:21 - train: epoch 0136, iter [00150, 00390], lr: 0.004000, loss: 2.0214
2023-07-02 01:35:22 - train: epoch 120, train_loss: 2.2619
2023-07-02 01:35:22 - train: epoch 0136, iter [00200, 00390], lr: 0.004000, loss: 2.1074
2023-07-02 01:35:23 - eval: epoch: 120, acc1: 38.000%, acc5: 66.430%, test_loss: 2.5736, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:35:24 - until epoch: 120, best_acc1: 38.260%
2023-07-02 01:35:24 - epoch 121 lr: 0.004000
2023-07-02 01:35:24 - train: epoch 0136, iter [00250, 00390], lr: 0.004000, loss: 2.0434
2023-07-02 01:35:26 - train: epoch 0136, iter [00300, 00390], lr: 0.004000, loss: 2.3883
2023-07-02 01:35:27 - train: epoch 0121, iter [00050, 00390], lr: 0.004000, loss: 1.8481
2023-07-02 01:35:28 - train: epoch 0136, iter [00350, 00390], lr: 0.004000, loss: 2.7382
2023-07-02 01:35:29 - train: epoch 0121, iter [00100, 00390], lr: 0.004000, loss: 1.8697
2023-07-02 01:35:30 - train: epoch 136, train_loss: 2.3932
2023-07-02 01:35:31 - eval: epoch: 136, acc1: 40.150%, acc5: 69.860%, test_loss: 2.3632, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:35:31 - until epoch: 136, best_acc1: 40.690%
2023-07-02 01:35:31 - epoch 137 lr: 0.004000
2023-07-02 01:35:31 - train: epoch 0121, iter [00150, 00390], lr: 0.004000, loss: 1.9936
2023-07-02 01:35:33 - train: epoch 0121, iter [00200, 00390], lr: 0.004000, loss: 2.0508
2023-07-02 01:35:34 - train: epoch 0137, iter [00050, 00390], lr: 0.004000, loss: 2.5098
2023-07-02 01:35:35 - train: epoch 0121, iter [00250, 00390], lr: 0.004000, loss: 1.8976
2023-07-02 01:35:36 - train: epoch 0137, iter [00100, 00390], lr: 0.004000, loss: 2.6931
2023-07-02 01:35:38 - train: epoch 0121, iter [00300, 00390], lr: 0.004000, loss: 1.7978
2023-07-02 01:35:38 - train: epoch 0137, iter [00150, 00390], lr: 0.004000, loss: 2.1508
2023-07-02 01:35:40 - train: epoch 0121, iter [00350, 00390], lr: 0.004000, loss: 2.0451
2023-07-02 01:35:40 - train: epoch 0137, iter [00200, 00390], lr: 0.004000, loss: 1.9325
2023-07-02 01:35:41 - train: epoch 121, train_loss: 1.9600
2023-07-02 01:35:42 - train: epoch 0137, iter [00250, 00390], lr: 0.004000, loss: 2.2966
2023-07-02 01:35:43 - eval: epoch: 121, acc1: 41.030%, acc5: 69.250%, test_loss: 2.4343, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:35:43 - until epoch: 121, best_acc1: 41.030%
2023-07-02 01:35:43 - epoch 122 lr: 0.004000
2023-07-02 01:35:43 - train: epoch 0137, iter [00300, 00390], lr: 0.004000, loss: 2.2070
2023-07-02 01:35:45 - train: epoch 0137, iter [00350, 00390], lr: 0.004000, loss: 2.1700
2023-07-02 01:35:46 - train: epoch 0122, iter [00050, 00390], lr: 0.004000, loss: 1.9512
2023-07-02 01:35:47 - train: epoch 137, train_loss: 2.4011
2023-07-02 01:35:48 - train: epoch 0122, iter [00100, 00390], lr: 0.004000, loss: 2.0074
2023-07-02 01:35:49 - eval: epoch: 137, acc1: 40.370%, acc5: 69.930%, test_loss: 2.3695, per_image_load_time: 0.068ms, per_image_inference_time: 0.055ms
2023-07-02 01:35:49 - until epoch: 137, best_acc1: 40.690%
2023-07-02 01:35:49 - epoch 138 lr: 0.004000
2023-07-02 01:35:50 - train: epoch 0122, iter [00150, 00390], lr: 0.004000, loss: 2.1115
2023-07-02 01:35:52 - train: epoch 0138, iter [00050, 00390], lr: 0.004000, loss: 2.1242
2023-07-02 01:35:52 - train: epoch 0122, iter [00200, 00390], lr: 0.004000, loss: 1.8193
2023-07-02 01:35:54 - train: epoch 0138, iter [00100, 00390], lr: 0.004000, loss: 2.8190
2023-07-02 01:35:54 - train: epoch 0122, iter [00250, 00390], lr: 0.004000, loss: 1.7843
2023-07-02 01:35:56 - train: epoch 0138, iter [00150, 00390], lr: 0.004000, loss: 2.3550
2023-07-02 01:35:56 - train: epoch 0122, iter [00300, 00390], lr: 0.004000, loss: 1.9029
2023-07-02 01:35:58 - train: epoch 0138, iter [00200, 00390], lr: 0.004000, loss: 2.9822
2023-07-02 01:35:58 - train: epoch 0122, iter [00350, 00390], lr: 0.004000, loss: 1.8135
2023-07-02 01:36:00 - train: epoch 122, train_loss: 1.8474
2023-07-02 01:36:00 - train: epoch 0138, iter [00250, 00390], lr: 0.004000, loss: 2.2023
2023-07-02 01:36:01 - eval: epoch: 122, acc1: 41.260%, acc5: 69.260%, test_loss: 2.4589, per_image_load_time: 0.066ms, per_image_inference_time: 0.057ms
2023-07-02 01:36:01 - train: epoch 0138, iter [00300, 00390], lr: 0.004000, loss: 1.9268
2023-07-02 01:36:02 - until epoch: 122, best_acc1: 41.260%
2023-07-02 01:36:02 - epoch 123 lr: 0.004000
2023-07-02 01:36:03 - train: epoch 0138, iter [00350, 00390], lr: 0.004000, loss: 2.2672
2023-07-02 01:36:05 - train: epoch 0123, iter [00050, 00390], lr: 0.004000, loss: 1.8231
2023-07-02 01:36:05 - train: epoch 138, train_loss: 2.3615
2023-07-02 01:36:06 - train: epoch 0123, iter [00100, 00390], lr: 0.004000, loss: 1.7328
2023-07-02 01:36:06 - eval: epoch: 138, acc1: 40.120%, acc5: 70.370%, test_loss: 2.3661, per_image_load_time: 0.079ms, per_image_inference_time: 0.054ms
2023-07-02 01:36:07 - until epoch: 138, best_acc1: 40.690%
2023-07-02 01:36:07 - epoch 139 lr: 0.004000
2023-07-02 01:36:08 - train: epoch 0123, iter [00150, 00390], lr: 0.004000, loss: 1.8064
2023-07-02 01:36:10 - train: epoch 0139, iter [00050, 00390], lr: 0.004000, loss: 2.1252
2023-07-02 01:36:10 - train: epoch 0123, iter [00200, 00390], lr: 0.004000, loss: 1.7326
2023-07-02 01:36:12 - train: epoch 0139, iter [00100, 00390], lr: 0.004000, loss: 2.6212
2023-07-02 01:36:12 - train: epoch 0123, iter [00250, 00390], lr: 0.004000, loss: 1.9522
2023-07-02 01:36:14 - train: epoch 0139, iter [00150, 00390], lr: 0.004000, loss: 3.6908
2023-07-02 01:36:14 - train: epoch 0123, iter [00300, 00390], lr: 0.004000, loss: 1.7110
2023-07-02 01:36:16 - train: epoch 0139, iter [00200, 00390], lr: 0.004000, loss: 2.0812
2023-07-02 01:36:17 - train: epoch 0123, iter [00350, 00390], lr: 0.004000, loss: 1.5592
2023-07-02 01:36:18 - train: epoch 0139, iter [00250, 00390], lr: 0.004000, loss: 2.2563
2023-07-02 01:36:18 - train: epoch 123, train_loss: 1.8000
2023-07-02 01:36:20 - train: epoch 0139, iter [00300, 00390], lr: 0.004000, loss: 3.2969
2023-07-02 01:36:20 - eval: epoch: 123, acc1: 41.480%, acc5: 68.710%, test_loss: 2.4680, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:36:21 - until epoch: 123, best_acc1: 41.480%
2023-07-02 01:36:21 - epoch 124 lr: 0.004000
2023-07-02 01:36:21 - train: epoch 0139, iter [00350, 00390], lr: 0.004000, loss: 3.0874
2023-07-02 01:36:23 - train: epoch 139, train_loss: 2.4176
2023-07-02 01:36:23 - train: epoch 0124, iter [00050, 00390], lr: 0.004000, loss: 1.6570
2023-07-02 01:36:24 - eval: epoch: 139, acc1: 40.200%, acc5: 70.060%, test_loss: 2.3686, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:36:24 - until epoch: 139, best_acc1: 40.690%
2023-07-02 01:36:24 - epoch 140 lr: 0.004000
2023-07-02 01:36:25 - train: epoch 0124, iter [00100, 00390], lr: 0.004000, loss: 1.7619
2023-07-02 01:36:27 - train: epoch 0124, iter [00150, 00390], lr: 0.004000, loss: 1.8781
2023-07-02 01:36:27 - train: epoch 0140, iter [00050, 00390], lr: 0.004000, loss: 2.1962
2023-07-02 01:36:29 - train: epoch 0140, iter [00100, 00390], lr: 0.004000, loss: 2.3548
2023-07-02 01:36:29 - train: epoch 0124, iter [00200, 00390], lr: 0.004000, loss: 1.9456
2023-07-02 01:36:31 - train: epoch 0140, iter [00150, 00390], lr: 0.004000, loss: 2.4226
2023-07-02 01:36:31 - train: epoch 0124, iter [00250, 00390], lr: 0.004000, loss: 1.8138
2023-07-02 01:36:33 - train: epoch 0140, iter [00200, 00390], lr: 0.004000, loss: 2.3629
2023-07-02 01:36:34 - train: epoch 0124, iter [00300, 00390], lr: 0.004000, loss: 1.7088
2023-07-02 01:36:35 - train: epoch 0140, iter [00250, 00390], lr: 0.004000, loss: 2.6842
2023-07-02 01:36:36 - train: epoch 0124, iter [00350, 00390], lr: 0.004000, loss: 1.7830
2023-07-02 01:36:37 - train: epoch 0140, iter [00300, 00390], lr: 0.004000, loss: 2.0642
2023-07-02 01:36:37 - train: epoch 124, train_loss: 1.7706
2023-07-02 01:36:39 - eval: epoch: 124, acc1: 40.710%, acc5: 68.530%, test_loss: 2.4915, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:36:39 - train: epoch 0140, iter [00350, 00390], lr: 0.004000, loss: 2.7055
2023-07-02 01:36:39 - until epoch: 124, best_acc1: 41.480%
2023-07-02 01:36:39 - epoch 125 lr: 0.004000
2023-07-02 01:36:40 - train: epoch 140, train_loss: 2.3939
2023-07-02 01:36:42 - train: epoch 0125, iter [00050, 00390], lr: 0.004000, loss: 1.7007
2023-07-02 01:36:42 - eval: epoch: 140, acc1: 40.610%, acc5: 70.630%, test_loss: 2.3394, per_image_load_time: 0.083ms, per_image_inference_time: 0.054ms
2023-07-02 01:36:42 - until epoch: 140, best_acc1: 40.690%
2023-07-02 01:36:42 - epoch 141 lr: 0.004000
2023-07-02 01:36:43 - train: epoch 0125, iter [00100, 00390], lr: 0.004000, loss: 1.6559
2023-07-02 01:36:45 - train: epoch 0141, iter [00050, 00390], lr: 0.004000, loss: 1.8496
2023-07-02 01:36:46 - train: epoch 0125, iter [00150, 00390], lr: 0.004000, loss: 1.8718
2023-07-02 01:36:47 - train: epoch 0141, iter [00100, 00390], lr: 0.004000, loss: 2.5043
2023-07-02 01:36:48 - train: epoch 0125, iter [00200, 00390], lr: 0.004000, loss: 1.8550
2023-07-02 01:36:49 - train: epoch 0141, iter [00150, 00390], lr: 0.004000, loss: 1.8431
2023-07-02 01:36:50 - train: epoch 0125, iter [00250, 00390], lr: 0.004000, loss: 1.7634
2023-07-02 01:36:51 - train: epoch 0141, iter [00200, 00390], lr: 0.004000, loss: 3.6180
2023-07-02 01:36:52 - train: epoch 0125, iter [00300, 00390], lr: 0.004000, loss: 1.8440
2023-07-02 01:36:53 - train: epoch 0141, iter [00250, 00390], lr: 0.004000, loss: 2.2649
2023-07-02 01:36:54 - train: epoch 0125, iter [00350, 00390], lr: 0.004000, loss: 1.5721
2023-07-02 01:36:55 - train: epoch 0141, iter [00300, 00390], lr: 0.004000, loss: 3.1713
2023-07-02 01:36:56 - train: epoch 125, train_loss: 1.7452
2023-07-02 01:36:57 - train: epoch 0141, iter [00350, 00390], lr: 0.004000, loss: 2.0562
2023-07-02 01:36:57 - eval: epoch: 125, acc1: 41.070%, acc5: 68.610%, test_loss: 2.4954, per_image_load_time: 0.068ms, per_image_inference_time: 0.060ms
2023-07-02 01:36:58 - until epoch: 125, best_acc1: 41.480%
2023-07-02 01:36:58 - epoch 126 lr: 0.004000
2023-07-02 01:36:58 - train: epoch 141, train_loss: 2.3650
2023-07-02 01:37:00 - eval: epoch: 141, acc1: 40.600%, acc5: 70.480%, test_loss: 2.3423, per_image_load_time: 0.076ms, per_image_inference_time: 0.053ms
2023-07-02 01:37:00 - until epoch: 141, best_acc1: 40.690%
2023-07-02 01:37:00 - epoch 142 lr: 0.004000
2023-07-02 01:37:00 - train: epoch 0126, iter [00050, 00390], lr: 0.004000, loss: 1.6362
2023-07-02 01:37:02 - train: epoch 0126, iter [00100, 00390], lr: 0.004000, loss: 1.6600
2023-07-02 01:37:03 - train: epoch 0142, iter [00050, 00390], lr: 0.004000, loss: 1.8898
2023-07-02 01:37:04 - train: epoch 0126, iter [00150, 00390], lr: 0.004000, loss: 1.8156
2023-07-02 01:37:05 - train: epoch 0142, iter [00100, 00390], lr: 0.004000, loss: 1.6941
2023-07-02 01:37:07 - train: epoch 0126, iter [00200, 00390], lr: 0.004000, loss: 1.8468
2023-07-02 01:37:07 - train: epoch 0142, iter [00150, 00390], lr: 0.004000, loss: 2.0140
2023-07-02 01:37:09 - train: epoch 0126, iter [00250, 00390], lr: 0.004000, loss: 1.7612
2023-07-02 01:37:09 - train: epoch 0142, iter [00200, 00390], lr: 0.004000, loss: 2.7413
2023-07-02 01:37:11 - train: epoch 0126, iter [00300, 00390], lr: 0.004000, loss: 1.6550
2023-07-02 01:37:11 - train: epoch 0142, iter [00250, 00390], lr: 0.004000, loss: 2.1990
2023-07-02 01:37:13 - train: epoch 0126, iter [00350, 00390], lr: 0.004000, loss: 1.8773
2023-07-02 01:37:13 - train: epoch 0142, iter [00300, 00390], lr: 0.004000, loss: 2.9777
2023-07-02 01:37:15 - train: epoch 126, train_loss: 1.7287
2023-07-02 01:37:15 - train: epoch 0142, iter [00350, 00390], lr: 0.004000, loss: 2.0808
2023-07-02 01:37:16 - eval: epoch: 126, acc1: 40.550%, acc5: 68.490%, test_loss: 2.5173, per_image_load_time: 0.071ms, per_image_inference_time: 0.058ms
2023-07-02 01:37:16 - train: epoch 142, train_loss: 2.3888
2023-07-02 01:37:16 - until epoch: 126, best_acc1: 41.480%
2023-07-02 01:37:16 - epoch 127 lr: 0.004000
2023-07-02 01:37:18 - eval: epoch: 142, acc1: 40.290%, acc5: 70.360%, test_loss: 2.3666, per_image_load_time: 0.070ms, per_image_inference_time: 0.062ms
2023-07-02 01:37:18 - until epoch: 142, best_acc1: 40.690%
2023-07-02 01:37:18 - epoch 143 lr: 0.004000
2023-07-02 01:37:19 - train: epoch 0127, iter [00050, 00390], lr: 0.004000, loss: 1.7242
2023-07-02 01:37:21 - train: epoch 0143, iter [00050, 00390], lr: 0.004000, loss: 2.6063
2023-07-02 01:37:21 - train: epoch 0127, iter [00100, 00390], lr: 0.004000, loss: 1.8306
2023-07-02 01:37:23 - train: epoch 0143, iter [00100, 00390], lr: 0.004000, loss: 1.8893
2023-07-02 01:37:23 - train: epoch 0127, iter [00150, 00390], lr: 0.004000, loss: 1.7671
2023-07-02 01:37:25 - train: epoch 0143, iter [00150, 00390], lr: 0.004000, loss: 2.5928
2023-07-02 01:37:26 - train: epoch 0127, iter [00200, 00390], lr: 0.004000, loss: 1.7716
2023-07-02 01:37:27 - train: epoch 0143, iter [00200, 00390], lr: 0.004000, loss: 2.1071
2023-07-02 01:37:28 - train: epoch 0127, iter [00250, 00390], lr: 0.004000, loss: 1.7054
2023-07-02 01:37:29 - train: epoch 0143, iter [00250, 00390], lr: 0.004000, loss: 2.4227
2023-07-02 01:37:30 - train: epoch 0127, iter [00300, 00390], lr: 0.004000, loss: 1.7591
2023-07-02 01:37:31 - train: epoch 0143, iter [00300, 00390], lr: 0.004000, loss: 2.4128
2023-07-02 01:37:32 - train: epoch 0127, iter [00350, 00390], lr: 0.004000, loss: 1.7190
2023-07-02 01:37:33 - train: epoch 0143, iter [00350, 00390], lr: 0.004000, loss: 2.1117
2023-07-02 01:37:34 - train: epoch 127, train_loss: 1.7121
2023-07-02 01:37:34 - train: epoch 143, train_loss: 2.3874
2023-07-02 01:37:35 - eval: epoch: 127, acc1: 40.460%, acc5: 67.840%, test_loss: 2.5501, per_image_load_time: 0.067ms, per_image_inference_time: 0.059ms
2023-07-02 01:37:36 - until epoch: 127, best_acc1: 41.480%
2023-07-02 01:37:36 - epoch 128 lr: 0.004000
2023-07-02 01:37:36 - eval: epoch: 143, acc1: 39.990%, acc5: 70.100%, test_loss: 2.3634, per_image_load_time: 0.069ms, per_image_inference_time: 0.064ms
2023-07-02 01:37:36 - until epoch: 143, best_acc1: 40.690%
2023-07-02 01:37:36 - epoch 144 lr: 0.004000
2023-07-02 01:37:39 - train: epoch 0128, iter [00050, 00390], lr: 0.004000, loss: 1.6763
2023-07-02 01:37:39 - train: epoch 0144, iter [00050, 00390], lr: 0.004000, loss: 1.7109
2023-07-02 01:37:41 - train: epoch 0128, iter [00100, 00390], lr: 0.004000, loss: 1.6564
2023-07-02 01:37:41 - train: epoch 0144, iter [00100, 00390], lr: 0.004000, loss: 2.2413
2023-07-02 01:37:43 - train: epoch 0128, iter [00150, 00390], lr: 0.004000, loss: 1.6922
2023-07-02 01:37:43 - train: epoch 0144, iter [00150, 00390], lr: 0.004000, loss: 2.5964
2023-07-02 01:37:45 - train: epoch 0128, iter [00200, 00390], lr: 0.004000, loss: 1.6585
2023-07-02 01:37:45 - train: epoch 0144, iter [00200, 00390], lr: 0.004000, loss: 3.2825
2023-07-02 01:37:47 - train: epoch 0128, iter [00250, 00390], lr: 0.004000, loss: 1.6443
2023-07-02 01:37:47 - train: epoch 0144, iter [00250, 00390], lr: 0.004000, loss: 2.5859
2023-07-02 01:37:49 - train: epoch 0128, iter [00300, 00390], lr: 0.004000, loss: 1.6624
2023-07-02 01:37:49 - train: epoch 0144, iter [00300, 00390], lr: 0.004000, loss: 2.0268
2023-07-02 01:37:51 - train: epoch 0128, iter [00350, 00390], lr: 0.004000, loss: 1.7412
2023-07-02 01:37:51 - train: epoch 0144, iter [00350, 00390], lr: 0.004000, loss: 2.0855
2023-07-02 01:37:53 - train: epoch 128, train_loss: 1.7048
2023-07-02 01:37:53 - train: epoch 144, train_loss: 2.4011
2023-07-02 01:37:54 - eval: epoch: 144, acc1: 40.160%, acc5: 70.000%, test_loss: 2.3721, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:37:55 - eval: epoch: 128, acc1: 40.590%, acc5: 68.210%, test_loss: 2.5344, per_image_load_time: 0.067ms, per_image_inference_time: 0.076ms
2023-07-02 01:37:55 - until epoch: 144, best_acc1: 40.690%
2023-07-02 01:37:55 - epoch 145 lr: 0.004000
2023-07-02 01:37:55 - until epoch: 128, best_acc1: 41.480%
2023-07-02 01:37:55 - epoch 129 lr: 0.004000
2023-07-02 01:37:58 - train: epoch 0145, iter [00050, 00390], lr: 0.004000, loss: 2.0225
2023-07-02 01:37:58 - train: epoch 0129, iter [00050, 00390], lr: 0.004000, loss: 1.4611
2023-07-02 01:38:00 - train: epoch 0145, iter [00100, 00390], lr: 0.004000, loss: 2.1377
2023-07-02 01:38:00 - train: epoch 0129, iter [00100, 00390], lr: 0.004000, loss: 1.6880
2023-07-02 01:38:02 - train: epoch 0145, iter [00150, 00390], lr: 0.004000, loss: 2.1969
2023-07-02 01:38:02 - train: epoch 0129, iter [00150, 00390], lr: 0.004000, loss: 1.6461
2023-07-02 01:38:04 - train: epoch 0145, iter [00200, 00390], lr: 0.004000, loss: 3.1416
2023-07-02 01:38:04 - train: epoch 0129, iter [00200, 00390], lr: 0.004000, loss: 1.6828
2023-07-02 01:38:06 - train: epoch 0145, iter [00250, 00390], lr: 0.004000, loss: 1.9210
2023-07-02 01:38:06 - train: epoch 0129, iter [00250, 00390], lr: 0.004000, loss: 1.5905
2023-07-02 01:38:08 - train: epoch 0145, iter [00300, 00390], lr: 0.004000, loss: 2.0099
2023-07-02 01:38:08 - train: epoch 0129, iter [00300, 00390], lr: 0.004000, loss: 1.7130
2023-07-02 01:38:10 - train: epoch 0145, iter [00350, 00390], lr: 0.004000, loss: 1.9246
2023-07-02 01:38:11 - train: epoch 0129, iter [00350, 00390], lr: 0.004000, loss: 1.6413
2023-07-02 01:38:12 - train: epoch 145, train_loss: 2.3434
2023-07-02 01:38:12 - train: epoch 129, train_loss: 1.6827
2023-07-02 01:38:13 - eval: epoch: 145, acc1: 40.520%, acc5: 70.800%, test_loss: 2.3456, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-07-02 01:38:13 - eval: epoch: 129, acc1: 41.320%, acc5: 67.720%, test_loss: 2.5428, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:38:13 - until epoch: 145, best_acc1: 40.690%
2023-07-02 01:38:13 - epoch 146 lr: 0.004000
2023-07-02 01:38:14 - until epoch: 129, best_acc1: 41.480%
2023-07-02 01:38:14 - epoch 130 lr: 0.004000
2023-07-02 01:38:16 - train: epoch 0146, iter [00050, 00390], lr: 0.004000, loss: 1.8834
2023-07-02 01:38:17 - train: epoch 0130, iter [00050, 00390], lr: 0.004000, loss: 1.7110
2023-07-02 01:38:18 - train: epoch 0146, iter [00100, 00390], lr: 0.004000, loss: 2.6867
2023-07-02 01:38:19 - train: epoch 0130, iter [00100, 00390], lr: 0.004000, loss: 1.5512
2023-07-02 01:38:21 - train: epoch 0146, iter [00150, 00390], lr: 0.004000, loss: 2.3708
2023-07-02 01:38:21 - train: epoch 0130, iter [00150, 00390], lr: 0.004000, loss: 1.7270
2023-07-02 01:38:23 - train: epoch 0146, iter [00200, 00390], lr: 0.004000, loss: 2.1968
2023-07-02 01:38:23 - train: epoch 0130, iter [00200, 00390], lr: 0.004000, loss: 1.6395
2023-07-02 01:38:25 - train: epoch 0146, iter [00250, 00390], lr: 0.004000, loss: 3.1035
2023-07-02 01:38:25 - train: epoch 0130, iter [00250, 00390], lr: 0.004000, loss: 1.6220
2023-07-02 01:38:27 - train: epoch 0146, iter [00300, 00390], lr: 0.004000, loss: 2.2027
2023-07-02 01:38:27 - train: epoch 0130, iter [00300, 00390], lr: 0.004000, loss: 1.5954
2023-07-02 01:38:29 - train: epoch 0146, iter [00350, 00390], lr: 0.004000, loss: 1.7017
2023-07-02 01:38:29 - train: epoch 0130, iter [00350, 00390], lr: 0.004000, loss: 1.7349
2023-07-02 01:38:30 - train: epoch 146, train_loss: 2.3239
2023-07-02 01:38:31 - train: epoch 130, train_loss: 1.6806
2023-07-02 01:38:32 - eval: epoch: 146, acc1: 40.850%, acc5: 69.960%, test_loss: 2.3596, per_image_load_time: 0.072ms, per_image_inference_time: 0.055ms
2023-07-02 01:38:32 - until epoch: 146, best_acc1: 40.850%
2023-07-02 01:38:32 - epoch 147 lr: 0.004000
2023-07-02 01:38:32 - eval: epoch: 130, acc1: 40.650%, acc5: 67.980%, test_loss: 2.5649, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:38:32 - until epoch: 130, best_acc1: 41.480%
2023-07-02 01:38:32 - epoch 131 lr: 0.004000
2023-07-02 01:38:35 - train: epoch 0147, iter [00050, 00390], lr: 0.004000, loss: 3.1642
2023-07-02 01:38:35 - train: epoch 0131, iter [00050, 00390], lr: 0.004000, loss: 1.5784
2023-07-02 01:38:37 - train: epoch 0147, iter [00100, 00390], lr: 0.004000, loss: 2.9082
2023-07-02 01:38:38 - train: epoch 0131, iter [00100, 00390], lr: 0.004000, loss: 1.5733
2023-07-02 01:38:39 - train: epoch 0147, iter [00150, 00390], lr: 0.004000, loss: 2.3964
2023-07-02 01:38:40 - train: epoch 0131, iter [00150, 00390], lr: 0.004000, loss: 1.5970
2023-07-02 01:38:41 - train: epoch 0147, iter [00200, 00390], lr: 0.004000, loss: 2.1896
2023-07-02 01:38:42 - train: epoch 0131, iter [00200, 00390], lr: 0.004000, loss: 1.6764
2023-07-02 01:38:43 - train: epoch 0147, iter [00250, 00390], lr: 0.004000, loss: 2.6752
2023-07-02 01:38:44 - train: epoch 0131, iter [00250, 00390], lr: 0.004000, loss: 1.7038
2023-07-02 01:38:45 - train: epoch 0147, iter [00300, 00390], lr: 0.004000, loss: 2.6145
2023-07-02 01:38:46 - train: epoch 0131, iter [00300, 00390], lr: 0.004000, loss: 1.7152
2023-07-02 01:38:47 - train: epoch 0147, iter [00350, 00390], lr: 0.004000, loss: 2.6051
2023-07-02 01:38:48 - train: epoch 0131, iter [00350, 00390], lr: 0.004000, loss: 1.7001
2023-07-02 01:38:49 - train: epoch 147, train_loss: 2.4023
2023-07-02 01:38:50 - train: epoch 131, train_loss: 1.6670
2023-07-02 01:38:50 - eval: epoch: 147, acc1: 40.750%, acc5: 70.210%, test_loss: 2.3691, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-07-02 01:38:51 - until epoch: 147, best_acc1: 40.850%
2023-07-02 01:38:51 - epoch 148 lr: 0.004000
2023-07-02 01:38:51 - eval: epoch: 131, acc1: 40.310%, acc5: 67.690%, test_loss: 2.5793, per_image_load_time: 0.069ms, per_image_inference_time: 0.057ms
2023-07-02 01:38:51 - until epoch: 131, best_acc1: 41.480%
2023-07-02 01:38:51 - epoch 132 lr: 0.004000
2023-07-02 01:38:53 - train: epoch 0148, iter [00050, 00390], lr: 0.004000, loss: 3.4418
2023-07-02 01:38:54 - train: epoch 0132, iter [00050, 00390], lr: 0.004000, loss: 1.5970
2023-07-02 01:38:56 - train: epoch 0148, iter [00100, 00390], lr: 0.004000, loss: 3.1170
2023-07-02 01:38:56 - train: epoch 0132, iter [00100, 00390], lr: 0.004000, loss: 1.6507
2023-07-02 01:38:58 - train: epoch 0148, iter [00150, 00390], lr: 0.004000, loss: 1.8996
2023-07-02 01:38:58 - train: epoch 0132, iter [00150, 00390], lr: 0.004000, loss: 1.7097
2023-07-02 01:39:00 - train: epoch 0148, iter [00200, 00390], lr: 0.004000, loss: 2.1300
2023-07-02 01:39:00 - train: epoch 0132, iter [00200, 00390], lr: 0.004000, loss: 1.5534
2023-07-02 01:39:02 - train: epoch 0148, iter [00250, 00390], lr: 0.004000, loss: 2.4572
2023-07-02 01:39:02 - train: epoch 0132, iter [00250, 00390], lr: 0.004000, loss: 1.7749
2023-07-02 01:39:05 - train: epoch 0132, iter [00300, 00390], lr: 0.004000, loss: 1.6256
2023-07-02 01:39:05 - train: epoch 0148, iter [00300, 00390], lr: 0.004000, loss: 2.3405
2023-07-02 01:39:07 - train: epoch 0148, iter [00350, 00390], lr: 0.004000, loss: 2.0553
2023-07-02 01:39:07 - train: epoch 0132, iter [00350, 00390], lr: 0.004000, loss: 1.6344
2023-07-02 01:39:08 - train: epoch 148, train_loss: 2.3613
2023-07-02 01:39:09 - train: epoch 132, train_loss: 1.6546
2023-07-02 01:39:10 - eval: epoch: 132, acc1: 40.070%, acc5: 67.600%, test_loss: 2.5862, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:39:10 - eval: epoch: 148, acc1: 40.490%, acc5: 70.550%, test_loss: 2.3545, per_image_load_time: 0.085ms, per_image_inference_time: 0.055ms
2023-07-02 01:39:10 - until epoch: 148, best_acc1: 40.850%
2023-07-02 01:39:10 - epoch 149 lr: 0.004000
2023-07-02 01:39:10 - until epoch: 132, best_acc1: 41.480%
2023-07-02 01:39:10 - epoch 133 lr: 0.004000
2023-07-02 01:39:13 - train: epoch 0149, iter [00050, 00390], lr: 0.004000, loss: 2.7117
2023-07-02 01:39:13 - train: epoch 0133, iter [00050, 00390], lr: 0.004000, loss: 1.6126
2023-07-02 01:39:15 - train: epoch 0149, iter [00100, 00390], lr: 0.004000, loss: 3.2466
2023-07-02 01:39:16 - train: epoch 0133, iter [00100, 00390], lr: 0.004000, loss: 1.7039
2023-07-02 01:39:17 - train: epoch 0149, iter [00150, 00390], lr: 0.004000, loss: 2.1431
2023-07-02 01:39:18 - train: epoch 0133, iter [00150, 00390], lr: 0.004000, loss: 1.5752
2023-07-02 01:39:19 - train: epoch 0149, iter [00200, 00390], lr: 0.004000, loss: 2.4647
2023-07-02 01:39:20 - train: epoch 0133, iter [00200, 00390], lr: 0.004000, loss: 1.6600
2023-07-02 01:39:21 - train: epoch 0149, iter [00250, 00390], lr: 0.004000, loss: 1.9604
2023-07-02 01:39:22 - train: epoch 0133, iter [00250, 00390], lr: 0.004000, loss: 1.7145
2023-07-02 01:39:23 - train: epoch 0149, iter [00300, 00390], lr: 0.004000, loss: 1.9662
2023-07-02 01:39:24 - train: epoch 0133, iter [00300, 00390], lr: 0.004000, loss: 1.7934
2023-07-02 01:39:26 - train: epoch 0149, iter [00350, 00390], lr: 0.004000, loss: 3.2306
2023-07-02 01:39:26 - train: epoch 0133, iter [00350, 00390], lr: 0.004000, loss: 1.7285
2023-07-02 01:39:27 - train: epoch 149, train_loss: 2.3663
2023-07-02 01:39:28 - train: epoch 133, train_loss: 1.6480
2023-07-02 01:39:29 - eval: epoch: 149, acc1: 40.390%, acc5: 70.430%, test_loss: 2.3572, per_image_load_time: 0.072ms, per_image_inference_time: 0.061ms
2023-07-02 01:39:29 - until epoch: 149, best_acc1: 40.850%
2023-07-02 01:39:29 - epoch 150 lr: 0.004000
2023-07-02 01:39:29 - eval: epoch: 133, acc1: 41.030%, acc5: 67.490%, test_loss: 2.5750, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:39:29 - until epoch: 133, best_acc1: 41.480%
2023-07-02 01:39:29 - epoch 134 lr: 0.004000
2023-07-02 01:39:32 - train: epoch 0150, iter [00050, 00390], lr: 0.004000, loss: 1.9269
2023-07-02 01:39:32 - train: epoch 0134, iter [00050, 00390], lr: 0.004000, loss: 1.8073
2023-07-02 01:39:34 - train: epoch 0150, iter [00100, 00390], lr: 0.004000, loss: 2.0402
2023-07-02 01:39:35 - train: epoch 0134, iter [00100, 00390], lr: 0.004000, loss: 1.4649
2023-07-02 01:39:36 - train: epoch 0150, iter [00150, 00390], lr: 0.004000, loss: 2.0577
2023-07-02 01:39:37 - train: epoch 0134, iter [00150, 00390], lr: 0.004000, loss: 1.7113
2023-07-02 01:39:38 - train: epoch 0150, iter [00200, 00390], lr: 0.004000, loss: 2.0225
2023-07-02 01:39:39 - train: epoch 0134, iter [00200, 00390], lr: 0.004000, loss: 1.6446
2023-07-02 01:39:40 - train: epoch 0150, iter [00250, 00390], lr: 0.004000, loss: 3.2205
2023-07-02 01:39:41 - train: epoch 0134, iter [00250, 00390], lr: 0.004000, loss: 1.7036
2023-07-02 01:39:42 - train: epoch 0150, iter [00300, 00390], lr: 0.004000, loss: 3.1568
2023-07-02 01:39:43 - train: epoch 0134, iter [00300, 00390], lr: 0.004000, loss: 1.7436
2023-07-02 01:39:44 - train: epoch 0150, iter [00350, 00390], lr: 0.004000, loss: 2.2353
2023-07-02 01:39:45 - train: epoch 0134, iter [00350, 00390], lr: 0.004000, loss: 1.7097
2023-07-02 01:39:46 - train: epoch 150, train_loss: 2.3603
2023-07-02 01:39:47 - train: epoch 134, train_loss: 1.6370
2023-07-02 01:39:48 - eval: epoch: 150, acc1: 40.400%, acc5: 70.430%, test_loss: 2.3603, per_image_load_time: 0.072ms, per_image_inference_time: 0.055ms
2023-07-02 01:39:48 - until epoch: 150, best_acc1: 40.850%
2023-07-02 01:39:48 - epoch 151 lr: 0.004000
2023-07-02 01:39:48 - eval: epoch: 134, acc1: 40.880%, acc5: 67.510%, test_loss: 2.5938, per_image_load_time: 0.066ms, per_image_inference_time: 0.058ms
2023-07-02 01:39:48 - until epoch: 134, best_acc1: 41.480%
2023-07-02 01:39:48 - epoch 135 lr: 0.004000
2023-07-02 01:39:51 - train: epoch 0151, iter [00050, 00390], lr: 0.004000, loss: 2.0785
2023-07-02 01:39:51 - train: epoch 0135, iter [00050, 00390], lr: 0.004000, loss: 1.4885
2023-07-02 01:39:53 - train: epoch 0151, iter [00100, 00390], lr: 0.004000, loss: 2.3666
2023-07-02 01:39:53 - train: epoch 0135, iter [00100, 00390], lr: 0.004000, loss: 1.6049
2023-07-02 01:39:55 - train: epoch 0151, iter [00150, 00390], lr: 0.004000, loss: 2.6278
2023-07-02 01:39:55 - train: epoch 0135, iter [00150, 00390], lr: 0.004000, loss: 1.5904
2023-07-02 01:39:57 - train: epoch 0151, iter [00200, 00390], lr: 0.004000, loss: 2.7106
2023-07-02 01:39:58 - train: epoch 0135, iter [00200, 00390], lr: 0.004000, loss: 1.6230
2023-07-02 01:39:59 - train: epoch 0151, iter [00250, 00390], lr: 0.004000, loss: 2.1196
2023-07-02 01:40:00 - train: epoch 0135, iter [00250, 00390], lr: 0.004000, loss: 1.6541
2023-07-02 01:40:01 - train: epoch 0151, iter [00300, 00390], lr: 0.004000, loss: 1.8961
2023-07-02 01:40:02 - train: epoch 0135, iter [00300, 00390], lr: 0.004000, loss: 1.8015
2023-07-02 01:40:03 - train: epoch 0151, iter [00350, 00390], lr: 0.004000, loss: 1.7907
2023-07-02 01:40:04 - train: epoch 151, train_loss: 2.3700
2023-07-02 01:40:05 - train: epoch 0135, iter [00350, 00390], lr: 0.004000, loss: 1.5570
2023-07-02 01:40:06 - eval: epoch: 151, acc1: 40.300%, acc5: 70.390%, test_loss: 2.3541, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:40:06 - until epoch: 151, best_acc1: 40.850%
2023-07-02 01:40:06 - epoch 152 lr: 0.004000
2023-07-02 01:40:06 - train: epoch 135, train_loss: 1.6294
2023-07-02 01:40:08 - eval: epoch: 135, acc1: 40.500%, acc5: 67.360%, test_loss: 2.6013, per_image_load_time: 0.069ms, per_image_inference_time: 0.067ms
2023-07-02 01:40:08 - until epoch: 135, best_acc1: 41.480%
2023-07-02 01:40:08 - epoch 136 lr: 0.004000
2023-07-02 01:40:09 - train: epoch 0152, iter [00050, 00390], lr: 0.004000, loss: 2.2121
2023-07-02 01:40:11 - train: epoch 0152, iter [00100, 00390], lr: 0.004000, loss: 1.7780
2023-07-02 01:40:11 - train: epoch 0136, iter [00050, 00390], lr: 0.004000, loss: 1.4414
2023-07-02 01:40:13 - train: epoch 0152, iter [00150, 00390], lr: 0.004000, loss: 1.8583
2023-07-02 01:40:13 - train: epoch 0136, iter [00100, 00390], lr: 0.004000, loss: 1.5095
2023-07-02 01:40:15 - train: epoch 0152, iter [00200, 00390], lr: 0.004000, loss: 1.6220
2023-07-02 01:40:15 - train: epoch 0136, iter [00150, 00390], lr: 0.004000, loss: 1.5914
2023-07-02 01:40:17 - train: epoch 0152, iter [00250, 00390], lr: 0.004000, loss: 1.8374
2023-07-02 01:40:17 - train: epoch 0136, iter [00200, 00390], lr: 0.004000, loss: 1.6998
2023-07-02 01:40:19 - train: epoch 0152, iter [00300, 00390], lr: 0.004000, loss: 2.3133
2023-07-02 01:40:19 - train: epoch 0136, iter [00250, 00390], lr: 0.004000, loss: 1.7044
2023-07-02 01:40:21 - train: epoch 0152, iter [00350, 00390], lr: 0.004000, loss: 2.1086
2023-07-02 01:40:21 - train: epoch 0136, iter [00300, 00390], lr: 0.004000, loss: 1.5824
2023-07-02 01:40:22 - train: epoch 152, train_loss: 2.3327
2023-07-02 01:40:23 - train: epoch 0136, iter [00350, 00390], lr: 0.004000, loss: 1.7210
2023-07-02 01:40:24 - eval: epoch: 152, acc1: 40.040%, acc5: 70.070%, test_loss: 2.3679, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:40:24 - until epoch: 152, best_acc1: 40.850%
2023-07-02 01:40:24 - epoch 153 lr: 0.004000
2023-07-02 01:40:25 - train: epoch 136, train_loss: 1.6242
2023-07-02 01:40:26 - eval: epoch: 136, acc1: 40.110%, acc5: 67.190%, test_loss: 2.6152, per_image_load_time: 0.069ms, per_image_inference_time: 0.057ms
2023-07-02 01:40:27 - train: epoch 0153, iter [00050, 00390], lr: 0.004000, loss: 1.5844
2023-07-02 01:40:27 - until epoch: 136, best_acc1: 41.480%
2023-07-02 01:40:27 - epoch 137 lr: 0.004000
2023-07-02 01:40:28 - train: epoch 0153, iter [00100, 00390], lr: 0.004000, loss: 2.6902
2023-07-02 01:40:29 - train: epoch 0137, iter [00050, 00390], lr: 0.004000, loss: 1.6302
2023-07-02 01:40:30 - train: epoch 0153, iter [00150, 00390], lr: 0.004000, loss: 2.8166
2023-07-02 01:40:32 - train: epoch 0137, iter [00100, 00390], lr: 0.004000, loss: 1.5086
2023-07-02 01:40:32 - train: epoch 0153, iter [00200, 00390], lr: 0.004000, loss: 2.6774
2023-07-02 01:40:34 - train: epoch 0137, iter [00150, 00390], lr: 0.004000, loss: 1.4870
2023-07-02 01:40:34 - train: epoch 0153, iter [00250, 00390], lr: 0.004000, loss: 2.1210
2023-07-02 01:40:36 - train: epoch 0137, iter [00200, 00390], lr: 0.004000, loss: 1.4760
2023-07-02 01:40:36 - train: epoch 0153, iter [00300, 00390], lr: 0.004000, loss: 2.5429
2023-07-02 01:40:38 - train: epoch 0137, iter [00250, 00390], lr: 0.004000, loss: 1.4845
2023-07-02 01:40:39 - train: epoch 0153, iter [00350, 00390], lr: 0.004000, loss: 2.3275
2023-07-02 01:40:40 - train: epoch 0137, iter [00300, 00390], lr: 0.004000, loss: 1.6425
2023-07-02 01:40:40 - train: epoch 153, train_loss: 2.3776
2023-07-02 01:40:42 - train: epoch 0137, iter [00350, 00390], lr: 0.004000, loss: 1.8178
2023-07-02 01:40:42 - eval: epoch: 153, acc1: 40.660%, acc5: 70.710%, test_loss: 2.3542, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 01:40:42 - until epoch: 153, best_acc1: 40.850%
2023-07-02 01:40:42 - epoch 154 lr: 0.004000
2023-07-02 01:40:43 - train: epoch 137, train_loss: 1.6229
2023-07-02 01:40:44 - eval: epoch: 137, acc1: 40.780%, acc5: 67.160%, test_loss: 2.6113, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:40:44 - train: epoch 0154, iter [00050, 00390], lr: 0.004000, loss: 3.1398
2023-07-02 01:40:45 - until epoch: 137, best_acc1: 41.480%
2023-07-02 01:40:45 - epoch 138 lr: 0.004000
2023-07-02 01:40:46 - train: epoch 0154, iter [00100, 00390], lr: 0.004000, loss: 2.4308
2023-07-02 01:40:48 - train: epoch 0138, iter [00050, 00390], lr: 0.004000, loss: 1.4996
2023-07-02 01:40:48 - train: epoch 0154, iter [00150, 00390], lr: 0.004000, loss: 2.0402
2023-07-02 01:40:50 - train: epoch 0154, iter [00200, 00390], lr: 0.004000, loss: 2.1601
2023-07-02 01:40:50 - train: epoch 0138, iter [00100, 00390], lr: 0.004000, loss: 1.4775
2023-07-02 01:40:52 - train: epoch 0154, iter [00250, 00390], lr: 0.004000, loss: 2.2717
2023-07-02 01:40:52 - train: epoch 0138, iter [00150, 00390], lr: 0.004000, loss: 1.6581
2023-07-02 01:40:54 - train: epoch 0154, iter [00300, 00390], lr: 0.004000, loss: 2.4590
2023-07-02 01:40:54 - train: epoch 0138, iter [00200, 00390], lr: 0.004000, loss: 1.7040
2023-07-02 01:40:56 - train: epoch 0154, iter [00350, 00390], lr: 0.004000, loss: 2.0014
2023-07-02 01:40:56 - train: epoch 0138, iter [00250, 00390], lr: 0.004000, loss: 1.6263
2023-07-02 01:40:58 - train: epoch 154, train_loss: 2.3028
2023-07-02 01:40:58 - train: epoch 0138, iter [00300, 00390], lr: 0.004000, loss: 1.5973
2023-07-02 01:40:59 - eval: epoch: 154, acc1: 40.500%, acc5: 70.380%, test_loss: 2.3674, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:40:59 - until epoch: 154, best_acc1: 40.850%
2023-07-02 01:40:59 - epoch 155 lr: 0.004000
2023-07-02 01:41:00 - train: epoch 0138, iter [00350, 00390], lr: 0.004000, loss: 1.5209
2023-07-02 01:41:02 - train: epoch 138, train_loss: 1.6139
2023-07-02 01:41:02 - train: epoch 0155, iter [00050, 00390], lr: 0.004000, loss: 2.7111
2023-07-02 01:41:03 - eval: epoch: 138, acc1: 40.640%, acc5: 66.820%, test_loss: 2.6300, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:41:04 - train: epoch 0155, iter [00100, 00390], lr: 0.004000, loss: 2.4686
2023-07-02 01:41:04 - until epoch: 138, best_acc1: 41.480%
2023-07-02 01:41:04 - epoch 139 lr: 0.004000
2023-07-02 01:41:05 - train: epoch 0155, iter [00150, 00390], lr: 0.004000, loss: 2.3376
2023-07-02 01:41:07 - train: epoch 0139, iter [00050, 00390], lr: 0.004000, loss: 1.5673
2023-07-02 01:41:07 - train: epoch 0155, iter [00200, 00390], lr: 0.004000, loss: 2.2291
2023-07-02 01:41:09 - train: epoch 0139, iter [00100, 00390], lr: 0.004000, loss: 1.5971
2023-07-02 01:41:09 - train: epoch 0155, iter [00250, 00390], lr: 0.004000, loss: 2.3275
2023-07-02 01:41:11 - train: epoch 0139, iter [00150, 00390], lr: 0.004000, loss: 1.7189
2023-07-02 01:41:12 - train: epoch 0155, iter [00300, 00390], lr: 0.004000, loss: 1.8876
2023-07-02 01:41:13 - train: epoch 0139, iter [00200, 00390], lr: 0.004000, loss: 1.6565
2023-07-02 01:41:14 - train: epoch 0155, iter [00350, 00390], lr: 0.004000, loss: 3.0007
2023-07-02 01:41:15 - train: epoch 0139, iter [00250, 00390], lr: 0.004000, loss: 1.5892
2023-07-02 01:41:15 - train: epoch 155, train_loss: 2.3341
2023-07-02 01:41:17 - eval: epoch: 155, acc1: 40.350%, acc5: 71.150%, test_loss: 2.3337, per_image_load_time: 0.067ms, per_image_inference_time: 0.054ms
2023-07-02 01:41:17 - train: epoch 0139, iter [00300, 00390], lr: 0.004000, loss: 1.5382
2023-07-02 01:41:17 - until epoch: 155, best_acc1: 40.850%
2023-07-02 01:41:17 - epoch 156 lr: 0.004000
2023-07-02 01:41:19 - train: epoch 0139, iter [00350, 00390], lr: 0.004000, loss: 1.5423
2023-07-02 01:41:20 - train: epoch 0156, iter [00050, 00390], lr: 0.004000, loss: 2.3018
2023-07-02 01:41:20 - train: epoch 139, train_loss: 1.6030
2023-07-02 01:41:22 - eval: epoch: 139, acc1: 40.190%, acc5: 66.750%, test_loss: 2.6353, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:41:22 - train: epoch 0156, iter [00100, 00390], lr: 0.004000, loss: 1.8093
2023-07-02 01:41:22 - until epoch: 139, best_acc1: 41.480%
2023-07-02 01:41:22 - epoch 140 lr: 0.004000
2023-07-02 01:41:24 - train: epoch 0156, iter [00150, 00390], lr: 0.004000, loss: 2.0153
2023-07-02 01:41:25 - train: epoch 0140, iter [00050, 00390], lr: 0.004000, loss: 1.4968
2023-07-02 01:41:26 - train: epoch 0156, iter [00200, 00390], lr: 0.004000, loss: 1.9038
2023-07-02 01:41:27 - train: epoch 0140, iter [00100, 00390], lr: 0.004000, loss: 1.4832
2023-07-02 01:41:28 - train: epoch 0156, iter [00250, 00390], lr: 0.004000, loss: 1.8873
2023-07-02 01:41:29 - train: epoch 0140, iter [00150, 00390], lr: 0.004000, loss: 1.6992
2023-07-02 01:41:31 - train: epoch 0156, iter [00300, 00390], lr: 0.004000, loss: 2.4509
2023-07-02 01:41:31 - train: epoch 0140, iter [00200, 00390], lr: 0.004000, loss: 1.6833
2023-07-02 01:41:33 - train: epoch 0156, iter [00350, 00390], lr: 0.004000, loss: 2.5263
2023-07-02 01:41:33 - train: epoch 0140, iter [00250, 00390], lr: 0.004000, loss: 1.6884
2023-07-02 01:41:35 - train: epoch 156, train_loss: 2.3078
2023-07-02 01:41:35 - train: epoch 0140, iter [00300, 00390], lr: 0.004000, loss: 1.6425
2023-07-02 01:41:36 - eval: epoch: 156, acc1: 40.180%, acc5: 70.470%, test_loss: 2.3712, per_image_load_time: 0.067ms, per_image_inference_time: 0.054ms
2023-07-02 01:41:37 - until epoch: 156, best_acc1: 40.850%
2023-07-02 01:41:37 - epoch 157 lr: 0.004000
2023-07-02 01:41:37 - train: epoch 0140, iter [00350, 00390], lr: 0.004000, loss: 1.7042
2023-07-02 01:41:39 - train: epoch 140, train_loss: 1.6046
2023-07-02 01:41:39 - train: epoch 0157, iter [00050, 00390], lr: 0.004000, loss: 3.5789
2023-07-02 01:41:40 - eval: epoch: 140, acc1: 40.740%, acc5: 67.430%, test_loss: 2.6182, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:41:40 - until epoch: 140, best_acc1: 41.480%
2023-07-02 01:41:40 - epoch 141 lr: 0.004000
2023-07-02 01:41:41 - train: epoch 0157, iter [00100, 00390], lr: 0.004000, loss: 1.7863
2023-07-02 01:41:43 - train: epoch 0157, iter [00150, 00390], lr: 0.004000, loss: 2.5833
2023-07-02 01:41:43 - train: epoch 0141, iter [00050, 00390], lr: 0.004000, loss: 1.5063
2023-07-02 01:41:45 - train: epoch 0157, iter [00200, 00390], lr: 0.004000, loss: 2.5625
2023-07-02 01:41:45 - train: epoch 0141, iter [00100, 00390], lr: 0.004000, loss: 1.5409
2023-07-02 01:41:47 - train: epoch 0157, iter [00250, 00390], lr: 0.004000, loss: 2.5948
2023-07-02 01:41:47 - train: epoch 0141, iter [00150, 00390], lr: 0.004000, loss: 1.6229
2023-07-02 01:41:49 - train: epoch 0157, iter [00300, 00390], lr: 0.004000, loss: 1.8067
2023-07-02 01:41:49 - train: epoch 0141, iter [00200, 00390], lr: 0.004000, loss: 1.5740
2023-07-02 01:41:52 - train: epoch 0141, iter [00250, 00390], lr: 0.004000, loss: 1.5493
2023-07-02 01:41:52 - train: epoch 0157, iter [00350, 00390], lr: 0.004000, loss: 2.2576
2023-07-02 01:41:54 - train: epoch 157, train_loss: 2.3197
2023-07-02 01:41:54 - train: epoch 0141, iter [00300, 00390], lr: 0.004000, loss: 1.6168
2023-07-02 01:41:55 - eval: epoch: 157, acc1: 40.020%, acc5: 70.400%, test_loss: 2.3746, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:41:55 - until epoch: 157, best_acc1: 40.850%
2023-07-02 01:41:55 - epoch 158 lr: 0.004000
2023-07-02 01:41:55 - train: epoch 0141, iter [00350, 00390], lr: 0.004000, loss: 1.6101
2023-07-02 01:41:57 - train: epoch 141, train_loss: 1.5924
2023-07-02 01:41:58 - train: epoch 0158, iter [00050, 00390], lr: 0.004000, loss: 2.0948
2023-07-02 01:41:59 - eval: epoch: 141, acc1: 40.290%, acc5: 66.630%, test_loss: 2.6501, per_image_load_time: 0.081ms, per_image_inference_time: 0.057ms
2023-07-02 01:41:59 - until epoch: 141, best_acc1: 41.480%
2023-07-02 01:41:59 - epoch 142 lr: 0.004000
2023-07-02 01:42:00 - train: epoch 0158, iter [00100, 00390], lr: 0.004000, loss: 2.6806
2023-07-02 01:42:02 - train: epoch 0158, iter [00150, 00390], lr: 0.004000, loss: 2.2481
2023-07-02 01:42:02 - train: epoch 0142, iter [00050, 00390], lr: 0.004000, loss: 1.5745
2023-07-02 01:42:04 - train: epoch 0158, iter [00200, 00390], lr: 0.004000, loss: 2.6546
2023-07-02 01:42:04 - train: epoch 0142, iter [00100, 00390], lr: 0.004000, loss: 1.5504
2023-07-02 01:42:06 - train: epoch 0158, iter [00250, 00390], lr: 0.004000, loss: 2.5568
2023-07-02 01:42:06 - train: epoch 0142, iter [00150, 00390], lr: 0.004000, loss: 1.6091
2023-07-02 01:42:08 - train: epoch 0158, iter [00300, 00390], lr: 0.004000, loss: 2.1879
2023-07-02 01:42:08 - train: epoch 0142, iter [00200, 00390], lr: 0.004000, loss: 1.6238
2023-07-02 01:42:10 - train: epoch 0158, iter [00350, 00390], lr: 0.004000, loss: 2.4756
2023-07-02 01:42:10 - train: epoch 0142, iter [00250, 00390], lr: 0.004000, loss: 1.4985
2023-07-02 01:42:11 - train: epoch 158, train_loss: 2.3481
2023-07-02 01:42:12 - train: epoch 0142, iter [00300, 00390], lr: 0.004000, loss: 1.4539
2023-07-02 01:42:13 - eval: epoch: 158, acc1: 40.390%, acc5: 70.390%, test_loss: 2.3576, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:42:13 - until epoch: 158, best_acc1: 40.850%
2023-07-02 01:42:13 - epoch 159 lr: 0.004000
2023-07-02 01:42:14 - train: epoch 0142, iter [00350, 00390], lr: 0.004000, loss: 1.6001
2023-07-02 01:42:16 - train: epoch 142, train_loss: 1.5863
2023-07-02 01:42:16 - train: epoch 0159, iter [00050, 00390], lr: 0.004000, loss: 3.0025
2023-07-02 01:42:17 - eval: epoch: 142, acc1: 40.600%, acc5: 67.080%, test_loss: 2.6393, per_image_load_time: 0.069ms, per_image_inference_time: 0.056ms
2023-07-02 01:42:17 - until epoch: 142, best_acc1: 41.480%
2023-07-02 01:42:17 - epoch 143 lr: 0.004000
2023-07-02 01:42:18 - train: epoch 0159, iter [00100, 00390], lr: 0.004000, loss: 2.7443
2023-07-02 01:42:20 - train: epoch 0159, iter [00150, 00390], lr: 0.004000, loss: 1.7880
2023-07-02 01:42:20 - train: epoch 0143, iter [00050, 00390], lr: 0.004000, loss: 1.4772
2023-07-02 01:42:22 - train: epoch 0159, iter [00200, 00390], lr: 0.004000, loss: 1.9094
2023-07-02 01:42:22 - train: epoch 0143, iter [00100, 00390], lr: 0.004000, loss: 1.4848
2023-07-02 01:42:24 - train: epoch 0159, iter [00250, 00390], lr: 0.004000, loss: 2.4294
2023-07-02 01:42:24 - train: epoch 0143, iter [00150, 00390], lr: 0.004000, loss: 1.6154
2023-07-02 01:42:26 - train: epoch 0159, iter [00300, 00390], lr: 0.004000, loss: 2.7468
2023-07-02 01:42:27 - train: epoch 0143, iter [00200, 00390], lr: 0.004000, loss: 1.4661
2023-07-02 01:42:28 - train: epoch 0159, iter [00350, 00390], lr: 0.004000, loss: 1.9538
2023-07-02 01:42:29 - train: epoch 0143, iter [00250, 00390], lr: 0.004000, loss: 1.7060
2023-07-02 01:42:30 - train: epoch 159, train_loss: 2.3423
2023-07-02 01:42:30 - train: epoch 0143, iter [00300, 00390], lr: 0.004000, loss: 1.7087
2023-07-02 01:42:31 - eval: epoch: 159, acc1: 40.320%, acc5: 69.890%, test_loss: 2.3780, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:42:31 - until epoch: 159, best_acc1: 40.850%
2023-07-02 01:42:31 - epoch 160 lr: 0.004000
2023-07-02 01:42:32 - train: epoch 0143, iter [00350, 00390], lr: 0.004000, loss: 1.6770
2023-07-02 01:42:34 - train: epoch 143, train_loss: 1.5871
2023-07-02 01:42:34 - train: epoch 0160, iter [00050, 00390], lr: 0.004000, loss: 2.2413
2023-07-02 01:42:35 - eval: epoch: 143, acc1: 39.800%, acc5: 66.670%, test_loss: 2.6668, per_image_load_time: 0.067ms, per_image_inference_time: 0.061ms
2023-07-02 01:42:36 - until epoch: 143, best_acc1: 41.480%
2023-07-02 01:42:36 - epoch 144 lr: 0.004000
2023-07-02 01:42:36 - train: epoch 0160, iter [00100, 00390], lr: 0.004000, loss: 2.3795
2023-07-02 01:42:38 - train: epoch 0160, iter [00150, 00390], lr: 0.004000, loss: 2.5574
2023-07-02 01:42:38 - train: epoch 0144, iter [00050, 00390], lr: 0.004000, loss: 1.4635
2023-07-02 01:42:40 - train: epoch 0160, iter [00200, 00390], lr: 0.004000, loss: 2.0885
2023-07-02 01:42:41 - train: epoch 0144, iter [00100, 00390], lr: 0.004000, loss: 1.5976
2023-07-02 01:42:42 - train: epoch 0160, iter [00250, 00390], lr: 0.004000, loss: 2.5397
2023-07-02 01:42:43 - train: epoch 0144, iter [00150, 00390], lr: 0.004000, loss: 1.6094
2023-07-02 01:42:44 - train: epoch 0160, iter [00300, 00390], lr: 0.004000, loss: 1.9618
2023-07-02 01:42:45 - train: epoch 0144, iter [00200, 00390], lr: 0.004000, loss: 1.5801
2023-07-02 01:42:46 - train: epoch 0160, iter [00350, 00390], lr: 0.004000, loss: 2.1041
2023-07-02 01:42:47 - train: epoch 0144, iter [00250, 00390], lr: 0.004000, loss: 1.6946
2023-07-02 01:42:48 - train: epoch 160, train_loss: 2.3445
2023-07-02 01:42:49 - train: epoch 0144, iter [00300, 00390], lr: 0.004000, loss: 1.7180
2023-07-02 01:42:49 - eval: epoch: 160, acc1: 40.300%, acc5: 69.820%, test_loss: 2.3854, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:42:49 - until epoch: 160, best_acc1: 40.850%
2023-07-02 01:42:49 - epoch 161 lr: 0.000800
2023-07-02 01:42:50 - train: epoch 0144, iter [00350, 00390], lr: 0.004000, loss: 1.6344
2023-07-02 01:42:52 - train: epoch 144, train_loss: 1.5768
2023-07-02 01:42:52 - train: epoch 0161, iter [00050, 00390], lr: 0.000800, loss: 2.1710
2023-07-02 01:42:54 - eval: epoch: 144, acc1: 40.010%, acc5: 67.370%, test_loss: 2.6371, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:42:54 - train: epoch 0161, iter [00100, 00390], lr: 0.000800, loss: 1.5594
2023-07-02 01:42:54 - until epoch: 144, best_acc1: 41.480%
2023-07-02 01:42:54 - epoch 145 lr: 0.004000
2023-07-02 01:42:55 - train: epoch 0161, iter [00150, 00390], lr: 0.000800, loss: 1.4369
2023-07-02 01:42:57 - train: epoch 0161, iter [00200, 00390], lr: 0.000800, loss: 2.8293
2023-07-02 01:42:57 - train: epoch 0145, iter [00050, 00390], lr: 0.004000, loss: 1.5726
2023-07-02 01:42:59 - train: epoch 0161, iter [00250, 00390], lr: 0.000800, loss: 1.9429
2023-07-02 01:42:59 - train: epoch 0145, iter [00100, 00390], lr: 0.004000, loss: 1.6892
2023-07-02 01:43:01 - train: epoch 0161, iter [00300, 00390], lr: 0.000800, loss: 2.5610
2023-07-02 01:43:01 - train: epoch 0145, iter [00150, 00390], lr: 0.004000, loss: 1.6595
2023-07-02 01:43:03 - train: epoch 0161, iter [00350, 00390], lr: 0.000800, loss: 2.0063
2023-07-02 01:43:04 - train: epoch 0145, iter [00200, 00390], lr: 0.004000, loss: 1.7690
2023-07-02 01:43:05 - train: epoch 161, train_loss: 2.1980
2023-07-02 01:43:06 - train: epoch 0145, iter [00250, 00390], lr: 0.004000, loss: 1.6462
2023-07-02 01:43:07 - eval: epoch: 161, acc1: 41.790%, acc5: 71.130%, test_loss: 2.3079, per_image_load_time: 0.086ms, per_image_inference_time: 0.054ms
2023-07-02 01:43:07 - until epoch: 161, best_acc1: 41.790%
2023-07-02 01:43:07 - epoch 162 lr: 0.000800
2023-07-02 01:43:07 - train: epoch 0145, iter [00300, 00390], lr: 0.004000, loss: 1.6830
2023-07-02 01:43:09 - train: epoch 0145, iter [00350, 00390], lr: 0.004000, loss: 1.5469
2023-07-02 01:43:10 - train: epoch 0162, iter [00050, 00390], lr: 0.000800, loss: 2.5045
2023-07-02 01:43:11 - train: epoch 145, train_loss: 1.5703
2023-07-02 01:43:12 - train: epoch 0162, iter [00100, 00390], lr: 0.000800, loss: 2.0451
2023-07-02 01:43:13 - eval: epoch: 145, acc1: 40.280%, acc5: 66.930%, test_loss: 2.6519, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:43:13 - until epoch: 145, best_acc1: 41.480%
2023-07-02 01:43:13 - epoch 146 lr: 0.004000
2023-07-02 01:43:13 - train: epoch 0162, iter [00150, 00390], lr: 0.000800, loss: 2.3114
2023-07-02 01:43:16 - train: epoch 0162, iter [00200, 00390], lr: 0.000800, loss: 2.2878
2023-07-02 01:43:16 - train: epoch 0146, iter [00050, 00390], lr: 0.004000, loss: 1.6642
2023-07-02 01:43:18 - train: epoch 0162, iter [00250, 00390], lr: 0.000800, loss: 1.6256
2023-07-02 01:43:18 - train: epoch 0146, iter [00100, 00390], lr: 0.004000, loss: 1.4387
2023-07-02 01:43:20 - train: epoch 0162, iter [00300, 00390], lr: 0.000800, loss: 2.5372
2023-07-02 01:43:20 - train: epoch 0146, iter [00150, 00390], lr: 0.004000, loss: 1.5322
2023-07-02 01:43:22 - train: epoch 0162, iter [00350, 00390], lr: 0.000800, loss: 2.2163
2023-07-02 01:43:22 - train: epoch 0146, iter [00200, 00390], lr: 0.004000, loss: 1.5166
2023-07-02 01:43:23 - train: epoch 162, train_loss: 2.1987
2023-07-02 01:43:24 - train: epoch 0146, iter [00250, 00390], lr: 0.004000, loss: 1.4047
2023-07-02 01:43:25 - eval: epoch: 162, acc1: 41.880%, acc5: 71.530%, test_loss: 2.3091, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-07-02 01:43:26 - until epoch: 162, best_acc1: 41.880%
2023-07-02 01:43:26 - epoch 163 lr: 0.000800
2023-07-02 01:43:26 - train: epoch 0146, iter [00300, 00390], lr: 0.004000, loss: 1.6739
2023-07-02 01:43:28 - train: epoch 0146, iter [00350, 00390], lr: 0.004000, loss: 1.5676
2023-07-02 01:43:28 - train: epoch 0163, iter [00050, 00390], lr: 0.000800, loss: 2.0754
2023-07-02 01:43:29 - train: epoch 146, train_loss: 1.5715
2023-07-02 01:43:30 - train: epoch 0163, iter [00100, 00390], lr: 0.000800, loss: 3.7960
2023-07-02 01:43:31 - eval: epoch: 146, acc1: 40.350%, acc5: 66.350%, test_loss: 2.6674, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:43:31 - until epoch: 146, best_acc1: 41.480%
2023-07-02 01:43:31 - epoch 147 lr: 0.004000
2023-07-02 01:43:32 - train: epoch 0163, iter [00150, 00390], lr: 0.000800, loss: 2.0876
2023-07-02 01:43:34 - train: epoch 0163, iter [00200, 00390], lr: 0.000800, loss: 2.0602
2023-07-02 01:43:34 - train: epoch 0147, iter [00050, 00390], lr: 0.004000, loss: 1.5265
2023-07-02 01:43:36 - train: epoch 0163, iter [00250, 00390], lr: 0.000800, loss: 1.9444
2023-07-02 01:43:36 - train: epoch 0147, iter [00100, 00390], lr: 0.004000, loss: 1.5259
2023-07-02 01:43:38 - train: epoch 0163, iter [00300, 00390], lr: 0.000800, loss: 3.1118
2023-07-02 01:43:38 - train: epoch 0147, iter [00150, 00390], lr: 0.004000, loss: 1.5749
2023-07-02 01:43:40 - train: epoch 0163, iter [00350, 00390], lr: 0.000800, loss: 2.8507
2023-07-02 01:43:40 - train: epoch 0147, iter [00200, 00390], lr: 0.004000, loss: 1.5230
2023-07-02 01:43:42 - train: epoch 163, train_loss: 2.1599
2023-07-02 01:43:42 - train: epoch 0147, iter [00250, 00390], lr: 0.004000, loss: 1.5840
2023-07-02 01:43:43 - eval: epoch: 163, acc1: 41.980%, acc5: 71.610%, test_loss: 2.3002, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:43:44 - train: epoch 0147, iter [00300, 00390], lr: 0.004000, loss: 1.6032
2023-07-02 01:43:44 - until epoch: 163, best_acc1: 41.980%
2023-07-02 01:43:44 - epoch 164 lr: 0.000800
2023-07-02 01:43:46 - train: epoch 0147, iter [00350, 00390], lr: 0.004000, loss: 1.4869
2023-07-02 01:43:47 - train: epoch 0164, iter [00050, 00390], lr: 0.000800, loss: 2.0786
2023-07-02 01:43:47 - train: epoch 147, train_loss: 1.5676
2023-07-02 01:43:49 - eval: epoch: 147, acc1: 40.210%, acc5: 66.650%, test_loss: 2.6578, per_image_load_time: 0.068ms, per_image_inference_time: 0.057ms
2023-07-02 01:43:49 - train: epoch 0164, iter [00100, 00390], lr: 0.000800, loss: 3.1027
2023-07-02 01:43:49 - until epoch: 147, best_acc1: 41.480%
2023-07-02 01:43:49 - epoch 148 lr: 0.004000
2023-07-02 01:43:51 - train: epoch 0164, iter [00150, 00390], lr: 0.000800, loss: 2.4604
2023-07-02 01:43:52 - train: epoch 0148, iter [00050, 00390], lr: 0.004000, loss: 1.5861
2023-07-02 01:43:53 - train: epoch 0164, iter [00200, 00390], lr: 0.000800, loss: 2.0040
2023-07-02 01:43:54 - train: epoch 0148, iter [00100, 00390], lr: 0.004000, loss: 1.5195
2023-07-02 01:43:55 - train: epoch 0164, iter [00250, 00390], lr: 0.000800, loss: 1.6110
2023-07-02 01:43:56 - train: epoch 0148, iter [00150, 00390], lr: 0.004000, loss: 1.6927
2023-07-02 01:43:57 - train: epoch 0164, iter [00300, 00390], lr: 0.000800, loss: 1.9163
2023-07-02 01:43:58 - train: epoch 0148, iter [00200, 00390], lr: 0.004000, loss: 1.4867
2023-07-02 01:43:59 - train: epoch 0164, iter [00350, 00390], lr: 0.000800, loss: 2.5034
2023-07-02 01:44:00 - train: epoch 0148, iter [00250, 00390], lr: 0.004000, loss: 1.4592
2023-07-02 01:44:01 - train: epoch 164, train_loss: 2.1984
2023-07-02 01:44:02 - eval: epoch: 164, acc1: 41.600%, acc5: 71.340%, test_loss: 2.3162, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 01:44:02 - train: epoch 0148, iter [00300, 00390], lr: 0.004000, loss: 1.4695
2023-07-02 01:44:02 - until epoch: 164, best_acc1: 41.980%
2023-07-02 01:44:02 - epoch 165 lr: 0.000800
2023-07-02 01:44:04 - train: epoch 0148, iter [00350, 00390], lr: 0.004000, loss: 1.5861
2023-07-02 01:44:05 - train: epoch 0165, iter [00050, 00390], lr: 0.000800, loss: 1.7373
2023-07-02 01:44:05 - train: epoch 148, train_loss: 1.5603
2023-07-02 01:44:07 - eval: epoch: 148, acc1: 40.530%, acc5: 67.050%, test_loss: 2.6592, per_image_load_time: 0.071ms, per_image_inference_time: 0.056ms
2023-07-02 01:44:07 - train: epoch 0165, iter [00100, 00390], lr: 0.000800, loss: 1.5031
2023-07-02 01:44:07 - until epoch: 148, best_acc1: 41.480%
2023-07-02 01:44:07 - epoch 149 lr: 0.004000
2023-07-02 01:44:09 - train: epoch 0165, iter [00150, 00390], lr: 0.000800, loss: 2.8834
2023-07-02 01:44:10 - train: epoch 0149, iter [00050, 00390], lr: 0.004000, loss: 1.4053
2023-07-02 01:44:11 - train: epoch 0165, iter [00200, 00390], lr: 0.000800, loss: 2.0834
2023-07-02 01:44:12 - train: epoch 0149, iter [00100, 00390], lr: 0.004000, loss: 1.5051
2023-07-02 01:44:13 - train: epoch 0165, iter [00250, 00390], lr: 0.000800, loss: 2.3796
2023-07-02 01:44:14 - train: epoch 0149, iter [00150, 00390], lr: 0.004000, loss: 1.4952
2023-07-02 01:44:15 - train: epoch 0165, iter [00300, 00390], lr: 0.000800, loss: 1.7068
2023-07-02 01:44:16 - train: epoch 0149, iter [00200, 00390], lr: 0.004000, loss: 1.6211
2023-07-02 01:44:17 - train: epoch 0165, iter [00350, 00390], lr: 0.000800, loss: 1.9048
2023-07-02 01:44:19 - train: epoch 0149, iter [00250, 00390], lr: 0.004000, loss: 1.5832
2023-07-02 01:44:19 - train: epoch 165, train_loss: 2.1892
2023-07-02 01:44:20 - eval: epoch: 165, acc1: 41.750%, acc5: 71.150%, test_loss: 2.3150, per_image_load_time: 0.070ms, per_image_inference_time: 0.055ms
2023-07-02 01:44:20 - train: epoch 0149, iter [00300, 00390], lr: 0.004000, loss: 1.5398
2023-07-02 01:44:20 - until epoch: 165, best_acc1: 41.980%
2023-07-02 01:44:20 - epoch 166 lr: 0.000800
2023-07-02 01:44:22 - train: epoch 0149, iter [00350, 00390], lr: 0.004000, loss: 1.4941
2023-07-02 01:44:23 - train: epoch 0166, iter [00050, 00390], lr: 0.000800, loss: 2.0425
2023-07-02 01:44:24 - train: epoch 149, train_loss: 1.5547
2023-07-02 01:44:25 - train: epoch 0166, iter [00100, 00390], lr: 0.000800, loss: 3.0061
2023-07-02 01:44:25 - eval: epoch: 149, acc1: 40.210%, acc5: 66.770%, test_loss: 2.6683, per_image_load_time: 0.071ms, per_image_inference_time: 0.057ms
2023-07-02 01:44:26 - until epoch: 149, best_acc1: 41.480%
2023-07-02 01:44:26 - epoch 150 lr: 0.004000
2023-07-02 01:44:27 - train: epoch 0166, iter [00150, 00390], lr: 0.000800, loss: 2.1110
2023-07-02 01:44:29 - train: epoch 0150, iter [00050, 00390], lr: 0.004000, loss: 1.5474
2023-07-02 01:44:29 - train: epoch 0166, iter [00200, 00390], lr: 0.000800, loss: 2.0912
2023-07-02 01:44:31 - train: epoch 0150, iter [00100, 00390], lr: 0.004000, loss: 1.5729
2023-07-02 01:44:31 - train: epoch 0166, iter [00250, 00390], lr: 0.000800, loss: 2.3953
2023-07-02 01:44:33 - train: epoch 0150, iter [00150, 00390], lr: 0.004000, loss: 1.5136
2023-07-02 01:44:33 - train: epoch 0166, iter [00300, 00390], lr: 0.000800, loss: 2.2388
2023-07-02 01:44:35 - train: epoch 0150, iter [00200, 00390], lr: 0.004000, loss: 1.4075
2023-07-02 01:44:35 - train: epoch 0166, iter [00350, 00390], lr: 0.000800, loss: 3.1495
2023-07-02 01:44:37 - train: epoch 166, train_loss: 2.1133
2023-07-02 01:44:37 - train: epoch 0150, iter [00250, 00390], lr: 0.004000, loss: 1.4476
2023-07-02 01:44:38 - eval: epoch: 166, acc1: 41.820%, acc5: 71.640%, test_loss: 2.3090, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 01:44:39 - until epoch: 166, best_acc1: 41.980%
2023-07-02 01:44:39 - epoch 167 lr: 0.000800
2023-07-02 01:44:39 - train: epoch 0150, iter [00300, 00390], lr: 0.004000, loss: 1.4585
2023-07-02 01:44:40 - train: epoch 0150, iter [00350, 00390], lr: 0.004000, loss: 1.5269
2023-07-02 01:44:41 - train: epoch 0167, iter [00050, 00390], lr: 0.000800, loss: 1.5606
2023-07-02 01:44:42 - train: epoch 150, train_loss: 1.5565
2023-07-02 01:44:43 - train: epoch 0167, iter [00100, 00390], lr: 0.000800, loss: 2.4416
2023-07-02 01:44:44 - eval: epoch: 150, acc1: 39.990%, acc5: 66.640%, test_loss: 2.6706, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:44:44 - until epoch: 150, best_acc1: 41.480%
2023-07-02 01:44:44 - epoch 151 lr: 0.004000
2023-07-02 01:44:45 - train: epoch 0167, iter [00150, 00390], lr: 0.000800, loss: 1.8681
2023-07-02 01:44:47 - train: epoch 0167, iter [00200, 00390], lr: 0.000800, loss: 2.0655
2023-07-02 01:44:47 - train: epoch 0151, iter [00050, 00390], lr: 0.004000, loss: 1.5094
2023-07-02 01:44:49 - train: epoch 0167, iter [00250, 00390], lr: 0.000800, loss: 3.2621
2023-07-02 01:44:49 - train: epoch 0151, iter [00100, 00390], lr: 0.004000, loss: 1.6075
2023-07-02 01:44:51 - train: epoch 0167, iter [00300, 00390], lr: 0.000800, loss: 1.6088
2023-07-02 01:44:51 - train: epoch 0151, iter [00150, 00390], lr: 0.004000, loss: 1.6701
2023-07-02 01:44:53 - train: epoch 0167, iter [00350, 00390], lr: 0.000800, loss: 1.7379
2023-07-02 01:44:53 - train: epoch 0151, iter [00200, 00390], lr: 0.004000, loss: 1.7141
2023-07-02 01:44:55 - train: epoch 167, train_loss: 2.1634
2023-07-02 01:44:55 - train: epoch 0151, iter [00250, 00390], lr: 0.004000, loss: 1.5813
2023-07-02 01:44:56 - eval: epoch: 167, acc1: 41.940%, acc5: 71.560%, test_loss: 2.3098, per_image_load_time: 0.073ms, per_image_inference_time: 0.057ms
2023-07-02 01:44:57 - until epoch: 167, best_acc1: 41.980%
2023-07-02 01:44:57 - epoch 168 lr: 0.000800
2023-07-02 01:44:57 - train: epoch 0151, iter [00300, 00390], lr: 0.004000, loss: 1.5023
2023-07-02 01:44:59 - train: epoch 0151, iter [00350, 00390], lr: 0.004000, loss: 1.5298
2023-07-02 01:45:00 - train: epoch 0168, iter [00050, 00390], lr: 0.000800, loss: 2.4563
2023-07-02 01:45:01 - train: epoch 151, train_loss: 1.5539
2023-07-02 01:45:01 - train: epoch 0168, iter [00100, 00390], lr: 0.000800, loss: 3.0330
2023-07-02 01:45:03 - eval: epoch: 151, acc1: 39.950%, acc5: 66.820%, test_loss: 2.6740, per_image_load_time: 0.071ms, per_image_inference_time: 0.056ms
2023-07-02 01:45:03 - until epoch: 151, best_acc1: 41.480%
2023-07-02 01:45:03 - epoch 152 lr: 0.004000
2023-07-02 01:45:03 - train: epoch 0168, iter [00150, 00390], lr: 0.000800, loss: 3.2036
2023-07-02 01:45:05 - train: epoch 0168, iter [00200, 00390], lr: 0.000800, loss: 2.8232
2023-07-02 01:45:06 - train: epoch 0152, iter [00050, 00390], lr: 0.004000, loss: 1.4410
2023-07-02 01:45:07 - train: epoch 0168, iter [00250, 00390], lr: 0.000800, loss: 1.9516
2023-07-02 01:45:08 - train: epoch 0152, iter [00100, 00390], lr: 0.004000, loss: 1.5122
2023-07-02 01:45:09 - train: epoch 0168, iter [00300, 00390], lr: 0.000800, loss: 1.6457
2023-07-02 01:45:10 - train: epoch 0152, iter [00150, 00390], lr: 0.004000, loss: 1.4745
2023-07-02 01:45:11 - train: epoch 0168, iter [00350, 00390], lr: 0.000800, loss: 1.9822
2023-07-02 01:45:12 - train: epoch 0152, iter [00200, 00390], lr: 0.004000, loss: 1.4688
2023-07-02 01:45:13 - train: epoch 168, train_loss: 2.1717
2023-07-02 01:45:14 - train: epoch 0152, iter [00250, 00390], lr: 0.004000, loss: 1.5486
2023-07-02 01:45:14 - eval: epoch: 168, acc1: 42.150%, acc5: 71.640%, test_loss: 2.3113, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-07-02 01:45:15 - until epoch: 168, best_acc1: 42.150%
2023-07-02 01:45:15 - epoch 169 lr: 0.000800
2023-07-02 01:45:15 - train: epoch 0152, iter [00300, 00390], lr: 0.004000, loss: 1.5431
2023-07-02 01:45:17 - train: epoch 0152, iter [00350, 00390], lr: 0.004000, loss: 1.5247
2023-07-02 01:45:18 - train: epoch 0169, iter [00050, 00390], lr: 0.000800, loss: 1.5346
2023-07-02 01:45:19 - train: epoch 152, train_loss: 1.5449
2023-07-02 01:45:20 - train: epoch 0169, iter [00100, 00390], lr: 0.000800, loss: 2.2771
2023-07-02 01:45:21 - eval: epoch: 152, acc1: 39.990%, acc5: 66.210%, test_loss: 2.6735, per_image_load_time: 0.069ms, per_image_inference_time: 0.055ms
2023-07-02 01:45:21 - until epoch: 152, best_acc1: 41.480%
2023-07-02 01:45:21 - epoch 153 lr: 0.004000
2023-07-02 01:45:21 - train: epoch 0169, iter [00150, 00390], lr: 0.000800, loss: 2.3209
2023-07-02 01:45:23 - train: epoch 0169, iter [00200, 00390], lr: 0.000800, loss: 2.9099
2023-07-02 01:45:24 - train: epoch 0153, iter [00050, 00390], lr: 0.004000, loss: 1.4057
2023-07-02 01:45:25 - train: epoch 0169, iter [00250, 00390], lr: 0.000800, loss: 1.4551
2023-07-02 01:45:26 - train: epoch 0153, iter [00100, 00390], lr: 0.004000, loss: 1.4915
2023-07-02 01:45:27 - train: epoch 0169, iter [00300, 00390], lr: 0.000800, loss: 2.6732
2023-07-02 01:45:28 - train: epoch 0153, iter [00150, 00390], lr: 0.004000, loss: 1.6471
2023-07-02 01:45:29 - train: epoch 0169, iter [00350, 00390], lr: 0.000800, loss: 1.9814
2023-07-02 01:45:30 - train: epoch 0153, iter [00200, 00390], lr: 0.004000, loss: 1.5839
2023-07-02 01:45:31 - train: epoch 169, train_loss: 2.1479
2023-07-02 01:45:32 - train: epoch 0153, iter [00250, 00390], lr: 0.004000, loss: 1.4851
2023-07-02 01:45:32 - eval: epoch: 169, acc1: 41.820%, acc5: 71.470%, test_loss: 2.3109, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 01:45:32 - until epoch: 169, best_acc1: 42.150%
2023-07-02 01:45:32 - epoch 170 lr: 0.000800
2023-07-02 01:45:34 - train: epoch 0153, iter [00300, 00390], lr: 0.004000, loss: 1.5265
2023-07-02 01:45:35 - train: epoch 0170, iter [00050, 00390], lr: 0.000800, loss: 3.2815
2023-07-02 01:45:36 - train: epoch 0153, iter [00350, 00390], lr: 0.004000, loss: 1.5612
2023-07-02 01:45:37 - train: epoch 0170, iter [00100, 00390], lr: 0.000800, loss: 2.5532
2023-07-02 01:45:38 - train: epoch 153, train_loss: 1.5422
2023-07-02 01:45:39 - train: epoch 0170, iter [00150, 00390], lr: 0.000800, loss: 1.9276
2023-07-02 01:45:39 - eval: epoch: 153, acc1: 39.040%, acc5: 65.720%, test_loss: 2.7099, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-07-02 01:45:40 - until epoch: 153, best_acc1: 41.480%
2023-07-02 01:45:40 - epoch 154 lr: 0.004000
2023-07-02 01:45:41 - train: epoch 0170, iter [00200, 00390], lr: 0.000800, loss: 1.6504
2023-07-02 01:45:42 - train: epoch 0154, iter [00050, 00390], lr: 0.004000, loss: 1.5140
2023-07-02 01:45:43 - train: epoch 0170, iter [00250, 00390], lr: 0.000800, loss: 2.1475
2023-07-02 01:45:44 - train: epoch 0154, iter [00100, 00390], lr: 0.004000, loss: 1.5808
2023-07-02 01:45:45 - train: epoch 0170, iter [00300, 00390], lr: 0.000800, loss: 2.5798
2023-07-02 01:45:47 - train: epoch 0154, iter [00150, 00390], lr: 0.004000, loss: 1.4944
2023-07-02 01:45:47 - train: epoch 0170, iter [00350, 00390], lr: 0.000800, loss: 1.7637
2023-07-02 01:45:49 - train: epoch 170, train_loss: 2.1462
2023-07-02 01:45:49 - train: epoch 0154, iter [00200, 00390], lr: 0.004000, loss: 1.5327
2023-07-02 01:45:50 - eval: epoch: 170, acc1: 42.070%, acc5: 71.310%, test_loss: 2.3163, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:45:50 - until epoch: 170, best_acc1: 42.150%
2023-07-02 01:45:50 - epoch 171 lr: 0.000800
2023-07-02 01:45:50 - train: epoch 0154, iter [00250, 00390], lr: 0.004000, loss: 1.6759
2023-07-02 01:45:52 - train: epoch 0154, iter [00300, 00390], lr: 0.004000, loss: 1.7139
2023-07-02 01:45:53 - train: epoch 0171, iter [00050, 00390], lr: 0.000800, loss: 1.8081
2023-07-02 01:45:54 - train: epoch 0154, iter [00350, 00390], lr: 0.004000, loss: 1.5850
2023-07-02 01:45:55 - train: epoch 0171, iter [00100, 00390], lr: 0.000800, loss: 2.2332
2023-07-02 01:45:56 - train: epoch 154, train_loss: 1.5350
2023-07-02 01:45:57 - train: epoch 0171, iter [00150, 00390], lr: 0.000800, loss: 1.7494
2023-07-02 01:45:57 - eval: epoch: 154, acc1: 39.980%, acc5: 66.650%, test_loss: 2.6863, per_image_load_time: 0.069ms, per_image_inference_time: 0.056ms
2023-07-02 01:45:58 - until epoch: 154, best_acc1: 41.480%
2023-07-02 01:45:58 - epoch 155 lr: 0.004000
2023-07-02 01:45:59 - train: epoch 0171, iter [00200, 00390], lr: 0.000800, loss: 1.8547
2023-07-02 01:46:01 - train: epoch 0155, iter [00050, 00390], lr: 0.004000, loss: 1.4120
2023-07-02 01:46:01 - train: epoch 0171, iter [00250, 00390], lr: 0.000800, loss: 1.4478
2023-07-02 01:46:03 - train: epoch 0155, iter [00100, 00390], lr: 0.004000, loss: 1.4718
2023-07-02 01:46:03 - train: epoch 0171, iter [00300, 00390], lr: 0.000800, loss: 3.3980
2023-07-02 01:46:05 - train: epoch 0155, iter [00150, 00390], lr: 0.004000, loss: 1.4197
2023-07-02 01:46:05 - train: epoch 0171, iter [00350, 00390], lr: 0.000800, loss: 1.9844
2023-07-02 01:46:07 - train: epoch 171, train_loss: 2.1137
2023-07-02 01:46:07 - train: epoch 0155, iter [00200, 00390], lr: 0.004000, loss: 1.5482
2023-07-02 01:46:08 - eval: epoch: 171, acc1: 41.850%, acc5: 71.350%, test_loss: 2.3163, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-07-02 01:46:08 - until epoch: 171, best_acc1: 42.150%
2023-07-02 01:46:08 - epoch 172 lr: 0.000800
2023-07-02 01:46:09 - train: epoch 0155, iter [00250, 00390], lr: 0.004000, loss: 1.5199
2023-07-02 01:46:10 - train: epoch 0155, iter [00300, 00390], lr: 0.004000, loss: 1.6772
2023-07-02 01:46:11 - train: epoch 0172, iter [00050, 00390], lr: 0.000800, loss: 3.5506
2023-07-02 01:46:13 - train: epoch 0155, iter [00350, 00390], lr: 0.004000, loss: 1.6262
2023-07-02 01:46:13 - train: epoch 0172, iter [00100, 00390], lr: 0.000800, loss: 1.6198
2023-07-02 01:46:14 - train: epoch 155, train_loss: 1.5373
2023-07-02 01:46:15 - train: epoch 0172, iter [00150, 00390], lr: 0.000800, loss: 3.2254
2023-07-02 01:46:16 - eval: epoch: 155, acc1: 39.880%, acc5: 66.670%, test_loss: 2.6949, per_image_load_time: 0.069ms, per_image_inference_time: 0.061ms
2023-07-02 01:46:16 - until epoch: 155, best_acc1: 41.480%
2023-07-02 01:46:16 - epoch 156 lr: 0.004000
2023-07-02 01:46:17 - train: epoch 0172, iter [00200, 00390], lr: 0.000800, loss: 1.9301
2023-07-02 01:46:19 - train: epoch 0172, iter [00250, 00390], lr: 0.000800, loss: 1.8390
2023-07-02 01:46:19 - train: epoch 0156, iter [00050, 00390], lr: 0.004000, loss: 1.6017
2023-07-02 01:46:21 - train: epoch 0172, iter [00300, 00390], lr: 0.000800, loss: 2.3085
2023-07-02 01:46:21 - train: epoch 0156, iter [00100, 00390], lr: 0.004000, loss: 1.5699
2023-07-02 01:46:23 - train: epoch 0172, iter [00350, 00390], lr: 0.000800, loss: 1.6152
2023-07-02 01:46:23 - train: epoch 0156, iter [00150, 00390], lr: 0.004000, loss: 1.5449
2023-07-02 01:46:24 - train: epoch 172, train_loss: 2.0939
2023-07-02 01:46:25 - train: epoch 0156, iter [00200, 00390], lr: 0.004000, loss: 1.6296
2023-07-02 01:46:26 - eval: epoch: 172, acc1: 42.070%, acc5: 71.430%, test_loss: 2.3106, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 01:46:26 - until epoch: 172, best_acc1: 42.150%
2023-07-02 01:46:26 - epoch 173 lr: 0.000800
2023-07-02 01:46:27 - train: epoch 0156, iter [00250, 00390], lr: 0.004000, loss: 1.5667
2023-07-02 01:46:29 - train: epoch 0173, iter [00050, 00390], lr: 0.000800, loss: 1.9749
2023-07-02 01:46:29 - train: epoch 0156, iter [00300, 00390], lr: 0.004000, loss: 1.4950
2023-07-02 01:46:31 - train: epoch 0173, iter [00100, 00390], lr: 0.000800, loss: 1.8307
2023-07-02 01:46:31 - train: epoch 0156, iter [00350, 00390], lr: 0.004000, loss: 1.5392
2023-07-02 01:46:33 - train: epoch 156, train_loss: 1.5298
2023-07-02 01:46:33 - train: epoch 0173, iter [00150, 00390], lr: 0.000800, loss: 2.6129
2023-07-02 01:46:34 - eval: epoch: 156, acc1: 40.000%, acc5: 66.610%, test_loss: 2.7093, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:46:34 - train: epoch 0173, iter [00200, 00390], lr: 0.000800, loss: 1.8997
2023-07-02 01:46:34 - until epoch: 156, best_acc1: 41.480%
2023-07-02 01:46:34 - epoch 157 lr: 0.004000
2023-07-02 01:46:36 - train: epoch 0173, iter [00250, 00390], lr: 0.000800, loss: 3.4511
2023-07-02 01:46:37 - train: epoch 0157, iter [00050, 00390], lr: 0.004000, loss: 1.4044
2023-07-02 01:46:38 - train: epoch 0173, iter [00300, 00390], lr: 0.000800, loss: 1.3712
2023-07-02 01:46:39 - train: epoch 0157, iter [00100, 00390], lr: 0.004000, loss: 1.4022
2023-07-02 01:46:40 - train: epoch 0173, iter [00350, 00390], lr: 0.000800, loss: 2.9582
2023-07-02 01:46:41 - train: epoch 0157, iter [00150, 00390], lr: 0.004000, loss: 1.4182
2023-07-02 01:46:42 - train: epoch 173, train_loss: 2.1082
2023-07-02 01:46:43 - train: epoch 0157, iter [00200, 00390], lr: 0.004000, loss: 1.5948
2023-07-02 01:46:43 - eval: epoch: 173, acc1: 42.500%, acc5: 71.590%, test_loss: 2.3102, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:46:44 - until epoch: 173, best_acc1: 42.500%
2023-07-02 01:46:44 - epoch 174 lr: 0.000800
2023-07-02 01:46:45 - train: epoch 0157, iter [00250, 00390], lr: 0.004000, loss: 1.4290
2023-07-02 01:46:47 - train: epoch 0157, iter [00300, 00390], lr: 0.004000, loss: 1.5155
2023-07-02 01:46:47 - train: epoch 0174, iter [00050, 00390], lr: 0.000800, loss: 2.3874
2023-07-02 01:46:49 - train: epoch 0157, iter [00350, 00390], lr: 0.004000, loss: 1.5611
2023-07-02 01:46:49 - train: epoch 0174, iter [00100, 00390], lr: 0.000800, loss: 3.0861
2023-07-02 01:46:51 - train: epoch 157, train_loss: 1.5318
2023-07-02 01:46:51 - train: epoch 0174, iter [00150, 00390], lr: 0.000800, loss: 1.8287
2023-07-02 01:46:52 - eval: epoch: 157, acc1: 39.580%, acc5: 66.690%, test_loss: 2.7027, per_image_load_time: 0.066ms, per_image_inference_time: 0.057ms
2023-07-02 01:46:52 - until epoch: 157, best_acc1: 41.480%
2023-07-02 01:46:52 - epoch 158 lr: 0.004000
2023-07-02 01:46:52 - train: epoch 0174, iter [00200, 00390], lr: 0.000800, loss: 1.7070
2023-07-02 01:46:54 - train: epoch 0174, iter [00250, 00390], lr: 0.000800, loss: 1.8313
2023-07-02 01:46:55 - train: epoch 0158, iter [00050, 00390], lr: 0.004000, loss: 1.5510
2023-07-02 01:46:56 - train: epoch 0174, iter [00300, 00390], lr: 0.000800, loss: 1.5824
2023-07-02 01:46:57 - train: epoch 0158, iter [00100, 00390], lr: 0.004000, loss: 1.5627
2023-07-02 01:46:58 - train: epoch 0174, iter [00350, 00390], lr: 0.000800, loss: 1.3667
2023-07-02 01:47:00 - train: epoch 0158, iter [00150, 00390], lr: 0.004000, loss: 1.5193
2023-07-02 01:47:00 - train: epoch 174, train_loss: 2.1260
2023-07-02 01:47:01 - train: epoch 0158, iter [00200, 00390], lr: 0.004000, loss: 1.5729
2023-07-02 01:47:01 - eval: epoch: 174, acc1: 41.700%, acc5: 71.390%, test_loss: 2.3250, per_image_load_time: 0.067ms, per_image_inference_time: 0.054ms
2023-07-02 01:47:02 - until epoch: 174, best_acc1: 42.500%
2023-07-02 01:47:02 - epoch 175 lr: 0.000800
2023-07-02 01:47:03 - train: epoch 0158, iter [00250, 00390], lr: 0.004000, loss: 1.5973
2023-07-02 01:47:05 - train: epoch 0175, iter [00050, 00390], lr: 0.000800, loss: 2.5421
2023-07-02 01:47:05 - train: epoch 0158, iter [00300, 00390], lr: 0.004000, loss: 1.6310
2023-07-02 01:47:07 - train: epoch 0175, iter [00100, 00390], lr: 0.000800, loss: 3.0409
2023-07-02 01:47:07 - train: epoch 0158, iter [00350, 00390], lr: 0.004000, loss: 1.4153
2023-07-02 01:47:09 - train: epoch 0175, iter [00150, 00390], lr: 0.000800, loss: 2.5290
2023-07-02 01:47:09 - train: epoch 158, train_loss: 1.5310
2023-07-02 01:47:10 - train: epoch 0175, iter [00200, 00390], lr: 0.000800, loss: 1.7428
2023-07-02 01:47:10 - eval: epoch: 158, acc1: 40.020%, acc5: 66.510%, test_loss: 2.7009, per_image_load_time: 0.067ms, per_image_inference_time: 0.058ms
2023-07-02 01:47:11 - until epoch: 158, best_acc1: 41.480%
2023-07-02 01:47:11 - epoch 159 lr: 0.004000
2023-07-02 01:47:12 - train: epoch 0175, iter [00250, 00390], lr: 0.000800, loss: 1.9004
2023-07-02 01:47:14 - train: epoch 0159, iter [00050, 00390], lr: 0.004000, loss: 1.5204
2023-07-02 01:47:14 - train: epoch 0175, iter [00300, 00390], lr: 0.000800, loss: 2.0655
2023-07-02 01:47:16 - train: epoch 0159, iter [00100, 00390], lr: 0.004000, loss: 1.3790
2023-07-02 01:47:16 - train: epoch 0175, iter [00350, 00390], lr: 0.000800, loss: 1.6281
2023-07-02 01:47:18 - train: epoch 0159, iter [00150, 00390], lr: 0.004000, loss: 1.5030
2023-07-02 01:47:18 - train: epoch 175, train_loss: 2.1324
2023-07-02 01:47:19 - eval: epoch: 175, acc1: 41.730%, acc5: 71.500%, test_loss: 2.3194, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:47:19 - until epoch: 175, best_acc1: 42.500%
2023-07-02 01:47:19 - epoch 176 lr: 0.000800
2023-07-02 01:47:20 - train: epoch 0159, iter [00200, 00390], lr: 0.004000, loss: 1.4781
2023-07-02 01:47:21 - train: epoch 0159, iter [00250, 00390], lr: 0.004000, loss: 1.4896
2023-07-02 01:47:22 - train: epoch 0176, iter [00050, 00390], lr: 0.000800, loss: 2.5312
2023-07-02 01:47:24 - train: epoch 0159, iter [00300, 00390], lr: 0.004000, loss: 1.6118
2023-07-02 01:47:24 - train: epoch 0176, iter [00100, 00390], lr: 0.000800, loss: 2.4149
2023-07-02 01:47:26 - train: epoch 0159, iter [00350, 00390], lr: 0.004000, loss: 1.6802
2023-07-02 01:47:27 - train: epoch 0176, iter [00150, 00390], lr: 0.000800, loss: 2.7976
2023-07-02 01:47:27 - train: epoch 159, train_loss: 1.5212
2023-07-02 01:47:28 - train: epoch 0176, iter [00200, 00390], lr: 0.000800, loss: 1.7571
2023-07-02 01:47:29 - eval: epoch: 159, acc1: 39.830%, acc5: 65.920%, test_loss: 2.7192, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:47:29 - until epoch: 159, best_acc1: 41.480%
2023-07-02 01:47:29 - epoch 160 lr: 0.004000
2023-07-02 01:47:30 - train: epoch 0176, iter [00250, 00390], lr: 0.000800, loss: 3.0024
2023-07-02 01:47:32 - train: epoch 0176, iter [00300, 00390], lr: 0.000800, loss: 2.8894
2023-07-02 01:47:32 - train: epoch 0160, iter [00050, 00390], lr: 0.004000, loss: 1.4474
2023-07-02 01:47:34 - train: epoch 0176, iter [00350, 00390], lr: 0.000800, loss: 2.0290
2023-07-02 01:47:34 - train: epoch 0160, iter [00100, 00390], lr: 0.004000, loss: 1.4735
2023-07-02 01:47:36 - train: epoch 176, train_loss: 2.1380
2023-07-02 01:47:36 - train: epoch 0160, iter [00150, 00390], lr: 0.004000, loss: 1.6733
2023-07-02 01:47:37 - eval: epoch: 176, acc1: 42.130%, acc5: 71.400%, test_loss: 2.3212, per_image_load_time: 0.070ms, per_image_inference_time: 0.055ms
2023-07-02 01:47:37 - until epoch: 176, best_acc1: 42.500%
2023-07-02 01:47:37 - epoch 177 lr: 0.000800
2023-07-02 01:47:38 - train: epoch 0160, iter [00200, 00390], lr: 0.004000, loss: 1.4827
2023-07-02 01:47:40 - train: epoch 0160, iter [00250, 00390], lr: 0.004000, loss: 1.6732
2023-07-02 01:47:40 - train: epoch 0177, iter [00050, 00390], lr: 0.000800, loss: 1.8280
2023-07-02 01:47:42 - train: epoch 0160, iter [00300, 00390], lr: 0.004000, loss: 1.4895
2023-07-02 01:47:42 - train: epoch 0177, iter [00100, 00390], lr: 0.000800, loss: 1.8620
2023-07-02 01:47:44 - train: epoch 0160, iter [00350, 00390], lr: 0.004000, loss: 1.5900
2023-07-02 01:47:44 - train: epoch 0177, iter [00150, 00390], lr: 0.000800, loss: 1.5888
2023-07-02 01:47:46 - train: epoch 160, train_loss: 1.5115
2023-07-02 01:47:46 - train: epoch 0177, iter [00200, 00390], lr: 0.000800, loss: 2.1750
2023-07-02 01:47:48 - eval: epoch: 160, acc1: 39.220%, acc5: 66.290%, test_loss: 2.7109, per_image_load_time: 0.070ms, per_image_inference_time: 0.078ms
2023-07-02 01:47:48 - train: epoch 0177, iter [00250, 00390], lr: 0.000800, loss: 1.5799
2023-07-02 01:47:49 - until epoch: 160, best_acc1: 41.480%
2023-07-02 01:47:49 - epoch 161 lr: 0.000800
2023-07-02 01:47:49 - train: epoch 0177, iter [00300, 00390], lr: 0.000800, loss: 1.6329
2023-07-02 01:47:52 - train: epoch 0177, iter [00350, 00390], lr: 0.000800, loss: 1.8806
2023-07-02 01:47:52 - train: epoch 0161, iter [00050, 00390], lr: 0.000800, loss: 1.4157
2023-07-02 01:47:53 - train: epoch 177, train_loss: 2.0839
2023-07-02 01:47:53 - train: epoch 0161, iter [00100, 00390], lr: 0.000800, loss: 1.4868
2023-07-02 01:47:55 - eval: epoch: 177, acc1: 42.000%, acc5: 71.660%, test_loss: 2.3151, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-07-02 01:47:55 - until epoch: 177, best_acc1: 42.500%
2023-07-02 01:47:55 - epoch 178 lr: 0.000800
2023-07-02 01:47:55 - train: epoch 0161, iter [00150, 00390], lr: 0.000800, loss: 1.3227
2023-07-02 01:47:57 - train: epoch 0161, iter [00200, 00390], lr: 0.000800, loss: 1.3563
2023-07-02 01:47:58 - train: epoch 0178, iter [00050, 00390], lr: 0.000800, loss: 1.6064
2023-07-02 01:47:59 - train: epoch 0161, iter [00250, 00390], lr: 0.000800, loss: 1.3369
2023-07-02 01:48:00 - train: epoch 0178, iter [00100, 00390], lr: 0.000800, loss: 1.5307
2023-07-02 01:48:01 - train: epoch 0161, iter [00300, 00390], lr: 0.000800, loss: 1.4667
2023-07-02 01:48:02 - train: epoch 0178, iter [00150, 00390], lr: 0.000800, loss: 1.7856
2023-07-02 01:48:04 - train: epoch 0161, iter [00350, 00390], lr: 0.000800, loss: 1.3871
2023-07-02 01:48:04 - train: epoch 0178, iter [00200, 00390], lr: 0.000800, loss: 1.6842
2023-07-02 01:48:05 - train: epoch 161, train_loss: 1.3933
2023-07-02 01:48:06 - train: epoch 0178, iter [00250, 00390], lr: 0.000800, loss: 1.8078
2023-07-02 01:48:07 - eval: epoch: 161, acc1: 40.480%, acc5: 67.050%, test_loss: 2.6573, per_image_load_time: 0.069ms, per_image_inference_time: 0.057ms
2023-07-02 01:48:07 - until epoch: 161, best_acc1: 41.480%
2023-07-02 01:48:07 - epoch 162 lr: 0.000800
2023-07-02 01:48:08 - train: epoch 0178, iter [00300, 00390], lr: 0.000800, loss: 2.4886
2023-07-02 01:48:10 - train: epoch 0178, iter [00350, 00390], lr: 0.000800, loss: 1.5618
2023-07-02 01:48:10 - train: epoch 0162, iter [00050, 00390], lr: 0.000800, loss: 1.3361
2023-07-02 01:48:11 - train: epoch 178, train_loss: 2.0759
2023-07-02 01:48:12 - train: epoch 0162, iter [00100, 00390], lr: 0.000800, loss: 1.3584
2023-07-02 01:48:13 - eval: epoch: 178, acc1: 41.840%, acc5: 71.530%, test_loss: 2.3233, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-07-02 01:48:13 - until epoch: 178, best_acc1: 42.500%
2023-07-02 01:48:13 - epoch 179 lr: 0.000800
2023-07-02 01:48:14 - train: epoch 0162, iter [00150, 00390], lr: 0.000800, loss: 1.3910
2023-07-02 01:48:16 - train: epoch 0179, iter [00050, 00390], lr: 0.000800, loss: 1.9852
2023-07-02 01:48:16 - train: epoch 0162, iter [00200, 00390], lr: 0.000800, loss: 1.3353
2023-07-02 01:48:18 - train: epoch 0179, iter [00100, 00390], lr: 0.000800, loss: 1.6650
2023-07-02 01:48:18 - train: epoch 0162, iter [00250, 00390], lr: 0.000800, loss: 1.2596
2023-07-02 01:48:20 - train: epoch 0179, iter [00150, 00390], lr: 0.000800, loss: 2.7620
2023-07-02 01:48:20 - train: epoch 0162, iter [00300, 00390], lr: 0.000800, loss: 1.3434
2023-07-02 01:48:22 - train: epoch 0179, iter [00200, 00390], lr: 0.000800, loss: 2.3024
2023-07-02 01:48:22 - train: epoch 0162, iter [00350, 00390], lr: 0.000800, loss: 1.3031
2023-07-02 01:48:24 - train: epoch 162, train_loss: 1.3526
2023-07-02 01:48:24 - train: epoch 0179, iter [00250, 00390], lr: 0.000800, loss: 2.6903
2023-07-02 01:48:25 - eval: epoch: 162, acc1: 40.600%, acc5: 66.940%, test_loss: 2.6661, per_image_load_time: 0.069ms, per_image_inference_time: 0.082ms
2023-07-02 01:48:26 - train: epoch 0179, iter [00300, 00390], lr: 0.000800, loss: 1.4993
2023-07-02 01:48:26 - until epoch: 162, best_acc1: 41.480%
2023-07-02 01:48:26 - epoch 163 lr: 0.000800
2023-07-02 01:48:27 - train: epoch 0179, iter [00350, 00390], lr: 0.000800, loss: 2.1370
2023-07-02 01:48:29 - train: epoch 0163, iter [00050, 00390], lr: 0.000800, loss: 1.3976
2023-07-02 01:48:29 - train: epoch 179, train_loss: 2.1243
2023-07-02 01:48:30 - eval: epoch: 179, acc1: 41.800%, acc5: 71.490%, test_loss: 2.3149, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:48:30 - train: epoch 0163, iter [00100, 00390], lr: 0.000800, loss: 1.3430
2023-07-02 01:48:31 - until epoch: 179, best_acc1: 42.500%
2023-07-02 01:48:31 - epoch 180 lr: 0.000800
2023-07-02 01:48:32 - train: epoch 0163, iter [00150, 00390], lr: 0.000800, loss: 1.4142
2023-07-02 01:48:33 - train: epoch 0180, iter [00050, 00390], lr: 0.000800, loss: 2.1277
2023-07-02 01:48:34 - train: epoch 0163, iter [00200, 00390], lr: 0.000800, loss: 1.1991
2023-07-02 01:48:35 - train: epoch 0180, iter [00100, 00390], lr: 0.000800, loss: 1.6244
2023-07-02 01:48:37 - train: epoch 0163, iter [00250, 00390], lr: 0.000800, loss: 1.3664
2023-07-02 01:48:37 - train: epoch 0180, iter [00150, 00390], lr: 0.000800, loss: 1.6071
2023-07-02 01:48:39 - train: epoch 0163, iter [00300, 00390], lr: 0.000800, loss: 1.3189
2023-07-02 01:48:39 - train: epoch 0180, iter [00200, 00390], lr: 0.000800, loss: 1.6824
2023-07-02 01:48:41 - train: epoch 0163, iter [00350, 00390], lr: 0.000800, loss: 1.3431
2023-07-02 01:48:41 - train: epoch 0180, iter [00250, 00390], lr: 0.000800, loss: 1.6840
2023-07-02 01:48:43 - train: epoch 163, train_loss: 1.3414
2023-07-02 01:48:43 - train: epoch 0180, iter [00300, 00390], lr: 0.000800, loss: 1.8648
2023-07-02 01:48:44 - eval: epoch: 163, acc1: 40.560%, acc5: 66.740%, test_loss: 2.6689, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:48:44 - until epoch: 163, best_acc1: 41.480%
2023-07-02 01:48:44 - epoch 164 lr: 0.000800
2023-07-02 01:48:45 - train: epoch 0180, iter [00350, 00390], lr: 0.000800, loss: 1.5751
2023-07-02 01:48:47 - train: epoch 180, train_loss: 2.1109
2023-07-02 01:48:47 - train: epoch 0164, iter [00050, 00390], lr: 0.000800, loss: 1.2623
2023-07-02 01:48:48 - eval: epoch: 180, acc1: 42.010%, acc5: 71.450%, test_loss: 2.3204, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:48:49 - until epoch: 180, best_acc1: 42.500%
2023-07-02 01:48:49 - epoch 181 lr: 0.000800
2023-07-02 01:48:49 - train: epoch 0164, iter [00100, 00390], lr: 0.000800, loss: 1.3610
2023-07-02 01:48:51 - train: epoch 0164, iter [00150, 00390], lr: 0.000800, loss: 1.3287
2023-07-02 01:48:52 - train: epoch 0181, iter [00050, 00390], lr: 0.000800, loss: 2.4714
2023-07-02 01:48:53 - train: epoch 0164, iter [00200, 00390], lr: 0.000800, loss: 1.3281
2023-07-02 01:48:54 - train: epoch 0181, iter [00100, 00390], lr: 0.000800, loss: 2.2151
2023-07-02 01:48:55 - train: epoch 0164, iter [00250, 00390], lr: 0.000800, loss: 1.2660
2023-07-02 01:48:56 - train: epoch 0181, iter [00150, 00390], lr: 0.000800, loss: 2.2684
2023-07-02 01:48:57 - train: epoch 0164, iter [00300, 00390], lr: 0.000800, loss: 1.3712
2023-07-02 01:48:58 - train: epoch 0181, iter [00200, 00390], lr: 0.000800, loss: 1.5999
2023-07-02 01:48:59 - train: epoch 0164, iter [00350, 00390], lr: 0.000800, loss: 1.2385
2023-07-02 01:49:00 - train: epoch 0181, iter [00250, 00390], lr: 0.000800, loss: 1.6253
2023-07-02 01:49:01 - train: epoch 164, train_loss: 1.3287
2023-07-02 01:49:01 - train: epoch 0181, iter [00300, 00390], lr: 0.000800, loss: 2.1601
2023-07-02 01:49:02 - eval: epoch: 164, acc1: 40.520%, acc5: 66.440%, test_loss: 2.6795, per_image_load_time: 0.066ms, per_image_inference_time: 0.057ms
2023-07-02 01:49:03 - until epoch: 164, best_acc1: 41.480%
2023-07-02 01:49:03 - epoch 165 lr: 0.000800
2023-07-02 01:49:03 - train: epoch 0181, iter [00350, 00390], lr: 0.000800, loss: 1.6175
2023-07-02 01:49:05 - train: epoch 181, train_loss: 2.0879
2023-07-02 01:49:05 - train: epoch 0165, iter [00050, 00390], lr: 0.000800, loss: 1.3319
2023-07-02 01:49:06 - eval: epoch: 181, acc1: 42.140%, acc5: 71.450%, test_loss: 2.3136, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 01:49:06 - until epoch: 181, best_acc1: 42.500%
2023-07-02 01:49:06 - epoch 182 lr: 0.000800
2023-07-02 01:49:07 - train: epoch 0165, iter [00100, 00390], lr: 0.000800, loss: 1.2329
2023-07-02 01:49:09 - train: epoch 0182, iter [00050, 00390], lr: 0.000800, loss: 1.8453
2023-07-02 01:49:09 - train: epoch 0165, iter [00150, 00390], lr: 0.000800, loss: 1.3215
2023-07-02 01:49:11 - train: epoch 0182, iter [00100, 00390], lr: 0.000800, loss: 2.0493
2023-07-02 01:49:11 - train: epoch 0165, iter [00200, 00390], lr: 0.000800, loss: 1.3229
2023-07-02 01:49:13 - train: epoch 0182, iter [00150, 00390], lr: 0.000800, loss: 2.0536
2023-07-02 01:49:13 - train: epoch 0165, iter [00250, 00390], lr: 0.000800, loss: 1.3457
2023-07-02 01:49:15 - train: epoch 0182, iter [00200, 00390], lr: 0.000800, loss: 1.8983
2023-07-02 01:49:16 - train: epoch 0165, iter [00300, 00390], lr: 0.000800, loss: 1.3844
2023-07-02 01:49:17 - train: epoch 0182, iter [00250, 00390], lr: 0.000800, loss: 1.8647
2023-07-02 01:49:18 - train: epoch 0165, iter [00350, 00390], lr: 0.000800, loss: 1.3190
2023-07-02 01:49:19 - train: epoch 0182, iter [00300, 00390], lr: 0.000800, loss: 1.8886
2023-07-02 01:49:19 - train: epoch 165, train_loss: 1.3174
2023-07-02 01:49:21 - eval: epoch: 165, acc1: 40.740%, acc5: 66.740%, test_loss: 2.6762, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:49:21 - train: epoch 0182, iter [00350, 00390], lr: 0.000800, loss: 2.4315
2023-07-02 01:49:21 - until epoch: 165, best_acc1: 41.480%
2023-07-02 01:49:21 - epoch 166 lr: 0.000800
2023-07-02 01:49:22 - train: epoch 182, train_loss: 2.1624
2023-07-02 01:49:24 - train: epoch 0166, iter [00050, 00390], lr: 0.000800, loss: 1.4469
2023-07-02 01:49:24 - eval: epoch: 182, acc1: 42.240%, acc5: 71.490%, test_loss: 2.3174, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-07-02 01:49:24 - until epoch: 182, best_acc1: 42.500%
2023-07-02 01:49:24 - epoch 183 lr: 0.000800
2023-07-02 01:49:25 - train: epoch 0166, iter [00100, 00390], lr: 0.000800, loss: 1.3187
2023-07-02 01:49:27 - train: epoch 0183, iter [00050, 00390], lr: 0.000800, loss: 1.5000
2023-07-02 01:49:28 - train: epoch 0166, iter [00150, 00390], lr: 0.000800, loss: 1.3143
2023-07-02 01:49:29 - train: epoch 0183, iter [00100, 00390], lr: 0.000800, loss: 1.9884
2023-07-02 01:49:30 - train: epoch 0166, iter [00200, 00390], lr: 0.000800, loss: 1.2799
2023-07-02 01:49:31 - train: epoch 0183, iter [00150, 00390], lr: 0.000800, loss: 2.0395
2023-07-02 01:49:32 - train: epoch 0166, iter [00250, 00390], lr: 0.000800, loss: 1.3012
2023-07-02 01:49:33 - train: epoch 0183, iter [00200, 00390], lr: 0.000800, loss: 2.0455
2023-07-02 01:49:34 - train: epoch 0166, iter [00300, 00390], lr: 0.000800, loss: 1.2749
2023-07-02 01:49:35 - train: epoch 0183, iter [00250, 00390], lr: 0.000800, loss: 2.8522
2023-07-02 01:49:36 - train: epoch 0166, iter [00350, 00390], lr: 0.000800, loss: 1.2446
2023-07-02 01:49:37 - train: epoch 0183, iter [00300, 00390], lr: 0.000800, loss: 3.5711
2023-07-02 01:49:38 - train: epoch 166, train_loss: 1.3078
2023-07-02 01:49:39 - train: epoch 0183, iter [00350, 00390], lr: 0.000800, loss: 3.3948
2023-07-02 01:49:39 - eval: epoch: 166, acc1: 40.560%, acc5: 66.660%, test_loss: 2.6921, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:49:40 - until epoch: 166, best_acc1: 41.480%
2023-07-02 01:49:40 - epoch 167 lr: 0.000800
2023-07-02 01:49:40 - train: epoch 183, train_loss: 2.1178
2023-07-02 01:49:42 - eval: epoch: 183, acc1: 42.100%, acc5: 71.350%, test_loss: 2.3270, per_image_load_time: 0.077ms, per_image_inference_time: 0.054ms
2023-07-02 01:49:42 - until epoch: 183, best_acc1: 42.500%
2023-07-02 01:49:42 - epoch 184 lr: 0.000800
2023-07-02 01:49:42 - train: epoch 0167, iter [00050, 00390], lr: 0.000800, loss: 1.2189
2023-07-02 01:49:44 - train: epoch 0167, iter [00100, 00390], lr: 0.000800, loss: 1.2486
2023-07-02 01:49:45 - train: epoch 0184, iter [00050, 00390], lr: 0.000800, loss: 1.5957
2023-07-02 01:49:46 - train: epoch 0167, iter [00150, 00390], lr: 0.000800, loss: 1.2151
2023-07-02 01:49:47 - train: epoch 0184, iter [00100, 00390], lr: 0.000800, loss: 1.9239
2023-07-02 01:49:49 - train: epoch 0167, iter [00200, 00390], lr: 0.000800, loss: 1.3729
2023-07-02 01:49:49 - train: epoch 0184, iter [00150, 00390], lr: 0.000800, loss: 1.5218
2023-07-02 01:49:51 - train: epoch 0184, iter [00200, 00390], lr: 0.000800, loss: 1.9045
2023-07-02 01:49:51 - train: epoch 0167, iter [00250, 00390], lr: 0.000800, loss: 1.2562
2023-07-02 01:49:53 - train: epoch 0184, iter [00250, 00390], lr: 0.000800, loss: 1.6272
2023-07-02 01:49:53 - train: epoch 0167, iter [00300, 00390], lr: 0.000800, loss: 1.3204
2023-07-02 01:49:55 - train: epoch 0184, iter [00300, 00390], lr: 0.000800, loss: 1.6369
2023-07-02 01:49:55 - train: epoch 0167, iter [00350, 00390], lr: 0.000800, loss: 1.4614
2023-07-02 01:49:57 - train: epoch 0184, iter [00350, 00390], lr: 0.000800, loss: 1.7941
2023-07-02 01:49:57 - train: epoch 167, train_loss: 1.3120
2023-07-02 01:49:58 - train: epoch 184, train_loss: 2.0790
2023-07-02 01:49:59 - eval: epoch: 167, acc1: 40.630%, acc5: 66.560%, test_loss: 2.6965, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:49:59 - until epoch: 167, best_acc1: 41.480%
2023-07-02 01:49:59 - epoch 168 lr: 0.000800
2023-07-02 01:50:00 - eval: epoch: 184, acc1: 41.980%, acc5: 71.480%, test_loss: 2.3224, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:50:00 - until epoch: 184, best_acc1: 42.500%
2023-07-02 01:50:00 - epoch 185 lr: 0.000800
2023-07-02 01:50:02 - train: epoch 0168, iter [00050, 00390], lr: 0.000800, loss: 1.2645
2023-07-02 01:50:03 - train: epoch 0185, iter [00050, 00390], lr: 0.000800, loss: 2.0193
2023-07-02 01:50:04 - train: epoch 0168, iter [00100, 00390], lr: 0.000800, loss: 1.2605
2023-07-02 01:50:05 - train: epoch 0185, iter [00100, 00390], lr: 0.000800, loss: 2.1816
2023-07-02 01:50:06 - train: epoch 0168, iter [00150, 00390], lr: 0.000800, loss: 1.2723
2023-07-02 01:50:07 - train: epoch 0185, iter [00150, 00390], lr: 0.000800, loss: 1.6973
2023-07-02 01:50:08 - train: epoch 0168, iter [00200, 00390], lr: 0.000800, loss: 1.3049
2023-07-02 01:50:09 - train: epoch 0185, iter [00200, 00390], lr: 0.000800, loss: 1.4319
2023-07-02 01:50:10 - train: epoch 0168, iter [00250, 00390], lr: 0.000800, loss: 1.2988
2023-07-02 01:50:11 - train: epoch 0185, iter [00250, 00390], lr: 0.000800, loss: 1.7257
2023-07-02 01:50:12 - train: epoch 0168, iter [00300, 00390], lr: 0.000800, loss: 1.3834
2023-07-02 01:50:13 - train: epoch 0185, iter [00300, 00390], lr: 0.000800, loss: 1.8787
2023-07-02 01:50:14 - train: epoch 0168, iter [00350, 00390], lr: 0.000800, loss: 1.2604
2023-07-02 01:50:15 - train: epoch 0185, iter [00350, 00390], lr: 0.000800, loss: 1.6047
2023-07-02 01:50:16 - train: epoch 168, train_loss: 1.3061
2023-07-02 01:50:17 - train: epoch 185, train_loss: 2.1269
2023-07-02 01:50:17 - eval: epoch: 168, acc1: 41.100%, acc5: 66.610%, test_loss: 2.6935, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:50:18 - until epoch: 168, best_acc1: 41.480%
2023-07-02 01:50:18 - epoch 169 lr: 0.000800
2023-07-02 01:50:19 - eval: epoch: 185, acc1: 42.160%, acc5: 71.650%, test_loss: 2.3243, per_image_load_time: 0.066ms, per_image_inference_time: 0.053ms
2023-07-02 01:50:20 - until epoch: 185, best_acc1: 42.500%
2023-07-02 01:50:20 - epoch 186 lr: 0.000800
2023-07-02 01:50:20 - train: epoch 0169, iter [00050, 00390], lr: 0.000800, loss: 1.3765
2023-07-02 01:50:22 - train: epoch 0169, iter [00100, 00390], lr: 0.000800, loss: 1.2042
2023-07-02 01:50:23 - train: epoch 0186, iter [00050, 00390], lr: 0.000800, loss: 1.4098
2023-07-02 01:50:24 - train: epoch 0169, iter [00150, 00390], lr: 0.000800, loss: 1.3941
2023-07-02 01:50:25 - train: epoch 0186, iter [00100, 00390], lr: 0.000800, loss: 1.7121
2023-07-02 01:50:26 - train: epoch 0169, iter [00200, 00390], lr: 0.000800, loss: 1.2753
2023-07-02 01:50:27 - train: epoch 0186, iter [00150, 00390], lr: 0.000800, loss: 2.1700
2023-07-02 01:50:28 - train: epoch 0169, iter [00250, 00390], lr: 0.000800, loss: 1.2171
2023-07-02 01:50:29 - train: epoch 0186, iter [00200, 00390], lr: 0.000800, loss: 1.6356
2023-07-02 01:50:31 - train: epoch 0169, iter [00300, 00390], lr: 0.000800, loss: 1.3372
2023-07-02 01:50:31 - train: epoch 0186, iter [00250, 00390], lr: 0.000800, loss: 2.1574
2023-07-02 01:50:33 - train: epoch 0169, iter [00350, 00390], lr: 0.000800, loss: 1.2802
2023-07-02 01:50:33 - train: epoch 0186, iter [00300, 00390], lr: 0.000800, loss: 2.5862
2023-07-02 01:50:34 - train: epoch 169, train_loss: 1.2936
2023-07-02 01:50:35 - train: epoch 0186, iter [00350, 00390], lr: 0.000800, loss: 1.9124
2023-07-02 01:50:36 - eval: epoch: 169, acc1: 40.500%, acc5: 66.410%, test_loss: 2.7007, per_image_load_time: 0.067ms, per_image_inference_time: 0.058ms
2023-07-02 01:50:36 - until epoch: 169, best_acc1: 41.480%
2023-07-02 01:50:36 - epoch 170 lr: 0.000800
2023-07-02 01:50:36 - train: epoch 186, train_loss: 2.0626
2023-07-02 01:50:38 - eval: epoch: 186, acc1: 41.990%, acc5: 71.520%, test_loss: 2.3293, per_image_load_time: 0.069ms, per_image_inference_time: 0.056ms
2023-07-02 01:50:38 - until epoch: 186, best_acc1: 42.500%
2023-07-02 01:50:38 - epoch 187 lr: 0.000800
2023-07-02 01:50:38 - train: epoch 0170, iter [00050, 00390], lr: 0.000800, loss: 1.2294
2023-07-02 01:50:40 - train: epoch 0170, iter [00100, 00390], lr: 0.000800, loss: 1.3360
2023-07-02 01:50:41 - train: epoch 0187, iter [00050, 00390], lr: 0.000800, loss: 1.9434
2023-07-02 01:50:43 - train: epoch 0170, iter [00150, 00390], lr: 0.000800, loss: 1.2658
2023-07-02 01:50:43 - train: epoch 0187, iter [00100, 00390], lr: 0.000800, loss: 1.5711
2023-07-02 01:50:45 - train: epoch 0170, iter [00200, 00390], lr: 0.000800, loss: 1.3176
2023-07-02 01:50:45 - train: epoch 0187, iter [00150, 00390], lr: 0.000800, loss: 2.9540
2023-07-02 01:50:47 - train: epoch 0170, iter [00250, 00390], lr: 0.000800, loss: 1.2837
2023-07-02 01:50:47 - train: epoch 0187, iter [00200, 00390], lr: 0.000800, loss: 2.1731
2023-07-02 01:50:49 - train: epoch 0170, iter [00300, 00390], lr: 0.000800, loss: 1.3287
2023-07-02 01:50:49 - train: epoch 0187, iter [00250, 00390], lr: 0.000800, loss: 1.6308
2023-07-02 01:50:51 - train: epoch 0170, iter [00350, 00390], lr: 0.000800, loss: 1.3295
2023-07-02 01:50:51 - train: epoch 0187, iter [00300, 00390], lr: 0.000800, loss: 2.4191
2023-07-02 01:50:52 - train: epoch 170, train_loss: 1.2961
2023-07-02 01:50:53 - train: epoch 0187, iter [00350, 00390], lr: 0.000800, loss: 1.6870
2023-07-02 01:50:54 - eval: epoch: 170, acc1: 40.710%, acc5: 66.560%, test_loss: 2.7103, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:50:54 - until epoch: 170, best_acc1: 41.480%
2023-07-02 01:50:54 - epoch 171 lr: 0.000800
2023-07-02 01:50:54 - train: epoch 187, train_loss: 2.1164
2023-07-02 01:50:56 - eval: epoch: 187, acc1: 42.180%, acc5: 71.430%, test_loss: 2.3270, per_image_load_time: 0.080ms, per_image_inference_time: 0.058ms
2023-07-02 01:50:56 - until epoch: 187, best_acc1: 42.500%
2023-07-02 01:50:56 - epoch 188 lr: 0.000800
2023-07-02 01:50:57 - train: epoch 0171, iter [00050, 00390], lr: 0.000800, loss: 1.2707
2023-07-02 01:50:59 - train: epoch 0188, iter [00050, 00390], lr: 0.000800, loss: 2.5165
2023-07-02 01:50:59 - train: epoch 0171, iter [00100, 00390], lr: 0.000800, loss: 1.3097
2023-07-02 01:51:01 - train: epoch 0188, iter [00100, 00390], lr: 0.000800, loss: 1.9155
2023-07-02 01:51:01 - train: epoch 0171, iter [00150, 00390], lr: 0.000800, loss: 1.3583
2023-07-02 01:51:03 - train: epoch 0188, iter [00150, 00390], lr: 0.000800, loss: 2.1909
2023-07-02 01:51:03 - train: epoch 0171, iter [00200, 00390], lr: 0.000800, loss: 1.2102
2023-07-02 01:51:05 - train: epoch 0188, iter [00200, 00390], lr: 0.000800, loss: 2.9449
2023-07-02 01:51:05 - train: epoch 0171, iter [00250, 00390], lr: 0.000800, loss: 1.3741
2023-07-02 01:51:07 - train: epoch 0188, iter [00250, 00390], lr: 0.000800, loss: 2.1710
2023-07-02 01:51:07 - train: epoch 0171, iter [00300, 00390], lr: 0.000800, loss: 1.3747
2023-07-02 01:51:09 - train: epoch 0188, iter [00300, 00390], lr: 0.000800, loss: 2.1107
2023-07-02 01:51:09 - train: epoch 0171, iter [00350, 00390], lr: 0.000800, loss: 1.3403
2023-07-02 01:51:11 - train: epoch 171, train_loss: 1.2921
2023-07-02 01:51:11 - train: epoch 0188, iter [00350, 00390], lr: 0.000800, loss: 1.9482
2023-07-02 01:51:12 - eval: epoch: 171, acc1: 40.620%, acc5: 66.380%, test_loss: 2.7122, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:51:12 - train: epoch 188, train_loss: 2.0982
2023-07-02 01:51:13 - until epoch: 171, best_acc1: 41.480%
2023-07-02 01:51:13 - epoch 172 lr: 0.000800
2023-07-02 01:51:14 - eval: epoch: 188, acc1: 42.010%, acc5: 71.660%, test_loss: 2.3195, per_image_load_time: 0.071ms, per_image_inference_time: 0.060ms
2023-07-02 01:51:14 - until epoch: 188, best_acc1: 42.500%
2023-07-02 01:51:14 - epoch 189 lr: 0.000800
2023-07-02 01:51:15 - train: epoch 0172, iter [00050, 00390], lr: 0.000800, loss: 1.2223
2023-07-02 01:51:17 - train: epoch 0189, iter [00050, 00390], lr: 0.000800, loss: 1.8324
2023-07-02 01:51:17 - train: epoch 0172, iter [00100, 00390], lr: 0.000800, loss: 1.2387
2023-07-02 01:51:19 - train: epoch 0189, iter [00100, 00390], lr: 0.000800, loss: 2.3195
2023-07-02 01:51:20 - train: epoch 0172, iter [00150, 00390], lr: 0.000800, loss: 1.3377
2023-07-02 01:51:21 - train: epoch 0189, iter [00150, 00390], lr: 0.000800, loss: 1.7632
2023-07-02 01:51:22 - train: epoch 0172, iter [00200, 00390], lr: 0.000800, loss: 1.2844
2023-07-02 01:51:23 - train: epoch 0189, iter [00200, 00390], lr: 0.000800, loss: 2.2773
2023-07-02 01:51:24 - train: epoch 0172, iter [00250, 00390], lr: 0.000800, loss: 1.2734
2023-07-02 01:51:25 - train: epoch 0189, iter [00250, 00390], lr: 0.000800, loss: 2.0286
2023-07-02 01:51:26 - train: epoch 0172, iter [00300, 00390], lr: 0.000800, loss: 1.3176
2023-07-02 01:51:27 - train: epoch 0189, iter [00300, 00390], lr: 0.000800, loss: 2.0077
2023-07-02 01:51:28 - train: epoch 0172, iter [00350, 00390], lr: 0.000800, loss: 1.3014
2023-07-02 01:51:29 - train: epoch 0189, iter [00350, 00390], lr: 0.000800, loss: 2.4616
2023-07-02 01:51:30 - train: epoch 172, train_loss: 1.2906
2023-07-02 01:51:30 - train: epoch 189, train_loss: 2.0672
2023-07-02 01:51:31 - eval: epoch: 172, acc1: 40.440%, acc5: 66.530%, test_loss: 2.7103, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:51:31 - until epoch: 172, best_acc1: 41.480%
2023-07-02 01:51:31 - epoch 173 lr: 0.000800
2023-07-02 01:51:32 - eval: epoch: 189, acc1: 42.290%, acc5: 71.250%, test_loss: 2.3334, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:51:32 - until epoch: 189, best_acc1: 42.500%
2023-07-02 01:51:32 - epoch 190 lr: 0.000800
2023-07-02 01:51:34 - train: epoch 0173, iter [00050, 00390], lr: 0.000800, loss: 1.2082
2023-07-02 01:51:35 - train: epoch 0190, iter [00050, 00390], lr: 0.000800, loss: 2.8835
2023-07-02 01:51:36 - train: epoch 0173, iter [00100, 00390], lr: 0.000800, loss: 1.2949
2023-07-02 01:51:37 - train: epoch 0190, iter [00100, 00390], lr: 0.000800, loss: 2.1471
2023-07-02 01:51:38 - train: epoch 0173, iter [00150, 00390], lr: 0.000800, loss: 1.3896
2023-07-02 01:51:39 - train: epoch 0190, iter [00150, 00390], lr: 0.000800, loss: 2.0869
2023-07-02 01:51:40 - train: epoch 0173, iter [00200, 00390], lr: 0.000800, loss: 1.3314
2023-07-02 01:51:41 - train: epoch 0190, iter [00200, 00390], lr: 0.000800, loss: 1.8515
2023-07-02 01:51:43 - train: epoch 0173, iter [00250, 00390], lr: 0.000800, loss: 1.3533
2023-07-02 01:51:43 - train: epoch 0190, iter [00250, 00390], lr: 0.000800, loss: 1.7502
2023-07-02 01:51:45 - train: epoch 0173, iter [00300, 00390], lr: 0.000800, loss: 1.2621
2023-07-02 01:51:45 - train: epoch 0190, iter [00300, 00390], lr: 0.000800, loss: 1.7401
2023-07-02 01:51:47 - train: epoch 0173, iter [00350, 00390], lr: 0.000800, loss: 1.3587
2023-07-02 01:51:47 - train: epoch 0190, iter [00350, 00390], lr: 0.000800, loss: 2.9134
2023-07-02 01:51:49 - train: epoch 173, train_loss: 1.2903
2023-07-02 01:51:49 - train: epoch 190, train_loss: 2.1143
2023-07-02 01:51:50 - eval: epoch: 190, acc1: 42.430%, acc5: 71.500%, test_loss: 2.3307, per_image_load_time: 0.069ms, per_image_inference_time: 0.055ms
2023-07-02 01:51:50 - eval: epoch: 173, acc1: 40.350%, acc5: 66.350%, test_loss: 2.7134, per_image_load_time: 0.068ms, per_image_inference_time: 0.057ms
2023-07-02 01:51:51 - until epoch: 173, best_acc1: 41.480%
2023-07-02 01:51:51 - epoch 174 lr: 0.000800
2023-07-02 01:51:51 - until epoch: 190, best_acc1: 42.500%
2023-07-02 01:51:51 - epoch 191 lr: 0.000800
2023-07-02 01:51:54 - train: epoch 0191, iter [00050, 00390], lr: 0.000800, loss: 1.2980
2023-07-02 01:51:54 - train: epoch 0174, iter [00050, 00390], lr: 0.000800, loss: 1.2217
2023-07-02 01:51:56 - train: epoch 0191, iter [00100, 00390], lr: 0.000800, loss: 2.4484
2023-07-02 01:51:56 - train: epoch 0174, iter [00100, 00390], lr: 0.000800, loss: 1.2150
2023-07-02 01:51:58 - train: epoch 0191, iter [00150, 00390], lr: 0.000800, loss: 1.6317
2023-07-02 01:51:58 - train: epoch 0174, iter [00150, 00390], lr: 0.000800, loss: 1.2965
2023-07-02 01:52:00 - train: epoch 0191, iter [00200, 00390], lr: 0.000800, loss: 2.1911
2023-07-02 01:52:00 - train: epoch 0174, iter [00200, 00390], lr: 0.000800, loss: 1.2651
2023-07-02 01:52:02 - train: epoch 0191, iter [00250, 00390], lr: 0.000800, loss: 1.7486
2023-07-02 01:52:02 - train: epoch 0174, iter [00250, 00390], lr: 0.000800, loss: 1.2747
2023-07-02 01:52:04 - train: epoch 0191, iter [00300, 00390], lr: 0.000800, loss: 1.4848
2023-07-02 01:52:04 - train: epoch 0174, iter [00300, 00390], lr: 0.000800, loss: 1.3059
2023-07-02 01:52:06 - train: epoch 0191, iter [00350, 00390], lr: 0.000800, loss: 2.1087
2023-07-02 01:52:06 - train: epoch 0174, iter [00350, 00390], lr: 0.000800, loss: 1.3133
2023-07-02 01:52:08 - train: epoch 191, train_loss: 2.0605
2023-07-02 01:52:08 - train: epoch 174, train_loss: 1.2822
2023-07-02 01:52:09 - eval: epoch: 191, acc1: 42.300%, acc5: 71.670%, test_loss: 2.3270, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:52:09 - until epoch: 191, best_acc1: 42.500%
2023-07-02 01:52:09 - epoch 192 lr: 0.000800
2023-07-02 01:52:10 - eval: epoch: 174, acc1: 40.290%, acc5: 66.450%, test_loss: 2.7158, per_image_load_time: 0.089ms, per_image_inference_time: 0.063ms
2023-07-02 01:52:10 - until epoch: 174, best_acc1: 41.480%
2023-07-02 01:52:10 - epoch 175 lr: 0.000800
2023-07-02 01:52:12 - train: epoch 0192, iter [00050, 00390], lr: 0.000800, loss: 3.0797
2023-07-02 01:52:13 - train: epoch 0175, iter [00050, 00390], lr: 0.000800, loss: 1.3590
2023-07-02 01:52:14 - train: epoch 0192, iter [00100, 00390], lr: 0.000800, loss: 1.6234
2023-07-02 01:52:15 - train: epoch 0175, iter [00100, 00390], lr: 0.000800, loss: 1.1915
2023-07-02 01:52:16 - train: epoch 0192, iter [00150, 00390], lr: 0.000800, loss: 1.7328
2023-07-02 01:52:18 - train: epoch 0175, iter [00150, 00390], lr: 0.000800, loss: 1.2895
2023-07-02 01:52:18 - train: epoch 0192, iter [00200, 00390], lr: 0.000800, loss: 3.4493
2023-07-02 01:52:20 - train: epoch 0175, iter [00200, 00390], lr: 0.000800, loss: 1.1833
2023-07-02 01:52:20 - train: epoch 0192, iter [00250, 00390], lr: 0.000800, loss: 2.1576
2023-07-02 01:52:22 - train: epoch 0175, iter [00250, 00390], lr: 0.000800, loss: 1.2313
2023-07-02 01:52:22 - train: epoch 0192, iter [00300, 00390], lr: 0.000800, loss: 2.0839
2023-07-02 01:52:24 - train: epoch 0192, iter [00350, 00390], lr: 0.000800, loss: 1.9829
2023-07-02 01:52:24 - train: epoch 0175, iter [00300, 00390], lr: 0.000800, loss: 1.3244
2023-07-02 01:52:26 - train: epoch 192, train_loss: 2.0627
2023-07-02 01:52:26 - train: epoch 0175, iter [00350, 00390], lr: 0.000800, loss: 1.2074
2023-07-02 01:52:27 - eval: epoch: 192, acc1: 41.790%, acc5: 71.210%, test_loss: 2.3388, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 01:52:27 - until epoch: 192, best_acc1: 42.500%
2023-07-02 01:52:27 - epoch 193 lr: 0.000800
2023-07-02 01:52:27 - train: epoch 175, train_loss: 1.2810
2023-07-02 01:52:29 - eval: epoch: 175, acc1: 40.160%, acc5: 66.280%, test_loss: 2.7226, per_image_load_time: 0.076ms, per_image_inference_time: 0.056ms
2023-07-02 01:52:30 - until epoch: 175, best_acc1: 41.480%
2023-07-02 01:52:30 - epoch 176 lr: 0.000800
2023-07-02 01:52:30 - train: epoch 0193, iter [00050, 00390], lr: 0.000800, loss: 2.7294
2023-07-02 01:52:32 - train: epoch 0193, iter [00100, 00390], lr: 0.000800, loss: 2.5478
2023-07-02 01:52:33 - train: epoch 0176, iter [00050, 00390], lr: 0.000800, loss: 1.2150
2023-07-02 01:52:34 - train: epoch 0193, iter [00150, 00390], lr: 0.000800, loss: 1.5600
2023-07-02 01:52:35 - train: epoch 0176, iter [00100, 00390], lr: 0.000800, loss: 1.2553
2023-07-02 01:52:36 - train: epoch 0193, iter [00200, 00390], lr: 0.000800, loss: 2.3767
2023-07-02 01:52:37 - train: epoch 0176, iter [00150, 00390], lr: 0.000800, loss: 1.2307
2023-07-02 01:52:38 - train: epoch 0193, iter [00250, 00390], lr: 0.000800, loss: 1.5634
2023-07-02 01:52:39 - train: epoch 0176, iter [00200, 00390], lr: 0.000800, loss: 1.3156
2023-07-02 01:52:40 - train: epoch 0193, iter [00300, 00390], lr: 0.000800, loss: 2.0189
2023-07-02 01:52:41 - train: epoch 0176, iter [00250, 00390], lr: 0.000800, loss: 1.2584
2023-07-02 01:52:42 - train: epoch 0193, iter [00350, 00390], lr: 0.000800, loss: 2.3151
2023-07-02 01:52:43 - train: epoch 0176, iter [00300, 00390], lr: 0.000800, loss: 1.2738
2023-07-02 01:52:44 - train: epoch 193, train_loss: 2.0931
2023-07-02 01:52:45 - train: epoch 0176, iter [00350, 00390], lr: 0.000800, loss: 1.2881
2023-07-02 01:52:45 - eval: epoch: 193, acc1: 42.200%, acc5: 71.510%, test_loss: 2.3283, per_image_load_time: 0.067ms, per_image_inference_time: 0.054ms
2023-07-02 01:52:46 - until epoch: 193, best_acc1: 42.500%
2023-07-02 01:52:46 - epoch 194 lr: 0.000800
2023-07-02 01:52:46 - train: epoch 176, train_loss: 1.2822
2023-07-02 01:52:48 - eval: epoch: 176, acc1: 40.480%, acc5: 66.110%, test_loss: 2.7175, per_image_load_time: 0.071ms, per_image_inference_time: 0.056ms
2023-07-02 01:52:48 - until epoch: 176, best_acc1: 41.480%
2023-07-02 01:52:48 - epoch 177 lr: 0.000800
2023-07-02 01:52:48 - train: epoch 0194, iter [00050, 00390], lr: 0.000800, loss: 1.9200
2023-07-02 01:52:50 - train: epoch 0194, iter [00100, 00390], lr: 0.000800, loss: 2.0971
2023-07-02 01:52:51 - train: epoch 0177, iter [00050, 00390], lr: 0.000800, loss: 1.2611
2023-07-02 01:52:52 - train: epoch 0194, iter [00150, 00390], lr: 0.000800, loss: 1.6171
2023-07-02 01:52:53 - train: epoch 0177, iter [00100, 00390], lr: 0.000800, loss: 1.2317
2023-07-02 01:52:54 - train: epoch 0194, iter [00200, 00390], lr: 0.000800, loss: 2.3342
2023-07-02 01:52:55 - train: epoch 0177, iter [00150, 00390], lr: 0.000800, loss: 1.3375
2023-07-02 01:52:56 - train: epoch 0194, iter [00250, 00390], lr: 0.000800, loss: 2.1834
2023-07-02 01:52:57 - train: epoch 0177, iter [00200, 00390], lr: 0.000800, loss: 1.2250
2023-07-02 01:52:58 - train: epoch 0194, iter [00300, 00390], lr: 0.000800, loss: 1.6134
2023-07-02 01:52:59 - train: epoch 0177, iter [00250, 00390], lr: 0.000800, loss: 1.3489
2023-07-02 01:53:00 - train: epoch 0194, iter [00350, 00390], lr: 0.000800, loss: 2.1377
2023-07-02 01:53:01 - train: epoch 0177, iter [00300, 00390], lr: 0.000800, loss: 1.1708
2023-07-02 01:53:02 - train: epoch 194, train_loss: 2.0622
2023-07-02 01:53:03 - eval: epoch: 194, acc1: 41.960%, acc5: 71.480%, test_loss: 2.3360, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-07-02 01:53:03 - train: epoch 0177, iter [00350, 00390], lr: 0.000800, loss: 1.2969
2023-07-02 01:53:04 - until epoch: 194, best_acc1: 42.500%
2023-07-02 01:53:04 - epoch 195 lr: 0.000800
2023-07-02 01:53:05 - train: epoch 177, train_loss: 1.2738
2023-07-02 01:53:06 - train: epoch 0195, iter [00050, 00390], lr: 0.000800, loss: 2.7897
2023-07-02 01:53:06 - eval: epoch: 177, acc1: 40.130%, acc5: 66.080%, test_loss: 2.7381, per_image_load_time: 0.071ms, per_image_inference_time: 0.059ms
2023-07-02 01:53:07 - until epoch: 177, best_acc1: 41.480%
2023-07-02 01:53:07 - epoch 178 lr: 0.000800
2023-07-02 01:53:07 - train: epoch 0195, iter [00100, 00390], lr: 0.000800, loss: 1.8486
2023-07-02 01:53:09 - train: epoch 0178, iter [00050, 00390], lr: 0.000800, loss: 1.2747
2023-07-02 01:53:10 - train: epoch 0195, iter [00150, 00390], lr: 0.000800, loss: 1.6633
2023-07-02 01:53:11 - train: epoch 0178, iter [00100, 00390], lr: 0.000800, loss: 1.2168
2023-07-02 01:53:12 - train: epoch 0195, iter [00200, 00390], lr: 0.000800, loss: 1.8951
2023-07-02 01:53:14 - train: epoch 0178, iter [00150, 00390], lr: 0.000800, loss: 1.1838
2023-07-02 01:53:14 - train: epoch 0195, iter [00250, 00390], lr: 0.000800, loss: 2.7142
2023-07-02 01:53:16 - train: epoch 0195, iter [00300, 00390], lr: 0.000800, loss: 1.6029
2023-07-02 01:53:16 - train: epoch 0178, iter [00200, 00390], lr: 0.000800, loss: 1.2650
2023-07-02 01:53:18 - train: epoch 0195, iter [00350, 00390], lr: 0.000800, loss: 1.6626
2023-07-02 01:53:18 - train: epoch 0178, iter [00250, 00390], lr: 0.000800, loss: 1.2889
2023-07-02 01:53:19 - train: epoch 195, train_loss: 2.0873
2023-07-02 01:53:20 - train: epoch 0178, iter [00300, 00390], lr: 0.000800, loss: 1.2876
2023-07-02 01:53:21 - eval: epoch: 195, acc1: 41.840%, acc5: 71.180%, test_loss: 2.3400, per_image_load_time: 0.067ms, per_image_inference_time: 0.053ms
2023-07-02 01:53:21 - until epoch: 195, best_acc1: 42.500%
2023-07-02 01:53:21 - epoch 196 lr: 0.000800
2023-07-02 01:53:22 - train: epoch 0178, iter [00350, 00390], lr: 0.000800, loss: 1.3192
2023-07-02 01:53:23 - train: epoch 178, train_loss: 1.2784
2023-07-02 01:53:24 - train: epoch 0196, iter [00050, 00390], lr: 0.000800, loss: 2.0454
2023-07-02 01:53:25 - eval: epoch: 178, acc1: 40.400%, acc5: 66.290%, test_loss: 2.7225, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:53:25 - until epoch: 178, best_acc1: 41.480%
2023-07-02 01:53:25 - epoch 179 lr: 0.000800
2023-07-02 01:53:25 - train: epoch 0196, iter [00100, 00390], lr: 0.000800, loss: 1.5956
2023-07-02 01:53:27 - train: epoch 0196, iter [00150, 00390], lr: 0.000800, loss: 2.2989
2023-07-02 01:53:28 - train: epoch 0179, iter [00050, 00390], lr: 0.000800, loss: 1.1544
2023-07-02 01:53:29 - train: epoch 0196, iter [00200, 00390], lr: 0.000800, loss: 1.7456
2023-07-02 01:53:30 - train: epoch 0179, iter [00100, 00390], lr: 0.000800, loss: 1.2621
2023-07-02 01:53:31 - train: epoch 0196, iter [00250, 00390], lr: 0.000800, loss: 1.4908
2023-07-02 01:53:32 - train: epoch 0179, iter [00150, 00390], lr: 0.000800, loss: 1.2983
2023-07-02 01:53:33 - train: epoch 0196, iter [00300, 00390], lr: 0.000800, loss: 1.6556
2023-07-02 01:53:34 - train: epoch 0179, iter [00200, 00390], lr: 0.000800, loss: 1.3334
2023-07-02 01:53:35 - train: epoch 0196, iter [00350, 00390], lr: 0.000800, loss: 1.9755
2023-07-02 01:53:36 - train: epoch 0179, iter [00250, 00390], lr: 0.000800, loss: 1.3317
2023-07-02 01:53:37 - train: epoch 196, train_loss: 2.0676
2023-07-02 01:53:38 - eval: epoch: 196, acc1: 42.400%, acc5: 71.330%, test_loss: 2.3381, per_image_load_time: 0.067ms, per_image_inference_time: 0.054ms
2023-07-02 01:53:38 - train: epoch 0179, iter [00300, 00390], lr: 0.000800, loss: 1.3505
2023-07-02 01:53:38 - until epoch: 196, best_acc1: 42.500%
2023-07-02 01:53:38 - epoch 197 lr: 0.000800
2023-07-02 01:53:40 - train: epoch 0179, iter [00350, 00390], lr: 0.000800, loss: 1.2617
2023-07-02 01:53:41 - train: epoch 0197, iter [00050, 00390], lr: 0.000800, loss: 1.6198
2023-07-02 01:53:42 - train: epoch 179, train_loss: 1.2709
2023-07-02 01:53:43 - train: epoch 0197, iter [00100, 00390], lr: 0.000800, loss: 2.1451
2023-07-02 01:53:43 - eval: epoch: 179, acc1: 40.270%, acc5: 66.030%, test_loss: 2.7289, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:53:43 - until epoch: 179, best_acc1: 41.480%
2023-07-02 01:53:43 - epoch 180 lr: 0.000800
2023-07-02 01:53:44 - train: epoch 0197, iter [00150, 00390], lr: 0.000800, loss: 1.8932
2023-07-02 01:53:46 - train: epoch 0180, iter [00050, 00390], lr: 0.000800, loss: 1.2761
2023-07-02 01:53:46 - train: epoch 0197, iter [00200, 00390], lr: 0.000800, loss: 2.3033
2023-07-02 01:53:48 - train: epoch 0180, iter [00100, 00390], lr: 0.000800, loss: 1.2284
2023-07-02 01:53:49 - train: epoch 0197, iter [00250, 00390], lr: 0.000800, loss: 1.5621
2023-07-02 01:53:50 - train: epoch 0180, iter [00150, 00390], lr: 0.000800, loss: 1.2931
2023-07-02 01:53:51 - train: epoch 0197, iter [00300, 00390], lr: 0.000800, loss: 2.5704
2023-07-02 01:53:52 - train: epoch 0180, iter [00200, 00390], lr: 0.000800, loss: 1.2566
2023-07-02 01:53:53 - train: epoch 0197, iter [00350, 00390], lr: 0.000800, loss: 3.0002
2023-07-02 01:53:54 - train: epoch 197, train_loss: 2.0853
2023-07-02 01:53:54 - train: epoch 0180, iter [00250, 00390], lr: 0.000800, loss: 1.2815
2023-07-02 01:53:56 - eval: epoch: 197, acc1: 42.390%, acc5: 71.480%, test_loss: 2.3350, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:53:56 - until epoch: 197, best_acc1: 42.500%
2023-07-02 01:53:56 - epoch 198 lr: 0.000800
2023-07-02 01:53:56 - train: epoch 0180, iter [00300, 00390], lr: 0.000800, loss: 1.2006
2023-07-02 01:53:58 - train: epoch 0180, iter [00350, 00390], lr: 0.000800, loss: 1.1803
2023-07-02 01:53:59 - train: epoch 0198, iter [00050, 00390], lr: 0.000800, loss: 1.8989
2023-07-02 01:54:00 - train: epoch 180, train_loss: 1.2703
2023-07-02 01:54:01 - train: epoch 0198, iter [00100, 00390], lr: 0.000800, loss: 1.5267
2023-07-02 01:54:01 - eval: epoch: 180, acc1: 40.320%, acc5: 66.140%, test_loss: 2.7262, per_image_load_time: 0.066ms, per_image_inference_time: 0.057ms
2023-07-02 01:54:02 - until epoch: 180, best_acc1: 41.480%
2023-07-02 01:54:02 - epoch 181 lr: 0.000800
2023-07-02 01:54:02 - train: epoch 0198, iter [00150, 00390], lr: 0.000800, loss: 1.6424
2023-07-02 01:54:04 - train: epoch 0198, iter [00200, 00390], lr: 0.000800, loss: 2.3370
2023-07-02 01:54:04 - train: epoch 0181, iter [00050, 00390], lr: 0.000800, loss: 1.2874
2023-07-02 01:54:06 - train: epoch 0198, iter [00250, 00390], lr: 0.000800, loss: 1.7866
2023-07-02 01:54:07 - train: epoch 0181, iter [00100, 00390], lr: 0.000800, loss: 1.1603
2023-07-02 01:54:08 - train: epoch 0198, iter [00300, 00390], lr: 0.000800, loss: 2.2155
2023-07-02 01:54:09 - train: epoch 0181, iter [00150, 00390], lr: 0.000800, loss: 1.2951
2023-07-02 01:54:10 - train: epoch 0198, iter [00350, 00390], lr: 0.000800, loss: 1.6411
2023-07-02 01:54:11 - train: epoch 0181, iter [00200, 00390], lr: 0.000800, loss: 1.2189
2023-07-02 01:54:12 - train: epoch 198, train_loss: 2.0697
2023-07-02 01:54:13 - train: epoch 0181, iter [00250, 00390], lr: 0.000800, loss: 1.2615
2023-07-02 01:54:13 - eval: epoch: 198, acc1: 42.220%, acc5: 71.320%, test_loss: 2.3383, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-07-02 01:54:14 - until epoch: 198, best_acc1: 42.500%
2023-07-02 01:54:14 - epoch 199 lr: 0.000800
2023-07-02 01:54:14 - train: epoch 0181, iter [00300, 00390], lr: 0.000800, loss: 1.2120
2023-07-02 01:54:17 - train: epoch 0181, iter [00350, 00390], lr: 0.000800, loss: 1.2771
2023-07-02 01:54:17 - train: epoch 0199, iter [00050, 00390], lr: 0.000800, loss: 1.8990
2023-07-02 01:54:18 - train: epoch 181, train_loss: 1.2640
2023-07-02 01:54:19 - train: epoch 0199, iter [00100, 00390], lr: 0.000800, loss: 1.5755
2023-07-02 01:54:20 - eval: epoch: 181, acc1: 40.400%, acc5: 66.200%, test_loss: 2.7341, per_image_load_time: 0.069ms, per_image_inference_time: 0.056ms
2023-07-02 01:54:20 - until epoch: 181, best_acc1: 41.480%
2023-07-02 01:54:20 - epoch 182 lr: 0.000800
2023-07-02 01:54:20 - train: epoch 0199, iter [00150, 00390], lr: 0.000800, loss: 2.9196
2023-07-02 01:54:22 - train: epoch 0199, iter [00200, 00390], lr: 0.000800, loss: 1.5063
2023-07-02 01:54:23 - train: epoch 0182, iter [00050, 00390], lr: 0.000800, loss: 1.1459
2023-07-02 01:54:24 - train: epoch 0199, iter [00250, 00390], lr: 0.000800, loss: 2.1493
2023-07-02 01:54:25 - train: epoch 0182, iter [00100, 00390], lr: 0.000800, loss: 1.2642
2023-07-02 01:54:26 - train: epoch 0199, iter [00300, 00390], lr: 0.000800, loss: 1.8862
2023-07-02 01:54:27 - train: epoch 0182, iter [00150, 00390], lr: 0.000800, loss: 1.2976
2023-07-02 01:54:28 - train: epoch 0199, iter [00350, 00390], lr: 0.000800, loss: 1.6586
2023-07-02 01:54:29 - train: epoch 0182, iter [00200, 00390], lr: 0.000800, loss: 1.2240
2023-07-02 01:54:30 - train: epoch 199, train_loss: 2.0878
2023-07-02 01:54:31 - train: epoch 0182, iter [00250, 00390], lr: 0.000800, loss: 1.2669
2023-07-02 01:54:31 - eval: epoch: 199, acc1: 41.950%, acc5: 71.390%, test_loss: 2.3383, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-07-02 01:54:32 - until epoch: 199, best_acc1: 42.500%
2023-07-02 01:54:32 - epoch 200 lr: 0.000800
2023-07-02 01:54:33 - train: epoch 0182, iter [00300, 00390], lr: 0.000800, loss: 1.2058
2023-07-02 01:54:35 - train: epoch 0200, iter [00050, 00390], lr: 0.000800, loss: 3.0226
2023-07-02 01:54:35 - train: epoch 0182, iter [00350, 00390], lr: 0.000800, loss: 1.1675
2023-07-02 01:54:37 - train: epoch 182, train_loss: 1.2631
2023-07-02 01:54:37 - train: epoch 0200, iter [00100, 00390], lr: 0.000800, loss: 1.7775
2023-07-02 01:54:38 - eval: epoch: 182, acc1: 40.430%, acc5: 66.080%, test_loss: 2.7396, per_image_load_time: 0.078ms, per_image_inference_time: 0.056ms
2023-07-02 01:54:38 - train: epoch 0200, iter [00150, 00390], lr: 0.000800, loss: 2.3189
2023-07-02 01:54:38 - until epoch: 182, best_acc1: 41.480%
2023-07-02 01:54:38 - epoch 183 lr: 0.000800
2023-07-02 01:54:40 - train: epoch 0200, iter [00200, 00390], lr: 0.000800, loss: 1.4220
2023-07-02 01:54:41 - train: epoch 0183, iter [00050, 00390], lr: 0.000800, loss: 1.2467
2023-07-02 01:54:42 - train: epoch 0200, iter [00250, 00390], lr: 0.000800, loss: 2.3051
2023-07-02 01:54:43 - train: epoch 0183, iter [00100, 00390], lr: 0.000800, loss: 1.2557
2023-07-02 01:54:44 - train: epoch 0200, iter [00300, 00390], lr: 0.000800, loss: 2.2483
2023-07-02 01:54:45 - train: epoch 0183, iter [00150, 00390], lr: 0.000800, loss: 1.3326
2023-07-02 01:54:46 - train: epoch 0200, iter [00350, 00390], lr: 0.000800, loss: 3.2565
2023-07-02 01:54:48 - train: epoch 0183, iter [00200, 00390], lr: 0.000800, loss: 1.3034
2023-07-02 01:54:48 - train: epoch 200, train_loss: 2.0602
2023-07-02 01:54:49 - eval: epoch: 200, acc1: 42.230%, acc5: 71.290%, test_loss: 2.3463, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-07-02 01:54:49 - train: epoch 0183, iter [00250, 00390], lr: 0.000800, loss: 1.2610
2023-07-02 01:54:49 - until epoch: 200, best_acc1: 42.500%
2023-07-02 01:54:49 - train done. model: vit_mid_small_patch16, train time: 0.973 hours, best_acc1: 42.500%
2023-07-02 01:54:51 - train: epoch 0183, iter [00300, 00390], lr: 0.000800, loss: 1.3241
2023-07-02 01:54:52 - train: epoch 0183, iter [00350, 00390], lr: 0.000800, loss: 1.2713
2023-07-02 01:54:53 - train: epoch 183, train_loss: 1.2608
2023-07-02 01:54:55 - eval: epoch: 183, acc1: 40.240%, acc5: 66.130%, test_loss: 2.7396, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:54:55 - until epoch: 183, best_acc1: 41.480%
2023-07-02 01:54:55 - epoch 184 lr: 0.000800
2023-07-02 01:54:58 - train: epoch 0184, iter [00050, 00390], lr: 0.000800, loss: 1.2376
2023-07-02 01:54:59 - train: epoch 0184, iter [00100, 00390], lr: 0.000800, loss: 1.1780
2023-07-02 01:55:01 - train: epoch 0184, iter [00150, 00390], lr: 0.000800, loss: 1.1996
2023-07-02 01:55:02 - train: epoch 0184, iter [00200, 00390], lr: 0.000800, loss: 1.2665
2023-07-02 01:55:04 - train: epoch 0184, iter [00250, 00390], lr: 0.000800, loss: 1.2123
2023-07-02 01:55:05 - train: epoch 0184, iter [00300, 00390], lr: 0.000800, loss: 1.2159
2023-07-02 01:55:07 - train: epoch 0184, iter [00350, 00390], lr: 0.000800, loss: 1.2098
2023-07-02 01:55:08 - train: epoch 184, train_loss: 1.2616
2023-07-02 01:55:09 - eval: epoch: 184, acc1: 40.270%, acc5: 65.980%, test_loss: 2.7409, per_image_load_time: 0.065ms, per_image_inference_time: 0.057ms
2023-07-02 01:55:09 - until epoch: 184, best_acc1: 41.480%
2023-07-02 01:55:09 - epoch 185 lr: 0.000800
2023-07-02 01:55:12 - train: epoch 0185, iter [00050, 00390], lr: 0.000800, loss: 1.2468
2023-07-02 01:55:13 - train: epoch 0185, iter [00100, 00390], lr: 0.000800, loss: 1.3083
2023-07-02 01:55:15 - train: epoch 0185, iter [00150, 00390], lr: 0.000800, loss: 1.1911
2023-07-02 01:55:16 - train: epoch 0185, iter [00200, 00390], lr: 0.000800, loss: 1.2737
2023-07-02 01:55:18 - train: epoch 0185, iter [00250, 00390], lr: 0.000800, loss: 1.2574
2023-07-02 01:55:19 - train: epoch 0185, iter [00300, 00390], lr: 0.000800, loss: 1.3032
2023-07-02 01:55:21 - train: epoch 0185, iter [00350, 00390], lr: 0.000800, loss: 1.1660
2023-07-02 01:55:22 - train: epoch 185, train_loss: 1.2587
2023-07-02 01:55:23 - eval: epoch: 185, acc1: 40.430%, acc5: 65.650%, test_loss: 2.7392, per_image_load_time: 0.065ms, per_image_inference_time: 0.056ms
2023-07-02 01:55:23 - until epoch: 185, best_acc1: 41.480%
2023-07-02 01:55:23 - epoch 186 lr: 0.000800
2023-07-02 01:55:26 - train: epoch 0186, iter [00050, 00390], lr: 0.000800, loss: 1.2402
2023-07-02 01:55:27 - train: epoch 0186, iter [00100, 00390], lr: 0.000800, loss: 1.2133
2023-07-02 01:55:29 - train: epoch 0186, iter [00150, 00390], lr: 0.000800, loss: 1.2821
2023-07-02 01:55:30 - train: epoch 0186, iter [00200, 00390], lr: 0.000800, loss: 1.2030
2023-07-02 01:55:32 - train: epoch 0186, iter [00250, 00390], lr: 0.000800, loss: 1.3166
2023-07-02 01:55:33 - train: epoch 0186, iter [00300, 00390], lr: 0.000800, loss: 1.2366
2023-07-02 01:55:34 - train: epoch 0186, iter [00350, 00390], lr: 0.000800, loss: 1.3429
2023-07-02 01:55:36 - train: epoch 186, train_loss: 1.2575
2023-07-02 01:55:37 - eval: epoch: 186, acc1: 40.120%, acc5: 65.820%, test_loss: 2.7440, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:55:37 - until epoch: 186, best_acc1: 41.480%
2023-07-02 01:55:37 - epoch 187 lr: 0.000800
2023-07-02 01:55:40 - train: epoch 0187, iter [00050, 00390], lr: 0.000800, loss: 1.0888
2023-07-02 01:55:41 - train: epoch 0187, iter [00100, 00390], lr: 0.000800, loss: 1.2282
2023-07-02 01:55:43 - train: epoch 0187, iter [00150, 00390], lr: 0.000800, loss: 1.2210
2023-07-02 01:55:44 - train: epoch 0187, iter [00200, 00390], lr: 0.000800, loss: 1.2901
2023-07-02 01:55:46 - train: epoch 0187, iter [00250, 00390], lr: 0.000800, loss: 1.2343
2023-07-02 01:55:47 - train: epoch 0187, iter [00300, 00390], lr: 0.000800, loss: 1.3191
2023-07-02 01:55:49 - train: epoch 0187, iter [00350, 00390], lr: 0.000800, loss: 1.2544
2023-07-02 01:55:50 - train: epoch 187, train_loss: 1.2508
2023-07-02 01:55:52 - eval: epoch: 187, acc1: 40.080%, acc5: 66.060%, test_loss: 2.7425, per_image_load_time: 0.068ms, per_image_inference_time: 0.057ms
2023-07-02 01:55:52 - until epoch: 187, best_acc1: 41.480%
2023-07-02 01:55:52 - epoch 188 lr: 0.000800
2023-07-02 01:55:54 - train: epoch 0188, iter [00050, 00390], lr: 0.000800, loss: 1.3451
2023-07-02 01:55:56 - train: epoch 0188, iter [00100, 00390], lr: 0.000800, loss: 1.1760
2023-07-02 01:55:58 - train: epoch 0188, iter [00150, 00390], lr: 0.000800, loss: 1.1926
2023-07-02 01:56:00 - train: epoch 0188, iter [00200, 00390], lr: 0.000800, loss: 1.2339
2023-07-02 01:56:02 - train: epoch 0188, iter [00250, 00390], lr: 0.000800, loss: 1.2692
2023-07-02 01:56:04 - train: epoch 0188, iter [00300, 00390], lr: 0.000800, loss: 1.2684
2023-07-02 01:56:06 - train: epoch 0188, iter [00350, 00390], lr: 0.000800, loss: 1.2523
2023-07-02 01:56:07 - train: epoch 188, train_loss: 1.2528
2023-07-02 01:56:09 - eval: epoch: 188, acc1: 40.270%, acc5: 65.820%, test_loss: 2.7458, per_image_load_time: 0.066ms, per_image_inference_time: 0.069ms
2023-07-02 01:56:09 - until epoch: 188, best_acc1: 41.480%
2023-07-02 01:56:09 - epoch 189 lr: 0.000800
2023-07-02 01:56:11 - train: epoch 0189, iter [00050, 00390], lr: 0.000800, loss: 1.2485
2023-07-02 01:56:13 - train: epoch 0189, iter [00100, 00390], lr: 0.000800, loss: 1.2532
2023-07-02 01:56:14 - train: epoch 0189, iter [00150, 00390], lr: 0.000800, loss: 1.2536
2023-07-02 01:56:16 - train: epoch 0189, iter [00200, 00390], lr: 0.000800, loss: 1.2079
2023-07-02 01:56:17 - train: epoch 0189, iter [00250, 00390], lr: 0.000800, loss: 1.1503
2023-07-02 01:56:19 - train: epoch 0189, iter [00300, 00390], lr: 0.000800, loss: 1.2104
2023-07-02 01:56:20 - train: epoch 0189, iter [00350, 00390], lr: 0.000800, loss: 1.2075
2023-07-02 01:56:21 - train: epoch 189, train_loss: 1.2500
2023-07-02 01:56:23 - eval: epoch: 189, acc1: 40.230%, acc5: 65.930%, test_loss: 2.7542, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:56:24 - until epoch: 189, best_acc1: 41.480%
2023-07-02 01:56:24 - epoch 190 lr: 0.000800
2023-07-02 01:56:26 - train: epoch 0190, iter [00050, 00390], lr: 0.000800, loss: 1.2220
2023-07-02 01:56:28 - train: epoch 0190, iter [00100, 00390], lr: 0.000800, loss: 1.3672
2023-07-02 01:56:30 - train: epoch 0190, iter [00150, 00390], lr: 0.000800, loss: 1.3349
2023-07-02 01:56:31 - train: epoch 0190, iter [00200, 00390], lr: 0.000800, loss: 1.3106
2023-07-02 01:56:33 - train: epoch 0190, iter [00250, 00390], lr: 0.000800, loss: 1.2052
2023-07-02 01:56:34 - train: epoch 0190, iter [00300, 00390], lr: 0.000800, loss: 1.3211
2023-07-02 01:56:36 - train: epoch 0190, iter [00350, 00390], lr: 0.000800, loss: 1.1457
2023-07-02 01:56:37 - train: epoch 190, train_loss: 1.2481
2023-07-02 01:56:38 - eval: epoch: 190, acc1: 40.230%, acc5: 65.860%, test_loss: 2.7558, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-07-02 01:56:39 - until epoch: 190, best_acc1: 41.480%
2023-07-02 01:56:39 - epoch 191 lr: 0.000800
2023-07-02 01:56:41 - train: epoch 0191, iter [00050, 00390], lr: 0.000800, loss: 1.2032
2023-07-02 01:56:42 - train: epoch 0191, iter [00100, 00390], lr: 0.000800, loss: 1.3596
2023-07-02 01:56:44 - train: epoch 0191, iter [00150, 00390], lr: 0.000800, loss: 1.2914
2023-07-02 01:56:45 - train: epoch 0191, iter [00200, 00390], lr: 0.000800, loss: 1.2982
2023-07-02 01:56:47 - train: epoch 0191, iter [00250, 00390], lr: 0.000800, loss: 1.1358
2023-07-02 01:56:48 - train: epoch 0191, iter [00300, 00390], lr: 0.000800, loss: 1.2636
2023-07-02 01:56:50 - train: epoch 0191, iter [00350, 00390], lr: 0.000800, loss: 1.1565
2023-07-02 01:56:51 - train: epoch 191, train_loss: 1.2447
2023-07-02 01:56:53 - eval: epoch: 191, acc1: 40.410%, acc5: 65.910%, test_loss: 2.7422, per_image_load_time: 0.070ms, per_image_inference_time: 0.056ms
2023-07-02 01:56:54 - until epoch: 191, best_acc1: 41.480%
2023-07-02 01:56:54 - epoch 192 lr: 0.000800
2023-07-02 01:56:56 - train: epoch 0192, iter [00050, 00390], lr: 0.000800, loss: 1.1944
2023-07-02 01:56:58 - train: epoch 0192, iter [00100, 00390], lr: 0.000800, loss: 1.2091
2023-07-02 01:56:59 - train: epoch 0192, iter [00150, 00390], lr: 0.000800, loss: 1.3178
2023-07-02 01:57:01 - train: epoch 0192, iter [00200, 00390], lr: 0.000800, loss: 1.3322
2023-07-02 01:57:02 - train: epoch 0192, iter [00250, 00390], lr: 0.000800, loss: 1.3173
2023-07-02 01:57:04 - train: epoch 0192, iter [00300, 00390], lr: 0.000800, loss: 1.1817
2023-07-02 01:57:05 - train: epoch 0192, iter [00350, 00390], lr: 0.000800, loss: 1.1647
2023-07-02 01:57:06 - train: epoch 192, train_loss: 1.2498
2023-07-02 01:57:08 - eval: epoch: 192, acc1: 39.760%, acc5: 65.580%, test_loss: 2.7668, per_image_load_time: 0.073ms, per_image_inference_time: 0.056ms
2023-07-02 01:57:08 - until epoch: 192, best_acc1: 41.480%
2023-07-02 01:57:08 - epoch 193 lr: 0.000800
2023-07-02 01:57:10 - train: epoch 0193, iter [00050, 00390], lr: 0.000800, loss: 1.2830
2023-07-02 01:57:12 - train: epoch 0193, iter [00100, 00390], lr: 0.000800, loss: 1.2350
2023-07-02 01:57:13 - train: epoch 0193, iter [00150, 00390], lr: 0.000800, loss: 1.2416
2023-07-02 01:57:15 - train: epoch 0193, iter [00200, 00390], lr: 0.000800, loss: 1.2615
2023-07-02 01:57:16 - train: epoch 0193, iter [00250, 00390], lr: 0.000800, loss: 1.2274
2023-07-02 01:57:18 - train: epoch 0193, iter [00300, 00390], lr: 0.000800, loss: 1.3521
2023-07-02 01:57:19 - train: epoch 0193, iter [00350, 00390], lr: 0.000800, loss: 1.3578
2023-07-02 01:57:21 - train: epoch 193, train_loss: 1.2454
2023-07-02 01:57:22 - eval: epoch: 193, acc1: 40.030%, acc5: 65.630%, test_loss: 2.7593, per_image_load_time: 0.069ms, per_image_inference_time: 0.056ms
2023-07-02 01:57:22 - until epoch: 193, best_acc1: 41.480%
2023-07-02 01:57:22 - epoch 194 lr: 0.000800
2023-07-02 01:57:25 - train: epoch 0194, iter [00050, 00390], lr: 0.000800, loss: 1.1665
2023-07-02 01:57:26 - train: epoch 0194, iter [00100, 00390], lr: 0.000800, loss: 1.2153
2023-07-02 01:57:28 - train: epoch 0194, iter [00150, 00390], lr: 0.000800, loss: 1.2115
2023-07-02 01:57:29 - train: epoch 0194, iter [00200, 00390], lr: 0.000800, loss: 1.2096
2023-07-02 01:57:31 - train: epoch 0194, iter [00250, 00390], lr: 0.000800, loss: 1.2745
2023-07-02 01:57:33 - train: epoch 0194, iter [00300, 00390], lr: 0.000800, loss: 1.2779
2023-07-02 01:57:34 - train: epoch 0194, iter [00350, 00390], lr: 0.000800, loss: 1.2372
2023-07-02 01:57:36 - train: epoch 194, train_loss: 1.2438
2023-07-02 01:57:37 - eval: epoch: 194, acc1: 40.020%, acc5: 65.460%, test_loss: 2.7600, per_image_load_time: 0.066ms, per_image_inference_time: 0.056ms
2023-07-02 01:57:37 - until epoch: 194, best_acc1: 41.480%
2023-07-02 01:57:37 - epoch 195 lr: 0.000800
2023-07-02 01:57:40 - train: epoch 0195, iter [00050, 00390], lr: 0.000800, loss: 1.2021
2023-07-02 01:57:42 - train: epoch 0195, iter [00100, 00390], lr: 0.000800, loss: 1.1805
2023-07-02 01:57:43 - train: epoch 0195, iter [00150, 00390], lr: 0.000800, loss: 1.2806
2023-07-02 01:57:45 - train: epoch 0195, iter [00200, 00390], lr: 0.000800, loss: 1.2368
2023-07-02 01:57:46 - train: epoch 0195, iter [00250, 00390], lr: 0.000800, loss: 1.2347
2023-07-02 01:57:48 - train: epoch 0195, iter [00300, 00390], lr: 0.000800, loss: 1.2320
2023-07-02 01:57:49 - train: epoch 0195, iter [00350, 00390], lr: 0.000800, loss: 1.2398
2023-07-02 01:57:51 - train: epoch 195, train_loss: 1.2366
2023-07-02 01:57:52 - eval: epoch: 195, acc1: 39.700%, acc5: 65.580%, test_loss: 2.7651, per_image_load_time: 0.069ms, per_image_inference_time: 0.056ms
2023-07-02 01:57:52 - until epoch: 195, best_acc1: 41.480%
2023-07-02 01:57:52 - epoch 196 lr: 0.000800
2023-07-02 01:57:55 - train: epoch 0196, iter [00050, 00390], lr: 0.000800, loss: 1.2396
2023-07-02 01:57:56 - train: epoch 0196, iter [00100, 00390], lr: 0.000800, loss: 1.2601
2023-07-02 01:57:58 - train: epoch 0196, iter [00150, 00390], lr: 0.000800, loss: 1.2599
2023-07-02 01:57:59 - train: epoch 0196, iter [00200, 00390], lr: 0.000800, loss: 1.3154
2023-07-02 01:58:01 - train: epoch 0196, iter [00250, 00390], lr: 0.000800, loss: 1.2510
2023-07-02 01:58:02 - train: epoch 0196, iter [00300, 00390], lr: 0.000800, loss: 1.2731
2023-07-02 01:58:04 - train: epoch 0196, iter [00350, 00390], lr: 0.000800, loss: 1.1725
2023-07-02 01:58:05 - train: epoch 196, train_loss: 1.2405
2023-07-02 01:58:06 - eval: epoch: 196, acc1: 40.040%, acc5: 65.690%, test_loss: 2.7667, per_image_load_time: 0.064ms, per_image_inference_time: 0.056ms
2023-07-02 01:58:07 - until epoch: 196, best_acc1: 41.480%
2023-07-02 01:58:07 - epoch 197 lr: 0.000800
2023-07-02 01:58:09 - train: epoch 0197, iter [00050, 00390], lr: 0.000800, loss: 1.1971
2023-07-02 01:58:11 - train: epoch 0197, iter [00100, 00390], lr: 0.000800, loss: 1.3070
2023-07-02 01:58:12 - train: epoch 0197, iter [00150, 00390], lr: 0.000800, loss: 1.2159
2023-07-02 01:58:14 - train: epoch 0197, iter [00200, 00390], lr: 0.000800, loss: 1.2937
2023-07-02 01:58:15 - train: epoch 0197, iter [00250, 00390], lr: 0.000800, loss: 1.2512
2023-07-02 01:58:17 - train: epoch 0197, iter [00300, 00390], lr: 0.000800, loss: 1.2301
2023-07-02 01:58:18 - train: epoch 0197, iter [00350, 00390], lr: 0.000800, loss: 1.1824
2023-07-02 01:58:20 - train: epoch 197, train_loss: 1.2380
2023-07-02 01:58:21 - eval: epoch: 197, acc1: 40.310%, acc5: 65.950%, test_loss: 2.7590, per_image_load_time: 0.065ms, per_image_inference_time: 0.066ms
2023-07-02 01:58:21 - until epoch: 197, best_acc1: 41.480%
2023-07-02 01:58:21 - epoch 198 lr: 0.000800
2023-07-02 01:58:24 - train: epoch 0198, iter [00050, 00390], lr: 0.000800, loss: 1.2508
2023-07-02 01:58:25 - train: epoch 0198, iter [00100, 00390], lr: 0.000800, loss: 1.2204
2023-07-02 01:58:27 - train: epoch 0198, iter [00150, 00390], lr: 0.000800, loss: 1.3052
2023-07-02 01:58:28 - train: epoch 0198, iter [00200, 00390], lr: 0.000800, loss: 1.2965
2023-07-02 01:58:30 - train: epoch 0198, iter [00250, 00390], lr: 0.000800, loss: 1.2369
2023-07-02 01:58:31 - train: epoch 0198, iter [00300, 00390], lr: 0.000800, loss: 1.3100
2023-07-02 01:58:33 - train: epoch 0198, iter [00350, 00390], lr: 0.000800, loss: 1.1615
2023-07-02 01:58:34 - train: epoch 198, train_loss: 1.2383
2023-07-02 01:58:36 - eval: epoch: 198, acc1: 40.140%, acc5: 65.800%, test_loss: 2.7602, per_image_load_time: 0.072ms, per_image_inference_time: 0.060ms
2023-07-02 01:58:36 - until epoch: 198, best_acc1: 41.480%
2023-07-02 01:58:36 - epoch 199 lr: 0.000800
2023-07-02 01:58:38 - train: epoch 0199, iter [00050, 00390], lr: 0.000800, loss: 1.2538
2023-07-02 01:58:40 - train: epoch 0199, iter [00100, 00390], lr: 0.000800, loss: 1.2731
2023-07-02 01:58:41 - train: epoch 0199, iter [00150, 00390], lr: 0.000800, loss: 1.2441
2023-07-02 01:58:43 - train: epoch 0199, iter [00200, 00390], lr: 0.000800, loss: 1.2676
2023-07-02 01:58:44 - train: epoch 0199, iter [00250, 00390], lr: 0.000800, loss: 1.1700
2023-07-02 01:58:46 - train: epoch 0199, iter [00300, 00390], lr: 0.000800, loss: 1.2320
2023-07-02 01:58:47 - train: epoch 0199, iter [00350, 00390], lr: 0.000800, loss: 1.2627
2023-07-02 01:58:48 - train: epoch 199, train_loss: 1.2365
2023-07-02 01:58:50 - eval: epoch: 199, acc1: 40.130%, acc5: 65.900%, test_loss: 2.7659, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:58:50 - until epoch: 199, best_acc1: 41.480%
2023-07-02 01:58:50 - epoch 200 lr: 0.000800
2023-07-02 01:58:53 - train: epoch 0200, iter [00050, 00390], lr: 0.000800, loss: 1.3453
2023-07-02 01:58:54 - train: epoch 0200, iter [00100, 00390], lr: 0.000800, loss: 1.2552
2023-07-02 01:58:56 - train: epoch 0200, iter [00150, 00390], lr: 0.000800, loss: 1.2726
2023-07-02 01:58:57 - train: epoch 0200, iter [00200, 00390], lr: 0.000800, loss: 1.1547
2023-07-02 01:58:59 - train: epoch 0200, iter [00250, 00390], lr: 0.000800, loss: 1.2131
2023-07-02 01:59:00 - train: epoch 0200, iter [00300, 00390], lr: 0.000800, loss: 1.1850
2023-07-02 01:59:02 - train: epoch 0200, iter [00350, 00390], lr: 0.000800, loss: 1.1704
2023-07-02 01:59:03 - train: epoch 200, train_loss: 1.2333
2023-07-02 01:59:04 - eval: epoch: 200, acc1: 40.080%, acc5: 66.130%, test_loss: 2.7542, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-07-02 01:59:05 - until epoch: 200, best_acc1: 41.480%
2023-07-02 01:59:05 - train done. model: vit_mid_small_patch16, train time: 0.993 hours, best_acc1: 41.480%
