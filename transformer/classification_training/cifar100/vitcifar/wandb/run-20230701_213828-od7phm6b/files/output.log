21630436
No pretrained model file!
Dataset Size:50000
Dataset Class Num:100
Dataset Size:10000
Dataset Class Num:100
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.
Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError("No module named 'amp_C'")
Warning:  apex was installed without --cpp_ext.  Falling back to Python flatten and unflatten.
Traceback (most recent call last):
  File "/mnt/workspace/weigengchen/projects/PJ2_DATA620004/resnet18/classification_training/cifar100/vitcifar/../../../tools/train_classification_model.py", line 263, in <module>
    main()
  File "/mnt/workspace/weigengchen/projects/PJ2_DATA620004/resnet18/classification_training/cifar100/vitcifar/../../../tools/train_classification_model.py", line 148, in main
    model.load_state_dict(checkpoint['model_state_dict'])
  File "/home/pai/envs/FCOS/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1604, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for DistributedDataParallel:
	size mismatch for module.cls_token: copying a param with shape torch.Size([1, 1, 192]) from checkpoint, the shape in current model is torch.Size([1, 1, 384]).
	size mismatch for module.position_encoding: copying a param with shape torch.Size([1, 5, 192]) from checkpoint, the shape in current model is torch.Size([1, 5, 384]).
	size mismatch for module.patch_embedding.conv.weight: copying a param with shape torch.Size([192, 3, 16, 16]) from checkpoint, the shape in current model is torch.Size([384, 3, 16, 16]).
	size mismatch for module.patch_embedding.conv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.0.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.0.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.0.attention.qkv_linear.weight: copying a param with shape torch.Size([576, 192]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for module.blocks.0.attention.qkv_linear.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for module.blocks.0.attention.out_linear.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for module.blocks.0.attention.out_linear.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.0.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.0.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.0.feed_forward.fc1.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for module.blocks.0.feed_forward.fc1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for module.blocks.0.feed_forward.fc2.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for module.blocks.0.feed_forward.fc2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.1.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.1.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.1.attention.qkv_linear.weight: copying a param with shape torch.Size([576, 192]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for module.blocks.1.attention.qkv_linear.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for module.blocks.1.attention.out_linear.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for module.blocks.1.attention.out_linear.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.1.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.1.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.1.feed_forward.fc1.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for module.blocks.1.feed_forward.fc1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for module.blocks.1.feed_forward.fc2.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for module.blocks.1.feed_forward.fc2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.2.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.2.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.2.attention.qkv_linear.weight: copying a param with shape torch.Size([576, 192]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for module.blocks.2.attention.qkv_linear.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for module.blocks.2.attention.out_linear.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for module.blocks.2.attention.out_linear.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.2.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.2.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.2.feed_forward.fc1.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for module.blocks.2.feed_forward.fc1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for module.blocks.2.feed_forward.fc2.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for module.blocks.2.feed_forward.fc2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.3.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.3.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.3.attention.qkv_linear.weight: copying a param with shape torch.Size([576, 192]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for module.blocks.3.attention.qkv_linear.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for module.blocks.3.attention.out_linear.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for module.blocks.3.attention.out_linear.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.3.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.3.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.3.feed_forward.fc1.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for module.blocks.3.feed_forward.fc1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for module.blocks.3.feed_forward.fc2.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for module.blocks.3.feed_forward.fc2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.4.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.4.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.4.attention.qkv_linear.weight: copying a param with shape torch.Size([576, 192]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for module.blocks.4.attention.qkv_linear.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for module.blocks.4.attention.out_linear.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for module.blocks.4.attention.out_linear.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.4.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.4.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.4.feed_forward.fc1.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for module.blocks.4.feed_forward.fc1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for module.blocks.4.feed_forward.fc2.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for module.blocks.4.feed_forward.fc2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.5.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.5.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.5.attention.qkv_linear.weight: copying a param with shape torch.Size([576, 192]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for module.blocks.5.attention.qkv_linear.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for module.blocks.5.attention.out_linear.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for module.blocks.5.attention.out_linear.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.5.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.5.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.5.feed_forward.fc1.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for module.blocks.5.feed_forward.fc1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for module.blocks.5.feed_forward.fc2.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for module.blocks.5.feed_forward.fc2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.6.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.6.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.6.attention.qkv_linear.weight: copying a param with shape torch.Size([576, 192]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for module.blocks.6.attention.qkv_linear.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for module.blocks.6.attention.out_linear.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for module.blocks.6.attention.out_linear.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.6.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.6.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.6.feed_forward.fc1.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for module.blocks.6.feed_forward.fc1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for module.blocks.6.feed_forward.fc2.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for module.blocks.6.feed_forward.fc2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.7.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.7.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.7.attention.qkv_linear.weight: copying a param with shape torch.Size([576, 192]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for module.blocks.7.attention.qkv_linear.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for module.blocks.7.attention.out_linear.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for module.blocks.7.attention.out_linear.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.7.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.7.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.7.feed_forward.fc1.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for module.blocks.7.feed_forward.fc1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for module.blocks.7.feed_forward.fc2.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for module.blocks.7.feed_forward.fc2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.8.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.8.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.8.attention.qkv_linear.weight: copying a param with shape torch.Size([576, 192]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for module.blocks.8.attention.qkv_linear.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for module.blocks.8.attention.out_linear.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for module.blocks.8.attention.out_linear.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.8.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.8.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.8.feed_forward.fc1.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for module.blocks.8.feed_forward.fc1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for module.blocks.8.feed_forward.fc2.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for module.blocks.8.feed_forward.fc2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.9.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.9.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.9.attention.qkv_linear.weight: copying a param with shape torch.Size([576, 192]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for module.blocks.9.attention.qkv_linear.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for module.blocks.9.attention.out_linear.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for module.blocks.9.attention.out_linear.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.9.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.9.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.9.feed_forward.fc1.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for module.blocks.9.feed_forward.fc1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for module.blocks.9.feed_forward.fc2.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for module.blocks.9.feed_forward.fc2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.10.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.10.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.10.attention.qkv_linear.weight: copying a param with shape torch.Size([576, 192]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for module.blocks.10.attention.qkv_linear.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for module.blocks.10.attention.out_linear.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for module.blocks.10.attention.out_linear.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.10.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.10.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.10.feed_forward.fc1.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for module.blocks.10.feed_forward.fc1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for module.blocks.10.feed_forward.fc2.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for module.blocks.10.feed_forward.fc2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.11.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.11.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.11.attention.qkv_linear.weight: copying a param with shape torch.Size([576, 192]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for module.blocks.11.attention.qkv_linear.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for module.blocks.11.attention.out_linear.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for module.blocks.11.attention.out_linear.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.11.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.11.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.blocks.11.feed_forward.fc1.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for module.blocks.11.feed_forward.fc1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for module.blocks.11.feed_forward.fc2.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for module.blocks.11.feed_forward.fc2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for module.fc.weight: copying a param with shape torch.Size([100, 192]) from checkpoint, the shape in current model is torch.Size([100, 384]).