No pretrained model file!
Dataset Size:50000
Dataset Class Num:100
Dataset Size:10000
Dataset Class Num:100
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.
Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError("No module named 'amp_C'")
Warning:  apex was installed without --cpp_ext.  Falling back to Python flatten and unflatten.
79it [00:01, 75.25it/s]
79it [00:01, 77.19it/s]

79it [00:01, 76.39it/s]
79it [00:01, 75.93it/s]
79it [00:01, 77.23it/s]
79it [00:01, 76.89it/s]
79it [00:01, 76.52it/s]

79it [00:01, 72.46it/s]

79it [00:01, 77.18it/s]
79it [00:01, 76.83it/s]
79it [00:01, 75.57it/s]
79it [00:01, 77.53it/s]
79it [00:01, 77.26it/s]
79it [00:01, 75.26it/s]
79it [00:01, 77.02it/s]
79it [00:01, 72.84it/s]
79it [00:01, 77.09it/s]

79it [00:01, 75.48it/s]
79it [00:01, 75.52it/s]
79it [00:01, 75.05it/s]
79it [00:01, 76.38it/s]

79it [00:01, 76.30it/s]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0

79it [00:01, 75.68it/s]
79it [00:01, 76.63it/s]

79it [00:01, 75.96it/s]

79it [00:01, 77.09it/s]

79it [00:01, 75.18it/s]

79it [00:01, 75.95it/s]

79it [00:01, 74.88it/s]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0
79it [00:01, 76.58it/s]

79it [00:01, 74.74it/s]

79it [00:01, 75.65it/s]
79it [00:01, 73.16it/s]
79it [00:01, 74.84it/s]
79it [00:01, 73.79it/s]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0
79it [00:01, 76.36it/s]

79it [00:01, 73.36it/s]

79it [00:01, 76.08it/s]

79it [00:01, 75.65it/s]
79it [00:01, 75.04it/s]

79it [00:01, 74.91it/s]
79it [00:01, 74.31it/s]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0
79it [00:01, 75.61it/s]
79it [00:01, 72.50it/s]

79it [00:01, 77.89it/s]

79it [00:01, 75.83it/s]

79it [00:01, 75.12it/s]
79it [00:01, 75.07it/s]

79it [00:01, 75.41it/s]

79it [00:01, 76.68it/s]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0
79it [00:01, 77.01it/s]
79it [00:01, 76.03it/s]
79it [00:01, 77.12it/s]
Traceback (most recent call last):
  File "/mnt/workspace/weigengchen/projects/PJ2_DATA620004/resnet18/classification_training/cifar100/vitcifar/../../../tools/train_classification_model.py", line 263, in <module>
    main()
  File "/mnt/workspace/weigengchen/projects/PJ2_DATA620004/resnet18/classification_training/cifar100/vitcifar/../../../tools/train_classification_model.py", line 234, in main
    torch.save(
  File "/home/pai/envs/FCOS/lib/python3.9/site-packages/torch/serialization.py", line 380, in save
    return
  File "/home/pai/envs/FCOS/lib/python3.9/site-packages/torch/serialization.py", line 214, in __exit__
    self.file_like.close()
KeyboardInterrupt